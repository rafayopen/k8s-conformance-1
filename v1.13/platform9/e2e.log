I0821 16:34:02.402967      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-507288067
I0821 16:34:02.404223      15 e2e.go:224] Starting e2e run "7b7dd514-c431-11e9-89d6-e2e196a4cdca" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1566405241 - Will randomize all specs
Will run 201 of 1946 specs

Aug 21 16:34:02.559: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:34:02.562: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 21 16:34:02.588: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 21 16:34:02.626: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 21 16:34:02.626: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Aug 21 16:34:02.626: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 21 16:34:02.636: INFO: e2e test version: v1.13.0
Aug 21 16:34:02.638: INFO: kube-apiserver version: v1.13.9
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:34:02.638: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir-wrapper
Aug 21 16:34:02.748: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:34:06.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-5gfh4" for this suite.
Aug 21 16:34:12.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:34:12.939: INFO: namespace: e2e-tests-emptydir-wrapper-5gfh4, resource: bindings, ignored listing per whitelist
Aug 21 16:34:13.104: INFO: namespace e2e-tests-emptydir-wrapper-5gfh4 deletion completed in 6.22570587s

â€¢ [SLOW TEST:10.467 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:34:13.104: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 21 16:34:13.262: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:13.262: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:13.262: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:13.270: INFO: Number of nodes with available pods: 0
Aug 21 16:34:13.271: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 16:34:14.280: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:14.280: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:14.280: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:14.286: INFO: Number of nodes with available pods: 0
Aug 21 16:34:14.286: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 16:34:15.278: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:15.278: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:15.278: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:15.291: INFO: Number of nodes with available pods: 0
Aug 21 16:34:15.291: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 16:34:16.283: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:16.283: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:16.283: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:16.289: INFO: Number of nodes with available pods: 0
Aug 21 16:34:16.289: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 16:34:17.278: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:17.278: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:17.278: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:17.284: INFO: Number of nodes with available pods: 1
Aug 21 16:34:17.284: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 16:34:18.280: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:18.280: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:18.280: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:18.286: INFO: Number of nodes with available pods: 2
Aug 21 16:34:18.286: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 16:34:19.278: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:19.278: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:19.278: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:19.285: INFO: Number of nodes with available pods: 2
Aug 21 16:34:19.285: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 16:34:20.280: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:20.280: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:20.280: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:20.287: INFO: Number of nodes with available pods: 3
Aug 21 16:34:20.287: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 21 16:34:20.315: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:20.315: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:20.315: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:20.322: INFO: Number of nodes with available pods: 2
Aug 21 16:34:20.322: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 16:34:21.330: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:21.330: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:21.330: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:21.336: INFO: Number of nodes with available pods: 2
Aug 21 16:34:21.336: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 16:34:22.331: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:22.331: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:22.331: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:22.338: INFO: Number of nodes with available pods: 2
Aug 21 16:34:22.338: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 16:34:23.329: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:23.329: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:23.329: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 16:34:23.335: INFO: Number of nodes with available pods: 3
Aug 21 16:34:23.335: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-md9rh, will wait for the garbage collector to delete the pods
Aug 21 16:34:23.417: INFO: Deleting DaemonSet.extensions daemon-set took: 12.848782ms
Aug 21 16:34:23.518: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.237303ms
Aug 21 16:35:06.824: INFO: Number of nodes with available pods: 0
Aug 21 16:35:06.824: INFO: Number of running nodes: 0, number of available pods: 0
Aug 21 16:35:06.831: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-md9rh/daemonsets","resourceVersion":"4102"},"items":null}

Aug 21 16:35:06.837: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-md9rh/pods","resourceVersion":"4102"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:35:06.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-md9rh" for this suite.
Aug 21 16:35:12.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:35:13.037: INFO: namespace: e2e-tests-daemonsets-md9rh, resource: bindings, ignored listing per whitelist
Aug 21 16:35:13.150: INFO: namespace e2e-tests-daemonsets-md9rh deletion completed in 6.279188782s

â€¢ [SLOW TEST:60.045 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:35:13.150: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-6sp4v
I0821 16:35:13.269276      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-6sp4v, replica count: 1
I0821 16:35:14.319753      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0821 16:35:15.319965      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0821 16:35:16.320185      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 21 16:35:16.435: INFO: Created: latency-svc-pwxwl
Aug 21 16:35:16.440: INFO: Got endpoints: latency-svc-pwxwl [20.269614ms]
Aug 21 16:35:16.459: INFO: Created: latency-svc-t5pfz
Aug 21 16:35:16.464: INFO: Got endpoints: latency-svc-t5pfz [24.061364ms]
Aug 21 16:35:16.475: INFO: Created: latency-svc-72znb
Aug 21 16:35:16.481: INFO: Got endpoints: latency-svc-72znb [39.86164ms]
Aug 21 16:35:16.494: INFO: Created: latency-svc-sbhkm
Aug 21 16:35:16.496: INFO: Got endpoints: latency-svc-sbhkm [55.864928ms]
Aug 21 16:35:16.509: INFO: Created: latency-svc-vs9q8
Aug 21 16:35:16.511: INFO: Got endpoints: latency-svc-vs9q8 [69.713485ms]
Aug 21 16:35:16.521: INFO: Created: latency-svc-lwbnx
Aug 21 16:35:16.524: INFO: Got endpoints: latency-svc-lwbnx [82.953268ms]
Aug 21 16:35:16.534: INFO: Created: latency-svc-vm2mm
Aug 21 16:35:16.538: INFO: Got endpoints: latency-svc-vm2mm [97.073528ms]
Aug 21 16:35:16.546: INFO: Created: latency-svc-7tnwz
Aug 21 16:35:16.562: INFO: Got endpoints: latency-svc-7tnwz [121.254536ms]
Aug 21 16:35:16.563: INFO: Created: latency-svc-lc4zd
Aug 21 16:35:16.566: INFO: Got endpoints: latency-svc-lc4zd [125.236963ms]
Aug 21 16:35:16.579: INFO: Created: latency-svc-hqpxb
Aug 21 16:35:16.583: INFO: Got endpoints: latency-svc-hqpxb [142.141919ms]
Aug 21 16:35:16.594: INFO: Created: latency-svc-vjmcj
Aug 21 16:35:16.599: INFO: Got endpoints: latency-svc-vjmcj [157.585748ms]
Aug 21 16:35:16.608: INFO: Created: latency-svc-btnww
Aug 21 16:35:16.615: INFO: Got endpoints: latency-svc-btnww [173.550237ms]
Aug 21 16:35:16.622: INFO: Created: latency-svc-w9plz
Aug 21 16:35:16.629: INFO: Got endpoints: latency-svc-w9plz [187.610334ms]
Aug 21 16:35:16.637: INFO: Created: latency-svc-2fdgc
Aug 21 16:35:16.640: INFO: Got endpoints: latency-svc-2fdgc [198.978524ms]
Aug 21 16:35:16.650: INFO: Created: latency-svc-9b4d2
Aug 21 16:35:16.654: INFO: Got endpoints: latency-svc-9b4d2 [212.995962ms]
Aug 21 16:35:16.666: INFO: Created: latency-svc-wl7pz
Aug 21 16:35:16.668: INFO: Got endpoints: latency-svc-wl7pz [226.533203ms]
Aug 21 16:35:16.677: INFO: Created: latency-svc-qt7zj
Aug 21 16:35:16.684: INFO: Got endpoints: latency-svc-qt7zj [219.212451ms]
Aug 21 16:35:16.691: INFO: Created: latency-svc-lt59f
Aug 21 16:35:16.697: INFO: Got endpoints: latency-svc-lt59f [215.986639ms]
Aug 21 16:35:16.707: INFO: Created: latency-svc-5jrsf
Aug 21 16:35:16.709: INFO: Got endpoints: latency-svc-5jrsf [212.958442ms]
Aug 21 16:35:16.722: INFO: Created: latency-svc-ztx29
Aug 21 16:35:16.728: INFO: Got endpoints: latency-svc-ztx29 [217.048624ms]
Aug 21 16:35:16.740: INFO: Created: latency-svc-2ck5f
Aug 21 16:35:16.741: INFO: Got endpoints: latency-svc-2ck5f [216.815465ms]
Aug 21 16:35:16.757: INFO: Created: latency-svc-nnm8n
Aug 21 16:35:16.762: INFO: Got endpoints: latency-svc-nnm8n [223.684333ms]
Aug 21 16:35:16.774: INFO: Created: latency-svc-rwwdm
Aug 21 16:35:16.776: INFO: Got endpoints: latency-svc-rwwdm [213.74612ms]
Aug 21 16:35:16.788: INFO: Created: latency-svc-z2m67
Aug 21 16:35:16.789: INFO: Got endpoints: latency-svc-z2m67 [222.613432ms]
Aug 21 16:35:16.801: INFO: Created: latency-svc-6jh28
Aug 21 16:35:16.808: INFO: Got endpoints: latency-svc-6jh28 [224.325682ms]
Aug 21 16:35:16.813: INFO: Created: latency-svc-29t64
Aug 21 16:35:16.818: INFO: Got endpoints: latency-svc-29t64 [219.513724ms]
Aug 21 16:35:16.829: INFO: Created: latency-svc-px46j
Aug 21 16:35:16.835: INFO: Got endpoints: latency-svc-px46j [220.409459ms]
Aug 21 16:35:16.846: INFO: Created: latency-svc-2f6qs
Aug 21 16:35:16.858: INFO: Got endpoints: latency-svc-2f6qs [229.411829ms]
Aug 21 16:35:16.864: INFO: Created: latency-svc-mwhbj
Aug 21 16:35:16.869: INFO: Got endpoints: latency-svc-mwhbj [228.293386ms]
Aug 21 16:35:16.880: INFO: Created: latency-svc-69rl6
Aug 21 16:35:16.890: INFO: Got endpoints: latency-svc-69rl6 [235.469777ms]
Aug 21 16:35:16.895: INFO: Created: latency-svc-k88jx
Aug 21 16:35:16.900: INFO: Got endpoints: latency-svc-k88jx [231.60234ms]
Aug 21 16:35:16.910: INFO: Created: latency-svc-2dwlg
Aug 21 16:35:16.914: INFO: Got endpoints: latency-svc-2dwlg [230.085141ms]
Aug 21 16:35:16.927: INFO: Created: latency-svc-nn99k
Aug 21 16:35:16.930: INFO: Got endpoints: latency-svc-nn99k [233.486594ms]
Aug 21 16:35:16.946: INFO: Created: latency-svc-s84ln
Aug 21 16:35:16.946: INFO: Got endpoints: latency-svc-s84ln [236.448283ms]
Aug 21 16:35:16.966: INFO: Created: latency-svc-n5tkc
Aug 21 16:35:16.971: INFO: Got endpoints: latency-svc-n5tkc [243.473128ms]
Aug 21 16:35:16.980: INFO: Created: latency-svc-9clhh
Aug 21 16:35:16.982: INFO: Got endpoints: latency-svc-9clhh [240.809314ms]
Aug 21 16:35:16.994: INFO: Created: latency-svc-24xps
Aug 21 16:35:16.998: INFO: Got endpoints: latency-svc-24xps [236.04725ms]
Aug 21 16:35:17.018: INFO: Created: latency-svc-fpcx2
Aug 21 16:35:17.019: INFO: Got endpoints: latency-svc-fpcx2 [243.431759ms]
Aug 21 16:35:17.031: INFO: Created: latency-svc-btkjm
Aug 21 16:35:17.035: INFO: Got endpoints: latency-svc-btkjm [246.434234ms]
Aug 21 16:35:17.047: INFO: Created: latency-svc-c47m8
Aug 21 16:35:17.057: INFO: Got endpoints: latency-svc-c47m8 [249.715985ms]
Aug 21 16:35:17.064: INFO: Created: latency-svc-llt4h
Aug 21 16:35:17.072: INFO: Got endpoints: latency-svc-llt4h [253.229151ms]
Aug 21 16:35:17.081: INFO: Created: latency-svc-xkxg4
Aug 21 16:35:17.084: INFO: Got endpoints: latency-svc-xkxg4 [248.419563ms]
Aug 21 16:35:17.099: INFO: Created: latency-svc-pfdnx
Aug 21 16:35:17.102: INFO: Got endpoints: latency-svc-pfdnx [244.066596ms]
Aug 21 16:35:17.113: INFO: Created: latency-svc-9zvfh
Aug 21 16:35:17.127: INFO: Created: latency-svc-9mr4q
Aug 21 16:35:17.145: INFO: Created: latency-svc-k2t8q
Aug 21 16:35:17.165: INFO: Got endpoints: latency-svc-9zvfh [295.995812ms]
Aug 21 16:35:17.179: INFO: Created: latency-svc-r2pbf
Aug 21 16:35:17.192: INFO: Got endpoints: latency-svc-9mr4q [302.138619ms]
Aug 21 16:35:17.195: INFO: Created: latency-svc-xm9fg
Aug 21 16:35:17.207: INFO: Created: latency-svc-mw26j
Aug 21 16:35:17.219: INFO: Created: latency-svc-m6nfx
Aug 21 16:35:17.231: INFO: Created: latency-svc-w84nl
Aug 21 16:35:17.242: INFO: Got endpoints: latency-svc-k2t8q [342.507659ms]
Aug 21 16:35:17.248: INFO: Created: latency-svc-kz6dj
Aug 21 16:35:17.263: INFO: Created: latency-svc-xl9qq
Aug 21 16:35:17.282: INFO: Created: latency-svc-4bgd5
Aug 21 16:35:17.294: INFO: Got endpoints: latency-svc-r2pbf [379.96983ms]
Aug 21 16:35:17.296: INFO: Created: latency-svc-jr5ss
Aug 21 16:35:17.313: INFO: Created: latency-svc-fqkzt
Aug 21 16:35:17.326: INFO: Created: latency-svc-jthv2
Aug 21 16:35:17.339: INFO: Created: latency-svc-nn9tp
Aug 21 16:35:17.343: INFO: Got endpoints: latency-svc-xm9fg [412.96535ms]
Aug 21 16:35:17.355: INFO: Created: latency-svc-qhz4t
Aug 21 16:35:17.364: INFO: Created: latency-svc-4s566
Aug 21 16:35:17.377: INFO: Created: latency-svc-894x9
Aug 21 16:35:17.391: INFO: Got endpoints: latency-svc-mw26j [445.513933ms]
Aug 21 16:35:17.393: INFO: Created: latency-svc-z79gt
Aug 21 16:35:17.405: INFO: Created: latency-svc-xr4x8
Aug 21 16:35:17.415: INFO: Created: latency-svc-xkpcd
Aug 21 16:35:17.441: INFO: Got endpoints: latency-svc-m6nfx [470.046033ms]
Aug 21 16:35:17.472: INFO: Created: latency-svc-ft5f7
Aug 21 16:35:17.490: INFO: Got endpoints: latency-svc-w84nl [508.221001ms]
Aug 21 16:35:17.507: INFO: Created: latency-svc-klbw6
Aug 21 16:35:17.541: INFO: Got endpoints: latency-svc-kz6dj [542.887902ms]
Aug 21 16:35:17.560: INFO: Created: latency-svc-zcjbz
Aug 21 16:35:17.590: INFO: Got endpoints: latency-svc-xl9qq [570.961595ms]
Aug 21 16:35:17.609: INFO: Created: latency-svc-sjclf
Aug 21 16:35:17.640: INFO: Got endpoints: latency-svc-4bgd5 [604.822037ms]
Aug 21 16:35:17.666: INFO: Created: latency-svc-dlf8q
Aug 21 16:35:17.691: INFO: Got endpoints: latency-svc-jr5ss [634.151158ms]
Aug 21 16:35:17.709: INFO: Created: latency-svc-mdjgw
Aug 21 16:35:17.743: INFO: Got endpoints: latency-svc-fqkzt [671.905665ms]
Aug 21 16:35:17.763: INFO: Created: latency-svc-xvtb5
Aug 21 16:35:17.792: INFO: Got endpoints: latency-svc-jthv2 [707.96066ms]
Aug 21 16:35:17.809: INFO: Created: latency-svc-t6cbd
Aug 21 16:35:17.843: INFO: Got endpoints: latency-svc-nn9tp [740.442461ms]
Aug 21 16:35:17.864: INFO: Created: latency-svc-79g2z
Aug 21 16:35:17.893: INFO: Got endpoints: latency-svc-qhz4t [727.978823ms]
Aug 21 16:35:17.911: INFO: Created: latency-svc-fzhbp
Aug 21 16:35:17.943: INFO: Got endpoints: latency-svc-4s566 [750.765766ms]
Aug 21 16:35:17.965: INFO: Created: latency-svc-s8pzv
Aug 21 16:35:17.997: INFO: Got endpoints: latency-svc-894x9 [755.163495ms]
Aug 21 16:35:18.021: INFO: Created: latency-svc-79pwb
Aug 21 16:35:18.041: INFO: Got endpoints: latency-svc-z79gt [746.985195ms]
Aug 21 16:35:18.063: INFO: Created: latency-svc-hzqbv
Aug 21 16:35:18.091: INFO: Got endpoints: latency-svc-xr4x8 [748.196241ms]
Aug 21 16:35:18.114: INFO: Created: latency-svc-czbvl
Aug 21 16:35:18.142: INFO: Got endpoints: latency-svc-xkpcd [750.552444ms]
Aug 21 16:35:18.162: INFO: Created: latency-svc-7c6rk
Aug 21 16:35:18.192: INFO: Got endpoints: latency-svc-ft5f7 [750.819646ms]
Aug 21 16:35:18.212: INFO: Created: latency-svc-hvbb8
Aug 21 16:35:18.242: INFO: Got endpoints: latency-svc-klbw6 [751.164996ms]
Aug 21 16:35:18.260: INFO: Created: latency-svc-xjljj
Aug 21 16:35:18.291: INFO: Got endpoints: latency-svc-zcjbz [749.817893ms]
Aug 21 16:35:18.335: INFO: Created: latency-svc-hqvqr
Aug 21 16:35:18.340: INFO: Got endpoints: latency-svc-sjclf [749.556136ms]
Aug 21 16:35:18.359: INFO: Created: latency-svc-d9q95
Aug 21 16:35:18.390: INFO: Got endpoints: latency-svc-dlf8q [750.1788ms]
Aug 21 16:35:18.413: INFO: Created: latency-svc-skhs8
Aug 21 16:35:18.443: INFO: Got endpoints: latency-svc-mdjgw [751.775201ms]
Aug 21 16:35:18.464: INFO: Created: latency-svc-5kh2t
Aug 21 16:35:18.491: INFO: Got endpoints: latency-svc-xvtb5 [747.423627ms]
Aug 21 16:35:18.509: INFO: Created: latency-svc-7b24d
Aug 21 16:35:18.542: INFO: Got endpoints: latency-svc-t6cbd [750.309873ms]
Aug 21 16:35:18.570: INFO: Created: latency-svc-z8td5
Aug 21 16:35:18.590: INFO: Got endpoints: latency-svc-79g2z [747.509598ms]
Aug 21 16:35:18.609: INFO: Created: latency-svc-6mh7h
Aug 21 16:35:18.640: INFO: Got endpoints: latency-svc-fzhbp [747.516616ms]
Aug 21 16:35:18.662: INFO: Created: latency-svc-pnx54
Aug 21 16:35:18.690: INFO: Got endpoints: latency-svc-s8pzv [747.257783ms]
Aug 21 16:35:18.712: INFO: Created: latency-svc-99c9k
Aug 21 16:35:18.740: INFO: Got endpoints: latency-svc-79pwb [743.026777ms]
Aug 21 16:35:18.758: INFO: Created: latency-svc-kcdf4
Aug 21 16:35:18.792: INFO: Got endpoints: latency-svc-hzqbv [751.59198ms]
Aug 21 16:35:18.811: INFO: Created: latency-svc-zwx72
Aug 21 16:35:18.842: INFO: Got endpoints: latency-svc-czbvl [750.269535ms]
Aug 21 16:35:18.858: INFO: Created: latency-svc-gt579
Aug 21 16:35:18.891: INFO: Got endpoints: latency-svc-7c6rk [748.494172ms]
Aug 21 16:35:18.908: INFO: Created: latency-svc-gjm6q
Aug 21 16:35:18.942: INFO: Got endpoints: latency-svc-hvbb8 [749.869372ms]
Aug 21 16:35:18.959: INFO: Created: latency-svc-pzl7p
Aug 21 16:35:18.991: INFO: Got endpoints: latency-svc-xjljj [749.010851ms]
Aug 21 16:35:19.013: INFO: Created: latency-svc-wkrj9
Aug 21 16:35:19.041: INFO: Got endpoints: latency-svc-hqvqr [750.076331ms]
Aug 21 16:35:19.063: INFO: Created: latency-svc-ksjml
Aug 21 16:35:19.090: INFO: Got endpoints: latency-svc-d9q95 [750.249712ms]
Aug 21 16:35:19.109: INFO: Created: latency-svc-rp9vs
Aug 21 16:35:19.141: INFO: Got endpoints: latency-svc-skhs8 [750.308352ms]
Aug 21 16:35:19.161: INFO: Created: latency-svc-vmk4j
Aug 21 16:35:19.193: INFO: Got endpoints: latency-svc-5kh2t [749.316078ms]
Aug 21 16:35:19.211: INFO: Created: latency-svc-gfm8n
Aug 21 16:35:19.242: INFO: Got endpoints: latency-svc-7b24d [750.764436ms]
Aug 21 16:35:19.262: INFO: Created: latency-svc-s9zvv
Aug 21 16:35:19.291: INFO: Got endpoints: latency-svc-z8td5 [748.878821ms]
Aug 21 16:35:19.310: INFO: Created: latency-svc-nrj8n
Aug 21 16:35:19.341: INFO: Got endpoints: latency-svc-6mh7h [750.360696ms]
Aug 21 16:35:19.359: INFO: Created: latency-svc-6bghz
Aug 21 16:35:19.390: INFO: Got endpoints: latency-svc-pnx54 [750.227681ms]
Aug 21 16:35:19.407: INFO: Created: latency-svc-sxjd8
Aug 21 16:35:19.441: INFO: Got endpoints: latency-svc-99c9k [750.920047ms]
Aug 21 16:35:19.460: INFO: Created: latency-svc-6vpwj
Aug 21 16:35:19.492: INFO: Got endpoints: latency-svc-kcdf4 [751.610055ms]
Aug 21 16:35:19.513: INFO: Created: latency-svc-tcvd6
Aug 21 16:35:19.542: INFO: Got endpoints: latency-svc-zwx72 [749.961536ms]
Aug 21 16:35:19.562: INFO: Created: latency-svc-fx6h8
Aug 21 16:35:19.593: INFO: Got endpoints: latency-svc-gt579 [751.427692ms]
Aug 21 16:35:19.612: INFO: Created: latency-svc-jtd6l
Aug 21 16:35:19.642: INFO: Got endpoints: latency-svc-gjm6q [751.132231ms]
Aug 21 16:35:19.660: INFO: Created: latency-svc-f5lmh
Aug 21 16:35:19.691: INFO: Got endpoints: latency-svc-pzl7p [748.709824ms]
Aug 21 16:35:19.714: INFO: Created: latency-svc-jq9kx
Aug 21 16:35:19.743: INFO: Got endpoints: latency-svc-wkrj9 [752.006914ms]
Aug 21 16:35:19.759: INFO: Created: latency-svc-w5f9l
Aug 21 16:35:19.791: INFO: Got endpoints: latency-svc-ksjml [750.643647ms]
Aug 21 16:35:19.812: INFO: Created: latency-svc-wnwvq
Aug 21 16:35:19.844: INFO: Got endpoints: latency-svc-rp9vs [753.727393ms]
Aug 21 16:35:19.864: INFO: Created: latency-svc-mgljv
Aug 21 16:35:19.891: INFO: Got endpoints: latency-svc-vmk4j [750.456675ms]
Aug 21 16:35:19.911: INFO: Created: latency-svc-8zk68
Aug 21 16:35:19.941: INFO: Got endpoints: latency-svc-gfm8n [748.634551ms]
Aug 21 16:35:19.966: INFO: Created: latency-svc-t8wt5
Aug 21 16:35:19.992: INFO: Got endpoints: latency-svc-s9zvv [750.365472ms]
Aug 21 16:35:20.015: INFO: Created: latency-svc-pbgv9
Aug 21 16:35:20.041: INFO: Got endpoints: latency-svc-nrj8n [750.193515ms]
Aug 21 16:35:20.107: INFO: Created: latency-svc-qsb7z
Aug 21 16:35:20.110: INFO: Got endpoints: latency-svc-6bghz [768.780219ms]
Aug 21 16:35:20.141: INFO: Created: latency-svc-w66hq
Aug 21 16:35:20.142: INFO: Got endpoints: latency-svc-sxjd8 [751.589423ms]
Aug 21 16:35:20.161: INFO: Created: latency-svc-7k7pt
Aug 21 16:35:20.190: INFO: Got endpoints: latency-svc-6vpwj [749.293351ms]
Aug 21 16:35:20.228: INFO: Created: latency-svc-9vs55
Aug 21 16:35:20.241: INFO: Got endpoints: latency-svc-tcvd6 [748.426267ms]
Aug 21 16:35:20.260: INFO: Created: latency-svc-qggmh
Aug 21 16:35:20.293: INFO: Got endpoints: latency-svc-fx6h8 [750.261632ms]
Aug 21 16:35:20.320: INFO: Created: latency-svc-8wg4f
Aug 21 16:35:20.341: INFO: Got endpoints: latency-svc-jtd6l [747.964196ms]
Aug 21 16:35:20.359: INFO: Created: latency-svc-54qm9
Aug 21 16:35:20.390: INFO: Got endpoints: latency-svc-f5lmh [748.563153ms]
Aug 21 16:35:20.408: INFO: Created: latency-svc-dq9v8
Aug 21 16:35:20.441: INFO: Got endpoints: latency-svc-jq9kx [750.560937ms]
Aug 21 16:35:20.456: INFO: Created: latency-svc-whdwc
Aug 21 16:35:20.492: INFO: Got endpoints: latency-svc-w5f9l [749.159327ms]
Aug 21 16:35:20.513: INFO: Created: latency-svc-zkpr4
Aug 21 16:35:20.540: INFO: Got endpoints: latency-svc-wnwvq [749.051651ms]
Aug 21 16:35:20.557: INFO: Created: latency-svc-mwxrz
Aug 21 16:35:20.590: INFO: Got endpoints: latency-svc-mgljv [746.33298ms]
Aug 21 16:35:20.608: INFO: Created: latency-svc-vgcgg
Aug 21 16:35:20.648: INFO: Got endpoints: latency-svc-8zk68 [756.318192ms]
Aug 21 16:35:20.665: INFO: Created: latency-svc-hzd7c
Aug 21 16:35:20.694: INFO: Got endpoints: latency-svc-t8wt5 [752.86156ms]
Aug 21 16:35:20.714: INFO: Created: latency-svc-5rdfj
Aug 21 16:35:20.742: INFO: Got endpoints: latency-svc-pbgv9 [749.730505ms]
Aug 21 16:35:20.759: INFO: Created: latency-svc-kchb8
Aug 21 16:35:20.791: INFO: Got endpoints: latency-svc-qsb7z [749.835617ms]
Aug 21 16:35:20.809: INFO: Created: latency-svc-6kl2g
Aug 21 16:35:20.840: INFO: Got endpoints: latency-svc-w66hq [730.730729ms]
Aug 21 16:35:20.861: INFO: Created: latency-svc-chptc
Aug 21 16:35:20.890: INFO: Got endpoints: latency-svc-7k7pt [748.042617ms]
Aug 21 16:35:20.910: INFO: Created: latency-svc-hjpcv
Aug 21 16:35:20.941: INFO: Got endpoints: latency-svc-9vs55 [750.06161ms]
Aug 21 16:35:20.966: INFO: Created: latency-svc-vxw4m
Aug 21 16:35:20.990: INFO: Got endpoints: latency-svc-qggmh [749.501714ms]
Aug 21 16:35:21.008: INFO: Created: latency-svc-jrsq8
Aug 21 16:35:21.041: INFO: Got endpoints: latency-svc-8wg4f [747.923945ms]
Aug 21 16:35:21.059: INFO: Created: latency-svc-7mmsf
Aug 21 16:35:21.094: INFO: Got endpoints: latency-svc-54qm9 [752.813192ms]
Aug 21 16:35:21.113: INFO: Created: latency-svc-pcwnv
Aug 21 16:35:21.143: INFO: Got endpoints: latency-svc-dq9v8 [752.181207ms]
Aug 21 16:35:21.167: INFO: Created: latency-svc-n2sfk
Aug 21 16:35:21.191: INFO: Got endpoints: latency-svc-whdwc [749.626988ms]
Aug 21 16:35:21.209: INFO: Created: latency-svc-rvnht
Aug 21 16:35:21.241: INFO: Got endpoints: latency-svc-zkpr4 [749.492193ms]
Aug 21 16:35:21.260: INFO: Created: latency-svc-7ds7h
Aug 21 16:35:21.290: INFO: Got endpoints: latency-svc-mwxrz [749.994163ms]
Aug 21 16:35:21.308: INFO: Created: latency-svc-6rcxz
Aug 21 16:35:21.341: INFO: Got endpoints: latency-svc-vgcgg [750.736102ms]
Aug 21 16:35:21.357: INFO: Created: latency-svc-glgdq
Aug 21 16:35:21.391: INFO: Got endpoints: latency-svc-hzd7c [743.250939ms]
Aug 21 16:35:21.409: INFO: Created: latency-svc-w4gjh
Aug 21 16:35:21.441: INFO: Got endpoints: latency-svc-5rdfj [746.723507ms]
Aug 21 16:35:21.457: INFO: Created: latency-svc-m8xdm
Aug 21 16:35:21.491: INFO: Got endpoints: latency-svc-kchb8 [749.507521ms]
Aug 21 16:35:21.513: INFO: Created: latency-svc-5vbnh
Aug 21 16:35:21.542: INFO: Got endpoints: latency-svc-6kl2g [750.512422ms]
Aug 21 16:35:21.565: INFO: Created: latency-svc-rbjfz
Aug 21 16:35:21.593: INFO: Got endpoints: latency-svc-chptc [752.59224ms]
Aug 21 16:35:21.619: INFO: Created: latency-svc-7mgjk
Aug 21 16:35:21.641: INFO: Got endpoints: latency-svc-hjpcv [750.616488ms]
Aug 21 16:35:21.662: INFO: Created: latency-svc-w2jjv
Aug 21 16:35:21.691: INFO: Got endpoints: latency-svc-vxw4m [750.339616ms]
Aug 21 16:35:21.709: INFO: Created: latency-svc-jzzj4
Aug 21 16:35:21.742: INFO: Got endpoints: latency-svc-jrsq8 [751.876721ms]
Aug 21 16:35:21.760: INFO: Created: latency-svc-nmlvx
Aug 21 16:35:21.790: INFO: Got endpoints: latency-svc-7mmsf [749.568959ms]
Aug 21 16:35:21.807: INFO: Created: latency-svc-dmflj
Aug 21 16:35:21.842: INFO: Got endpoints: latency-svc-pcwnv [748.100078ms]
Aug 21 16:35:21.859: INFO: Created: latency-svc-x76q5
Aug 21 16:35:21.891: INFO: Got endpoints: latency-svc-n2sfk [748.216056ms]
Aug 21 16:35:21.908: INFO: Created: latency-svc-7qwfm
Aug 21 16:35:21.940: INFO: Got endpoints: latency-svc-rvnht [749.580674ms]
Aug 21 16:35:21.984: INFO: Created: latency-svc-djvhw
Aug 21 16:35:21.990: INFO: Got endpoints: latency-svc-7ds7h [748.709955ms]
Aug 21 16:35:22.007: INFO: Created: latency-svc-pd7bn
Aug 21 16:35:22.045: INFO: Got endpoints: latency-svc-6rcxz [754.258767ms]
Aug 21 16:35:22.064: INFO: Created: latency-svc-hdfsx
Aug 21 16:35:22.091: INFO: Got endpoints: latency-svc-glgdq [749.593905ms]
Aug 21 16:35:22.115: INFO: Created: latency-svc-2456x
Aug 21 16:35:22.141: INFO: Got endpoints: latency-svc-w4gjh [749.69145ms]
Aug 21 16:35:22.157: INFO: Created: latency-svc-tz2vf
Aug 21 16:35:22.191: INFO: Got endpoints: latency-svc-m8xdm [749.804308ms]
Aug 21 16:35:22.207: INFO: Created: latency-svc-p6wpv
Aug 21 16:35:22.241: INFO: Got endpoints: latency-svc-5vbnh [749.553634ms]
Aug 21 16:35:22.258: INFO: Created: latency-svc-mpjm7
Aug 21 16:35:22.291: INFO: Got endpoints: latency-svc-rbjfz [749.041723ms]
Aug 21 16:35:22.311: INFO: Created: latency-svc-5jp9v
Aug 21 16:35:22.341: INFO: Got endpoints: latency-svc-7mgjk [747.930091ms]
Aug 21 16:35:22.360: INFO: Created: latency-svc-vcn9t
Aug 21 16:35:22.391: INFO: Got endpoints: latency-svc-w2jjv [750.314201ms]
Aug 21 16:35:22.410: INFO: Created: latency-svc-hbgk4
Aug 21 16:35:22.441: INFO: Got endpoints: latency-svc-jzzj4 [750.465075ms]
Aug 21 16:35:22.459: INFO: Created: latency-svc-pszx2
Aug 21 16:35:22.491: INFO: Got endpoints: latency-svc-nmlvx [749.416917ms]
Aug 21 16:35:22.522: INFO: Created: latency-svc-fjxcs
Aug 21 16:35:22.541: INFO: Got endpoints: latency-svc-dmflj [750.841492ms]
Aug 21 16:35:22.564: INFO: Created: latency-svc-cs8g5
Aug 21 16:35:22.591: INFO: Got endpoints: latency-svc-x76q5 [749.140736ms]
Aug 21 16:35:22.611: INFO: Created: latency-svc-jm77d
Aug 21 16:35:22.641: INFO: Got endpoints: latency-svc-7qwfm [749.841886ms]
Aug 21 16:35:22.662: INFO: Created: latency-svc-zrh2s
Aug 21 16:35:22.691: INFO: Got endpoints: latency-svc-djvhw [750.102415ms]
Aug 21 16:35:22.711: INFO: Created: latency-svc-xm48g
Aug 21 16:35:22.742: INFO: Got endpoints: latency-svc-pd7bn [752.140705ms]
Aug 21 16:35:22.759: INFO: Created: latency-svc-6qvmn
Aug 21 16:35:22.794: INFO: Got endpoints: latency-svc-hdfsx [749.746805ms]
Aug 21 16:35:22.816: INFO: Created: latency-svc-ck2xg
Aug 21 16:35:22.841: INFO: Got endpoints: latency-svc-2456x [749.938961ms]
Aug 21 16:35:22.863: INFO: Created: latency-svc-98xrc
Aug 21 16:35:22.891: INFO: Got endpoints: latency-svc-tz2vf [750.321006ms]
Aug 21 16:35:22.912: INFO: Created: latency-svc-wpqt5
Aug 21 16:35:22.941: INFO: Got endpoints: latency-svc-p6wpv [750.110221ms]
Aug 21 16:35:22.960: INFO: Created: latency-svc-6npkf
Aug 21 16:35:22.991: INFO: Got endpoints: latency-svc-mpjm7 [749.594685ms]
Aug 21 16:35:23.009: INFO: Created: latency-svc-wwwwc
Aug 21 16:35:23.052: INFO: Got endpoints: latency-svc-5jp9v [761.597937ms]
Aug 21 16:35:23.071: INFO: Created: latency-svc-4msjl
Aug 21 16:35:23.090: INFO: Got endpoints: latency-svc-vcn9t [749.154902ms]
Aug 21 16:35:23.107: INFO: Created: latency-svc-68hhg
Aug 21 16:35:23.141: INFO: Got endpoints: latency-svc-hbgk4 [750.311738ms]
Aug 21 16:35:23.161: INFO: Created: latency-svc-z9chd
Aug 21 16:35:23.192: INFO: Got endpoints: latency-svc-pszx2 [750.439382ms]
Aug 21 16:35:23.213: INFO: Created: latency-svc-5j88l
Aug 21 16:35:23.243: INFO: Got endpoints: latency-svc-fjxcs [751.491186ms]
Aug 21 16:35:23.260: INFO: Created: latency-svc-zvq5l
Aug 21 16:35:23.299: INFO: Got endpoints: latency-svc-cs8g5 [757.591234ms]
Aug 21 16:35:23.317: INFO: Created: latency-svc-v5jfm
Aug 21 16:35:23.342: INFO: Got endpoints: latency-svc-jm77d [750.509643ms]
Aug 21 16:35:23.366: INFO: Created: latency-svc-m6bjj
Aug 21 16:35:23.390: INFO: Got endpoints: latency-svc-zrh2s [749.567425ms]
Aug 21 16:35:23.409: INFO: Created: latency-svc-sssqv
Aug 21 16:35:23.440: INFO: Got endpoints: latency-svc-xm48g [749.598073ms]
Aug 21 16:35:23.458: INFO: Created: latency-svc-6vzsp
Aug 21 16:35:23.498: INFO: Got endpoints: latency-svc-6qvmn [755.278129ms]
Aug 21 16:35:23.518: INFO: Created: latency-svc-vn6vt
Aug 21 16:35:23.544: INFO: Got endpoints: latency-svc-ck2xg [749.661097ms]
Aug 21 16:35:23.568: INFO: Created: latency-svc-774pc
Aug 21 16:35:23.591: INFO: Got endpoints: latency-svc-98xrc [750.050291ms]
Aug 21 16:35:23.612: INFO: Created: latency-svc-zhsqt
Aug 21 16:35:23.643: INFO: Got endpoints: latency-svc-wpqt5 [752.451982ms]
Aug 21 16:35:23.660: INFO: Created: latency-svc-rqcx4
Aug 21 16:35:23.691: INFO: Got endpoints: latency-svc-6npkf [749.647151ms]
Aug 21 16:35:23.711: INFO: Created: latency-svc-rhhhp
Aug 21 16:35:23.741: INFO: Got endpoints: latency-svc-wwwwc [750.278967ms]
Aug 21 16:35:23.763: INFO: Created: latency-svc-6t8mb
Aug 21 16:35:23.791: INFO: Got endpoints: latency-svc-4msjl [738.508496ms]
Aug 21 16:35:23.809: INFO: Created: latency-svc-t9ndf
Aug 21 16:35:23.841: INFO: Got endpoints: latency-svc-68hhg [751.238206ms]
Aug 21 16:35:23.861: INFO: Created: latency-svc-qqkhf
Aug 21 16:35:23.890: INFO: Got endpoints: latency-svc-z9chd [748.783171ms]
Aug 21 16:35:23.906: INFO: Created: latency-svc-9j7hc
Aug 21 16:35:23.941: INFO: Got endpoints: latency-svc-5j88l [748.717975ms]
Aug 21 16:35:23.965: INFO: Created: latency-svc-8d4fh
Aug 21 16:35:23.991: INFO: Got endpoints: latency-svc-zvq5l [747.688865ms]
Aug 21 16:35:24.011: INFO: Created: latency-svc-fqv5x
Aug 21 16:35:24.041: INFO: Got endpoints: latency-svc-v5jfm [742.433213ms]
Aug 21 16:35:24.062: INFO: Created: latency-svc-l5c5p
Aug 21 16:35:24.091: INFO: Got endpoints: latency-svc-m6bjj [749.16839ms]
Aug 21 16:35:24.114: INFO: Created: latency-svc-b27cd
Aug 21 16:35:24.142: INFO: Got endpoints: latency-svc-sssqv [751.485097ms]
Aug 21 16:35:24.161: INFO: Created: latency-svc-62p7w
Aug 21 16:35:24.191: INFO: Got endpoints: latency-svc-6vzsp [750.942819ms]
Aug 21 16:35:24.209: INFO: Created: latency-svc-c2df5
Aug 21 16:35:24.241: INFO: Got endpoints: latency-svc-vn6vt [743.101821ms]
Aug 21 16:35:24.257: INFO: Created: latency-svc-l7t5d
Aug 21 16:35:24.291: INFO: Got endpoints: latency-svc-774pc [746.799225ms]
Aug 21 16:35:24.343: INFO: Got endpoints: latency-svc-zhsqt [752.25995ms]
Aug 21 16:35:24.391: INFO: Got endpoints: latency-svc-rqcx4 [747.109482ms]
Aug 21 16:35:24.451: INFO: Got endpoints: latency-svc-rhhhp [760.074784ms]
Aug 21 16:35:24.494: INFO: Got endpoints: latency-svc-6t8mb [753.023244ms]
Aug 21 16:35:24.541: INFO: Got endpoints: latency-svc-t9ndf [750.492917ms]
Aug 21 16:35:24.591: INFO: Got endpoints: latency-svc-qqkhf [749.169379ms]
Aug 21 16:35:24.641: INFO: Got endpoints: latency-svc-9j7hc [751.031758ms]
Aug 21 16:35:24.691: INFO: Got endpoints: latency-svc-8d4fh [750.803539ms]
Aug 21 16:35:24.741: INFO: Got endpoints: latency-svc-fqv5x [750.618752ms]
Aug 21 16:35:24.792: INFO: Got endpoints: latency-svc-l5c5p [750.691897ms]
Aug 21 16:35:24.842: INFO: Got endpoints: latency-svc-b27cd [751.066361ms]
Aug 21 16:35:24.890: INFO: Got endpoints: latency-svc-62p7w [748.702668ms]
Aug 21 16:35:24.941: INFO: Got endpoints: latency-svc-c2df5 [749.385471ms]
Aug 21 16:35:24.991: INFO: Got endpoints: latency-svc-l7t5d [750.639038ms]
Aug 21 16:35:24.991: INFO: Latencies: [24.061364ms 39.86164ms 55.864928ms 69.713485ms 82.953268ms 97.073528ms 121.254536ms 125.236963ms 142.141919ms 157.585748ms 173.550237ms 187.610334ms 198.978524ms 212.958442ms 212.995962ms 213.74612ms 215.986639ms 216.815465ms 217.048624ms 219.212451ms 219.513724ms 220.409459ms 222.613432ms 223.684333ms 224.325682ms 226.533203ms 228.293386ms 229.411829ms 230.085141ms 231.60234ms 233.486594ms 235.469777ms 236.04725ms 236.448283ms 240.809314ms 243.431759ms 243.473128ms 244.066596ms 246.434234ms 248.419563ms 249.715985ms 253.229151ms 295.995812ms 302.138619ms 342.507659ms 379.96983ms 412.96535ms 445.513933ms 470.046033ms 508.221001ms 542.887902ms 570.961595ms 604.822037ms 634.151158ms 671.905665ms 707.96066ms 727.978823ms 730.730729ms 738.508496ms 740.442461ms 742.433213ms 743.026777ms 743.101821ms 743.250939ms 746.33298ms 746.723507ms 746.799225ms 746.985195ms 747.109482ms 747.257783ms 747.423627ms 747.509598ms 747.516616ms 747.688865ms 747.923945ms 747.930091ms 747.964196ms 748.042617ms 748.100078ms 748.196241ms 748.216056ms 748.426267ms 748.494172ms 748.563153ms 748.634551ms 748.702668ms 748.709824ms 748.709955ms 748.717975ms 748.783171ms 748.878821ms 749.010851ms 749.041723ms 749.051651ms 749.140736ms 749.154902ms 749.159327ms 749.16839ms 749.169379ms 749.293351ms 749.316078ms 749.385471ms 749.416917ms 749.492193ms 749.501714ms 749.507521ms 749.553634ms 749.556136ms 749.567425ms 749.568959ms 749.580674ms 749.593905ms 749.594685ms 749.598073ms 749.626988ms 749.647151ms 749.661097ms 749.69145ms 749.730505ms 749.746805ms 749.804308ms 749.817893ms 749.835617ms 749.841886ms 749.869372ms 749.938961ms 749.961536ms 749.994163ms 750.050291ms 750.06161ms 750.076331ms 750.102415ms 750.110221ms 750.1788ms 750.193515ms 750.227681ms 750.249712ms 750.261632ms 750.269535ms 750.278967ms 750.308352ms 750.309873ms 750.311738ms 750.314201ms 750.321006ms 750.339616ms 750.360696ms 750.365472ms 750.439382ms 750.456675ms 750.465075ms 750.492917ms 750.509643ms 750.512422ms 750.552444ms 750.560937ms 750.616488ms 750.618752ms 750.639038ms 750.643647ms 750.691897ms 750.736102ms 750.764436ms 750.765766ms 750.803539ms 750.819646ms 750.841492ms 750.920047ms 750.942819ms 751.031758ms 751.066361ms 751.132231ms 751.164996ms 751.238206ms 751.427692ms 751.485097ms 751.491186ms 751.589423ms 751.59198ms 751.610055ms 751.775201ms 751.876721ms 752.006914ms 752.140705ms 752.181207ms 752.25995ms 752.451982ms 752.59224ms 752.813192ms 752.86156ms 753.023244ms 753.727393ms 754.258767ms 755.163495ms 755.278129ms 756.318192ms 757.591234ms 760.074784ms 761.597937ms 768.780219ms]
Aug 21 16:35:24.992: INFO: 50 %ile: 749.316078ms
Aug 21 16:35:24.992: INFO: 90 %ile: 751.775201ms
Aug 21 16:35:24.992: INFO: 99 %ile: 761.597937ms
Aug 21 16:35:24.992: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:35:24.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-6sp4v" for this suite.
Aug 21 16:35:37.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:35:37.179: INFO: namespace: e2e-tests-svc-latency-6sp4v, resource: bindings, ignored listing per whitelist
Aug 21 16:35:37.226: INFO: namespace e2e-tests-svc-latency-6sp4v deletion completed in 12.22626701s

â€¢ [SLOW TEST:24.076 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:35:37.226: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:35:37.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-mjt88" for this suite.
Aug 21 16:35:59.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:35:59.427: INFO: namespace: e2e-tests-kubelet-test-mjt88, resource: bindings, ignored listing per whitelist
Aug 21 16:35:59.558: INFO: namespace e2e-tests-kubelet-test-mjt88 deletion completed in 22.218788726s

â€¢ [SLOW TEST:22.332 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:35:59.558: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0821 16:36:29.718644      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 16:36:29.718: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:36:29.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pqvlb" for this suite.
Aug 21 16:36:35.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:36:35.831: INFO: namespace: e2e-tests-gc-pqvlb, resource: bindings, ignored listing per whitelist
Aug 21 16:36:35.931: INFO: namespace e2e-tests-gc-pqvlb deletion completed in 6.206151425s

â€¢ [SLOW TEST:36.373 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:36:35.931: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Aug 21 16:36:36.018: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 21 16:36:36.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:36:36.764: INFO: stderr: ""
Aug 21 16:36:36.764: INFO: stdout: "service/redis-slave created\n"
Aug 21 16:36:36.764: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 21 16:36:36.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:36:36.939: INFO: stderr: ""
Aug 21 16:36:36.939: INFO: stdout: "service/redis-master created\n"
Aug 21 16:36:36.939: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 21 16:36:36.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:36:37.160: INFO: stderr: ""
Aug 21 16:36:37.160: INFO: stdout: "service/frontend created\n"
Aug 21 16:36:37.160: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 21 16:36:37.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:36:37.317: INFO: stderr: ""
Aug 21 16:36:37.317: INFO: stdout: "deployment.extensions/frontend created\n"
Aug 21 16:36:37.317: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 21 16:36:37.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:36:37.623: INFO: stderr: ""
Aug 21 16:36:37.624: INFO: stdout: "deployment.extensions/redis-master created\n"
Aug 21 16:36:37.624: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 21 16:36:37.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:36:37.809: INFO: stderr: ""
Aug 21 16:36:37.809: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Aug 21 16:36:37.809: INFO: Waiting for all frontend pods to be Running.
Aug 21 16:36:57.860: INFO: Waiting for frontend to serve content.
Aug 21 16:36:58.899: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Aug 21 16:37:03.933: INFO: Trying to add a new entry to the guestbook.
Aug 21 16:37:03.988: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 21 16:37:04.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:37:04.118: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 16:37:04.118: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 21 16:37:04.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:37:04.227: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 16:37:04.227: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 21 16:37:04.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:37:04.338: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 16:37:04.338: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 21 16:37:04.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:37:04.424: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 16:37:04.424: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 21 16:37:04.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:37:04.509: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 16:37:04.509: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 21 16:37:04.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4ccfj'
Aug 21 16:37:04.590: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 16:37:04.590: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:37:04.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4ccfj" for this suite.
Aug 21 16:39:08.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:39:08.714: INFO: namespace: e2e-tests-kubectl-4ccfj, resource: bindings, ignored listing per whitelist
Aug 21 16:39:08.803: INFO: namespace e2e-tests-kubectl-4ccfj deletion completed in 2m4.203220743s

â€¢ [SLOW TEST:152.872 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:39:08.804: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 21 16:39:08.897: INFO: Waiting up to 5m0s for pod "pod-32a89f38-c432-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-r9xwh" to be "success or failure"
Aug 21 16:39:08.903: INFO: Pod "pod-32a89f38-c432-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 5.80592ms
Aug 21 16:39:10.909: INFO: Pod "pod-32a89f38-c432-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012186182s
Aug 21 16:39:12.916: INFO: Pod "pod-32a89f38-c432-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018662871s
STEP: Saw pod success
Aug 21 16:39:12.916: INFO: Pod "pod-32a89f38-c432-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:39:12.921: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-32a89f38-c432-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 16:39:12.965: INFO: Waiting for pod pod-32a89f38-c432-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:39:12.971: INFO: Pod pod-32a89f38-c432-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:39:12.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r9xwh" for this suite.
Aug 21 16:39:18.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:39:19.070: INFO: namespace: e2e-tests-emptydir-r9xwh, resource: bindings, ignored listing per whitelist
Aug 21 16:39:19.177: INFO: namespace e2e-tests-emptydir-r9xwh deletion completed in 6.199022643s

â€¢ [SLOW TEST:10.373 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:39:19.177: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 16:39:19.323: INFO: Waiting up to 5m0s for pod "downwardapi-volume-38df5707-c432-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-7t5rm" to be "success or failure"
Aug 21 16:39:19.331: INFO: Pod "downwardapi-volume-38df5707-c432-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 8.281779ms
Aug 21 16:39:21.337: INFO: Pod "downwardapi-volume-38df5707-c432-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014733507s
Aug 21 16:39:23.344: INFO: Pod "downwardapi-volume-38df5707-c432-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021817769s
STEP: Saw pod success
Aug 21 16:39:23.344: INFO: Pod "downwardapi-volume-38df5707-c432-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:39:23.350: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downwardapi-volume-38df5707-c432-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 16:39:23.390: INFO: Waiting for pod downwardapi-volume-38df5707-c432-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:39:23.396: INFO: Pod downwardapi-volume-38df5707-c432-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:39:23.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7t5rm" for this suite.
Aug 21 16:39:29.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:39:29.440: INFO: namespace: e2e-tests-projected-7t5rm, resource: bindings, ignored listing per whitelist
Aug 21 16:39:29.605: INFO: namespace e2e-tests-projected-7t5rm deletion completed in 6.201669474s

â€¢ [SLOW TEST:10.428 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:39:29.605: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3f0fbaee-c432-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 16:39:29.712: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3f11369a-c432-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-6n2fn" to be "success or failure"
Aug 21 16:39:29.718: INFO: Pod "pod-projected-configmaps-3f11369a-c432-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.262573ms
Aug 21 16:39:31.725: INFO: Pod "pod-projected-configmaps-3f11369a-c432-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01271955s
Aug 21 16:39:33.731: INFO: Pod "pod-projected-configmaps-3f11369a-c432-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019109733s
STEP: Saw pod success
Aug 21 16:39:33.731: INFO: Pod "pod-projected-configmaps-3f11369a-c432-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:39:33.736: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-projected-configmaps-3f11369a-c432-11e9-89d6-e2e196a4cdca container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 16:39:33.767: INFO: Waiting for pod pod-projected-configmaps-3f11369a-c432-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:39:33.773: INFO: Pod pod-projected-configmaps-3f11369a-c432-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:39:33.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6n2fn" for this suite.
Aug 21 16:39:39.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:39:39.881: INFO: namespace: e2e-tests-projected-6n2fn, resource: bindings, ignored listing per whitelist
Aug 21 16:39:39.999: INFO: namespace e2e-tests-projected-6n2fn deletion completed in 6.22000193s

â€¢ [SLOW TEST:10.395 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:39:39.999: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-mm6mm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 21 16:39:40.089: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 21 16:40:10.251: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.20.3.10 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mm6mm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:10.251: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:11.419: INFO: Found all expected endpoints: [netserver-0]
Aug 21 16:40:11.429: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.20.35.7 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mm6mm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:11.429: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:12.580: INFO: Found all expected endpoints: [netserver-1]
Aug 21 16:40:12.587: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.20.12.9 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mm6mm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:12.587: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:13.744: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:40:13.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-mm6mm" for this suite.
Aug 21 16:40:35.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:40:35.860: INFO: namespace: e2e-tests-pod-network-test-mm6mm, resource: bindings, ignored listing per whitelist
Aug 21 16:40:35.980: INFO: namespace e2e-tests-pod-network-test-mm6mm deletion completed in 22.2271306s

â€¢ [SLOW TEST:55.980 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:40:35.980: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 21 16:40:44.120: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-phmbg PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:44.120: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:44.331: INFO: Exec stderr: ""
Aug 21 16:40:44.331: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-phmbg PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:44.331: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:44.506: INFO: Exec stderr: ""
Aug 21 16:40:44.506: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-phmbg PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:44.506: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:44.670: INFO: Exec stderr: ""
Aug 21 16:40:44.670: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-phmbg PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:44.670: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:44.839: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 21 16:40:44.839: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-phmbg PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:44.839: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:44.982: INFO: Exec stderr: ""
Aug 21 16:40:44.982: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-phmbg PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:44.982: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:45.151: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 21 16:40:45.151: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-phmbg PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:45.151: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:45.310: INFO: Exec stderr: ""
Aug 21 16:40:45.310: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-phmbg PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:45.310: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:45.471: INFO: Exec stderr: ""
Aug 21 16:40:45.471: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-phmbg PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:45.471: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:45.625: INFO: Exec stderr: ""
Aug 21 16:40:45.625: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-phmbg PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 16:40:45.625: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 16:40:45.765: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:40:45.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-phmbg" for this suite.
Aug 21 16:41:31.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:41:31.959: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-phmbg, resource: bindings, ignored listing per whitelist
Aug 21 16:41:31.969: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-phmbg deletion completed in 46.19699877s

â€¢ [SLOW TEST:55.990 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:41:31.969: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:41:38.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-btx26" for this suite.
Aug 21 16:42:18.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:42:18.180: INFO: namespace: e2e-tests-kubelet-test-btx26, resource: bindings, ignored listing per whitelist
Aug 21 16:42:18.334: INFO: namespace e2e-tests-kubelet-test-btx26 deletion completed in 40.230787762s

â€¢ [SLOW TEST:46.364 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:42:18.334: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 21 16:42:28.485: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:28.491: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:30.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:30.497: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:32.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:32.498: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:34.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:34.497: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:36.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:36.497: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:38.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:38.497: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:40.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:40.497: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:42.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:42.497: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:44.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:44.497: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:46.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:46.501: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:48.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:48.498: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:50.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:50.497: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:52.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:52.498: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:54.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:54.497: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:56.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:56.497: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 21 16:42:58.491: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 21 16:42:58.497: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:42:58.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-8p729" for this suite.
Aug 21 16:43:20.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:43:20.597: INFO: namespace: e2e-tests-container-lifecycle-hook-8p729, resource: bindings, ignored listing per whitelist
Aug 21 16:43:20.726: INFO: namespace e2e-tests-container-lifecycle-hook-8p729 deletion completed in 22.209466483s

â€¢ [SLOW TEST:62.392 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:43:20.726: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 21 16:43:28.879: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 21 16:43:28.885: INFO: Pod pod-with-prestop-http-hook still exists
Aug 21 16:43:30.885: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 21 16:43:30.892: INFO: Pod pod-with-prestop-http-hook still exists
Aug 21 16:43:32.885: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 21 16:43:32.891: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:43:32.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pvv8n" for this suite.
Aug 21 16:43:54.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:43:55.099: INFO: namespace: e2e-tests-container-lifecycle-hook-pvv8n, resource: bindings, ignored listing per whitelist
Aug 21 16:43:55.126: INFO: namespace e2e-tests-container-lifecycle-hook-pvv8n deletion completed in 22.214662646s

â€¢ [SLOW TEST:34.400 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:43:55.126: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Aug 21 16:43:55.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 api-versions'
Aug 21 16:43:55.278: INFO: stderr: ""
Aug 21 16:43:55.278: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:43:55.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-55nxh" for this suite.
Aug 21 16:44:01.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:44:01.336: INFO: namespace: e2e-tests-kubectl-55nxh, resource: bindings, ignored listing per whitelist
Aug 21 16:44:01.503: INFO: namespace e2e-tests-kubectl-55nxh deletion completed in 6.217623444s

â€¢ [SLOW TEST:6.377 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:44:01.503: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 21 16:44:01.588: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:44:06.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rg4lm" for this suite.
Aug 21 16:44:13.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:44:13.064: INFO: namespace: e2e-tests-init-container-rg4lm, resource: bindings, ignored listing per whitelist
Aug 21 16:44:13.213: INFO: namespace e2e-tests-init-container-rg4lm deletion completed in 6.216533167s

â€¢ [SLOW TEST:11.710 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:44:13.213: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 21 16:44:13.616: INFO: Pod name wrapped-volume-race-e847dd37-c432-11e9-89d6-e2e196a4cdca: Found 0 pods out of 5
Aug 21 16:44:18.625: INFO: Pod name wrapped-volume-race-e847dd37-c432-11e9-89d6-e2e196a4cdca: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e847dd37-c432-11e9-89d6-e2e196a4cdca in namespace e2e-tests-emptydir-wrapper-qxch7, will wait for the garbage collector to delete the pods
Aug 21 16:46:08.741: INFO: Deleting ReplicationController wrapped-volume-race-e847dd37-c432-11e9-89d6-e2e196a4cdca took: 15.125514ms
Aug 21 16:46:08.842: INFO: Terminating ReplicationController wrapped-volume-race-e847dd37-c432-11e9-89d6-e2e196a4cdca pods took: 100.222635ms
STEP: Creating RC which spawns configmap-volume pods
Aug 21 16:46:49.470: INFO: Pod name wrapped-volume-race-452c6190-c433-11e9-89d6-e2e196a4cdca: Found 0 pods out of 5
Aug 21 16:46:54.479: INFO: Pod name wrapped-volume-race-452c6190-c433-11e9-89d6-e2e196a4cdca: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-452c6190-c433-11e9-89d6-e2e196a4cdca in namespace e2e-tests-emptydir-wrapper-qxch7, will wait for the garbage collector to delete the pods
Aug 21 16:48:40.602: INFO: Deleting ReplicationController wrapped-volume-race-452c6190-c433-11e9-89d6-e2e196a4cdca took: 15.810722ms
Aug 21 16:48:40.703: INFO: Terminating ReplicationController wrapped-volume-race-452c6190-c433-11e9-89d6-e2e196a4cdca pods took: 100.233549ms
STEP: Creating RC which spawns configmap-volume pods
Aug 21 16:49:20.333: INFO: Pod name wrapped-volume-race-9f17ef77-c433-11e9-89d6-e2e196a4cdca: Found 0 pods out of 5
Aug 21 16:49:25.346: INFO: Pod name wrapped-volume-race-9f17ef77-c433-11e9-89d6-e2e196a4cdca: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9f17ef77-c433-11e9-89d6-e2e196a4cdca in namespace e2e-tests-emptydir-wrapper-qxch7, will wait for the garbage collector to delete the pods
Aug 21 16:51:07.456: INFO: Deleting ReplicationController wrapped-volume-race-9f17ef77-c433-11e9-89d6-e2e196a4cdca took: 16.259215ms
Aug 21 16:51:07.556: INFO: Terminating ReplicationController wrapped-volume-race-9f17ef77-c433-11e9-89d6-e2e196a4cdca pods took: 100.225485ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:51:42.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-qxch7" for this suite.
Aug 21 16:51:48.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:51:48.514: INFO: namespace: e2e-tests-emptydir-wrapper-qxch7, resource: bindings, ignored listing per whitelist
Aug 21 16:51:48.589: INFO: namespace e2e-tests-emptydir-wrapper-qxch7 deletion completed in 6.21491084s

â€¢ [SLOW TEST:455.376 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:51:48.589: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 16:51:48.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-m9p7t'
Aug 21 16:51:48.930: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 21 16:51:48.930: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Aug 21 16:51:50.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-m9p7t'
Aug 21 16:51:51.062: INFO: stderr: ""
Aug 21 16:51:51.062: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:51:51.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m9p7t" for this suite.
Aug 21 16:51:57.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:51:57.259: INFO: namespace: e2e-tests-kubectl-m9p7t, resource: bindings, ignored listing per whitelist
Aug 21 16:51:57.277: INFO: namespace e2e-tests-kubectl-m9p7t deletion completed in 6.206380048s

â€¢ [SLOW TEST:8.688 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:51:57.277: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-gkxbv
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-gkxbv
STEP: Deleting pre-stop pod
Aug 21 16:52:12.471: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:52:12.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-gkxbv" for this suite.
Aug 21 16:52:50.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:52:50.635: INFO: namespace: e2e-tests-prestop-gkxbv, resource: bindings, ignored listing per whitelist
Aug 21 16:52:50.704: INFO: namespace e2e-tests-prestop-gkxbv deletion completed in 38.212323564s

â€¢ [SLOW TEST:53.427 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:52:50.704: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 16:52:50.785: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:52:51.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-727np" for this suite.
Aug 21 16:52:57.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:52:58.032: INFO: namespace: e2e-tests-custom-resource-definition-727np, resource: bindings, ignored listing per whitelist
Aug 21 16:52:58.037: INFO: namespace e2e-tests-custom-resource-definition-727np deletion completed in 6.193989097s

â€¢ [SLOW TEST:7.333 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:52:58.037: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 16:52:58.132: INFO: Waiting up to 5m0s for pod "downwardapi-volume-20ebc68e-c434-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-lmrbz" to be "success or failure"
Aug 21 16:52:58.139: INFO: Pod "downwardapi-volume-20ebc68e-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.248307ms
Aug 21 16:53:00.146: INFO: Pod "downwardapi-volume-20ebc68e-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013951895s
Aug 21 16:53:02.156: INFO: Pod "downwardapi-volume-20ebc68e-c434-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023866497s
STEP: Saw pod success
Aug 21 16:53:02.156: INFO: Pod "downwardapi-volume-20ebc68e-c434-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:53:02.162: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downwardapi-volume-20ebc68e-c434-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 16:53:02.204: INFO: Waiting for pod downwardapi-volume-20ebc68e-c434-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:53:02.210: INFO: Pod downwardapi-volume-20ebc68e-c434-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:53:02.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lmrbz" for this suite.
Aug 21 16:53:08.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:53:08.298: INFO: namespace: e2e-tests-downward-api-lmrbz, resource: bindings, ignored listing per whitelist
Aug 21 16:53:08.516: INFO: namespace e2e-tests-downward-api-lmrbz deletion completed in 6.298399982s

â€¢ [SLOW TEST:10.479 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:53:08.516: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:53:12.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-4l94f" for this suite.
Aug 21 16:53:58.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:53:58.753: INFO: namespace: e2e-tests-kubelet-test-4l94f, resource: bindings, ignored listing per whitelist
Aug 21 16:53:58.865: INFO: namespace e2e-tests-kubelet-test-4l94f deletion completed in 46.209757154s

â€¢ [SLOW TEST:50.348 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:53:58.865: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 16:53:58.947: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:54:03.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-52fld" for this suite.
Aug 21 16:54:41.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:54:41.147: INFO: namespace: e2e-tests-pods-52fld, resource: bindings, ignored listing per whitelist
Aug 21 16:54:41.215: INFO: namespace e2e-tests-pods-52fld deletion completed in 38.201895379s

â€¢ [SLOW TEST:42.351 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:54:41.216: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-5e6c0516-c434-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 16:54:41.319: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5e6d841e-c434-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-6lzcx" to be "success or failure"
Aug 21 16:54:41.326: INFO: Pod "pod-projected-secrets-5e6d841e-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.417358ms
Aug 21 16:54:43.332: INFO: Pod "pod-projected-secrets-5e6d841e-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013762051s
Aug 21 16:54:45.339: INFO: Pod "pod-projected-secrets-5e6d841e-c434-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020602469s
STEP: Saw pod success
Aug 21 16:54:45.339: INFO: Pod "pod-projected-secrets-5e6d841e-c434-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:54:45.345: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-projected-secrets-5e6d841e-c434-11e9-89d6-e2e196a4cdca container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 21 16:54:45.376: INFO: Waiting for pod pod-projected-secrets-5e6d841e-c434-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:54:45.381: INFO: Pod pod-projected-secrets-5e6d841e-c434-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:54:45.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6lzcx" for this suite.
Aug 21 16:54:51.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:54:51.431: INFO: namespace: e2e-tests-projected-6lzcx, resource: bindings, ignored listing per whitelist
Aug 21 16:54:51.599: INFO: namespace e2e-tests-projected-6lzcx deletion completed in 6.211124897s

â€¢ [SLOW TEST:10.383 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:54:51.599: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 21 16:54:51.695: INFO: Waiting up to 5m0s for pod "downward-api-649bfcdf-c434-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-qx28n" to be "success or failure"
Aug 21 16:54:51.702: INFO: Pod "downward-api-649bfcdf-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.634365ms
Aug 21 16:54:53.708: INFO: Pod "downward-api-649bfcdf-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013052916s
Aug 21 16:54:55.715: INFO: Pod "downward-api-649bfcdf-c434-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019651225s
STEP: Saw pod success
Aug 21 16:54:55.715: INFO: Pod "downward-api-649bfcdf-c434-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:54:55.720: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downward-api-649bfcdf-c434-11e9-89d6-e2e196a4cdca container dapi-container: <nil>
STEP: delete the pod
Aug 21 16:54:55.752: INFO: Waiting for pod downward-api-649bfcdf-c434-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:54:55.757: INFO: Pod downward-api-649bfcdf-c434-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:54:55.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qx28n" for this suite.
Aug 21 16:55:01.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:55:01.828: INFO: namespace: e2e-tests-downward-api-qx28n, resource: bindings, ignored listing per whitelist
Aug 21 16:55:01.997: INFO: namespace e2e-tests-downward-api-qx28n deletion completed in 6.232790108s

â€¢ [SLOW TEST:10.398 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:55:01.997: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 21 16:55:06.641: INFO: Successfully updated pod "pod-update-6ad038b8-c434-11e9-89d6-e2e196a4cdca"
STEP: verifying the updated pod is in kubernetes
Aug 21 16:55:06.653: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:55:06.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-cfjjj" for this suite.
Aug 21 16:55:18.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:55:18.701: INFO: namespace: e2e-tests-pods-cfjjj, resource: bindings, ignored listing per whitelist
Aug 21 16:55:18.873: INFO: namespace e2e-tests-pods-cfjjj deletion completed in 12.209578967s

â€¢ [SLOW TEST:16.876 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:55:18.873: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Aug 21 16:55:18.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-mwhpt'
Aug 21 16:55:19.161: INFO: stderr: ""
Aug 21 16:55:19.161: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Aug 21 16:55:20.168: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 16:55:20.168: INFO: Found 0 / 1
Aug 21 16:55:21.168: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 16:55:21.168: INFO: Found 0 / 1
Aug 21 16:55:22.168: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 16:55:22.168: INFO: Found 1 / 1
Aug 21 16:55:22.168: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 21 16:55:22.174: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 16:55:22.174: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 21 16:55:22.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 logs redis-master-dvr88 redis-master --namespace=e2e-tests-kubectl-mwhpt'
Aug 21 16:55:22.283: INFO: stderr: ""
Aug 21 16:55:22.283: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Aug 16:55:21.058 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Aug 16:55:21.058 # Server started, Redis version 3.2.12\n1:M 21 Aug 16:55:21.059 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Aug 16:55:21.059 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 21 16:55:22.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 log redis-master-dvr88 redis-master --namespace=e2e-tests-kubectl-mwhpt --tail=1'
Aug 21 16:55:22.362: INFO: stderr: ""
Aug 21 16:55:22.362: INFO: stdout: "1:M 21 Aug 16:55:21.059 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 21 16:55:22.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 log redis-master-dvr88 redis-master --namespace=e2e-tests-kubectl-mwhpt --limit-bytes=1'
Aug 21 16:55:22.452: INFO: stderr: ""
Aug 21 16:55:22.452: INFO: stdout: " "
STEP: exposing timestamps
Aug 21 16:55:22.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 log redis-master-dvr88 redis-master --namespace=e2e-tests-kubectl-mwhpt --tail=1 --timestamps'
Aug 21 16:55:22.535: INFO: stderr: ""
Aug 21 16:55:22.535: INFO: stdout: "2019-08-21T16:55:21.060973777Z 1:M 21 Aug 16:55:21.059 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 21 16:55:25.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 log redis-master-dvr88 redis-master --namespace=e2e-tests-kubectl-mwhpt --since=1s'
Aug 21 16:55:25.146: INFO: stderr: ""
Aug 21 16:55:25.146: INFO: stdout: ""
Aug 21 16:55:25.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 log redis-master-dvr88 redis-master --namespace=e2e-tests-kubectl-mwhpt --since=24h'
Aug 21 16:55:25.234: INFO: stderr: ""
Aug 21 16:55:25.234: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Aug 16:55:21.058 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Aug 16:55:21.058 # Server started, Redis version 3.2.12\n1:M 21 Aug 16:55:21.059 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Aug 16:55:21.059 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Aug 21 16:55:25.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mwhpt'
Aug 21 16:55:25.307: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 16:55:25.307: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 21 16:55:25.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-mwhpt'
Aug 21 16:55:25.391: INFO: stderr: "No resources found.\n"
Aug 21 16:55:25.391: INFO: stdout: ""
Aug 21 16:55:25.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -l name=nginx --namespace=e2e-tests-kubectl-mwhpt -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 21 16:55:25.461: INFO: stderr: ""
Aug 21 16:55:25.461: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:55:25.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mwhpt" for this suite.
Aug 21 16:55:31.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:55:31.602: INFO: namespace: e2e-tests-kubectl-mwhpt, resource: bindings, ignored listing per whitelist
Aug 21 16:55:31.685: INFO: namespace e2e-tests-kubectl-mwhpt deletion completed in 6.216523674s

â€¢ [SLOW TEST:12.811 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:55:31.685: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Aug 21 16:55:31.768: INFO: namespace e2e-tests-kubectl-2xp7w
Aug 21 16:55:31.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-2xp7w'
Aug 21 16:55:31.947: INFO: stderr: ""
Aug 21 16:55:31.947: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 21 16:55:32.953: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 16:55:32.953: INFO: Found 0 / 1
Aug 21 16:55:33.953: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 16:55:33.953: INFO: Found 0 / 1
Aug 21 16:55:34.954: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 16:55:34.954: INFO: Found 0 / 1
Aug 21 16:55:35.953: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 16:55:35.953: INFO: Found 1 / 1
Aug 21 16:55:35.953: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 21 16:55:35.960: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 16:55:35.960: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 21 16:55:35.960: INFO: wait on redis-master startup in e2e-tests-kubectl-2xp7w 
Aug 21 16:55:35.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 logs redis-master-twl4p redis-master --namespace=e2e-tests-kubectl-2xp7w'
Aug 21 16:55:36.071: INFO: stderr: ""
Aug 21 16:55:36.071: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Aug 16:55:35.288 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Aug 16:55:35.289 # Server started, Redis version 3.2.12\n1:M 21 Aug 16:55:35.289 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Aug 16:55:35.289 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 21 16:55:36.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-2xp7w'
Aug 21 16:55:36.168: INFO: stderr: ""
Aug 21 16:55:36.168: INFO: stdout: "service/rm2 exposed\n"
Aug 21 16:55:36.175: INFO: Service rm2 in namespace e2e-tests-kubectl-2xp7w found.
STEP: exposing service
Aug 21 16:55:38.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-2xp7w'
Aug 21 16:55:38.297: INFO: stderr: ""
Aug 21 16:55:38.297: INFO: stdout: "service/rm3 exposed\n"
Aug 21 16:55:38.310: INFO: Service rm3 in namespace e2e-tests-kubectl-2xp7w found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:55:40.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2xp7w" for this suite.
Aug 21 16:56:02.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:56:02.426: INFO: namespace: e2e-tests-kubectl-2xp7w, resource: bindings, ignored listing per whitelist
Aug 21 16:56:02.545: INFO: namespace e2e-tests-kubectl-2xp7w deletion completed in 22.216968618s

â€¢ [SLOW TEST:30.861 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:56:02.546: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 21 16:56:02.629: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 21 16:56:02.643: INFO: Waiting for terminating namespaces to be deleted...
Aug 21 16:56:02.649: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-150.us-west-2.compute.internal before test
Aug 21 16:56:02.658: INFO: sonobuoy-systemd-logs-daemon-set-1990058480d24a87-rkdd2 from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 16:56:02.658: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 16:56:02.658: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 21 16:56:02.658: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-2-169.us-west-2.compute.internal before test
Aug 21 16:56:02.696: INFO: sonobuoy-e2e-job-b129cff7f8104912 from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 16:56:02.696: INFO: 	Container e2e ready: true, restart count 0
Aug 21 16:56:02.696: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 16:56:02.696: INFO: sonobuoy-systemd-logs-daemon-set-1990058480d24a87-xht7r from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 16:56:02.696: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 16:56:02.696: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 21 16:56:02.696: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-3-38.us-west-2.compute.internal before test
Aug 21 16:56:02.704: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-21 16:33:33 +0000 UTC (1 container statuses recorded)
Aug 21 16:56:02.704: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 21 16:56:02.704: INFO: sonobuoy-systemd-logs-daemon-set-1990058480d24a87-jppkx from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 16:56:02.704: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 16:56:02.704: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-915c8ab6-c434-11e9-89d6-e2e196a4cdca 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-915c8ab6-c434-11e9-89d6-e2e196a4cdca off the node ip-10-0-1-150.us-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-915c8ab6-c434-11e9-89d6-e2e196a4cdca
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:56:10.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-bfrp8" for this suite.
Aug 21 16:56:18.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:56:19.015: INFO: namespace: e2e-tests-sched-pred-bfrp8, resource: bindings, ignored listing per whitelist
Aug 21 16:56:19.043: INFO: namespace e2e-tests-sched-pred-bfrp8 deletion completed in 8.218543912s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:16.498 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:56:19.043: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 21 16:56:19.139: INFO: Waiting up to 5m0s for pod "pod-98baebc5-c434-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-gt8kq" to be "success or failure"
Aug 21 16:56:19.145: INFO: Pod "pod-98baebc5-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.224991ms
Aug 21 16:56:21.152: INFO: Pod "pod-98baebc5-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013092584s
Aug 21 16:56:23.159: INFO: Pod "pod-98baebc5-c434-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019960404s
STEP: Saw pod success
Aug 21 16:56:23.159: INFO: Pod "pod-98baebc5-c434-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:56:23.164: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-98baebc5-c434-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 16:56:23.213: INFO: Waiting for pod pod-98baebc5-c434-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:56:23.219: INFO: Pod pod-98baebc5-c434-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:56:23.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gt8kq" for this suite.
Aug 21 16:56:29.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:56:29.434: INFO: namespace: e2e-tests-emptydir-gt8kq, resource: bindings, ignored listing per whitelist
Aug 21 16:56:29.439: INFO: namespace e2e-tests-emptydir-gt8kq deletion completed in 6.213535438s

â€¢ [SLOW TEST:10.396 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:56:29.439: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0821 16:56:39.568386      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 16:56:39.568: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:56:39.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kdpts" for this suite.
Aug 21 16:56:45.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:56:45.791: INFO: namespace: e2e-tests-gc-kdpts, resource: bindings, ignored listing per whitelist
Aug 21 16:56:45.809: INFO: namespace e2e-tests-gc-kdpts deletion completed in 6.23431338s

â€¢ [SLOW TEST:16.370 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:56:45.809: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Aug 21 16:56:46.440: INFO: created pod pod-service-account-defaultsa
Aug 21 16:56:46.440: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 21 16:56:46.448: INFO: created pod pod-service-account-mountsa
Aug 21 16:56:46.448: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 21 16:56:46.454: INFO: created pod pod-service-account-nomountsa
Aug 21 16:56:46.454: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 21 16:56:46.461: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 21 16:56:46.461: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 21 16:56:46.469: INFO: created pod pod-service-account-mountsa-mountspec
Aug 21 16:56:46.469: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 21 16:56:46.483: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 21 16:56:46.483: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 21 16:56:46.491: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 21 16:56:46.491: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 21 16:56:46.500: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 21 16:56:46.500: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 21 16:56:46.508: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 21 16:56:46.508: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:56:46.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-bv258" for this suite.
Aug 21 16:57:08.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:57:08.715: INFO: namespace: e2e-tests-svcaccounts-bv258, resource: bindings, ignored listing per whitelist
Aug 21 16:57:08.727: INFO: namespace e2e-tests-svcaccounts-bv258 deletion completed in 22.210928318s

â€¢ [SLOW TEST:22.917 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:57:08.727: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 21 16:57:13.372: INFO: Successfully updated pod "labelsupdateb658e770-c434-11e9-89d6-e2e196a4cdca"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:57:15.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jq4qr" for this suite.
Aug 21 16:57:37.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:57:37.562: INFO: namespace: e2e-tests-downward-api-jq4qr, resource: bindings, ignored listing per whitelist
Aug 21 16:57:37.604: INFO: namespace e2e-tests-downward-api-jq4qr deletion completed in 22.197765982s

â€¢ [SLOW TEST:28.877 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:57:37.604: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 21 16:57:37.699: INFO: Waiting up to 5m0s for pod "pod-c78e5f54-c434-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-6nwcj" to be "success or failure"
Aug 21 16:57:37.706: INFO: Pod "pod-c78e5f54-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.465638ms
Aug 21 16:57:39.712: INFO: Pod "pod-c78e5f54-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013084997s
Aug 21 16:57:41.719: INFO: Pod "pod-c78e5f54-c434-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019535613s
STEP: Saw pod success
Aug 21 16:57:41.719: INFO: Pod "pod-c78e5f54-c434-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:57:41.724: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-c78e5f54-c434-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 16:57:41.755: INFO: Waiting for pod pod-c78e5f54-c434-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:57:41.761: INFO: Pod pod-c78e5f54-c434-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:57:41.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6nwcj" for this suite.
Aug 21 16:57:47.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:57:47.956: INFO: namespace: e2e-tests-emptydir-6nwcj, resource: bindings, ignored listing per whitelist
Aug 21 16:57:47.967: INFO: namespace e2e-tests-emptydir-6nwcj deletion completed in 6.199406192s

â€¢ [SLOW TEST:10.363 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:57:47.967: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-kb5lh
Aug 21 16:57:52.080: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-kb5lh
STEP: checking the pod's current state and verifying that restartCount is present
Aug 21 16:57:52.086: INFO: Initial restart count of pod liveness-http is 0
Aug 21 16:58:08.147: INFO: Restart count of pod e2e-tests-container-probe-kb5lh/liveness-http is now 1 (16.061781973s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:58:08.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kb5lh" for this suite.
Aug 21 16:58:14.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:58:14.374: INFO: namespace: e2e-tests-container-probe-kb5lh, resource: bindings, ignored listing per whitelist
Aug 21 16:58:14.429: INFO: namespace e2e-tests-container-probe-kb5lh deletion completed in 6.256099673s

â€¢ [SLOW TEST:26.462 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:58:14.429: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-dd8161b9-c434-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 16:58:14.530: INFO: Waiting up to 5m0s for pod "pod-configmaps-dd830543-c434-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-configmap-bzxxb" to be "success or failure"
Aug 21 16:58:14.537: INFO: Pod "pod-configmaps-dd830543-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.594404ms
Aug 21 16:58:16.547: INFO: Pod "pod-configmaps-dd830543-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017217157s
Aug 21 16:58:18.554: INFO: Pod "pod-configmaps-dd830543-c434-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023713581s
STEP: Saw pod success
Aug 21 16:58:18.554: INFO: Pod "pod-configmaps-dd830543-c434-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:58:18.559: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-configmaps-dd830543-c434-11e9-89d6-e2e196a4cdca container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 16:58:18.590: INFO: Waiting for pod pod-configmaps-dd830543-c434-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:58:18.596: INFO: Pod pod-configmaps-dd830543-c434-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:58:18.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bzxxb" for this suite.
Aug 21 16:58:24.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:58:24.777: INFO: namespace: e2e-tests-configmap-bzxxb, resource: bindings, ignored listing per whitelist
Aug 21 16:58:24.825: INFO: namespace e2e-tests-configmap-bzxxb deletion completed in 6.223022492s

â€¢ [SLOW TEST:10.397 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:58:24.826: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-mxhl
STEP: Creating a pod to test atomic-volume-subpath
Aug 21 16:58:24.934: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mxhl" in namespace "e2e-tests-subpath-tcqzr" to be "success or failure"
Aug 21 16:58:24.943: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.241378ms
Aug 21 16:58:26.949: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014911725s
Aug 21 16:58:28.956: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021344063s
Aug 21 16:58:30.962: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Running", Reason="", readiness=false. Elapsed: 6.027847604s
Aug 21 16:58:32.969: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Running", Reason="", readiness=false. Elapsed: 8.034603139s
Aug 21 16:58:34.976: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Running", Reason="", readiness=false. Elapsed: 10.041326669s
Aug 21 16:58:36.983: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Running", Reason="", readiness=false. Elapsed: 12.048242127s
Aug 21 16:58:38.990: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Running", Reason="", readiness=false. Elapsed: 14.055287842s
Aug 21 16:58:40.997: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Running", Reason="", readiness=false. Elapsed: 16.062273567s
Aug 21 16:58:43.003: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Running", Reason="", readiness=false. Elapsed: 18.068951218s
Aug 21 16:58:45.027: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Running", Reason="", readiness=false. Elapsed: 20.092482043s
Aug 21 16:58:47.034: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Running", Reason="", readiness=false. Elapsed: 22.099167937s
Aug 21 16:58:49.041: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Running", Reason="", readiness=false. Elapsed: 24.106162567s
Aug 21 16:58:51.049: INFO: Pod "pod-subpath-test-downwardapi-mxhl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.115073417s
STEP: Saw pod success
Aug 21 16:58:51.049: INFO: Pod "pod-subpath-test-downwardapi-mxhl" satisfied condition "success or failure"
Aug 21 16:58:51.055: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-subpath-test-downwardapi-mxhl container test-container-subpath-downwardapi-mxhl: <nil>
STEP: delete the pod
Aug 21 16:58:51.087: INFO: Waiting for pod pod-subpath-test-downwardapi-mxhl to disappear
Aug 21 16:58:51.092: INFO: Pod pod-subpath-test-downwardapi-mxhl no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mxhl
Aug 21 16:58:51.092: INFO: Deleting pod "pod-subpath-test-downwardapi-mxhl" in namespace "e2e-tests-subpath-tcqzr"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:58:51.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-tcqzr" for this suite.
Aug 21 16:58:57.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:58:57.183: INFO: namespace: e2e-tests-subpath-tcqzr, resource: bindings, ignored listing per whitelist
Aug 21 16:58:57.314: INFO: namespace e2e-tests-subpath-tcqzr deletion completed in 6.209784061s

â€¢ [SLOW TEST:32.488 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:58:57.314: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-f7114429-c434-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 16:58:57.415: INFO: Waiting up to 5m0s for pod "pod-configmaps-f712b7a1-c434-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-configmap-s5nv2" to be "success or failure"
Aug 21 16:58:57.422: INFO: Pod "pod-configmaps-f712b7a1-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.400942ms
Aug 21 16:58:59.428: INFO: Pod "pod-configmaps-f712b7a1-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012907439s
Aug 21 16:59:01.437: INFO: Pod "pod-configmaps-f712b7a1-c434-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021876395s
STEP: Saw pod success
Aug 21 16:59:01.437: INFO: Pod "pod-configmaps-f712b7a1-c434-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:59:01.443: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-configmaps-f712b7a1-c434-11e9-89d6-e2e196a4cdca container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 16:59:01.476: INFO: Waiting for pod pod-configmaps-f712b7a1-c434-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:59:01.482: INFO: Pod pod-configmaps-f712b7a1-c434-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:59:01.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-s5nv2" for this suite.
Aug 21 16:59:07.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:59:07.594: INFO: namespace: e2e-tests-configmap-s5nv2, resource: bindings, ignored listing per whitelist
Aug 21 16:59:07.701: INFO: namespace e2e-tests-configmap-s5nv2 deletion completed in 6.212167029s

â€¢ [SLOW TEST:10.387 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:59:07.701: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-fd421dba-c434-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 16:59:07.803: INFO: Waiting up to 5m0s for pod "pod-secrets-fd43ab3c-c434-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-secrets-zwn44" to be "success or failure"
Aug 21 16:59:07.809: INFO: Pod "pod-secrets-fd43ab3c-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.836503ms
Aug 21 16:59:09.816: INFO: Pod "pod-secrets-fd43ab3c-c434-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013193575s
Aug 21 16:59:11.823: INFO: Pod "pod-secrets-fd43ab3c-c434-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02003484s
STEP: Saw pod success
Aug 21 16:59:11.823: INFO: Pod "pod-secrets-fd43ab3c-c434-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:59:11.828: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-secrets-fd43ab3c-c434-11e9-89d6-e2e196a4cdca container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 16:59:11.861: INFO: Waiting for pod pod-secrets-fd43ab3c-c434-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:59:11.866: INFO: Pod pod-secrets-fd43ab3c-c434-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:59:11.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zwn44" for this suite.
Aug 21 16:59:17.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:59:17.932: INFO: namespace: e2e-tests-secrets-zwn44, resource: bindings, ignored listing per whitelist
Aug 21 16:59:18.091: INFO: namespace e2e-tests-secrets-zwn44 deletion completed in 6.218160115s

â€¢ [SLOW TEST:10.390 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:59:18.091: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 16:59:18.195: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0374ae4e-c435-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-ckjlz" to be "success or failure"
Aug 21 16:59:18.202: INFO: Pod "downwardapi-volume-0374ae4e-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.185024ms
Aug 21 16:59:20.208: INFO: Pod "downwardapi-volume-0374ae4e-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013641793s
Aug 21 16:59:22.214: INFO: Pod "downwardapi-volume-0374ae4e-c435-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01974053s
STEP: Saw pod success
Aug 21 16:59:22.214: INFO: Pod "downwardapi-volume-0374ae4e-c435-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 16:59:22.220: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downwardapi-volume-0374ae4e-c435-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 16:59:22.252: INFO: Waiting for pod downwardapi-volume-0374ae4e-c435-11e9-89d6-e2e196a4cdca to disappear
Aug 21 16:59:22.257: INFO: Pod downwardapi-volume-0374ae4e-c435-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 16:59:22.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ckjlz" for this suite.
Aug 21 16:59:28.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 16:59:28.305: INFO: namespace: e2e-tests-projected-ckjlz, resource: bindings, ignored listing per whitelist
Aug 21 16:59:28.485: INFO: namespace e2e-tests-projected-ckjlz deletion completed in 6.220443908s

â€¢ [SLOW TEST:10.394 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 16:59:28.485: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 21 16:59:28.569: INFO: PodSpec: initContainers in spec.initContainers
Aug 21 17:00:17.485: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-09a60f2d-c435-11e9-89d6-e2e196a4cdca", GenerateName:"", Namespace:"e2e-tests-init-container-kjv8g", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-kjv8g/pods/pod-init-09a60f2d-c435-11e9-89d6-e2e196a4cdca", UID:"09a75653-c435-11e9-b0fd-0afb3721cd16", ResourceVersion:"10235", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63702003568, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"569942980"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-nlw6q", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0015f0b00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nlw6q", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nlw6q", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nlw6q", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000cda6c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-1-150.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0016d6000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000cda740), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000cda744)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702003568, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702003568, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702003568, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702003568, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.1.150", PodIP:"10.20.3.46", StartTime:(*v1.Time)(0xc0017a07e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000573880)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000573ab0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://a37c708bc4f00b43fecc5c2c4bc18b2b7936b12571ba8e44155735876286a8d4"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0017a0820), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0017a0800), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:00:17.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-kjv8g" for this suite.
Aug 21 17:00:39.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:00:39.664: INFO: namespace: e2e-tests-init-container-kjv8g, resource: bindings, ignored listing per whitelist
Aug 21 17:00:39.706: INFO: namespace e2e-tests-init-container-kjv8g deletion completed in 22.213169231s

â€¢ [SLOW TEST:71.221 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:00:39.706: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-cnp4j.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-cnp4j.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-cnp4j.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-cnp4j.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-cnp4j.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-cnp4j.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 21 17:00:53.980: INFO: DNS probes using e2e-tests-dns-cnp4j/dns-test-34195bb7-c435-11e9-89d6-e2e196a4cdca succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:00:54.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-cnp4j" for this suite.
Aug 21 17:01:00.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:01:00.168: INFO: namespace: e2e-tests-dns-cnp4j, resource: bindings, ignored listing per whitelist
Aug 21 17:01:00.335: INFO: namespace e2e-tests-dns-cnp4j deletion completed in 6.326139853s

â€¢ [SLOW TEST:20.629 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:01:00.335: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Aug 21 17:01:00.432: INFO: Waiting up to 5m0s for pod "client-containers-4064f715-c435-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-containers-vwvfv" to be "success or failure"
Aug 21 17:01:00.439: INFO: Pod "client-containers-4064f715-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.196638ms
Aug 21 17:01:02.446: INFO: Pod "client-containers-4064f715-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0140213s
Aug 21 17:01:04.456: INFO: Pod "client-containers-4064f715-c435-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023721539s
STEP: Saw pod success
Aug 21 17:01:04.456: INFO: Pod "client-containers-4064f715-c435-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:01:04.461: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod client-containers-4064f715-c435-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 17:01:04.493: INFO: Waiting for pod client-containers-4064f715-c435-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:01:04.499: INFO: Pod client-containers-4064f715-c435-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:01:04.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-vwvfv" for this suite.
Aug 21 17:01:10.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:01:10.590: INFO: namespace: e2e-tests-containers-vwvfv, resource: bindings, ignored listing per whitelist
Aug 21 17:01:10.733: INFO: namespace e2e-tests-containers-vwvfv deletion completed in 6.22686839s

â€¢ [SLOW TEST:10.397 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:01:10.733: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-4697d5c8-c435-11e9-89d6-e2e196a4cdca
STEP: Creating secret with name secret-projected-all-test-volume-4697d5ab-c435-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 21 17:01:10.845: INFO: Waiting up to 5m0s for pod "projected-volume-4697d568-c435-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-92ffr" to be "success or failure"
Aug 21 17:01:10.851: INFO: Pod "projected-volume-4697d568-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.593147ms
Aug 21 17:01:12.857: INFO: Pod "projected-volume-4697d568-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012715401s
Aug 21 17:01:14.864: INFO: Pod "projected-volume-4697d568-c435-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019383687s
STEP: Saw pod success
Aug 21 17:01:14.864: INFO: Pod "projected-volume-4697d568-c435-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:01:14.869: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod projected-volume-4697d568-c435-11e9-89d6-e2e196a4cdca container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 21 17:01:14.903: INFO: Waiting for pod projected-volume-4697d568-c435-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:01:14.909: INFO: Pod projected-volume-4697d568-c435-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:01:14.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-92ffr" for this suite.
Aug 21 17:01:20.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:01:21.004: INFO: namespace: e2e-tests-projected-92ffr, resource: bindings, ignored listing per whitelist
Aug 21 17:01:21.129: INFO: namespace e2e-tests-projected-92ffr deletion completed in 6.212950961s

â€¢ [SLOW TEST:10.396 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:01:21.129: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:01:21.212: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:01:25.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kxnf5" for this suite.
Aug 21 17:02:07.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:02:07.569: INFO: namespace: e2e-tests-pods-kxnf5, resource: bindings, ignored listing per whitelist
Aug 21 17:02:07.627: INFO: namespace e2e-tests-pods-kxnf5 deletion completed in 42.213800811s

â€¢ [SLOW TEST:46.497 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:02:07.627: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7t6r5
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-7t6r5
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-7t6r5
Aug 21 17:02:07.751: INFO: Found 0 stateful pods, waiting for 1
Aug 21 17:02:17.761: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 21 17:02:17.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-7t6r5 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 17:02:18.035: INFO: stderr: ""
Aug 21 17:02:18.035: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 17:02:18.035: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 17:02:18.042: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 21 17:02:28.049: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 17:02:28.049: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 17:02:28.072: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999054s
Aug 21 17:02:29.079: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994149456s
Aug 21 17:02:30.085: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987257627s
Aug 21 17:02:31.093: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.980405749s
Aug 21 17:02:32.100: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.972826643s
Aug 21 17:02:33.107: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.965907887s
Aug 21 17:02:34.114: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.95926467s
Aug 21 17:02:35.121: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.951416977s
Aug 21 17:02:36.128: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.944560161s
Aug 21 17:02:37.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 937.525638ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-7t6r5
Aug 21 17:02:38.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-7t6r5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:02:38.366: INFO: stderr: ""
Aug 21 17:02:38.366: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 17:02:38.366: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 17:02:38.373: INFO: Found 1 stateful pods, waiting for 3
Aug 21 17:02:48.379: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:02:48.379: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:02:48.379: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 21 17:02:48.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-7t6r5 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 17:02:48.621: INFO: stderr: ""
Aug 21 17:02:48.621: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 17:02:48.621: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 17:02:48.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-7t6r5 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 17:02:48.899: INFO: stderr: ""
Aug 21 17:02:48.899: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 17:02:48.899: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 17:02:48.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-7t6r5 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 17:02:49.138: INFO: stderr: ""
Aug 21 17:02:49.138: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 17:02:49.138: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 17:02:49.138: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 17:02:49.147: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 21 17:02:59.163: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 17:02:59.163: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 17:02:59.163: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 17:02:59.184: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998957s
Aug 21 17:03:00.191: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992921798s
Aug 21 17:03:01.198: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985903945s
Aug 21 17:03:02.205: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978376562s
Aug 21 17:03:03.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.971692055s
Aug 21 17:03:04.220: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.96419731s
Aug 21 17:03:05.228: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.956403099s
Aug 21 17:03:06.235: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.94902131s
Aug 21 17:03:07.242: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.941814229s
Aug 21 17:03:08.249: INFO: Verifying statefulset ss doesn't scale past 3 for another 934.763998ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-7t6r5
Aug 21 17:03:09.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-7t6r5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:03:09.488: INFO: stderr: ""
Aug 21 17:03:09.489: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 17:03:09.489: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 17:03:09.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-7t6r5 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:03:09.717: INFO: stderr: ""
Aug 21 17:03:09.717: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 17:03:09.717: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 17:03:09.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-7t6r5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:03:09.977: INFO: stderr: ""
Aug 21 17:03:09.977: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 17:03:09.977: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 17:03:09.977: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 21 17:03:30.011: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7t6r5
Aug 21 17:03:30.020: INFO: Scaling statefulset ss to 0
Aug 21 17:03:30.049: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 17:03:30.057: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:03:30.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7t6r5" for this suite.
Aug 21 17:03:36.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:03:36.144: INFO: namespace: e2e-tests-statefulset-7t6r5, resource: bindings, ignored listing per whitelist
Aug 21 17:03:36.316: INFO: namespace e2e-tests-statefulset-7t6r5 deletion completed in 6.224234651s

â€¢ [SLOW TEST:88.690 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:03:36.316: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Aug 21 17:03:36.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-fj6gt'
Aug 21 17:03:36.709: INFO: stderr: ""
Aug 21 17:03:36.709: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 21 17:03:37.721: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 17:03:37.721: INFO: Found 0 / 1
Aug 21 17:03:38.716: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 17:03:38.716: INFO: Found 0 / 1
Aug 21 17:03:39.716: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 17:03:39.716: INFO: Found 1 / 1
Aug 21 17:03:39.716: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 21 17:03:39.722: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 17:03:39.722: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 21 17:03:39.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 patch pod redis-master-ztnj7 --namespace=e2e-tests-kubectl-fj6gt -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 21 17:03:39.808: INFO: stderr: ""
Aug 21 17:03:39.808: INFO: stdout: "pod/redis-master-ztnj7 patched\n"
STEP: checking annotations
Aug 21 17:03:39.814: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 17:03:39.814: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:03:39.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fj6gt" for this suite.
Aug 21 17:04:01.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:04:01.856: INFO: namespace: e2e-tests-kubectl-fj6gt, resource: bindings, ignored listing per whitelist
Aug 21 17:04:02.058: INFO: namespace e2e-tests-kubectl-fj6gt deletion completed in 22.235416087s

â€¢ [SLOW TEST:25.741 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:04:02.058: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:04:02.146: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 21 17:04:02.170: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 21 17:04:07.177: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 21 17:04:07.177: INFO: Creating deployment "test-rolling-update-deployment"
Aug 21 17:04:07.183: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 21 17:04:07.195: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 21 17:04:09.208: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 21 17:04:09.214: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702003847, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702003847, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702003847, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702003847, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 17:04:11.221: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 21 17:04:11.240: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-jc8k8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jc8k8/deployments/test-rolling-update-deployment,UID:afb6e0ef-c435-11e9-b0fd-0afb3721cd16,ResourceVersion:11084,Generation:1,CreationTimestamp:2019-08-21 17:04:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-21 17:04:07 +0000 UTC 2019-08-21 17:04:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-21 17:04:09 +0000 UTC 2019-08-21 17:04:07 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 21 17:04:11.248: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-jc8k8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jc8k8/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:afb8573b-c435-11e9-bb91-06b2a5b3abd6,ResourceVersion:11075,Generation:1,CreationTimestamp:2019-08-21 17:04:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment afb6e0ef-c435-11e9-b0fd-0afb3721cd16 0xc000cdaa77 0xc000cdaa78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 21 17:04:11.248: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 21 17:04:11.248: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-jc8k8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jc8k8/replicasets/test-rolling-update-controller,UID:acb750a4-c435-11e9-b0fd-0afb3721cd16,ResourceVersion:11083,Generation:2,CreationTimestamp:2019-08-21 17:04:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment afb6e0ef-c435-11e9-b0fd-0afb3721cd16 0xc000cda997 0xc000cda998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 17:04:11.255: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-6v8pl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-6v8pl,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-jc8k8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jc8k8/pods/test-rolling-update-deployment-68b55d7bc6-6v8pl,UID:afb92107-c435-11e9-bb91-06b2a5b3abd6,ResourceVersion:11074,Generation:0,CreationTimestamp:2019-08-21 17:04:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 afb8573b-c435-11e9-bb91-06b2a5b3abd6 0xc000cdb977 0xc000cdb978}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-b9txj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-b9txj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-b9txj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:04:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:04:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:04:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:04:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:10.20.12.33,StartTime:2019-08-21 17:04:07 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-21 17:04:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://b1bf6fbcaf722c022bb4cf96b9f8f401fd33aa5c9c02214ae5091f6125bd096a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:04:11.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jc8k8" for this suite.
Aug 21 17:04:17.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:04:17.381: INFO: namespace: e2e-tests-deployment-jc8k8, resource: bindings, ignored listing per whitelist
Aug 21 17:04:17.467: INFO: namespace e2e-tests-deployment-jc8k8 deletion completed in 6.205878105s

â€¢ [SLOW TEST:15.410 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:04:17.468: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-ls6t9/secret-test-b5e60608-c435-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 17:04:17.578: INFO: Waiting up to 5m0s for pod "pod-configmaps-b5e7976c-c435-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-secrets-ls6t9" to be "success or failure"
Aug 21 17:04:17.585: INFO: Pod "pod-configmaps-b5e7976c-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.835295ms
Aug 21 17:04:19.592: INFO: Pod "pod-configmaps-b5e7976c-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01397541s
Aug 21 17:04:21.599: INFO: Pod "pod-configmaps-b5e7976c-c435-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020498428s
STEP: Saw pod success
Aug 21 17:04:21.599: INFO: Pod "pod-configmaps-b5e7976c-c435-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:04:21.605: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-configmaps-b5e7976c-c435-11e9-89d6-e2e196a4cdca container env-test: <nil>
STEP: delete the pod
Aug 21 17:04:21.637: INFO: Waiting for pod pod-configmaps-b5e7976c-c435-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:04:21.643: INFO: Pod pod-configmaps-b5e7976c-c435-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:04:21.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ls6t9" for this suite.
Aug 21 17:04:27.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:04:27.846: INFO: namespace: e2e-tests-secrets-ls6t9, resource: bindings, ignored listing per whitelist
Aug 21 17:04:27.862: INFO: namespace e2e-tests-secrets-ls6t9 deletion completed in 6.212377307s

â€¢ [SLOW TEST:10.395 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:04:27.862: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-wn82j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wn82j to expose endpoints map[]
Aug 21 17:04:27.970: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wn82j exposes endpoints map[] (7.102615ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-wn82j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wn82j to expose endpoints map[pod1:[80]]
Aug 21 17:04:31.039: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wn82j exposes endpoints map[pod1:[80]] (3.057569164s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-wn82j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wn82j to expose endpoints map[pod1:[80] pod2:[80]]
Aug 21 17:04:34.118: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wn82j exposes endpoints map[pod1:[80] pod2:[80]] (3.07297092s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-wn82j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wn82j to expose endpoints map[pod2:[80]]
Aug 21 17:04:34.143: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wn82j exposes endpoints map[pod2:[80]] (13.664141ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-wn82j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wn82j to expose endpoints map[]
Aug 21 17:04:34.170: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wn82j exposes endpoints map[] (6.037011ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:04:34.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-wn82j" for this suite.
Aug 21 17:04:56.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:04:56.331: INFO: namespace: e2e-tests-services-wn82j, resource: bindings, ignored listing per whitelist
Aug 21 17:04:56.486: INFO: namespace e2e-tests-services-wn82j deletion completed in 22.244965937s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:28.624 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:04:56.486: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 21 17:05:04.650: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 17:05:04.657: INFO: Pod pod-with-poststart-http-hook still exists
Aug 21 17:05:06.658: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 17:05:06.665: INFO: Pod pod-with-poststart-http-hook still exists
Aug 21 17:05:08.658: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 21 17:05:08.664: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:05:08.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-qkslj" for this suite.
Aug 21 17:05:30.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:05:30.785: INFO: namespace: e2e-tests-container-lifecycle-hook-qkslj, resource: bindings, ignored listing per whitelist
Aug 21 17:05:30.895: INFO: namespace e2e-tests-container-lifecycle-hook-qkslj deletion completed in 22.221389125s

â€¢ [SLOW TEST:34.409 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:05:30.895: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:05:35.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-zw2gz" for this suite.
Aug 21 17:05:41.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:05:41.088: INFO: namespace: e2e-tests-kubelet-test-zw2gz, resource: bindings, ignored listing per whitelist
Aug 21 17:05:41.235: INFO: namespace e2e-tests-kubelet-test-zw2gz deletion completed in 6.217702237s

â€¢ [SLOW TEST:10.340 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:05:41.235: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 21 17:05:41.344: INFO: Waiting up to 5m0s for pod "pod-e7d3ce9f-c435-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-jvlvj" to be "success or failure"
Aug 21 17:05:41.351: INFO: Pod "pod-e7d3ce9f-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.849352ms
Aug 21 17:05:43.357: INFO: Pod "pod-e7d3ce9f-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013305139s
Aug 21 17:05:45.363: INFO: Pod "pod-e7d3ce9f-c435-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019703785s
STEP: Saw pod success
Aug 21 17:05:45.363: INFO: Pod "pod-e7d3ce9f-c435-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:05:45.369: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-e7d3ce9f-c435-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 17:05:45.401: INFO: Waiting for pod pod-e7d3ce9f-c435-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:05:45.406: INFO: Pod pod-e7d3ce9f-c435-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:05:45.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jvlvj" for this suite.
Aug 21 17:05:51.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:05:51.576: INFO: namespace: e2e-tests-emptydir-jvlvj, resource: bindings, ignored listing per whitelist
Aug 21 17:05:51.622: INFO: namespace e2e-tests-emptydir-jvlvj deletion completed in 6.2092211s

â€¢ [SLOW TEST:10.387 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:05:51.622: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 21 17:05:51.717: INFO: Waiting up to 5m0s for pod "downward-api-ee038f40-c435-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-5cr8z" to be "success or failure"
Aug 21 17:05:51.724: INFO: Pod "downward-api-ee038f40-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.463754ms
Aug 21 17:05:53.730: INFO: Pod "downward-api-ee038f40-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013231996s
Aug 21 17:05:55.738: INFO: Pod "downward-api-ee038f40-c435-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020382805s
STEP: Saw pod success
Aug 21 17:05:55.738: INFO: Pod "downward-api-ee038f40-c435-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:05:55.743: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downward-api-ee038f40-c435-11e9-89d6-e2e196a4cdca container dapi-container: <nil>
STEP: delete the pod
Aug 21 17:05:55.774: INFO: Waiting for pod downward-api-ee038f40-c435-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:05:55.780: INFO: Pod downward-api-ee038f40-c435-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:05:55.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5cr8z" for this suite.
Aug 21 17:06:01.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:06:02.013: INFO: namespace: e2e-tests-downward-api-5cr8z, resource: bindings, ignored listing per whitelist
Aug 21 17:06:02.052: INFO: namespace e2e-tests-downward-api-5cr8z deletion completed in 6.265526126s

â€¢ [SLOW TEST:10.430 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:06:02.052: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 17:06:02.162: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f43c7b57-c435-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-m2twn" to be "success or failure"
Aug 21 17:06:02.171: INFO: Pod "downwardapi-volume-f43c7b57-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 8.465422ms
Aug 21 17:06:04.178: INFO: Pod "downwardapi-volume-f43c7b57-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015863297s
Aug 21 17:06:06.185: INFO: Pod "downwardapi-volume-f43c7b57-c435-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022964132s
STEP: Saw pod success
Aug 21 17:06:06.185: INFO: Pod "downwardapi-volume-f43c7b57-c435-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:06:06.191: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downwardapi-volume-f43c7b57-c435-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 17:06:06.224: INFO: Waiting for pod downwardapi-volume-f43c7b57-c435-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:06:06.229: INFO: Pod downwardapi-volume-f43c7b57-c435-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:06:06.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m2twn" for this suite.
Aug 21 17:06:12.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:06:12.362: INFO: namespace: e2e-tests-downward-api-m2twn, resource: bindings, ignored listing per whitelist
Aug 21 17:06:12.467: INFO: namespace e2e-tests-downward-api-m2twn deletion completed in 6.229781801s

â€¢ [SLOW TEST:10.415 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:06:12.467: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 17:06:12.568: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa710d5c-c435-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-dj2l2" to be "success or failure"
Aug 21 17:06:12.576: INFO: Pod "downwardapi-volume-fa710d5c-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.631763ms
Aug 21 17:06:14.583: INFO: Pod "downwardapi-volume-fa710d5c-c435-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014604161s
Aug 21 17:06:16.590: INFO: Pod "downwardapi-volume-fa710d5c-c435-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022011762s
STEP: Saw pod success
Aug 21 17:06:16.590: INFO: Pod "downwardapi-volume-fa710d5c-c435-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:06:16.596: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downwardapi-volume-fa710d5c-c435-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 17:06:16.626: INFO: Waiting for pod downwardapi-volume-fa710d5c-c435-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:06:16.632: INFO: Pod downwardapi-volume-fa710d5c-c435-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:06:16.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dj2l2" for this suite.
Aug 21 17:06:22.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:06:22.709: INFO: namespace: e2e-tests-projected-dj2l2, resource: bindings, ignored listing per whitelist
Aug 21 17:06:22.876: INFO: namespace e2e-tests-projected-dj2l2 deletion completed in 6.236767535s

â€¢ [SLOW TEST:10.409 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:06:22.876: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:06:22.962: INFO: Creating deployment "nginx-deployment"
Aug 21 17:06:22.973: INFO: Waiting for observed generation 1
Aug 21 17:06:24.989: INFO: Waiting for all required pods to come up
Aug 21 17:06:24.996: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 21 17:06:29.015: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 21 17:06:29.027: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 21 17:06:29.039: INFO: Updating deployment nginx-deployment
Aug 21 17:06:29.039: INFO: Waiting for observed generation 2
Aug 21 17:06:31.055: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 21 17:06:31.061: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 21 17:06:31.066: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 21 17:06:31.083: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 21 17:06:31.083: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 21 17:06:31.092: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 21 17:06:31.103: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 21 17:06:31.103: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 21 17:06:31.116: INFO: Updating deployment nginx-deployment
Aug 21 17:06:31.116: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 21 17:06:31.133: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 21 17:06:33.147: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 21 17:06:33.159: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bsg5f/deployments/nginx-deployment,UID:00a60f6d-c436-11e9-b0fd-0afb3721cd16,ResourceVersion:11893,Generation:3,CreationTimestamp:2019-08-21 17:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-08-21 17:06:31 +0000 UTC 2019-08-21 17:06:31 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-21 17:06:31 +0000 UTC 2019-08-21 17:06:22 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Aug 21 17:06:33.165: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bsg5f/replicasets/nginx-deployment-65bbdb5f8,UID:044474c5-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11892,Generation:3,CreationTimestamp:2019-08-21 17:06:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 00a60f6d-c436-11e9-b0fd-0afb3721cd16 0xc001486617 0xc001486618}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 17:06:33.165: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 21 17:06:33.165: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bsg5f/replicasets/nginx-deployment-555b55d965,UID:00a6d09e-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11875,Generation:3,CreationTimestamp:2019-08-21 17:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 00a60f6d-c436-11e9-b0fd-0afb3721cd16 0xc0014863f7 0xc0014863f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Aug 21 17:06:33.176: INFO: Pod "nginx-deployment-555b55d965-4mccm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4mccm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-4mccm,UID:0585a74d-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11899,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc001487c47 0xc001487c48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.176: INFO: Pod "nginx-deployment-555b55d965-59hjq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-59hjq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-59hjq,UID:058340e5-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11856,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc001487d40 0xc001487d41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.176: INFO: Pod "nginx-deployment-555b55d965-797zf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-797zf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-797zf,UID:05873ffc-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11934,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc001487e70 0xc001487e71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.176: INFO: Pod "nginx-deployment-555b55d965-8j5gg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8j5gg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-8j5gg,UID:00a84068-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11723,Generation:0,CreationTimestamp:2019-08-21 17:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc001487f60 0xc001487f61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:10.20.3.56,StartTime:2019-08-21 17:06:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 17:06:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://5893d5ae173a7c6f04fed425f9dee7223afe63c68e4b63a2f44c864787ff28be}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.176: INFO: Pod "nginx-deployment-555b55d965-8mgdb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8mgdb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-8mgdb,UID:00aa0037-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11706,Generation:0,CreationTimestamp:2019-08-21 17:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f6080 0xc0012f6081}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:10.20.35.12,StartTime:2019-08-21 17:06:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 17:06:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://07c551f0f71388d30c57a683a2c6285bc3e31d059102dca36a33809b00b96cca}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.176: INFO: Pod "nginx-deployment-555b55d965-9fvzq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9fvzq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-9fvzq,UID:05823e6e-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11844,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f6430 0xc0012f6431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.176: INFO: Pod "nginx-deployment-555b55d965-b2rlm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-b2rlm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-b2rlm,UID:0586ea2e-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11904,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f6520 0xc0012f6521}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.176: INFO: Pod "nginx-deployment-555b55d965-bxqww" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bxqww,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-bxqww,UID:05856805-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11873,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f6670 0xc0012f6671}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.176: INFO: Pod "nginx-deployment-555b55d965-d4x5r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-d4x5r,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-d4x5r,UID:00ac8838-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11695,Generation:0,CreationTimestamp:2019-08-21 17:06:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f67a0 0xc0012f67a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:10.20.3.57,StartTime:2019-08-21 17:06:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 17:06:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d943010e2dc32e60a4da10e14a5aa3abb4eea73ec2ec53282b922f9b97d02a1d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.176: INFO: Pod "nginx-deployment-555b55d965-fgfnw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fgfnw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-fgfnw,UID:00a8e45c-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11709,Generation:0,CreationTimestamp:2019-08-21 17:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f68a0 0xc0012f68a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:10.20.35.11,StartTime:2019-08-21 17:06:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 17:06:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2d941d23598c0fa5a42eb359e50ddeb2f2af3cf826cd2c681154b7c7b3020f15}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.177: INFO: Pod "nginx-deployment-555b55d965-fw2bl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fw2bl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-fw2bl,UID:05876ece-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11931,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f69d0 0xc0012f69d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.177: INFO: Pod "nginx-deployment-555b55d965-gvlrt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gvlrt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-gvlrt,UID:00a8d0f9-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11716,Generation:0,CreationTimestamp:2019-08-21 17:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f6ac0 0xc0012f6ac1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:10.20.12.39,StartTime:2019-08-21 17:06:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 17:06:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://106a1ae69e02159d63a71a4e41a37ad8a017713d0f957ec9e28231c678b21de2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.177: INFO: Pod "nginx-deployment-555b55d965-hgmbv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hgmbv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-hgmbv,UID:00aa352c-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11726,Generation:0,CreationTimestamp:2019-08-21 17:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f6c40 0xc0012f6c41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:10.20.3.58,StartTime:2019-08-21 17:06:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 17:06:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9821bcbc62d72abad356df9b6baa8eb93a58889c3693d1b3c572d41a73579d5f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.177: INFO: Pod "nginx-deployment-555b55d965-jwcjl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jwcjl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-jwcjl,UID:00aa0f77-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11719,Generation:0,CreationTimestamp:2019-08-21 17:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f6db0 0xc0012f6db1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:10.20.12.40,StartTime:2019-08-21 17:06:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 17:06:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6a43b0748c87b71b09894065a573f79febba904e4f97a71464fabec0392b72f5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.177: INFO: Pod "nginx-deployment-555b55d965-lg6rn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lg6rn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-lg6rn,UID:05855742-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11881,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f6eb0 0xc0012f6eb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.177: INFO: Pod "nginx-deployment-555b55d965-rf8vs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rf8vs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-rf8vs,UID:0583314e-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11846,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f7050 0xc0012f7051}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.177: INFO: Pod "nginx-deployment-555b55d965-scrs9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-scrs9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-scrs9,UID:05859778-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11877,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f7140 0xc0012f7141}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.177: INFO: Pod "nginx-deployment-555b55d965-tcs62" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tcs62,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-tcs62,UID:05875cd5-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11855,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f72a0 0xc0012f72a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.177: INFO: Pod "nginx-deployment-555b55d965-wjw7t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wjw7t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-wjw7t,UID:00aa51e7-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11712,Generation:0,CreationTimestamp:2019-08-21 17:06:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f74a0 0xc0012f74a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:23 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:10.20.35.13,StartTime:2019-08-21 17:06:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-21 17:06:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://42f5130268b9dcb82c35032122e0f94ce3c5a09845d55160ea7426899e96d085}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.178: INFO: Pod "nginx-deployment-555b55d965-wk5jx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wk5jx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-555b55d965-wk5jx,UID:0586db6e-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11886,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 00a6d09e-c436-11e9-bb91-06b2a5b3abd6 0xc0012f75a0 0xc0012f75a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.178: INFO: Pod "nginx-deployment-65bbdb5f8-6txzb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6txzb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-6txzb,UID:04461875-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11763,Generation:0,CreationTimestamp:2019-08-21 17:06:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc0012f7770 0xc0012f7771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:,StartTime:2019-08-21 17:06:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.178: INFO: Pod "nginx-deployment-65bbdb5f8-7wljh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7wljh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-7wljh,UID:0584a793-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11863,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc0012f7880 0xc0012f7881}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.178: INFO: Pod "nginx-deployment-65bbdb5f8-cldnt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cldnt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-cldnt,UID:05863d6a-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11924,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc0012f7a20 0xc0012f7a21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.178: INFO: Pod "nginx-deployment-65bbdb5f8-dvc6l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dvc6l,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-dvc6l,UID:0584b6d3-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11861,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc0012f7ba0 0xc0012f7ba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.178: INFO: Pod "nginx-deployment-65bbdb5f8-f7dxb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-f7dxb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-f7dxb,UID:04453e1d-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11932,Generation:0,CreationTimestamp:2019-08-21 17:06:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc0012f7cb0 0xc0012f7cb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:10.20.3.59,StartTime:2019-08-21 17:06:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.178: INFO: Pod "nginx-deployment-65bbdb5f8-h2xpm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-h2xpm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-h2xpm,UID:044e9dce-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11786,Generation:0,CreationTimestamp:2019-08-21 17:06:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc0012f7e40 0xc0012f7e41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:,StartTime:2019-08-21 17:06:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.178: INFO: Pod "nginx-deployment-65bbdb5f8-h8nq7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-h8nq7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-h8nq7,UID:05835235-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11868,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc0012f7f50 0xc0012f7f51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.178: INFO: Pod "nginx-deployment-65bbdb5f8-lksrr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lksrr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-lksrr,UID:05865cf5-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11874,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc001cb8060 0xc001cb8061}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.178: INFO: Pod "nginx-deployment-65bbdb5f8-n6bs9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-n6bs9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-n6bs9,UID:058839ec-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11902,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc001cb8280 0xc001cb8281}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.179: INFO: Pod "nginx-deployment-65bbdb5f8-qmgp9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qmgp9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-qmgp9,UID:044fa75e-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11785,Generation:0,CreationTimestamp:2019-08-21 17:06:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc001cb8520 0xc001cb8521}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:,StartTime:2019-08-21 17:06:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.179: INFO: Pod "nginx-deployment-65bbdb5f8-twcwg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-twcwg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-twcwg,UID:04461a2e-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11762,Generation:0,CreationTimestamp:2019-08-21 17:06:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc001cb86e0 0xc001cb86e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:29 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:,StartTime:2019-08-21 17:06:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.179: INFO: Pod "nginx-deployment-65bbdb5f8-x5d4b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x5d4b,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-x5d4b,UID:05862d44-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11883,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc001cb87f0 0xc001cb87f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 21 17:06:33.179: INFO: Pod "nginx-deployment-65bbdb5f8-zk69g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zk69g,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bsg5f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bsg5f/pods/nginx-deployment-65bbdb5f8-zk69g,UID:05864c15-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:11891,Generation:0,CreationTimestamp:2019-08-21 17:06:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 044474c5-c436-11e9-bb91-06b2a5b3abd6 0xc001cb8940 0xc001cb8941}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5m8zt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5m8zt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5m8zt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-2-169.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:06:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.169,PodIP:,StartTime:2019-08-21 17:06:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:06:33.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bsg5f" for this suite.
Aug 21 17:06:41.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:06:41.284: INFO: namespace: e2e-tests-deployment-bsg5f, resource: bindings, ignored listing per whitelist
Aug 21 17:06:41.421: INFO: namespace e2e-tests-deployment-bsg5f deletion completed in 8.234309784s

â€¢ [SLOW TEST:18.545 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:06:41.421: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Aug 21 17:06:41.527: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-p9rcq" to be "success or failure"
Aug 21 17:06:41.533: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.550112ms
Aug 21 17:06:43.539: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012406822s
Aug 21 17:06:45.546: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019276159s
Aug 21 17:06:47.553: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026431724s
STEP: Saw pod success
Aug 21 17:06:47.554: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 21 17:06:47.559: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 21 17:06:47.593: INFO: Waiting for pod pod-host-path-test to disappear
Aug 21 17:06:47.598: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:06:47.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-p9rcq" for this suite.
Aug 21 17:06:53.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:06:53.700: INFO: namespace: e2e-tests-hostpath-p9rcq, resource: bindings, ignored listing per whitelist
Aug 21 17:06:53.816: INFO: namespace e2e-tests-hostpath-p9rcq deletion completed in 6.21068572s

â€¢ [SLOW TEST:12.395 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:06:53.816: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-13160f8d-c436-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 17:06:53.921: INFO: Waiting up to 5m0s for pod "pod-secrets-1317a3dd-c436-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-secrets-4fqj5" to be "success or failure"
Aug 21 17:06:53.927: INFO: Pod "pod-secrets-1317a3dd-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033058ms
Aug 21 17:06:55.933: INFO: Pod "pod-secrets-1317a3dd-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012875059s
Aug 21 17:06:57.940: INFO: Pod "pod-secrets-1317a3dd-c436-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019351052s
STEP: Saw pod success
Aug 21 17:06:57.940: INFO: Pod "pod-secrets-1317a3dd-c436-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:06:57.945: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-secrets-1317a3dd-c436-11e9-89d6-e2e196a4cdca container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 17:06:57.978: INFO: Waiting for pod pod-secrets-1317a3dd-c436-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:06:57.983: INFO: Pod pod-secrets-1317a3dd-c436-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:06:57.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4fqj5" for this suite.
Aug 21 17:07:04.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:07:04.146: INFO: namespace: e2e-tests-secrets-4fqj5, resource: bindings, ignored listing per whitelist
Aug 21 17:07:04.321: INFO: namespace e2e-tests-secrets-4fqj5 deletion completed in 6.331173181s

â€¢ [SLOW TEST:10.505 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:07:04.321: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:08:04.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xlddx" for this suite.
Aug 21 17:08:26.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:08:26.561: INFO: namespace: e2e-tests-container-probe-xlddx, resource: bindings, ignored listing per whitelist
Aug 21 17:08:26.659: INFO: namespace e2e-tests-container-probe-xlddx deletion completed in 22.205597293s

â€¢ [SLOW TEST:82.338 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:08:26.660: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-h8c6
STEP: Creating a pod to test atomic-volume-subpath
Aug 21 17:08:26.777: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-h8c6" in namespace "e2e-tests-subpath-wnbnl" to be "success or failure"
Aug 21 17:08:26.784: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.35421ms
Aug 21 17:08:28.790: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012887031s
Aug 21 17:08:30.798: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020096442s
Aug 21 17:08:32.804: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Running", Reason="", readiness=false. Elapsed: 6.026081375s
Aug 21 17:08:34.810: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Running", Reason="", readiness=false. Elapsed: 8.032672122s
Aug 21 17:08:36.817: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Running", Reason="", readiness=false. Elapsed: 10.039144394s
Aug 21 17:08:38.823: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Running", Reason="", readiness=false. Elapsed: 12.045882574s
Aug 21 17:08:40.829: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Running", Reason="", readiness=false. Elapsed: 14.051958415s
Aug 21 17:08:42.835: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Running", Reason="", readiness=false. Elapsed: 16.057881913s
Aug 21 17:08:44.842: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Running", Reason="", readiness=false. Elapsed: 18.06439725s
Aug 21 17:08:46.848: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Running", Reason="", readiness=false. Elapsed: 20.070873246s
Aug 21 17:08:48.855: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Running", Reason="", readiness=false. Elapsed: 22.077828887s
Aug 21 17:08:50.862: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Running", Reason="", readiness=false. Elapsed: 24.084624382s
Aug 21 17:08:52.869: INFO: Pod "pod-subpath-test-projected-h8c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.091216661s
STEP: Saw pod success
Aug 21 17:08:52.869: INFO: Pod "pod-subpath-test-projected-h8c6" satisfied condition "success or failure"
Aug 21 17:08:52.874: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-subpath-test-projected-h8c6 container test-container-subpath-projected-h8c6: <nil>
STEP: delete the pod
Aug 21 17:08:52.906: INFO: Waiting for pod pod-subpath-test-projected-h8c6 to disappear
Aug 21 17:08:52.912: INFO: Pod pod-subpath-test-projected-h8c6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-h8c6
Aug 21 17:08:52.912: INFO: Deleting pod "pod-subpath-test-projected-h8c6" in namespace "e2e-tests-subpath-wnbnl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:08:52.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-wnbnl" for this suite.
Aug 21 17:08:58.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:08:58.962: INFO: namespace: e2e-tests-subpath-wnbnl, resource: bindings, ignored listing per whitelist
Aug 21 17:08:59.130: INFO: namespace e2e-tests-subpath-wnbnl deletion completed in 6.205687358s

â€¢ [SLOW TEST:32.470 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:08:59.130: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-5dc70bc9-c436-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 17:08:59.232: INFO: Waiting up to 5m0s for pod "pod-secrets-5dc8a8c8-c436-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-secrets-fdgkk" to be "success or failure"
Aug 21 17:08:59.238: INFO: Pod "pod-secrets-5dc8a8c8-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019856ms
Aug 21 17:09:01.245: INFO: Pod "pod-secrets-5dc8a8c8-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012801418s
Aug 21 17:09:03.252: INFO: Pod "pod-secrets-5dc8a8c8-c436-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01959181s
STEP: Saw pod success
Aug 21 17:09:03.252: INFO: Pod "pod-secrets-5dc8a8c8-c436-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:09:03.257: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-secrets-5dc8a8c8-c436-11e9-89d6-e2e196a4cdca container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 17:09:03.287: INFO: Waiting for pod pod-secrets-5dc8a8c8-c436-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:09:03.293: INFO: Pod pod-secrets-5dc8a8c8-c436-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:09:03.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fdgkk" for this suite.
Aug 21 17:09:09.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:09:09.454: INFO: namespace: e2e-tests-secrets-fdgkk, resource: bindings, ignored listing per whitelist
Aug 21 17:09:09.506: INFO: namespace e2e-tests-secrets-fdgkk deletion completed in 6.206070015s

â€¢ [SLOW TEST:10.376 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:09:09.506: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 21 17:09:09.599: INFO: Waiting up to 5m0s for pod "pod-63f5eb72-c436-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-w7l6w" to be "success or failure"
Aug 21 17:09:09.605: INFO: Pod "pod-63f5eb72-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.40669ms
Aug 21 17:09:11.611: INFO: Pod "pod-63f5eb72-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012699147s
Aug 21 17:09:13.619: INFO: Pod "pod-63f5eb72-c436-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020718247s
STEP: Saw pod success
Aug 21 17:09:13.620: INFO: Pod "pod-63f5eb72-c436-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:09:13.625: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-63f5eb72-c436-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 17:09:13.665: INFO: Waiting for pod pod-63f5eb72-c436-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:09:13.671: INFO: Pod pod-63f5eb72-c436-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:09:13.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w7l6w" for this suite.
Aug 21 17:09:19.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:09:19.802: INFO: namespace: e2e-tests-emptydir-w7l6w, resource: bindings, ignored listing per whitelist
Aug 21 17:09:19.887: INFO: namespace e2e-tests-emptydir-w7l6w deletion completed in 6.208416212s

â€¢ [SLOW TEST:10.381 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:09:19.887: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 21 17:09:24.521: INFO: Successfully updated pod "pod-update-activedeadlineseconds-6a266ac8-c436-11e9-89d6-e2e196a4cdca"
Aug 21 17:09:24.521: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-6a266ac8-c436-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-pods-5d67n" to be "terminated due to deadline exceeded"
Aug 21 17:09:24.527: INFO: Pod "pod-update-activedeadlineseconds-6a266ac8-c436-11e9-89d6-e2e196a4cdca": Phase="Running", Reason="", readiness=true. Elapsed: 5.316945ms
Aug 21 17:09:26.533: INFO: Pod "pod-update-activedeadlineseconds-6a266ac8-c436-11e9-89d6-e2e196a4cdca": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.011551911s
Aug 21 17:09:26.533: INFO: Pod "pod-update-activedeadlineseconds-6a266ac8-c436-11e9-89d6-e2e196a4cdca" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:09:26.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5d67n" for this suite.
Aug 21 17:09:32.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:09:32.720: INFO: namespace: e2e-tests-pods-5d67n, resource: bindings, ignored listing per whitelist
Aug 21 17:09:32.755: INFO: namespace e2e-tests-pods-5d67n deletion completed in 6.214901268s

â€¢ [SLOW TEST:12.867 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:09:32.755: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9z8zk in namespace e2e-tests-proxy-pzhl9
I0821 17:09:32.867036      15 runners.go:184] Created replication controller with name: proxy-service-9z8zk, namespace: e2e-tests-proxy-pzhl9, replica count: 1
I0821 17:09:33.917472      15 runners.go:184] proxy-service-9z8zk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0821 17:09:34.917703      15 runners.go:184] proxy-service-9z8zk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0821 17:09:35.917930      15 runners.go:184] proxy-service-9z8zk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0821 17:09:36.918145      15 runners.go:184] proxy-service-9z8zk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0821 17:09:37.918384      15 runners.go:184] proxy-service-9z8zk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0821 17:09:38.918621      15 runners.go:184] proxy-service-9z8zk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0821 17:09:39.918851      15 runners.go:184] proxy-service-9z8zk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0821 17:09:40.919054      15 runners.go:184] proxy-service-9z8zk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0821 17:09:41.919282      15 runners.go:184] proxy-service-9z8zk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0821 17:09:42.919521      15 runners.go:184] proxy-service-9z8zk Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 21 17:09:42.925: INFO: setup took 10.086095597s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 21 17:09:42.943: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 17.723899ms)
Aug 21 17:09:42.945: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 19.86551ms)
Aug 21 17:09:42.949: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 23.357367ms)
Aug 21 17:09:42.949: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 23.770732ms)
Aug 21 17:09:42.950: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 24.541657ms)
Aug 21 17:09:42.950: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 24.647333ms)
Aug 21 17:09:42.950: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 24.660502ms)
Aug 21 17:09:42.951: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 25.669231ms)
Aug 21 17:09:42.955: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 29.472713ms)
Aug 21 17:09:42.956: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 30.23251ms)
Aug 21 17:09:42.956: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 30.620356ms)
Aug 21 17:09:42.957: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 31.171229ms)
Aug 21 17:09:42.957: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 31.471643ms)
Aug 21 17:09:42.957: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 31.786955ms)
Aug 21 17:09:42.957: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 31.871232ms)
Aug 21 17:09:42.959: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 33.511373ms)
Aug 21 17:09:42.973: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 13.877507ms)
Aug 21 17:09:42.973: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 13.538902ms)
Aug 21 17:09:42.973: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 13.750555ms)
Aug 21 17:09:42.973: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 13.913649ms)
Aug 21 17:09:42.974: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 14.851332ms)
Aug 21 17:09:42.974: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 14.991354ms)
Aug 21 17:09:42.974: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 15.088903ms)
Aug 21 17:09:42.974: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 15.162462ms)
Aug 21 17:09:42.974: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 15.390145ms)
Aug 21 17:09:42.974: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 14.761669ms)
Aug 21 17:09:42.975: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 16.118828ms)
Aug 21 17:09:42.975: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 16.08546ms)
Aug 21 17:09:42.977: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 17.535717ms)
Aug 21 17:09:42.977: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 17.65552ms)
Aug 21 17:09:42.977: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 17.920669ms)
Aug 21 17:09:42.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 18.614125ms)
Aug 21 17:09:42.990: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 10.977032ms)
Aug 21 17:09:42.990: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 11.609229ms)
Aug 21 17:09:42.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 12.146276ms)
Aug 21 17:09:42.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 12.777679ms)
Aug 21 17:09:42.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 12.240623ms)
Aug 21 17:09:42.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 12.636804ms)
Aug 21 17:09:42.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 12.023579ms)
Aug 21 17:09:42.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 12.003252ms)
Aug 21 17:09:42.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 12.197413ms)
Aug 21 17:09:42.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 12.572209ms)
Aug 21 17:09:42.994: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 15.930461ms)
Aug 21 17:09:42.994: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 15.729852ms)
Aug 21 17:09:42.994: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 15.803089ms)
Aug 21 17:09:42.995: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 16.712545ms)
Aug 21 17:09:42.995: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 16.583891ms)
Aug 21 17:09:42.995: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 16.338833ms)
Aug 21 17:09:43.009: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 14.090563ms)
Aug 21 17:09:43.009: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 13.984562ms)
Aug 21 17:09:43.009: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 14.02999ms)
Aug 21 17:09:43.010: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 14.732597ms)
Aug 21 17:09:43.010: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 14.982551ms)
Aug 21 17:09:43.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 15.364896ms)
Aug 21 17:09:43.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 15.66547ms)
Aug 21 17:09:43.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 15.858554ms)
Aug 21 17:09:43.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 15.714779ms)
Aug 21 17:09:43.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 16.039151ms)
Aug 21 17:09:43.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 15.793809ms)
Aug 21 17:09:43.015: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 19.151978ms)
Aug 21 17:09:43.015: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 20.144737ms)
Aug 21 17:09:43.016: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 20.277471ms)
Aug 21 17:09:43.016: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 21.072462ms)
Aug 21 17:09:43.016: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 21.002515ms)
Aug 21 17:09:43.031: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 13.551408ms)
Aug 21 17:09:43.031: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 14.212993ms)
Aug 21 17:09:43.031: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 13.767479ms)
Aug 21 17:09:43.032: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 14.585138ms)
Aug 21 17:09:43.032: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 14.825731ms)
Aug 21 17:09:43.032: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 15.069996ms)
Aug 21 17:09:43.032: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 14.921417ms)
Aug 21 17:09:43.032: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 15.32623ms)
Aug 21 17:09:43.032: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 15.217164ms)
Aug 21 17:09:43.032: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 15.696007ms)
Aug 21 17:09:43.032: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 15.485183ms)
Aug 21 17:09:43.032: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 15.632616ms)
Aug 21 17:09:43.032: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 15.058104ms)
Aug 21 17:09:43.034: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 17.073943ms)
Aug 21 17:09:43.035: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 17.72878ms)
Aug 21 17:09:43.035: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 18.08675ms)
Aug 21 17:09:43.047: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.53374ms)
Aug 21 17:09:43.047: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 11.513321ms)
Aug 21 17:09:43.048: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 12.409018ms)
Aug 21 17:09:43.048: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 12.577796ms)
Aug 21 17:09:43.048: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 12.733795ms)
Aug 21 17:09:43.048: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 12.665608ms)
Aug 21 17:09:43.048: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 12.348534ms)
Aug 21 17:09:43.048: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 12.5419ms)
Aug 21 17:09:43.048: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 12.441754ms)
Aug 21 17:09:43.048: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 12.651062ms)
Aug 21 17:09:43.050: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 14.987201ms)
Aug 21 17:09:43.051: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 15.337701ms)
Aug 21 17:09:43.051: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 16.17971ms)
Aug 21 17:09:43.051: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 16.009503ms)
Aug 21 17:09:43.051: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 16.207907ms)
Aug 21 17:09:43.053: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 17.823778ms)
Aug 21 17:09:43.062: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 8.72867ms)
Aug 21 17:09:43.062: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 9.20521ms)
Aug 21 17:09:43.065: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 10.769812ms)
Aug 21 17:09:43.065: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 11.213276ms)
Aug 21 17:09:43.065: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 11.744822ms)
Aug 21 17:09:43.066: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 12.205853ms)
Aug 21 17:09:43.066: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.819154ms)
Aug 21 17:09:43.066: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 12.203973ms)
Aug 21 17:09:43.066: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 12.169746ms)
Aug 21 17:09:43.066: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 12.598435ms)
Aug 21 17:09:43.069: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 15.080412ms)
Aug 21 17:09:43.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 16.110559ms)
Aug 21 17:09:43.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 15.991019ms)
Aug 21 17:09:43.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 16.042232ms)
Aug 21 17:09:43.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 16.533723ms)
Aug 21 17:09:43.071: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 16.80685ms)
Aug 21 17:09:43.080: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 9.26364ms)
Aug 21 17:09:43.080: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 9.025109ms)
Aug 21 17:09:43.082: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 11.431736ms)
Aug 21 17:09:43.083: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.897957ms)
Aug 21 17:09:43.083: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 11.694264ms)
Aug 21 17:09:43.084: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 12.26702ms)
Aug 21 17:09:43.084: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 12.296206ms)
Aug 21 17:09:43.084: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 12.432997ms)
Aug 21 17:09:43.084: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 12.348055ms)
Aug 21 17:09:43.084: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 12.645451ms)
Aug 21 17:09:43.087: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 16.564556ms)
Aug 21 17:09:43.088: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 17.039153ms)
Aug 21 17:09:43.088: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 16.59111ms)
Aug 21 17:09:43.088: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 17.059088ms)
Aug 21 17:09:43.088: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 17.729315ms)
Aug 21 17:09:43.089: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 17.946444ms)
Aug 21 17:09:43.099: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 9.763812ms)
Aug 21 17:09:43.100: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 11.095838ms)
Aug 21 17:09:43.100: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 11.044162ms)
Aug 21 17:09:43.100: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 11.164271ms)
Aug 21 17:09:43.100: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 11.351663ms)
Aug 21 17:09:43.100: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 11.243868ms)
Aug 21 17:09:43.100: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 11.001587ms)
Aug 21 17:09:43.100: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 10.939903ms)
Aug 21 17:09:43.100: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 11.451084ms)
Aug 21 17:09:43.100: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.158737ms)
Aug 21 17:09:43.103: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 14.270646ms)
Aug 21 17:09:43.103: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 14.181786ms)
Aug 21 17:09:43.104: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 14.616135ms)
Aug 21 17:09:43.104: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 14.367487ms)
Aug 21 17:09:43.104: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 15.123124ms)
Aug 21 17:09:43.104: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 15.003398ms)
Aug 21 17:09:43.116: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.4236ms)
Aug 21 17:09:43.116: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 11.16929ms)
Aug 21 17:09:43.116: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 12.029475ms)
Aug 21 17:09:43.117: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 12.715493ms)
Aug 21 17:09:43.117: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 12.872168ms)
Aug 21 17:09:43.118: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 13.333863ms)
Aug 21 17:09:43.118: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 13.067782ms)
Aug 21 17:09:43.119: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 14.751543ms)
Aug 21 17:09:43.119: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 15.018799ms)
Aug 21 17:09:43.119: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 14.94895ms)
Aug 21 17:09:43.119: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 14.940751ms)
Aug 21 17:09:43.119: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 14.701417ms)
Aug 21 17:09:43.119: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 14.925133ms)
Aug 21 17:09:43.119: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 14.874662ms)
Aug 21 17:09:43.120: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 15.799642ms)
Aug 21 17:09:43.120: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 15.724962ms)
Aug 21 17:09:43.127: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 6.665985ms)
Aug 21 17:09:43.131: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 10.072057ms)
Aug 21 17:09:43.131: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 10.07638ms)
Aug 21 17:09:43.131: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 10.548419ms)
Aug 21 17:09:43.132: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 11.079575ms)
Aug 21 17:09:43.132: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.392789ms)
Aug 21 17:09:43.133: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.842515ms)
Aug 21 17:09:43.133: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 11.763116ms)
Aug 21 17:09:43.133: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 11.997623ms)
Aug 21 17:09:43.133: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 11.948606ms)
Aug 21 17:09:43.134: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 13.040513ms)
Aug 21 17:09:43.134: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 13.618207ms)
Aug 21 17:09:43.134: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 13.746122ms)
Aug 21 17:09:43.135: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 14.32272ms)
Aug 21 17:09:43.136: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 15.671425ms)
Aug 21 17:09:43.137: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 16.225155ms)
Aug 21 17:09:43.148: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 10.044358ms)
Aug 21 17:09:43.148: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 10.829682ms)
Aug 21 17:09:43.150: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 12.692247ms)
Aug 21 17:09:43.151: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 13.413325ms)
Aug 21 17:09:43.151: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 13.490546ms)
Aug 21 17:09:43.151: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 14.139938ms)
Aug 21 17:09:43.152: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 13.812605ms)
Aug 21 17:09:43.152: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 13.893016ms)
Aug 21 17:09:43.153: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 14.530112ms)
Aug 21 17:09:43.153: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 14.725035ms)
Aug 21 17:09:43.158: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 20.822448ms)
Aug 21 17:09:43.159: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 21.376147ms)
Aug 21 17:09:43.159: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 21.519161ms)
Aug 21 17:09:43.160: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 22.17453ms)
Aug 21 17:09:43.160: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 21.711656ms)
Aug 21 17:09:43.160: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 22.088218ms)
Aug 21 17:09:43.171: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 10.215684ms)
Aug 21 17:09:43.171: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 10.323289ms)
Aug 21 17:09:43.171: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 10.661923ms)
Aug 21 17:09:43.171: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 10.530342ms)
Aug 21 17:09:43.172: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 11.460446ms)
Aug 21 17:09:43.172: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 11.732326ms)
Aug 21 17:09:43.172: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 11.634942ms)
Aug 21 17:09:43.172: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 11.406196ms)
Aug 21 17:09:43.172: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 11.447858ms)
Aug 21 17:09:43.172: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.511336ms)
Aug 21 17:09:43.173: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 12.33493ms)
Aug 21 17:09:43.176: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 15.650668ms)
Aug 21 17:09:43.176: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 15.821782ms)
Aug 21 17:09:43.177: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 16.361386ms)
Aug 21 17:09:43.177: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 16.891821ms)
Aug 21 17:09:43.177: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 16.774721ms)
Aug 21 17:09:43.188: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 10.713657ms)
Aug 21 17:09:43.188: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 10.59881ms)
Aug 21 17:09:43.188: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 10.925503ms)
Aug 21 17:09:43.189: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 11.601391ms)
Aug 21 17:09:43.189: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 11.814207ms)
Aug 21 17:09:43.189: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.539388ms)
Aug 21 17:09:43.189: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 11.748796ms)
Aug 21 17:09:43.189: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.60903ms)
Aug 21 17:09:43.190: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 12.208847ms)
Aug 21 17:09:43.190: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 12.259559ms)
Aug 21 17:09:43.191: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 13.130827ms)
Aug 21 17:09:43.194: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 16.218549ms)
Aug 21 17:09:43.194: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 16.989234ms)
Aug 21 17:09:43.195: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 17.578632ms)
Aug 21 17:09:43.195: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 17.777948ms)
Aug 21 17:09:43.195: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 17.870017ms)
Aug 21 17:09:43.206: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 10.113761ms)
Aug 21 17:09:43.206: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 10.156274ms)
Aug 21 17:09:43.206: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 10.560424ms)
Aug 21 17:09:43.206: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 10.33256ms)
Aug 21 17:09:43.206: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 10.40512ms)
Aug 21 17:09:43.207: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 10.85468ms)
Aug 21 17:09:43.207: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 11.191162ms)
Aug 21 17:09:43.207: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 11.155711ms)
Aug 21 17:09:43.207: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 10.891478ms)
Aug 21 17:09:43.207: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.007502ms)
Aug 21 17:09:43.210: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 14.554627ms)
Aug 21 17:09:43.211: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 14.96035ms)
Aug 21 17:09:43.211: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 14.907221ms)
Aug 21 17:09:43.211: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 15.77613ms)
Aug 21 17:09:43.211: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 15.937562ms)
Aug 21 17:09:43.212: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 15.873321ms)
Aug 21 17:09:43.226: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 14.332421ms)
Aug 21 17:09:43.226: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 14.149859ms)
Aug 21 17:09:43.226: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 14.134107ms)
Aug 21 17:09:43.226: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 14.274246ms)
Aug 21 17:09:43.226: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 14.254279ms)
Aug 21 17:09:43.227: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 15.241179ms)
Aug 21 17:09:43.227: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 14.977556ms)
Aug 21 17:09:43.227: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 15.312087ms)
Aug 21 17:09:43.227: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 15.02156ms)
Aug 21 17:09:43.227: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 15.133509ms)
Aug 21 17:09:43.229: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 17.148974ms)
Aug 21 17:09:43.230: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 17.90327ms)
Aug 21 17:09:43.231: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 19.052843ms)
Aug 21 17:09:43.231: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 18.964162ms)
Aug 21 17:09:43.231: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 18.778047ms)
Aug 21 17:09:43.231: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 19.188615ms)
Aug 21 17:09:43.243: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 10.953261ms)
Aug 21 17:09:43.243: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 11.674717ms)
Aug 21 17:09:43.244: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 12.000154ms)
Aug 21 17:09:43.244: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 11.714667ms)
Aug 21 17:09:43.244: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 12.162311ms)
Aug 21 17:09:43.244: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 12.536453ms)
Aug 21 17:09:43.244: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 11.815193ms)
Aug 21 17:09:43.244: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 12.512493ms)
Aug 21 17:09:43.244: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 12.119734ms)
Aug 21 17:09:43.244: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 12.199474ms)
Aug 21 17:09:43.245: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 13.765225ms)
Aug 21 17:09:43.245: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 13.546574ms)
Aug 21 17:09:43.247: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 15.503403ms)
Aug 21 17:09:43.247: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 15.785133ms)
Aug 21 17:09:43.248: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 16.168513ms)
Aug 21 17:09:43.248: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 16.590807ms)
Aug 21 17:09:43.273: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 23.616638ms)
Aug 21 17:09:43.273: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 23.698064ms)
Aug 21 17:09:43.273: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 23.813681ms)
Aug 21 17:09:43.274: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 25.159813ms)
Aug 21 17:09:43.274: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 25.619871ms)
Aug 21 17:09:43.274: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 25.273441ms)
Aug 21 17:09:43.274: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 25.413105ms)
Aug 21 17:09:43.274: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 25.193186ms)
Aug 21 17:09:43.274: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 25.151466ms)
Aug 21 17:09:43.274: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 25.399048ms)
Aug 21 17:09:43.277: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 28.552934ms)
Aug 21 17:09:43.283: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 34.004559ms)
Aug 21 17:09:43.284: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 34.754817ms)
Aug 21 17:09:43.284: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 35.429988ms)
Aug 21 17:09:43.285: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 36.606676ms)
Aug 21 17:09:43.285: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 36.545872ms)
Aug 21 17:09:43.295: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 10.461163ms)
Aug 21 17:09:43.295: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 10.501072ms)
Aug 21 17:09:43.296: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 11.528707ms)
Aug 21 17:09:43.296: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 11.485555ms)
Aug 21 17:09:43.296: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 11.189689ms)
Aug 21 17:09:43.296: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 11.299592ms)
Aug 21 17:09:43.297: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.576204ms)
Aug 21 17:09:43.297: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 11.626212ms)
Aug 21 17:09:43.297: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 11.869528ms)
Aug 21 17:09:43.297: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 11.605694ms)
Aug 21 17:09:43.298: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 12.534354ms)
Aug 21 17:09:43.300: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 14.78333ms)
Aug 21 17:09:43.300: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 15.141419ms)
Aug 21 17:09:43.301: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 15.892077ms)
Aug 21 17:09:43.302: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 17.344576ms)
Aug 21 17:09:43.303: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 17.528945ms)
Aug 21 17:09:43.310: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv/proxy/rewriteme"... (200; 7.009185ms)
Aug 21 17:09:43.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:460/proxy/: tls baz (200; 9.728041ms)
Aug 21 17:09:43.316: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname2/proxy/: tls qux (200; 13.262363ms)
Aug 21 17:09:43.316: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 13.386496ms)
Aug 21 17:09:43.316: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 13.373374ms)
Aug 21 17:09:43.317: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:462/proxy/: tls qux (200; 13.822352ms)
Aug 21 17:09:43.317: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/https:proxy-service-9z8zk-dq7gv:443/proxy/... (200; 13.946796ms)
Aug 21 17:09:43.317: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:162/proxy/: bar (200; 13.996666ms)
Aug 21 17:09:43.317: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:160/proxy/: foo (200; 14.322622ms)
Aug 21 17:09:43.317: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/http:proxy-service-9z8zk-dq7gv:1080/proxy/... (200; 13.88922ms)
Aug 21 17:09:43.317: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/https:proxy-service-9z8zk:tlsportname1/proxy/: tls baz (200; 14.076805ms)
Aug 21 17:09:43.317: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pzhl9/pods/proxy-service-9z8zk-dq7gv:1080/proxy/rewri... (200; 14.554081ms)
Aug 21 17:09:43.320: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname1/proxy/: foo (200; 16.635153ms)
Aug 21 17:09:43.320: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname2/proxy/: bar (200; 16.851554ms)
Aug 21 17:09:43.321: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/proxy-service-9z8zk:portname2/proxy/: bar (200; 17.822063ms)
Aug 21 17:09:43.321: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pzhl9/services/http:proxy-service-9z8zk:portname1/proxy/: foo (200; 17.875466ms)
STEP: deleting ReplicationController proxy-service-9z8zk in namespace e2e-tests-proxy-pzhl9, will wait for the garbage collector to delete the pods
Aug 21 17:09:43.390: INFO: Deleting ReplicationController proxy-service-9z8zk took: 13.463371ms
Aug 21 17:09:43.490: INFO: Terminating ReplicationController proxy-service-9z8zk pods took: 100.228601ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:09:45.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-pzhl9" for this suite.
Aug 21 17:09:51.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:09:51.506: INFO: namespace: e2e-tests-proxy-pzhl9, resource: bindings, ignored listing per whitelist
Aug 21 17:09:51.601: INFO: namespace e2e-tests-proxy-pzhl9 deletion completed in 6.203154662s

â€¢ [SLOW TEST:18.846 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:09:51.601: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-7d0e161c-c436-11e9-89d6-e2e196a4cdca
STEP: Creating configMap with name cm-test-opt-upd-7d0e165b-c436-11e9-89d6-e2e196a4cdca
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-7d0e161c-c436-11e9-89d6-e2e196a4cdca
STEP: Updating configmap cm-test-opt-upd-7d0e165b-c436-11e9-89d6-e2e196a4cdca
STEP: Creating configMap with name cm-test-opt-create-7d0e167a-c436-11e9-89d6-e2e196a4cdca
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:09:59.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sl92w" for this suite.
Aug 21 17:10:19.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:10:19.930: INFO: namespace: e2e-tests-configmap-sl92w, resource: bindings, ignored listing per whitelist
Aug 21 17:10:20.082: INFO: namespace e2e-tests-configmap-sl92w deletion completed in 20.220651911s

â€¢ [SLOW TEST:28.480 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:10:20.082: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 17:10:20.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6698v'
Aug 21 17:10:20.257: INFO: stderr: ""
Aug 21 17:10:20.257: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 21 17:10:25.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6698v -o json'
Aug 21 17:10:25.374: INFO: stderr: ""
Aug 21 17:10:25.374: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-08-21T17:10:20Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-6698v\",\n        \"resourceVersion\": \"12915\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-6698v/pods/e2e-test-nginx-pod\",\n        \"uid\": \"8e1402e9-c436-11e9-bb91-06b2a5b3abd6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-qprz2\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-1-150.us-west-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-qprz2\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-qprz2\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-21T17:10:20Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-21T17:10:22Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-21T17:10:22Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-21T17:10:20Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://aac7dc48c00858f3bd2fbe934d7f70e7eebc1b054f7b38abb8295875f655162a\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-21T17:10:22Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.1.150\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.20.3.76\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-21T17:10:20Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 21 17:10:25.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 replace -f - --namespace=e2e-tests-kubectl-6698v'
Aug 21 17:10:25.554: INFO: stderr: ""
Aug 21 17:10:25.554: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Aug 21 17:10:25.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6698v'
Aug 21 17:10:27.995: INFO: stderr: ""
Aug 21 17:10:27.995: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:10:27.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6698v" for this suite.
Aug 21 17:10:34.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:10:34.163: INFO: namespace: e2e-tests-kubectl-6698v, resource: bindings, ignored listing per whitelist
Aug 21 17:10:34.225: INFO: namespace e2e-tests-kubectl-6698v deletion completed in 6.220852977s

â€¢ [SLOW TEST:14.143 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:10:34.225: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:10:34.311: INFO: Creating deployment "test-recreate-deployment"
Aug 21 17:10:34.322: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 21 17:10:34.340: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 21 17:10:36.352: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 21 17:10:36.358: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702004234, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702004234, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702004234, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702004234, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 17:10:38.364: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 21 17:10:38.378: INFO: Updating deployment test-recreate-deployment
Aug 21 17:10:38.378: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 21 17:10:38.448: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-kw6mn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kw6mn/deployments/test-recreate-deployment,UID:9676cbbc-c436-11e9-b0fd-0afb3721cd16,ResourceVersion:13008,Generation:2,CreationTimestamp:2019-08-21 17:10:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-21 17:10:38 +0000 UTC 2019-08-21 17:10:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-21 17:10:38 +0000 UTC 2019-08-21 17:10:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 21 17:10:38.455: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-kw6mn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kw6mn/replicasets/test-recreate-deployment-697fbf54bf,UID:98e66838-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:13005,Generation:1,CreationTimestamp:2019-08-21 17:10:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9676cbbc-c436-11e9-b0fd-0afb3721cd16 0xc001bb2c07 0xc001bb2c08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 17:10:38.455: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 21 17:10:38.455: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-kw6mn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kw6mn/replicasets/test-recreate-deployment-5dfdcc846d,UID:96778e44-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:12996,Generation:2,CreationTimestamp:2019-08-21 17:10:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9676cbbc-c436-11e9-b0fd-0afb3721cd16 0xc001bb2b47 0xc001bb2b48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 17:10:38.462: INFO: Pod "test-recreate-deployment-697fbf54bf-rnpt5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-rnpt5,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-kw6mn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kw6mn/pods/test-recreate-deployment-697fbf54bf-rnpt5,UID:98e70db8-c436-11e9-bb91-06b2a5b3abd6,ResourceVersion:13009,Generation:0,CreationTimestamp:2019-08-21 17:10:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 98e66838-c436-11e9-bb91-06b2a5b3abd6 0xc0017e0267 0xc0017e0268}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l75pm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l75pm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l75pm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:10:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:10:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:10:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:10:38 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:,StartTime:2019-08-21 17:10:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:10:38.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-kw6mn" for this suite.
Aug 21 17:10:44.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:10:44.689: INFO: namespace: e2e-tests-deployment-kw6mn, resource: bindings, ignored listing per whitelist
Aug 21 17:10:44.699: INFO: namespace e2e-tests-deployment-kw6mn deletion completed in 6.229520311s

â€¢ [SLOW TEST:10.474 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:10:44.699: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-gphk
STEP: Creating a pod to test atomic-volume-subpath
Aug 21 17:10:44.816: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gphk" in namespace "e2e-tests-subpath-zfr85" to be "success or failure"
Aug 21 17:10:44.827: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Pending", Reason="", readiness=false. Elapsed: 10.536607ms
Aug 21 17:10:46.834: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017365868s
Aug 21 17:10:48.840: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024219446s
Aug 21 17:10:50.847: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Running", Reason="", readiness=false. Elapsed: 6.031115235s
Aug 21 17:10:52.854: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Running", Reason="", readiness=false. Elapsed: 8.03741257s
Aug 21 17:10:54.860: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Running", Reason="", readiness=false. Elapsed: 10.043969234s
Aug 21 17:10:56.867: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Running", Reason="", readiness=false. Elapsed: 12.050703001s
Aug 21 17:10:58.874: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Running", Reason="", readiness=false. Elapsed: 14.05793577s
Aug 21 17:11:00.881: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Running", Reason="", readiness=false. Elapsed: 16.065043514s
Aug 21 17:11:02.888: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Running", Reason="", readiness=false. Elapsed: 18.072251642s
Aug 21 17:11:04.895: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Running", Reason="", readiness=false. Elapsed: 20.078896595s
Aug 21 17:11:06.902: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Running", Reason="", readiness=false. Elapsed: 22.085394085s
Aug 21 17:11:08.908: INFO: Pod "pod-subpath-test-configmap-gphk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.092042192s
STEP: Saw pod success
Aug 21 17:11:08.908: INFO: Pod "pod-subpath-test-configmap-gphk" satisfied condition "success or failure"
Aug 21 17:11:08.914: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-subpath-test-configmap-gphk container test-container-subpath-configmap-gphk: <nil>
STEP: delete the pod
Aug 21 17:11:08.996: INFO: Waiting for pod pod-subpath-test-configmap-gphk to disappear
Aug 21 17:11:09.002: INFO: Pod pod-subpath-test-configmap-gphk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gphk
Aug 21 17:11:09.002: INFO: Deleting pod "pod-subpath-test-configmap-gphk" in namespace "e2e-tests-subpath-zfr85"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:11:09.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-zfr85" for this suite.
Aug 21 17:11:15.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:11:15.078: INFO: namespace: e2e-tests-subpath-zfr85, resource: bindings, ignored listing per whitelist
Aug 21 17:11:15.241: INFO: namespace e2e-tests-subpath-zfr85 deletion completed in 6.22617838s

â€¢ [SLOW TEST:30.542 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:11:15.242: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 21 17:11:15.330: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:11:19.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-94w4b" for this suite.
Aug 21 17:11:41.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:11:41.908: INFO: namespace: e2e-tests-init-container-94w4b, resource: bindings, ignored listing per whitelist
Aug 21 17:11:42.061: INFO: namespace e2e-tests-init-container-94w4b deletion completed in 22.215966513s

â€¢ [SLOW TEST:26.820 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:11:42.062: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Aug 21 17:11:42.159: INFO: Waiting up to 5m0s for pod "var-expansion-bee4cec4-c436-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-var-expansion-7lc9d" to be "success or failure"
Aug 21 17:11:42.168: INFO: Pod "var-expansion-bee4cec4-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 8.815471ms
Aug 21 17:11:44.175: INFO: Pod "var-expansion-bee4cec4-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015482662s
Aug 21 17:11:46.182: INFO: Pod "var-expansion-bee4cec4-c436-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02213044s
STEP: Saw pod success
Aug 21 17:11:46.182: INFO: Pod "var-expansion-bee4cec4-c436-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:11:46.187: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod var-expansion-bee4cec4-c436-11e9-89d6-e2e196a4cdca container dapi-container: <nil>
STEP: delete the pod
Aug 21 17:11:46.220: INFO: Waiting for pod var-expansion-bee4cec4-c436-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:11:46.226: INFO: Pod var-expansion-bee4cec4-c436-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:11:46.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-7lc9d" for this suite.
Aug 21 17:11:52.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:11:52.342: INFO: namespace: e2e-tests-var-expansion-7lc9d, resource: bindings, ignored listing per whitelist
Aug 21 17:11:52.451: INFO: namespace e2e-tests-var-expansion-7lc9d deletion completed in 6.218646313s

â€¢ [SLOW TEST:10.390 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:11:52.451: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 21 17:11:52.548: INFO: Waiting up to 5m0s for pod "pod-c515dc18-c436-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-6ps2r" to be "success or failure"
Aug 21 17:11:52.555: INFO: Pod "pod-c515dc18-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.665123ms
Aug 21 17:11:54.562: INFO: Pod "pod-c515dc18-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013391573s
Aug 21 17:11:56.568: INFO: Pod "pod-c515dc18-c436-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019930637s
STEP: Saw pod success
Aug 21 17:11:56.568: INFO: Pod "pod-c515dc18-c436-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:11:56.574: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-c515dc18-c436-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 17:11:56.608: INFO: Waiting for pod pod-c515dc18-c436-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:11:56.613: INFO: Pod pod-c515dc18-c436-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:11:56.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6ps2r" for this suite.
Aug 21 17:12:02.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:12:02.768: INFO: namespace: e2e-tests-emptydir-6ps2r, resource: bindings, ignored listing per whitelist
Aug 21 17:12:02.850: INFO: namespace e2e-tests-emptydir-6ps2r deletion completed in 6.229847552s

â€¢ [SLOW TEST:10.399 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:12:02.850: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-cb499dc1-c436-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 17:12:02.961: INFO: Waiting up to 5m0s for pod "pod-secrets-cb4b6a1d-c436-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-secrets-zf2pg" to be "success or failure"
Aug 21 17:12:02.969: INFO: Pod "pod-secrets-cb4b6a1d-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 8.306774ms
Aug 21 17:12:04.977: INFO: Pod "pod-secrets-cb4b6a1d-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015927413s
Aug 21 17:12:06.984: INFO: Pod "pod-secrets-cb4b6a1d-c436-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022623613s
STEP: Saw pod success
Aug 21 17:12:06.984: INFO: Pod "pod-secrets-cb4b6a1d-c436-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:12:06.989: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-secrets-cb4b6a1d-c436-11e9-89d6-e2e196a4cdca container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 17:12:07.021: INFO: Waiting for pod pod-secrets-cb4b6a1d-c436-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:12:07.027: INFO: Pod pod-secrets-cb4b6a1d-c436-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:12:07.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zf2pg" for this suite.
Aug 21 17:12:13.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:12:13.232: INFO: namespace: e2e-tests-secrets-zf2pg, resource: bindings, ignored listing per whitelist
Aug 21 17:12:13.250: INFO: namespace e2e-tests-secrets-zf2pg deletion completed in 6.215335002s

â€¢ [SLOW TEST:10.400 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:12:13.250: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 17:12:13.348: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d17b8c4d-c436-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-ldm48" to be "success or failure"
Aug 21 17:12:13.355: INFO: Pod "downwardapi-volume-d17b8c4d-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.164534ms
Aug 21 17:12:15.362: INFO: Pod "downwardapi-volume-d17b8c4d-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01365602s
Aug 21 17:12:17.369: INFO: Pod "downwardapi-volume-d17b8c4d-c436-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020659771s
STEP: Saw pod success
Aug 21 17:12:17.369: INFO: Pod "downwardapi-volume-d17b8c4d-c436-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:12:17.374: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downwardapi-volume-d17b8c4d-c436-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 17:12:17.407: INFO: Waiting for pod downwardapi-volume-d17b8c4d-c436-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:12:17.413: INFO: Pod downwardapi-volume-d17b8c4d-c436-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:12:17.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ldm48" for this suite.
Aug 21 17:12:23.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:12:23.507: INFO: namespace: e2e-tests-downward-api-ldm48, resource: bindings, ignored listing per whitelist
Aug 21 17:12:23.626: INFO: namespace e2e-tests-downward-api-ldm48 deletion completed in 6.204657146s

â€¢ [SLOW TEST:10.376 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:12:23.626: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 21 17:12:23.720: INFO: Waiting up to 5m0s for pod "pod-d7aa8b6b-c436-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-vf5mc" to be "success or failure"
Aug 21 17:12:23.726: INFO: Pod "pod-d7aa8b6b-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.49299ms
Aug 21 17:12:25.733: INFO: Pod "pod-d7aa8b6b-c436-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012953648s
Aug 21 17:12:27.740: INFO: Pod "pod-d7aa8b6b-c436-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019773565s
STEP: Saw pod success
Aug 21 17:12:27.740: INFO: Pod "pod-d7aa8b6b-c436-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:12:27.745: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-d7aa8b6b-c436-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 17:12:27.775: INFO: Waiting for pod pod-d7aa8b6b-c436-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:12:27.780: INFO: Pod pod-d7aa8b6b-c436-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:12:27.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vf5mc" for this suite.
Aug 21 17:12:33.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:12:33.892: INFO: namespace: e2e-tests-emptydir-vf5mc, resource: bindings, ignored listing per whitelist
Aug 21 17:12:34.010: INFO: namespace e2e-tests-emptydir-vf5mc deletion completed in 6.223147563s

â€¢ [SLOW TEST:10.384 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:12:34.010: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Aug 21 17:12:34.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 cluster-info'
Aug 21 17:12:34.226: INFO: stderr: ""
Aug 21 17:12:34.226: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:12:34.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ln4qp" for this suite.
Aug 21 17:12:40.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:12:40.265: INFO: namespace: e2e-tests-kubectl-ln4qp, resource: bindings, ignored listing per whitelist
Aug 21 17:12:40.441: INFO: namespace e2e-tests-kubectl-ln4qp deletion completed in 6.20646993s

â€¢ [SLOW TEST:6.431 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:12:40.441: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 21 17:12:40.555: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-kbhxz,SelfLink:/api/v1/namespaces/e2e-tests-watch-kbhxz/configmaps/e2e-watch-test-label-changed,UID:e1b115d9-c436-11e9-b0fd-0afb3721cd16,ResourceVersion:13483,Generation:0,CreationTimestamp:2019-08-21 17:12:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 21 17:12:40.555: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-kbhxz,SelfLink:/api/v1/namespaces/e2e-tests-watch-kbhxz/configmaps/e2e-watch-test-label-changed,UID:e1b115d9-c436-11e9-b0fd-0afb3721cd16,ResourceVersion:13484,Generation:0,CreationTimestamp:2019-08-21 17:12:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 21 17:12:40.555: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-kbhxz,SelfLink:/api/v1/namespaces/e2e-tests-watch-kbhxz/configmaps/e2e-watch-test-label-changed,UID:e1b115d9-c436-11e9-b0fd-0afb3721cd16,ResourceVersion:13485,Generation:0,CreationTimestamp:2019-08-21 17:12:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 21 17:12:50.601: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-kbhxz,SelfLink:/api/v1/namespaces/e2e-tests-watch-kbhxz/configmaps/e2e-watch-test-label-changed,UID:e1b115d9-c436-11e9-b0fd-0afb3721cd16,ResourceVersion:13506,Generation:0,CreationTimestamp:2019-08-21 17:12:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 21 17:12:50.601: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-kbhxz,SelfLink:/api/v1/namespaces/e2e-tests-watch-kbhxz/configmaps/e2e-watch-test-label-changed,UID:e1b115d9-c436-11e9-b0fd-0afb3721cd16,ResourceVersion:13507,Generation:0,CreationTimestamp:2019-08-21 17:12:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 21 17:12:50.602: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-kbhxz,SelfLink:/api/v1/namespaces/e2e-tests-watch-kbhxz/configmaps/e2e-watch-test-label-changed,UID:e1b115d9-c436-11e9-b0fd-0afb3721cd16,ResourceVersion:13508,Generation:0,CreationTimestamp:2019-08-21 17:12:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:12:50.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-kbhxz" for this suite.
Aug 21 17:12:56.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:12:56.691: INFO: namespace: e2e-tests-watch-kbhxz, resource: bindings, ignored listing per whitelist
Aug 21 17:12:56.821: INFO: namespace e2e-tests-watch-kbhxz deletion completed in 6.212910237s

â€¢ [SLOW TEST:16.380 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:12:56.821: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:12:56.936: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 21 17:12:56.954: INFO: Number of nodes with available pods: 0
Aug 21 17:12:56.954: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 21 17:12:56.980: INFO: Number of nodes with available pods: 0
Aug 21 17:12:56.980: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:12:57.987: INFO: Number of nodes with available pods: 0
Aug 21 17:12:57.987: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:12:58.987: INFO: Number of nodes with available pods: 0
Aug 21 17:12:58.987: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:12:59.987: INFO: Number of nodes with available pods: 1
Aug 21 17:12:59.987: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 21 17:13:00.028: INFO: Number of nodes with available pods: 0
Aug 21 17:13:00.028: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 21 17:13:00.059: INFO: Number of nodes with available pods: 0
Aug 21 17:13:00.059: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:01.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:01.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:02.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:02.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:03.067: INFO: Number of nodes with available pods: 0
Aug 21 17:13:03.067: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:04.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:04.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:05.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:05.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:06.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:06.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:07.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:07.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:08.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:08.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:09.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:09.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:10.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:10.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:11.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:11.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:12.065: INFO: Number of nodes with available pods: 0
Aug 21 17:13:12.065: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:13.065: INFO: Number of nodes with available pods: 0
Aug 21 17:13:13.065: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:14.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:14.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:15.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:15.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:16.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:16.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:17.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:17.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:18.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:18.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:19.067: INFO: Number of nodes with available pods: 0
Aug 21 17:13:19.067: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:20.065: INFO: Number of nodes with available pods: 0
Aug 21 17:13:20.065: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:21.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:21.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:22.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:22.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:23.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:23.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:24.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:24.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:25.065: INFO: Number of nodes with available pods: 0
Aug 21 17:13:25.065: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:26.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:26.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:27.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:27.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:28.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:28.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:29.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:29.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:30.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:30.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:31.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:31.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:32.067: INFO: Number of nodes with available pods: 0
Aug 21 17:13:32.067: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:33.065: INFO: Number of nodes with available pods: 0
Aug 21 17:13:33.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:34.066: INFO: Number of nodes with available pods: 0
Aug 21 17:13:34.066: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:35.065: INFO: Number of nodes with available pods: 0
Aug 21 17:13:35.065: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:13:36.066: INFO: Number of nodes with available pods: 1
Aug 21 17:13:36.066: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-qpdgp, will wait for the garbage collector to delete the pods
Aug 21 17:13:36.149: INFO: Deleting DaemonSet.extensions daemon-set took: 14.015535ms
Aug 21 17:13:36.250: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.211305ms
Aug 21 17:14:10.156: INFO: Number of nodes with available pods: 0
Aug 21 17:14:10.156: INFO: Number of running nodes: 0, number of available pods: 0
Aug 21 17:14:10.162: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qpdgp/daemonsets","resourceVersion":"13718"},"items":null}

Aug 21 17:14:10.167: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qpdgp/pods","resourceVersion":"13718"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:14:10.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qpdgp" for this suite.
Aug 21 17:14:16.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:14:16.405: INFO: namespace: e2e-tests-daemonsets-qpdgp, resource: bindings, ignored listing per whitelist
Aug 21 17:14:16.412: INFO: namespace e2e-tests-daemonsets-qpdgp deletion completed in 6.204055081s

â€¢ [SLOW TEST:79.591 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:14:16.412: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 21 17:14:21.064: INFO: Successfully updated pod "annotationupdate1ae44834-c437-11e9-89d6-e2e196a4cdca"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:14:23.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mpxk7" for this suite.
Aug 21 17:14:45.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:14:45.190: INFO: namespace: e2e-tests-downward-api-mpxk7, resource: bindings, ignored listing per whitelist
Aug 21 17:14:45.314: INFO: namespace e2e-tests-downward-api-mpxk7 deletion completed in 22.204490801s

â€¢ [SLOW TEST:28.902 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:14:45.314: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0821 17:15:25.454041      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 17:15:25.454: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:15:25.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-b6krp" for this suite.
Aug 21 17:15:31.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:15:31.635: INFO: namespace: e2e-tests-gc-b6krp, resource: bindings, ignored listing per whitelist
Aug 21 17:15:31.670: INFO: namespace e2e-tests-gc-b6krp deletion completed in 6.209546438s

â€¢ [SLOW TEST:46.356 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:15:31.671: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-47c14876-c437-11e9-89d6-e2e196a4cdca
STEP: Creating secret with name s-test-opt-upd-47c148c4-c437-11e9-89d6-e2e196a4cdca
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-47c14876-c437-11e9-89d6-e2e196a4cdca
STEP: Updating secret s-test-opt-upd-47c148c4-c437-11e9-89d6-e2e196a4cdca
STEP: Creating secret with name s-test-opt-create-47c14902-c437-11e9-89d6-e2e196a4cdca
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:15:37.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r92q8" for this suite.
Aug 21 17:15:59.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:16:00.058: INFO: namespace: e2e-tests-projected-r92q8, resource: bindings, ignored listing per whitelist
Aug 21 17:16:00.216: INFO: namespace e2e-tests-projected-r92q8 deletion completed in 22.290414809s

â€¢ [SLOW TEST:28.545 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:16:00.216: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 21 17:16:00.316: INFO: Waiting up to 5m0s for pod "pod-58c4653d-c437-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-bg7xn" to be "success or failure"
Aug 21 17:16:00.323: INFO: Pod "pod-58c4653d-c437-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.310281ms
Aug 21 17:16:02.330: INFO: Pod "pod-58c4653d-c437-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013952511s
Aug 21 17:16:04.337: INFO: Pod "pod-58c4653d-c437-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020934827s
STEP: Saw pod success
Aug 21 17:16:04.337: INFO: Pod "pod-58c4653d-c437-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:16:04.343: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-58c4653d-c437-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 17:16:04.376: INFO: Waiting for pod pod-58c4653d-c437-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:16:04.381: INFO: Pod pod-58c4653d-c437-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:16:04.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bg7xn" for this suite.
Aug 21 17:16:10.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:16:10.490: INFO: namespace: e2e-tests-emptydir-bg7xn, resource: bindings, ignored listing per whitelist
Aug 21 17:16:10.617: INFO: namespace e2e-tests-emptydir-bg7xn deletion completed in 6.228309015s

â€¢ [SLOW TEST:10.401 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:16:10.617: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 21 17:16:10.735: INFO: Waiting up to 5m0s for pod "downward-api-5ef9ea71-c437-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-cwwrk" to be "success or failure"
Aug 21 17:16:10.742: INFO: Pod "downward-api-5ef9ea71-c437-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.911382ms
Aug 21 17:16:12.749: INFO: Pod "downward-api-5ef9ea71-c437-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014197833s
Aug 21 17:16:14.756: INFO: Pod "downward-api-5ef9ea71-c437-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021287299s
STEP: Saw pod success
Aug 21 17:16:14.756: INFO: Pod "downward-api-5ef9ea71-c437-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:16:14.762: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downward-api-5ef9ea71-c437-11e9-89d6-e2e196a4cdca container dapi-container: <nil>
STEP: delete the pod
Aug 21 17:16:14.795: INFO: Waiting for pod downward-api-5ef9ea71-c437-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:16:14.801: INFO: Pod downward-api-5ef9ea71-c437-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:16:14.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cwwrk" for this suite.
Aug 21 17:16:20.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:16:20.850: INFO: namespace: e2e-tests-downward-api-cwwrk, resource: bindings, ignored listing per whitelist
Aug 21 17:16:21.034: INFO: namespace e2e-tests-downward-api-cwwrk deletion completed in 6.225632335s

â€¢ [SLOW TEST:10.417 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:16:21.034: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:16:21.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hgs7g" for this suite.
Aug 21 17:16:27.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:16:27.161: INFO: namespace: e2e-tests-services-hgs7g, resource: bindings, ignored listing per whitelist
Aug 21 17:16:27.353: INFO: namespace e2e-tests-services-hgs7g deletion completed in 6.224303913s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:6.319 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:16:27.353: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-68f3dbf0-c437-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 17:16:27.478: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-68f57ff6-c437-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-w6n2j" to be "success or failure"
Aug 21 17:16:27.484: INFO: Pod "pod-projected-secrets-68f57ff6-c437-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.527386ms
Aug 21 17:16:29.491: INFO: Pod "pod-projected-secrets-68f57ff6-c437-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013026s
Aug 21 17:16:31.497: INFO: Pod "pod-projected-secrets-68f57ff6-c437-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019380707s
STEP: Saw pod success
Aug 21 17:16:31.497: INFO: Pod "pod-projected-secrets-68f57ff6-c437-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:16:31.503: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-projected-secrets-68f57ff6-c437-11e9-89d6-e2e196a4cdca container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 17:16:31.534: INFO: Waiting for pod pod-projected-secrets-68f57ff6-c437-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:16:31.540: INFO: Pod pod-projected-secrets-68f57ff6-c437-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:16:31.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w6n2j" for this suite.
Aug 21 17:16:37.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:16:37.607: INFO: namespace: e2e-tests-projected-w6n2j, resource: bindings, ignored listing per whitelist
Aug 21 17:16:37.753: INFO: namespace e2e-tests-projected-w6n2j deletion completed in 6.206069502s

â€¢ [SLOW TEST:10.400 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:16:37.753: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-znqvf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 21 17:16:37.833: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 21 17:16:55.979: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.3.91:8080/dial?request=hostName&protocol=http&host=10.20.12.67&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-znqvf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 17:16:55.979: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 17:16:56.238: INFO: Waiting for endpoints: map[]
Aug 21 17:16:56.247: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.3.91:8080/dial?request=hostName&protocol=http&host=10.20.35.28&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-znqvf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 17:16:56.247: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 17:16:56.414: INFO: Waiting for endpoints: map[]
Aug 21 17:16:56.421: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.3.91:8080/dial?request=hostName&protocol=http&host=10.20.3.90&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-znqvf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 17:16:56.421: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 17:16:56.584: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:16:56.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-znqvf" for this suite.
Aug 21 17:17:18.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:17:18.752: INFO: namespace: e2e-tests-pod-network-test-znqvf, resource: bindings, ignored listing per whitelist
Aug 21 17:17:18.793: INFO: namespace e2e-tests-pod-network-test-znqvf deletion completed in 22.201474371s

â€¢ [SLOW TEST:41.040 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:17:18.793: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-82jgc/configmap-test-8799a095-c437-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:17:18.896: INFO: Waiting up to 5m0s for pod "pod-configmaps-879b439d-c437-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-configmap-82jgc" to be "success or failure"
Aug 21 17:17:18.902: INFO: Pod "pod-configmaps-879b439d-c437-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012736ms
Aug 21 17:17:20.908: INFO: Pod "pod-configmaps-879b439d-c437-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012121325s
Aug 21 17:17:22.914: INFO: Pod "pod-configmaps-879b439d-c437-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018572088s
STEP: Saw pod success
Aug 21 17:17:22.914: INFO: Pod "pod-configmaps-879b439d-c437-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:17:22.920: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-configmaps-879b439d-c437-11e9-89d6-e2e196a4cdca container env-test: <nil>
STEP: delete the pod
Aug 21 17:17:22.950: INFO: Waiting for pod pod-configmaps-879b439d-c437-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:17:22.955: INFO: Pod pod-configmaps-879b439d-c437-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:17:22.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-82jgc" for this suite.
Aug 21 17:17:28.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:17:29.079: INFO: namespace: e2e-tests-configmap-82jgc, resource: bindings, ignored listing per whitelist
Aug 21 17:17:29.179: INFO: namespace e2e-tests-configmap-82jgc deletion completed in 6.217552153s

â€¢ [SLOW TEST:10.386 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:17:29.180: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-2tmjg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2tmjg to expose endpoints map[]
Aug 21 17:17:29.289: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2tmjg exposes endpoints map[] (9.696458ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-2tmjg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2tmjg to expose endpoints map[pod1:[100]]
Aug 21 17:17:32.353: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2tmjg exposes endpoints map[pod1:[100]] (3.048190459s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-2tmjg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2tmjg to expose endpoints map[pod1:[100] pod2:[101]]
Aug 21 17:17:35.430: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2tmjg exposes endpoints map[pod2:[101] pod1:[100]] (3.069575847s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-2tmjg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2tmjg to expose endpoints map[pod2:[101]]
Aug 21 17:17:35.451: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2tmjg exposes endpoints map[pod2:[101]] (11.479616ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-2tmjg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-2tmjg to expose endpoints map[]
Aug 21 17:17:35.469: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-2tmjg exposes endpoints map[] (6.968088ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:17:35.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-2tmjg" for this suite.
Aug 21 17:17:41.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:17:41.682: INFO: namespace: e2e-tests-services-2tmjg, resource: bindings, ignored listing per whitelist
Aug 21 17:17:41.721: INFO: namespace e2e-tests-services-2tmjg deletion completed in 6.209536236s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:12.542 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:17:41.721: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 21 17:17:49.882: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 17:17:49.887: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 17:17:51.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 17:17:51.894: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 17:17:53.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 17:17:53.894: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 17:17:55.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 17:17:55.894: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 17:17:57.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 17:17:57.894: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 17:17:59.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 17:17:59.893: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 17:18:01.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 17:18:01.894: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 17:18:03.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 17:18:03.894: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 17:18:05.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 17:18:05.894: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 21 17:18:07.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 21 17:18:07.894: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:18:07.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gphr5" for this suite.
Aug 21 17:18:29.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:18:29.966: INFO: namespace: e2e-tests-container-lifecycle-hook-gphr5, resource: bindings, ignored listing per whitelist
Aug 21 17:18:30.143: INFO: namespace e2e-tests-container-lifecycle-hook-gphr5 deletion completed in 22.240847242s

â€¢ [SLOW TEST:48.421 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:18:30.143: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Aug 21 17:18:30.251: INFO: Waiting up to 5m0s for pod "var-expansion-b2229aa3-c437-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-var-expansion-9h7wq" to be "success or failure"
Aug 21 17:18:30.258: INFO: Pod "var-expansion-b2229aa3-c437-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.305094ms
Aug 21 17:18:32.268: INFO: Pod "var-expansion-b2229aa3-c437-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016112591s
Aug 21 17:18:34.274: INFO: Pod "var-expansion-b2229aa3-c437-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02284478s
STEP: Saw pod success
Aug 21 17:18:34.274: INFO: Pod "var-expansion-b2229aa3-c437-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:18:34.283: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod var-expansion-b2229aa3-c437-11e9-89d6-e2e196a4cdca container dapi-container: <nil>
STEP: delete the pod
Aug 21 17:18:34.315: INFO: Waiting for pod var-expansion-b2229aa3-c437-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:18:34.320: INFO: Pod var-expansion-b2229aa3-c437-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:18:34.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-9h7wq" for this suite.
Aug 21 17:18:40.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:18:40.484: INFO: namespace: e2e-tests-var-expansion-9h7wq, resource: bindings, ignored listing per whitelist
Aug 21 17:18:40.530: INFO: namespace e2e-tests-var-expansion-9h7wq deletion completed in 6.203196411s

â€¢ [SLOW TEST:10.387 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:18:40.530: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Aug 21 17:18:44.662: INFO: Pod pod-hostip-b853385d-c437-11e9-89d6-e2e196a4cdca has hostIP: 10.0.3.38
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:18:44.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pplcf" for this suite.
Aug 21 17:19:06.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:19:06.800: INFO: namespace: e2e-tests-pods-pplcf, resource: bindings, ignored listing per whitelist
Aug 21 17:19:06.879: INFO: namespace e2e-tests-pods-pplcf deletion completed in 22.209237908s

â€¢ [SLOW TEST:26.349 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:19:06.879: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-f97xc
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-f97xc
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-f97xc
Aug 21 17:19:07.021: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Aug 21 17:19:17.028: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 21 17:19:17.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 17:19:17.276: INFO: stderr: ""
Aug 21 17:19:17.276: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 17:19:17.276: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 17:19:17.284: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 21 17:19:27.292: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 17:19:27.292: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 17:19:27.319: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:19:27.319: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:19:27.319: INFO: ss-1                                            Pending         []
Aug 21 17:19:27.319: INFO: 
Aug 21 17:19:27.319: INFO: StatefulSet ss has not reached scale 3, at 2
Aug 21 17:19:28.328: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991451375s
Aug 21 17:19:29.335: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982710344s
Aug 21 17:19:30.342: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.97538867s
Aug 21 17:19:31.349: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.967999374s
Aug 21 17:19:32.357: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.960868913s
Aug 21 17:19:33.364: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.952897286s
Aug 21 17:19:34.372: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.945746284s
Aug 21 17:19:35.379: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.938584868s
Aug 21 17:19:36.387: INFO: Verifying statefulset ss doesn't scale past 3 for another 930.96024ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-f97xc
Aug 21 17:19:37.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:19:37.632: INFO: stderr: ""
Aug 21 17:19:37.632: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 17:19:37.632: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 17:19:37.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:19:37.903: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Aug 21 17:19:37.903: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 17:19:37.903: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 17:19:37.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:19:38.168: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Aug 21 17:19:38.168: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 17:19:38.168: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 17:19:38.175: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 21 17:19:48.182: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:19:48.182: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:19:48.182: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 21 17:19:48.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 17:19:48.428: INFO: stderr: ""
Aug 21 17:19:48.428: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 17:19:48.428: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 17:19:48.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 17:19:48.662: INFO: stderr: ""
Aug 21 17:19:48.662: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 17:19:48.662: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 17:19:48.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 17:19:48.904: INFO: stderr: ""
Aug 21 17:19:48.904: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 17:19:48.904: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 17:19:48.904: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 17:19:48.910: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 21 17:19:58.923: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 17:19:58.923: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 17:19:58.923: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 21 17:19:58.942: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:19:58.942: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:19:58.942: INFO: ss-1  ip-10-0-3-38.us-west-2.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  }]
Aug 21 17:19:58.942: INFO: ss-2  ip-10-0-2-169.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  }]
Aug 21 17:19:58.942: INFO: 
Aug 21 17:19:58.942: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 21 17:19:59.950: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:19:59.950: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:19:59.950: INFO: ss-1  ip-10-0-3-38.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  }]
Aug 21 17:19:59.950: INFO: ss-2  ip-10-0-2-169.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  }]
Aug 21 17:19:59.950: INFO: 
Aug 21 17:19:59.950: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 21 17:20:00.958: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:20:00.958: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:20:00.958: INFO: ss-1  ip-10-0-3-38.us-west-2.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  }]
Aug 21 17:20:00.958: INFO: ss-2  ip-10-0-2-169.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  }]
Aug 21 17:20:00.958: INFO: 
Aug 21 17:20:00.958: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 21 17:20:01.966: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:20:01.966: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:20:01.966: INFO: ss-2  ip-10-0-2-169.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  }]
Aug 21 17:20:01.966: INFO: 
Aug 21 17:20:01.966: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 21 17:20:02.973: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:20:02.973: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:20:02.973: INFO: ss-2  ip-10-0-2-169.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  }]
Aug 21 17:20:02.974: INFO: 
Aug 21 17:20:02.974: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 21 17:20:03.981: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:20:03.981: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:20:03.981: INFO: ss-2  ip-10-0-2-169.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:27 +0000 UTC  }]
Aug 21 17:20:03.981: INFO: 
Aug 21 17:20:03.981: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 21 17:20:04.995: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:20:04.995: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:20:04.995: INFO: 
Aug 21 17:20:04.995: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 21 17:20:06.010: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:20:06.010: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:20:06.010: INFO: 
Aug 21 17:20:06.010: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 21 17:20:07.025: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:20:07.025: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:20:07.025: INFO: 
Aug 21 17:20:07.025: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 21 17:20:08.036: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Aug 21 17:20:08.036: INFO: ss-0  ip-10-0-1-150.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:19:06 +0000 UTC  }]
Aug 21 17:20:08.036: INFO: 
Aug 21 17:20:08.036: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-f97xc
Aug 21 17:20:09.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:20:09.140: INFO: rc: 1
Aug 21 17:20:09.140: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001927170 exit status 1 <nil> <nil> true [0xc0019f0050 0xc0019f0068 0xc0019f0080] [0xc0019f0050 0xc0019f0068 0xc0019f0080] [0xc0019f0060 0xc0019f0078] [0x92f8e0 0x92f8e0] 0xc000c20420 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Aug 21 17:20:19.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:20:19.205: INFO: rc: 1
Aug 21 17:20:19.205: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00192a3f0 exit status 1 <nil> <nil> true [0xc0014fc0a0 0xc0014fc158 0xc0014fc380] [0xc0014fc0a0 0xc0014fc158 0xc0014fc380] [0xc0014fc100 0xc0014fc270] [0x92f8e0 0x92f8e0] 0xc0013de540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:20:29.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:20:29.272: INFO: rc: 1
Aug 21 17:20:29.272: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0019275f0 exit status 1 <nil> <nil> true [0xc0019f0098 0xc0019f00d8 0xc0019f00f0] [0xc0019f0098 0xc0019f00d8 0xc0019f00f0] [0xc0019f00d0 0xc0019f00e8] [0x92f8e0 0x92f8e0] 0xc000c20720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:20:39.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:20:39.344: INFO: rc: 1
Aug 21 17:20:39.344: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001927da0 exit status 1 <nil> <nil> true [0xc0019f0108 0xc0019f0130 0xc0019f0148] [0xc0019f0108 0xc0019f0130 0xc0019f0148] [0xc0019f0128 0xc0019f0140] [0x92f8e0 0x92f8e0] 0xc000c20a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:20:49.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:20:49.416: INFO: rc: 1
Aug 21 17:20:49.416: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00192a810 exit status 1 <nil> <nil> true [0xc0014fc3c0 0xc0014fc490 0xc0014fc590] [0xc0014fc3c0 0xc0014fc490 0xc0014fc590] [0xc0014fc428 0xc0014fc558] [0x92f8e0 0x92f8e0] 0xc0013de9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:20:59.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:20:59.481: INFO: rc: 1
Aug 21 17:20:59.481: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a96d20 exit status 1 <nil> <nil> true [0xc0019f0160 0xc0019f01a8 0xc0019f01d0] [0xc0019f0160 0xc0019f01a8 0xc0019f01d0] [0xc0019f0198 0xc0019f01c8] [0x92f8e0 0x92f8e0] 0xc000c20d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:21:09.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:21:09.554: INFO: rc: 1
Aug 21 17:21:09.554: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a97320 exit status 1 <nil> <nil> true [0xc0019f01e8 0xc0019f0228 0xc0019f0258] [0xc0019f01e8 0xc0019f0228 0xc0019f0258] [0xc0019f0220 0xc0019f0238] [0x92f8e0 0x92f8e0] 0xc000c21080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:21:19.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:21:19.619: INFO: rc: 1
Aug 21 17:21:19.619: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00192b830 exit status 1 <nil> <nil> true [0xc0014fc5c8 0xc0014fc8a0 0xc0014fcaf0] [0xc0014fc5c8 0xc0014fc8a0 0xc0014fcaf0] [0xc0014fc7c0 0xc0014fca48] [0x92f8e0 0x92f8e0] 0xc0013ded20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:21:29.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:21:29.691: INFO: rc: 1
Aug 21 17:21:29.691: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a97950 exit status 1 <nil> <nil> true [0xc0019f0270 0xc0019f02b0 0xc0019f02d8] [0xc0019f0270 0xc0019f02b0 0xc0019f02d8] [0xc0019f0290 0xc0019f02d0] [0x92f8e0 0x92f8e0] 0xc000c21380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:21:39.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:21:39.757: INFO: rc: 1
Aug 21 17:21:39.757: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a97d10 exit status 1 <nil> <nil> true [0xc0019f02e0 0xc0019f0308 0xc0019f0360] [0xc0019f02e0 0xc0019f0308 0xc0019f0360] [0xc0019f02f0 0xc0019f0348] [0x92f8e0 0x92f8e0] 0xc000c216e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:21:49.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:21:49.825: INFO: rc: 1
Aug 21 17:21:49.825: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000c2a000 exit status 1 <nil> <nil> true [0xc0014fcb08 0xc0014fcc40 0xc0014fccc8] [0xc0014fcb08 0xc0014fcc40 0xc0014fccc8] [0xc0014fcbb8 0xc0014fccb8] [0x92f8e0 0x92f8e0] 0xc0013df020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:21:59.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:21:59.896: INFO: rc: 1
Aug 21 17:21:59.896: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0001e6150 exit status 1 <nil> <nil> true [0xc0019f0368 0xc0019f0380 0xc0019f0398] [0xc0019f0368 0xc0019f0380 0xc0019f0398] [0xc0019f0378 0xc0019f0390] [0x92f8e0 0x92f8e0] 0xc000c219e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:22:09.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:22:09.974: INFO: rc: 1
Aug 21 17:22:09.974: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000c2a3f0 exit status 1 <nil> <nil> true [0xc0014fcdc0 0xc0014fd088 0xc0014fd118] [0xc0014fcdc0 0xc0014fd088 0xc0014fd118] [0xc0014fcfd8 0xc0014fd110] [0x92f8e0 0x92f8e0] 0xc0013df320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:22:19.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:22:20.047: INFO: rc: 1
Aug 21 17:22:20.047: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001926720 exit status 1 <nil> <nil> true [0xc0014fc0a0 0xc0014fc158 0xc0014fc380] [0xc0014fc0a0 0xc0014fc158 0xc0014fc380] [0xc0014fc100 0xc0014fc270] [0x92f8e0 0x92f8e0] 0xc0013de540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:22:30.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:22:30.120: INFO: rc: 1
Aug 21 17:22:30.120: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a96ea0 exit status 1 <nil> <nil> true [0xc0019f0000 0xc0019f0040 0xc0019f0058] [0xc0019f0000 0xc0019f0040 0xc0019f0058] [0xc0019f0028 0xc0019f0050] [0x92f8e0 0x92f8e0] 0xc000c202a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:22:40.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:22:40.186: INFO: rc: 1
Aug 21 17:22:40.186: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a97710 exit status 1 <nil> <nil> true [0xc0019f0060 0xc0019f0078 0xc0019f00b8] [0xc0019f0060 0xc0019f0078 0xc0019f00b8] [0xc0019f0070 0xc0019f0098] [0x92f8e0 0x92f8e0] 0xc000c205a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:22:50.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:22:50.258: INFO: rc: 1
Aug 21 17:22:50.258: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001927020 exit status 1 <nil> <nil> true [0xc0014fc3c0 0xc0014fc490 0xc0014fc590] [0xc0014fc3c0 0xc0014fc490 0xc0014fc590] [0xc0014fc428 0xc0014fc558] [0x92f8e0 0x92f8e0] 0xc0013de9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:23:00.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:23:00.325: INFO: rc: 1
Aug 21 17:23:00.325: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a97b30 exit status 1 <nil> <nil> true [0xc0019f00d0 0xc0019f00e8 0xc0019f0120] [0xc0019f00d0 0xc0019f00e8 0xc0019f0120] [0xc0019f00e0 0xc0019f0108] [0x92f8e0 0x92f8e0] 0xc000c208a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:23:10.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:23:10.390: INFO: rc: 1
Aug 21 17:23:10.391: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a97f50 exit status 1 <nil> <nil> true [0xc0019f0128 0xc0019f0140 0xc0019f0180] [0xc0019f0128 0xc0019f0140 0xc0019f0180] [0xc0019f0138 0xc0019f0160] [0x92f8e0 0x92f8e0] 0xc000c20c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:23:20.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:23:20.455: INFO: rc: 1
Aug 21 17:23:20.455: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00192a390 exit status 1 <nil> <nil> true [0xc0019f0198 0xc0019f01c8 0xc0019f0208] [0xc0019f0198 0xc0019f01c8 0xc0019f0208] [0xc0019f01c0 0xc0019f01e8] [0x92f8e0 0x92f8e0] 0xc000c20f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:23:30.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:23:30.527: INFO: rc: 1
Aug 21 17:23:30.527: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0019274d0 exit status 1 <nil> <nil> true [0xc0014fc5c8 0xc0014fc8a0 0xc0014fcaf0] [0xc0014fc5c8 0xc0014fc8a0 0xc0014fcaf0] [0xc0014fc7c0 0xc0014fca48] [0x92f8e0 0x92f8e0] 0xc0013ded20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:23:40.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:23:40.595: INFO: rc: 1
Aug 21 17:23:40.595: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001927bf0 exit status 1 <nil> <nil> true [0xc0014fcb08 0xc0014fcc40 0xc0014fccc8] [0xc0014fcb08 0xc0014fcc40 0xc0014fccc8] [0xc0014fcbb8 0xc0014fccb8] [0x92f8e0 0x92f8e0] 0xc0013df020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:23:50.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:23:50.666: INFO: rc: 1
Aug 21 17:23:50.666: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00192a7e0 exit status 1 <nil> <nil> true [0xc0019f0220 0xc0019f0238 0xc0019f0278] [0xc0019f0220 0xc0019f0238 0xc0019f0278] [0xc0019f0230 0xc0019f0270] [0x92f8e0 0x92f8e0] 0xc000c21200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:24:00.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:24:00.737: INFO: rc: 1
Aug 21 17:24:00.737: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000c2a570 exit status 1 <nil> <nil> true [0xc0014fd130 0xc0014fd1c8 0xc0014fd298] [0xc0014fd130 0xc0014fd1c8 0xc0014fd298] [0xc0014fd1c0 0xc0014fd220] [0x92f8e0 0x92f8e0] 0xc0013df620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:24:10.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:24:10.813: INFO: rc: 1
Aug 21 17:24:10.814: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000c2a960 exit status 1 <nil> <nil> true [0xc0014fd2c0 0xc0014fd358 0xc0014fd390] [0xc0014fd2c0 0xc0014fd358 0xc0014fd390] [0xc0014fd330 0xc0014fd378] [0x92f8e0 0x92f8e0] 0xc0013df8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:24:20.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:24:20.884: INFO: rc: 1
Aug 21 17:24:20.884: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a96e70 exit status 1 <nil> <nil> true [0xc0014fc0a0 0xc0014fc158 0xc0014fc380] [0xc0014fc0a0 0xc0014fc158 0xc0014fc380] [0xc0014fc100 0xc0014fc270] [0x92f8e0 0x92f8e0] 0xc0013de540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:24:30.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:24:30.951: INFO: rc: 1
Aug 21 17:24:30.952: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a97740 exit status 1 <nil> <nil> true [0xc0014fc3c0 0xc0014fc490 0xc0014fc590] [0xc0014fc3c0 0xc0014fc490 0xc0014fc590] [0xc0014fc428 0xc0014fc558] [0x92f8e0 0x92f8e0] 0xc0013de9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:24:40.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:24:41.026: INFO: rc: 1
Aug 21 17:24:41.026: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001926960 exit status 1 <nil> <nil> true [0xc0019f0000 0xc0019f0040 0xc0019f0058] [0xc0019f0000 0xc0019f0040 0xc0019f0058] [0xc0019f0028 0xc0019f0050] [0x92f8e0 0x92f8e0] 0xc000c202a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:24:51.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:24:51.091: INFO: rc: 1
Aug 21 17:24:51.091: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001a97b60 exit status 1 <nil> <nil> true [0xc0014fc5c8 0xc0014fc8a0 0xc0014fcaf0] [0xc0014fc5c8 0xc0014fc8a0 0xc0014fcaf0] [0xc0014fc7c0 0xc0014fca48] [0x92f8e0 0x92f8e0] 0xc0013ded20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:25:01.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:25:01.165: INFO: rc: 1
Aug 21 17:25:01.165: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001927050 exit status 1 <nil> <nil> true [0xc0019f0060 0xc0019f0078 0xc0019f00b8] [0xc0019f0060 0xc0019f0078 0xc0019f00b8] [0xc0019f0070 0xc0019f0098] [0x92f8e0 0x92f8e0] 0xc000c205a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Aug 21 17:25:11.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-f97xc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:25:11.231: INFO: rc: 1
Aug 21 17:25:11.231: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Aug 21 17:25:11.231: INFO: Scaling statefulset ss to 0
Aug 21 17:25:11.282: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 21 17:25:11.300: INFO: Deleting all statefulset in ns e2e-tests-statefulset-f97xc
Aug 21 17:25:11.312: INFO: Scaling statefulset ss to 0
Aug 21 17:25:11.334: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 17:25:11.340: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:25:11.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-f97xc" for this suite.
Aug 21 17:25:17.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:25:17.525: INFO: namespace: e2e-tests-statefulset-f97xc, resource: bindings, ignored listing per whitelist
Aug 21 17:25:17.579: INFO: namespace e2e-tests-statefulset-f97xc deletion completed in 6.204765974s

â€¢ [SLOW TEST:370.700 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:25:17.579: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a4faa933-c438-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:25:17.682: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a4fc32c7-c438-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-95t7d" to be "success or failure"
Aug 21 17:25:17.689: INFO: Pod "pod-projected-configmaps-a4fc32c7-c438-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.892684ms
Aug 21 17:25:19.695: INFO: Pod "pod-projected-configmaps-a4fc32c7-c438-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01358733s
Aug 21 17:25:21.702: INFO: Pod "pod-projected-configmaps-a4fc32c7-c438-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02054337s
STEP: Saw pod success
Aug 21 17:25:21.702: INFO: Pod "pod-projected-configmaps-a4fc32c7-c438-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:25:21.708: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-projected-configmaps-a4fc32c7-c438-11e9-89d6-e2e196a4cdca container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 17:25:21.741: INFO: Waiting for pod pod-projected-configmaps-a4fc32c7-c438-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:25:21.746: INFO: Pod pod-projected-configmaps-a4fc32c7-c438-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:25:21.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-95t7d" for this suite.
Aug 21 17:25:27.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:25:27.906: INFO: namespace: e2e-tests-projected-95t7d, resource: bindings, ignored listing per whitelist
Aug 21 17:25:27.971: INFO: namespace e2e-tests-projected-95t7d deletion completed in 6.217513329s

â€¢ [SLOW TEST:10.391 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:25:27.971: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 17:25:28.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-bcnzq'
Aug 21 17:25:28.457: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 21 17:25:28.458: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Aug 21 17:25:30.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-bcnzq'
Aug 21 17:25:30.547: INFO: stderr: ""
Aug 21 17:25:30.547: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:25:30.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bcnzq" for this suite.
Aug 21 17:26:52.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:26:52.764: INFO: namespace: e2e-tests-kubectl-bcnzq, resource: bindings, ignored listing per whitelist
Aug 21 17:26:52.769: INFO: namespace e2e-tests-kubectl-bcnzq deletion completed in 1m22.214296422s

â€¢ [SLOW TEST:84.798 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:26:52.769: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Aug 21 17:26:52.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-t6kr5'
Aug 21 17:26:53.068: INFO: stderr: ""
Aug 21 17:26:53.068: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 17:26:53.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t6kr5'
Aug 21 17:26:53.143: INFO: stderr: ""
Aug 21 17:26:53.143: INFO: stdout: "update-demo-nautilus-9c2gh update-demo-nautilus-pvl8c "
Aug 21 17:26:53.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-9c2gh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t6kr5'
Aug 21 17:26:53.210: INFO: stderr: ""
Aug 21 17:26:53.210: INFO: stdout: ""
Aug 21 17:26:53.210: INFO: update-demo-nautilus-9c2gh is created but not running
Aug 21 17:26:58.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t6kr5'
Aug 21 17:26:58.284: INFO: stderr: ""
Aug 21 17:26:58.284: INFO: stdout: "update-demo-nautilus-9c2gh update-demo-nautilus-pvl8c "
Aug 21 17:26:58.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-9c2gh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t6kr5'
Aug 21 17:26:58.353: INFO: stderr: ""
Aug 21 17:26:58.353: INFO: stdout: "true"
Aug 21 17:26:58.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-9c2gh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t6kr5'
Aug 21 17:26:58.421: INFO: stderr: ""
Aug 21 17:26:58.421: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 17:26:58.421: INFO: validating pod update-demo-nautilus-9c2gh
Aug 21 17:26:58.443: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 17:26:58.443: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 17:26:58.443: INFO: update-demo-nautilus-9c2gh is verified up and running
Aug 21 17:26:58.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-pvl8c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t6kr5'
Aug 21 17:26:58.512: INFO: stderr: ""
Aug 21 17:26:58.512: INFO: stdout: "true"
Aug 21 17:26:58.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-pvl8c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t6kr5'
Aug 21 17:26:58.584: INFO: stderr: ""
Aug 21 17:26:58.584: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 17:26:58.584: INFO: validating pod update-demo-nautilus-pvl8c
Aug 21 17:26:58.597: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 17:26:58.597: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 17:26:58.597: INFO: update-demo-nautilus-pvl8c is verified up and running
STEP: using delete to clean up resources
Aug 21 17:26:58.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t6kr5'
Aug 21 17:26:58.680: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 17:26:58.680: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 21 17:26:58.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-t6kr5'
Aug 21 17:26:58.755: INFO: stderr: "No resources found.\n"
Aug 21 17:26:58.755: INFO: stdout: ""
Aug 21 17:26:58.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -l name=update-demo --namespace=e2e-tests-kubectl-t6kr5 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 21 17:26:58.828: INFO: stderr: ""
Aug 21 17:26:58.828: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:26:58.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t6kr5" for this suite.
Aug 21 17:27:20.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:27:20.912: INFO: namespace: e2e-tests-kubectl-t6kr5, resource: bindings, ignored listing per whitelist
Aug 21 17:27:21.055: INFO: namespace e2e-tests-kubectl-t6kr5 deletion completed in 22.220252595s

â€¢ [SLOW TEST:28.286 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:27:21.056: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-x6wf4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 21 17:27:21.157: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 21 17:27:47.291: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.3.99:8080/dial?request=hostName&protocol=udp&host=10.20.3.98&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-x6wf4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 17:27:47.291: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 17:27:47.498: INFO: Waiting for endpoints: map[]
Aug 21 17:27:47.504: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.3.99:8080/dial?request=hostName&protocol=udp&host=10.20.12.75&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-x6wf4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 17:27:47.504: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 17:27:47.675: INFO: Waiting for endpoints: map[]
Aug 21 17:27:47.681: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.3.99:8080/dial?request=hostName&protocol=udp&host=10.20.35.30&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-x6wf4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 17:27:47.681: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 17:27:47.853: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:27:47.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-x6wf4" for this suite.
Aug 21 17:28:09.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:28:09.902: INFO: namespace: e2e-tests-pod-network-test-x6wf4, resource: bindings, ignored listing per whitelist
Aug 21 17:28:10.077: INFO: namespace e2e-tests-pod-network-test-x6wf4 deletion completed in 22.215297994s

â€¢ [SLOW TEST:49.022 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:28:10.077: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-c7f2v
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Aug 21 17:28:10.188: INFO: Found 0 stateful pods, waiting for 3
Aug 21 17:28:20.195: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:28:20.195: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:28:20.195: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 21 17:28:20.234: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 21 17:28:30.286: INFO: Updating stateful set ss2
Aug 21 17:28:30.306: INFO: Waiting for Pod e2e-tests-statefulset-c7f2v/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Aug 21 17:28:40.381: INFO: Found 2 stateful pods, waiting for 3
Aug 21 17:28:50.388: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:28:50.388: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:28:50.388: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 21 17:28:50.421: INFO: Updating stateful set ss2
Aug 21 17:28:50.436: INFO: Waiting for Pod e2e-tests-statefulset-c7f2v/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 21 17:29:00.473: INFO: Updating stateful set ss2
Aug 21 17:29:00.486: INFO: Waiting for StatefulSet e2e-tests-statefulset-c7f2v/ss2 to complete update
Aug 21 17:29:00.486: INFO: Waiting for Pod e2e-tests-statefulset-c7f2v/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 21 17:29:10.499: INFO: Waiting for StatefulSet e2e-tests-statefulset-c7f2v/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 21 17:29:20.499: INFO: Deleting all statefulset in ns e2e-tests-statefulset-c7f2v
Aug 21 17:29:20.504: INFO: Scaling statefulset ss2 to 0
Aug 21 17:29:40.532: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 17:29:40.537: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:29:40.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-c7f2v" for this suite.
Aug 21 17:29:46.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:29:46.677: INFO: namespace: e2e-tests-statefulset-c7f2v, resource: bindings, ignored listing per whitelist
Aug 21 17:29:46.772: INFO: namespace e2e-tests-statefulset-c7f2v deletion completed in 6.203447961s

â€¢ [SLOW TEST:96.695 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:29:46.772: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-456dfc78-c439-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:29:46.874: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-456f9ec0-c439-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-fmmd4" to be "success or failure"
Aug 21 17:29:46.880: INFO: Pod "pod-projected-configmaps-456f9ec0-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.253879ms
Aug 21 17:29:48.886: INFO: Pod "pod-projected-configmaps-456f9ec0-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012655308s
Aug 21 17:29:50.893: INFO: Pod "pod-projected-configmaps-456f9ec0-c439-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019405381s
STEP: Saw pod success
Aug 21 17:29:50.893: INFO: Pod "pod-projected-configmaps-456f9ec0-c439-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:29:50.898: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-projected-configmaps-456f9ec0-c439-11e9-89d6-e2e196a4cdca container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 17:29:50.928: INFO: Waiting for pod pod-projected-configmaps-456f9ec0-c439-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:29:50.934: INFO: Pod pod-projected-configmaps-456f9ec0-c439-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:29:50.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fmmd4" for this suite.
Aug 21 17:29:56.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:29:57.008: INFO: namespace: e2e-tests-projected-fmmd4, resource: bindings, ignored listing per whitelist
Aug 21 17:29:57.146: INFO: namespace e2e-tests-projected-fmmd4 deletion completed in 6.204602983s

â€¢ [SLOW TEST:10.374 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:29:57.146: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Aug 21 17:29:57.753: INFO: Waiting up to 5m0s for pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-z9dgw" in namespace "e2e-tests-svcaccounts-lrcsp" to be "success or failure"
Aug 21 17:29:57.760: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-z9dgw": Phase="Pending", Reason="", readiness=false. Elapsed: 7.194299ms
Aug 21 17:29:59.766: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-z9dgw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013693444s
Aug 21 17:30:01.773: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-z9dgw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020853292s
Aug 21 17:30:03.780: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-z9dgw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02793924s
STEP: Saw pod success
Aug 21 17:30:03.781: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-z9dgw" satisfied condition "success or failure"
Aug 21 17:30:03.787: INFO: Trying to get logs from node ip-10-0-2-169.us-west-2.compute.internal pod pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-z9dgw container token-test: <nil>
STEP: delete the pod
Aug 21 17:30:03.820: INFO: Waiting for pod pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-z9dgw to disappear
Aug 21 17:30:03.826: INFO: Pod pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-z9dgw no longer exists
STEP: Creating a pod to test consume service account root CA
Aug 21 17:30:03.833: INFO: Waiting up to 5m0s for pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-58q7l" in namespace "e2e-tests-svcaccounts-lrcsp" to be "success or failure"
Aug 21 17:30:03.841: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-58q7l": Phase="Pending", Reason="", readiness=false. Elapsed: 8.068823ms
Aug 21 17:30:05.848: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-58q7l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014704094s
Aug 21 17:30:07.854: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-58q7l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021417639s
STEP: Saw pod success
Aug 21 17:30:07.854: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-58q7l" satisfied condition "success or failure"
Aug 21 17:30:07.860: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-58q7l container root-ca-test: <nil>
STEP: delete the pod
Aug 21 17:30:07.896: INFO: Waiting for pod pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-58q7l to disappear
Aug 21 17:30:07.902: INFO: Pod pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-58q7l no longer exists
STEP: Creating a pod to test consume service account namespace
Aug 21 17:30:07.908: INFO: Waiting up to 5m0s for pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-hmjnf" in namespace "e2e-tests-svcaccounts-lrcsp" to be "success or failure"
Aug 21 17:30:07.914: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-hmjnf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.654557ms
Aug 21 17:30:09.921: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-hmjnf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013590245s
Aug 21 17:30:11.928: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-hmjnf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020161367s
STEP: Saw pod success
Aug 21 17:30:11.928: INFO: Pod "pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-hmjnf" satisfied condition "success or failure"
Aug 21 17:30:11.934: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-hmjnf container namespace-test: <nil>
STEP: delete the pod
Aug 21 17:30:11.968: INFO: Waiting for pod pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-hmjnf to disappear
Aug 21 17:30:11.977: INFO: Pod pod-service-account-4beafff5-c439-11e9-89d6-e2e196a4cdca-hmjnf no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:30:11.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-lrcsp" for this suite.
Aug 21 17:30:18.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:30:18.114: INFO: namespace: e2e-tests-svcaccounts-lrcsp, resource: bindings, ignored listing per whitelist
Aug 21 17:30:18.232: INFO: namespace e2e-tests-svcaccounts-lrcsp deletion completed in 6.239720118s

â€¢ [SLOW TEST:21.086 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:30:18.232: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:30:18.356: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 21 17:30:22.374: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 21 17:30:24.380: INFO: Creating deployment "test-rollover-deployment"
Aug 21 17:30:24.393: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 21 17:30:26.406: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 21 17:30:26.417: INFO: Ensure that both replica sets have 1 created replica
Aug 21 17:30:26.429: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 21 17:30:26.440: INFO: Updating deployment test-rollover-deployment
Aug 21 17:30:26.440: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 21 17:30:28.455: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 21 17:30:28.466: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 21 17:30:28.478: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 17:30:28.478: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005426, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 17:30:30.491: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 17:30:30.491: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005429, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 17:30:32.490: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 17:30:32.490: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005429, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 17:30:34.491: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 17:30:34.491: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005429, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 17:30:36.490: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 17:30:36.490: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005429, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 17:30:38.491: INFO: all replica sets need to contain the pod-template-hash label
Aug 21 17:30:38.491: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005429, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005424, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 21 17:30:40.491: INFO: 
Aug 21 17:30:40.491: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 21 17:30:40.508: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-ljc2x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ljc2x/deployments/test-rollover-deployment,UID:5bcc88fe-c439-11e9-b0fd-0afb3721cd16,ResourceVersion:17026,Generation:2,CreationTimestamp:2019-08-21 17:30:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-21 17:30:24 +0000 UTC 2019-08-21 17:30:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-21 17:30:39 +0000 UTC 2019-08-21 17:30:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 21 17:30:40.513: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-ljc2x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ljc2x/replicasets/test-rollover-deployment-6b7f9d6597,UID:5d064b97-c439-11e9-bb91-06b2a5b3abd6,ResourceVersion:17017,Generation:2,CreationTimestamp:2019-08-21 17:30:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5bcc88fe-c439-11e9-b0fd-0afb3721cd16 0xc000054db7 0xc000054db8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 21 17:30:40.513: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 21 17:30:40.514: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-ljc2x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ljc2x/replicasets/test-rollover-controller,UID:5831f2f9-c439-11e9-b0fd-0afb3721cd16,ResourceVersion:17025,Generation:2,CreationTimestamp:2019-08-21 17:30:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5bcc88fe-c439-11e9-b0fd-0afb3721cd16 0xc000054a37 0xc000054a38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 17:30:40.514: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-ljc2x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ljc2x/replicasets/test-rollover-deployment-6586df867b,UID:5bce034c-c439-11e9-bb91-06b2a5b3abd6,ResourceVersion:16981,Generation:2,CreationTimestamp:2019-08-21 17:30:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5bcc88fe-c439-11e9-b0fd-0afb3721cd16 0xc000054bd7 0xc000054bd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 21 17:30:40.519: INFO: Pod "test-rollover-deployment-6b7f9d6597-mm2dg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-mm2dg,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-ljc2x,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ljc2x/pods/test-rollover-deployment-6b7f9d6597-mm2dg,UID:5d0a125c-c439-11e9-bb91-06b2a5b3abd6,ResourceVersion:16995,Generation:0,CreationTimestamp:2019-08-21 17:30:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 5d064b97-c439-11e9-bb91-06b2a5b3abd6 0xc0006589e7 0xc0006589e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-n6sn7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-n6sn7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-n6sn7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:30:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:30:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:30:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:30:26 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:10.20.3.105,StartTime:2019-08-21 17:30:26 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-21 17:30:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1058da0b794af73b25a3c64d2b6372747f73ca6a56454b42fec687bdc6a2907d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:30:40.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ljc2x" for this suite.
Aug 21 17:30:46.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:30:46.558: INFO: namespace: e2e-tests-deployment-ljc2x, resource: bindings, ignored listing per whitelist
Aug 21 17:30:46.725: INFO: namespace e2e-tests-deployment-ljc2x deletion completed in 6.197903617s

â€¢ [SLOW TEST:28.493 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:30:46.725: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-692b3516-c439-11e9-89d6-e2e196a4cdca
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-692b3516-c439-11e9-89d6-e2e196a4cdca
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:32:09.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wxn6b" for this suite.
Aug 21 17:32:31.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:32:31.569: INFO: namespace: e2e-tests-projected-wxn6b, resource: bindings, ignored listing per whitelist
Aug 21 17:32:31.643: INFO: namespace e2e-tests-projected-wxn6b deletion completed in 22.197875578s

â€¢ [SLOW TEST:104.918 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:32:31.643: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a7bb1c17-c439-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:32:31.794: INFO: Waiting up to 5m0s for pod "pod-configmaps-a7bc91c1-c439-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-configmap-rflwl" to be "success or failure"
Aug 21 17:32:31.801: INFO: Pod "pod-configmaps-a7bc91c1-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.323541ms
Aug 21 17:32:33.808: INFO: Pod "pod-configmaps-a7bc91c1-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013778388s
Aug 21 17:32:35.814: INFO: Pod "pod-configmaps-a7bc91c1-c439-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019767628s
STEP: Saw pod success
Aug 21 17:32:35.814: INFO: Pod "pod-configmaps-a7bc91c1-c439-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:32:35.819: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-configmaps-a7bc91c1-c439-11e9-89d6-e2e196a4cdca container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 17:32:35.849: INFO: Waiting for pod pod-configmaps-a7bc91c1-c439-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:32:35.854: INFO: Pod pod-configmaps-a7bc91c1-c439-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:32:35.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rflwl" for this suite.
Aug 21 17:32:41.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:32:41.965: INFO: namespace: e2e-tests-configmap-rflwl, resource: bindings, ignored listing per whitelist
Aug 21 17:32:42.060: INFO: namespace e2e-tests-configmap-rflwl deletion completed in 6.198129875s

â€¢ [SLOW TEST:10.417 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:32:42.060: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 17:32:42.153: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ade8bd9e-c439-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-h42dl" to be "success or failure"
Aug 21 17:32:42.160: INFO: Pod "downwardapi-volume-ade8bd9e-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.780171ms
Aug 21 17:32:44.167: INFO: Pod "downwardapi-volume-ade8bd9e-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013459212s
Aug 21 17:32:46.175: INFO: Pod "downwardapi-volume-ade8bd9e-c439-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021472533s
STEP: Saw pod success
Aug 21 17:32:46.175: INFO: Pod "downwardapi-volume-ade8bd9e-c439-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:32:46.183: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downwardapi-volume-ade8bd9e-c439-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 17:32:46.216: INFO: Waiting for pod downwardapi-volume-ade8bd9e-c439-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:32:46.221: INFO: Pod downwardapi-volume-ade8bd9e-c439-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:32:46.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h42dl" for this suite.
Aug 21 17:32:52.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:32:52.313: INFO: namespace: e2e-tests-projected-h42dl, resource: bindings, ignored listing per whitelist
Aug 21 17:32:52.477: INFO: namespace e2e-tests-projected-h42dl deletion completed in 6.247191531s

â€¢ [SLOW TEST:10.417 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:32:52.477: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b41f275c-c439-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:32:52.584: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b420c974-c439-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-npqrb" to be "success or failure"
Aug 21 17:32:52.590: INFO: Pod "pod-projected-configmaps-b420c974-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 5.933001ms
Aug 21 17:32:54.596: INFO: Pod "pod-projected-configmaps-b420c974-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011958993s
Aug 21 17:32:56.602: INFO: Pod "pod-projected-configmaps-b420c974-c439-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018000343s
STEP: Saw pod success
Aug 21 17:32:56.602: INFO: Pod "pod-projected-configmaps-b420c974-c439-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:32:56.608: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-projected-configmaps-b420c974-c439-11e9-89d6-e2e196a4cdca container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 17:32:56.644: INFO: Waiting for pod pod-projected-configmaps-b420c974-c439-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:32:56.649: INFO: Pod pod-projected-configmaps-b420c974-c439-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:32:56.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-npqrb" for this suite.
Aug 21 17:33:02.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:33:02.728: INFO: namespace: e2e-tests-projected-npqrb, resource: bindings, ignored listing per whitelist
Aug 21 17:33:02.884: INFO: namespace e2e-tests-projected-npqrb deletion completed in 6.227105209s

â€¢ [SLOW TEST:10.407 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:33:02.884: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ba53adc9-c439-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 17:33:03.028: INFO: Waiting up to 5m0s for pod "pod-secrets-ba5a828c-c439-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-secrets-dx9t5" to be "success or failure"
Aug 21 17:33:03.035: INFO: Pod "pod-secrets-ba5a828c-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.129235ms
Aug 21 17:33:05.042: INFO: Pod "pod-secrets-ba5a828c-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014037375s
Aug 21 17:33:07.049: INFO: Pod "pod-secrets-ba5a828c-c439-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020943507s
STEP: Saw pod success
Aug 21 17:33:07.049: INFO: Pod "pod-secrets-ba5a828c-c439-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:33:07.055: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-secrets-ba5a828c-c439-11e9-89d6-e2e196a4cdca container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 17:33:07.088: INFO: Waiting for pod pod-secrets-ba5a828c-c439-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:33:07.094: INFO: Pod pod-secrets-ba5a828c-c439-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:33:07.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dx9t5" for this suite.
Aug 21 17:33:13.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:33:13.197: INFO: namespace: e2e-tests-secrets-dx9t5, resource: bindings, ignored listing per whitelist
Aug 21 17:33:13.307: INFO: namespace e2e-tests-secrets-dx9t5 deletion completed in 6.205691257s
STEP: Destroying namespace "e2e-tests-secret-namespace-7zmxf" for this suite.
Aug 21 17:33:19.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:33:19.458: INFO: namespace: e2e-tests-secret-namespace-7zmxf, resource: bindings, ignored listing per whitelist
Aug 21 17:33:19.512: INFO: namespace e2e-tests-secret-namespace-7zmxf deletion completed in 6.204217419s

â€¢ [SLOW TEST:16.627 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:33:19.512: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:33:23.648: INFO: Waiting up to 5m0s for pod "client-envvars-c6a4dbaa-c439-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-pods-g5hh9" to be "success or failure"
Aug 21 17:33:23.656: INFO: Pod "client-envvars-c6a4dbaa-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.722528ms
Aug 21 17:33:25.663: INFO: Pod "client-envvars-c6a4dbaa-c439-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014404064s
Aug 21 17:33:27.670: INFO: Pod "client-envvars-c6a4dbaa-c439-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02102628s
STEP: Saw pod success
Aug 21 17:33:27.670: INFO: Pod "client-envvars-c6a4dbaa-c439-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:33:27.675: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod client-envvars-c6a4dbaa-c439-11e9-89d6-e2e196a4cdca container env3cont: <nil>
STEP: delete the pod
Aug 21 17:33:27.706: INFO: Waiting for pod client-envvars-c6a4dbaa-c439-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:33:27.712: INFO: Pod client-envvars-c6a4dbaa-c439-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:33:27.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-g5hh9" for this suite.
Aug 21 17:34:05.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:34:05.749: INFO: namespace: e2e-tests-pods-g5hh9, resource: bindings, ignored listing per whitelist
Aug 21 17:34:05.930: INFO: namespace e2e-tests-pods-g5hh9 deletion completed in 38.210791376s

â€¢ [SLOW TEST:46.419 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:34:05.931: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Aug 21 17:34:10.082: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:34:34.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-v5zz2" for this suite.
Aug 21 17:34:40.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:34:40.312: INFO: namespace: e2e-tests-namespaces-v5zz2, resource: bindings, ignored listing per whitelist
Aug 21 17:34:40.354: INFO: namespace e2e-tests-namespaces-v5zz2 deletion completed in 6.203952908s
STEP: Destroying namespace "e2e-tests-nsdeletetest-97s9m" for this suite.
Aug 21 17:34:40.360: INFO: Namespace e2e-tests-nsdeletetest-97s9m was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-2rztb" for this suite.
Aug 21 17:34:46.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:34:46.471: INFO: namespace: e2e-tests-nsdeletetest-2rztb, resource: bindings, ignored listing per whitelist
Aug 21 17:34:46.567: INFO: namespace e2e-tests-nsdeletetest-2rztb deletion completed in 6.207412079s

â€¢ [SLOW TEST:40.636 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:34:46.567: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-jtwqr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 21 17:34:46.647: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 21 17:35:06.781: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.20.12.85:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-jtwqr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 17:35:06.781: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 17:35:06.988: INFO: Found all expected endpoints: [netserver-0]
Aug 21 17:35:06.994: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.20.3.112:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-jtwqr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 17:35:06.994: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 17:35:07.159: INFO: Found all expected endpoints: [netserver-1]
Aug 21 17:35:07.166: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.20.35.35:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-jtwqr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 21 17:35:07.166: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
Aug 21 17:35:07.342: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:35:07.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-jtwqr" for this suite.
Aug 21 17:35:19.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:35:19.546: INFO: namespace: e2e-tests-pod-network-test-jtwqr, resource: bindings, ignored listing per whitelist
Aug 21 17:35:19.558: INFO: namespace e2e-tests-pod-network-test-jtwqr deletion completed in 12.207049095s

â€¢ [SLOW TEST:32.991 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:35:19.559: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 21 17:35:19.655: INFO: Waiting up to 5m0s for pod "pod-0bc96f9c-c43a-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-t2ss5" to be "success or failure"
Aug 21 17:35:19.662: INFO: Pod "pod-0bc96f9c-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.686751ms
Aug 21 17:35:21.668: INFO: Pod "pod-0bc96f9c-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013336404s
Aug 21 17:35:23.675: INFO: Pod "pod-0bc96f9c-c43a-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019839525s
STEP: Saw pod success
Aug 21 17:35:23.675: INFO: Pod "pod-0bc96f9c-c43a-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:35:23.680: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-0bc96f9c-c43a-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 17:35:23.709: INFO: Waiting for pod pod-0bc96f9c-c43a-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:35:23.714: INFO: Pod pod-0bc96f9c-c43a-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:35:23.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t2ss5" for this suite.
Aug 21 17:35:29.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:35:29.893: INFO: namespace: e2e-tests-emptydir-t2ss5, resource: bindings, ignored listing per whitelist
Aug 21 17:35:29.934: INFO: namespace e2e-tests-emptydir-t2ss5 deletion completed in 6.210983335s

â€¢ [SLOW TEST:10.375 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:35:29.934: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-cb92t
Aug 21 17:35:34.086: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-cb92t
STEP: checking the pod's current state and verifying that restartCount is present
Aug 21 17:35:34.092: INFO: Initial restart count of pod liveness-exec is 0
Aug 21 17:36:20.256: INFO: Restart count of pod e2e-tests-container-probe-cb92t/liveness-exec is now 1 (46.164020461s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:36:20.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cb92t" for this suite.
Aug 21 17:36:26.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:36:26.414: INFO: namespace: e2e-tests-container-probe-cb92t, resource: bindings, ignored listing per whitelist
Aug 21 17:36:26.491: INFO: namespace e2e-tests-container-probe-cb92t deletion completed in 6.205017895s

â€¢ [SLOW TEST:56.557 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:36:26.492: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-33aeb867-c43a-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:36:26.595: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-33b03b05-c43a-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-pzhjw" to be "success or failure"
Aug 21 17:36:26.602: INFO: Pod "pod-projected-configmaps-33b03b05-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.20351ms
Aug 21 17:36:28.608: INFO: Pod "pod-projected-configmaps-33b03b05-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013237809s
Aug 21 17:36:30.615: INFO: Pod "pod-projected-configmaps-33b03b05-c43a-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019997442s
STEP: Saw pod success
Aug 21 17:36:30.615: INFO: Pod "pod-projected-configmaps-33b03b05-c43a-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:36:30.621: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-projected-configmaps-33b03b05-c43a-11e9-89d6-e2e196a4cdca container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 17:36:30.652: INFO: Waiting for pod pod-projected-configmaps-33b03b05-c43a-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:36:30.657: INFO: Pod pod-projected-configmaps-33b03b05-c43a-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:36:30.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pzhjw" for this suite.
Aug 21 17:36:36.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:36:36.930: INFO: namespace: e2e-tests-projected-pzhjw, resource: bindings, ignored listing per whitelist
Aug 21 17:36:36.978: INFO: namespace e2e-tests-projected-pzhjw deletion completed in 6.313312822s

â€¢ [SLOW TEST:10.486 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:36:36.978: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-39eea0b3-c43a-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 17:36:37.078: INFO: Waiting up to 5m0s for pod "pod-secrets-39f01599-c43a-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-secrets-jj98z" to be "success or failure"
Aug 21 17:36:37.084: INFO: Pod "pod-secrets-39f01599-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 5.440242ms
Aug 21 17:36:39.091: INFO: Pod "pod-secrets-39f01599-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012221419s
Aug 21 17:36:41.097: INFO: Pod "pod-secrets-39f01599-c43a-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019002238s
STEP: Saw pod success
Aug 21 17:36:41.098: INFO: Pod "pod-secrets-39f01599-c43a-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:36:41.103: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-secrets-39f01599-c43a-11e9-89d6-e2e196a4cdca container secret-env-test: <nil>
STEP: delete the pod
Aug 21 17:36:41.135: INFO: Waiting for pod pod-secrets-39f01599-c43a-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:36:41.140: INFO: Pod pod-secrets-39f01599-c43a-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:36:41.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jj98z" for this suite.
Aug 21 17:36:47.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:36:47.364: INFO: namespace: e2e-tests-secrets-jj98z, resource: bindings, ignored listing per whitelist
Aug 21 17:36:47.364: INFO: namespace e2e-tests-secrets-jj98z deletion completed in 6.215681151s

â€¢ [SLOW TEST:10.386 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:36:47.364: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-401f4ab7-c43a-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:36:47.466: INFO: Waiting up to 5m0s for pod "pod-configmaps-4020bc32-c43a-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-configmap-9c2kj" to be "success or failure"
Aug 21 17:36:47.472: INFO: Pod "pod-configmaps-4020bc32-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.452161ms
Aug 21 17:36:49.479: INFO: Pod "pod-configmaps-4020bc32-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013108629s
Aug 21 17:36:51.485: INFO: Pod "pod-configmaps-4020bc32-c43a-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019708844s
STEP: Saw pod success
Aug 21 17:36:51.485: INFO: Pod "pod-configmaps-4020bc32-c43a-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:36:51.491: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-configmaps-4020bc32-c43a-11e9-89d6-e2e196a4cdca container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 17:36:51.522: INFO: Waiting for pod pod-configmaps-4020bc32-c43a-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:36:51.528: INFO: Pod pod-configmaps-4020bc32-c43a-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:36:51.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9c2kj" for this suite.
Aug 21 17:36:57.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:36:57.737: INFO: namespace: e2e-tests-configmap-9c2kj, resource: bindings, ignored listing per whitelist
Aug 21 17:36:57.747: INFO: namespace e2e-tests-configmap-9c2kj deletion completed in 6.211465522s

â€¢ [SLOW TEST:10.383 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:36:57.747: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 21 17:36:57.846: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:36:58.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-nl5k9" for this suite.
Aug 21 17:37:04.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:37:04.986: INFO: namespace: e2e-tests-replication-controller-nl5k9, resource: bindings, ignored listing per whitelist
Aug 21 17:37:05.162: INFO: namespace e2e-tests-replication-controller-nl5k9 deletion completed in 6.280410009s

â€¢ [SLOW TEST:7.415 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:37:05.162: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4abbc295-c43a-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:37:05.268: INFO: Waiting up to 5m0s for pod "pod-configmaps-4abd56b6-c43a-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-configmap-v59tb" to be "success or failure"
Aug 21 17:37:05.276: INFO: Pod "pod-configmaps-4abd56b6-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.116813ms
Aug 21 17:37:07.282: INFO: Pod "pod-configmaps-4abd56b6-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013863215s
Aug 21 17:37:09.289: INFO: Pod "pod-configmaps-4abd56b6-c43a-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020747774s
STEP: Saw pod success
Aug 21 17:37:09.289: INFO: Pod "pod-configmaps-4abd56b6-c43a-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:37:09.295: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-configmaps-4abd56b6-c43a-11e9-89d6-e2e196a4cdca container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 17:37:09.326: INFO: Waiting for pod pod-configmaps-4abd56b6-c43a-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:37:09.332: INFO: Pod pod-configmaps-4abd56b6-c43a-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:37:09.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v59tb" for this suite.
Aug 21 17:37:15.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:37:15.484: INFO: namespace: e2e-tests-configmap-v59tb, resource: bindings, ignored listing per whitelist
Aug 21 17:37:15.539: INFO: namespace e2e-tests-configmap-v59tb deletion completed in 6.199644766s

â€¢ [SLOW TEST:10.377 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:37:15.539: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:37:33.654: INFO: Container started at 2019-08-21 17:37:17 +0000 UTC, pod became ready at 2019-08-21 17:37:32 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:37:33.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wrrkm" for this suite.
Aug 21 17:37:55.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:37:55.829: INFO: namespace: e2e-tests-container-probe-wrrkm, resource: bindings, ignored listing per whitelist
Aug 21 17:37:55.872: INFO: namespace e2e-tests-container-probe-wrrkm deletion completed in 22.206426393s

â€¢ [SLOW TEST:40.332 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:37:55.872: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 21 17:37:55.975: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nkggq,SelfLink:/api/v1/namespaces/e2e-tests-watch-nkggq/configmaps/e2e-watch-test-watch-closed,UID:68f55581-c43a-11e9-b0fd-0afb3721cd16,ResourceVersion:18535,Generation:0,CreationTimestamp:2019-08-21 17:37:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 21 17:37:55.975: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nkggq,SelfLink:/api/v1/namespaces/e2e-tests-watch-nkggq/configmaps/e2e-watch-test-watch-closed,UID:68f55581-c43a-11e9-b0fd-0afb3721cd16,ResourceVersion:18536,Generation:0,CreationTimestamp:2019-08-21 17:37:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 21 17:37:56.000: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nkggq,SelfLink:/api/v1/namespaces/e2e-tests-watch-nkggq/configmaps/e2e-watch-test-watch-closed,UID:68f55581-c43a-11e9-b0fd-0afb3721cd16,ResourceVersion:18537,Generation:0,CreationTimestamp:2019-08-21 17:37:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 21 17:37:56.000: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nkggq,SelfLink:/api/v1/namespaces/e2e-tests-watch-nkggq/configmaps/e2e-watch-test-watch-closed,UID:68f55581-c43a-11e9-b0fd-0afb3721cd16,ResourceVersion:18538,Generation:0,CreationTimestamp:2019-08-21 17:37:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:37:56.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nkggq" for this suite.
Aug 21 17:38:02.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:38:02.213: INFO: namespace: e2e-tests-watch-nkggq, resource: bindings, ignored listing per whitelist
Aug 21 17:38:02.241: INFO: namespace e2e-tests-watch-nkggq deletion completed in 6.231903927s

â€¢ [SLOW TEST:6.369 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:38:02.241: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 21 17:38:02.348: INFO: Waiting up to 5m0s for pod "downward-api-6cc20b94-c43a-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-7ghx7" to be "success or failure"
Aug 21 17:38:02.357: INFO: Pod "downward-api-6cc20b94-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 8.394388ms
Aug 21 17:38:04.364: INFO: Pod "downward-api-6cc20b94-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015232504s
Aug 21 17:38:06.371: INFO: Pod "downward-api-6cc20b94-c43a-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022454385s
STEP: Saw pod success
Aug 21 17:38:06.371: INFO: Pod "downward-api-6cc20b94-c43a-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:38:06.377: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downward-api-6cc20b94-c43a-11e9-89d6-e2e196a4cdca container dapi-container: <nil>
STEP: delete the pod
Aug 21 17:38:06.407: INFO: Waiting for pod downward-api-6cc20b94-c43a-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:38:06.413: INFO: Pod downward-api-6cc20b94-c43a-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:38:06.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7ghx7" for this suite.
Aug 21 17:38:12.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:38:12.570: INFO: namespace: e2e-tests-downward-api-7ghx7, resource: bindings, ignored listing per whitelist
Aug 21 17:38:12.633: INFO: namespace e2e-tests-downward-api-7ghx7 deletion completed in 6.212016623s

â€¢ [SLOW TEST:10.392 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:38:12.633: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 21 17:38:12.723: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 21 17:38:12.740: INFO: Waiting for terminating namespaces to be deleted...
Aug 21 17:38:12.746: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-150.us-west-2.compute.internal before test
Aug 21 17:38:12.753: INFO: sonobuoy-systemd-logs-daemon-set-1990058480d24a87-rkdd2 from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 17:38:12.753: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 21 17:38:12.753: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 21 17:38:12.753: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-2-169.us-west-2.compute.internal before test
Aug 21 17:38:12.761: INFO: sonobuoy-e2e-job-b129cff7f8104912 from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 17:38:12.761: INFO: 	Container e2e ready: true, restart count 0
Aug 21 17:38:12.761: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 17:38:12.761: INFO: sonobuoy-systemd-logs-daemon-set-1990058480d24a87-xht7r from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 17:38:12.761: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 21 17:38:12.761: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 21 17:38:12.761: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-3-38.us-west-2.compute.internal before test
Aug 21 17:38:12.769: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-21 16:33:33 +0000 UTC (1 container statuses recorded)
Aug 21 17:38:12.769: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 21 17:38:12.769: INFO: sonobuoy-systemd-logs-daemon-set-1990058480d24a87-jppkx from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 17:38:12.769: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 21 17:38:12.769: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-10-0-1-150.us-west-2.compute.internal
STEP: verifying the node has the label node ip-10-0-2-169.us-west-2.compute.internal
STEP: verifying the node has the label node ip-10-0-3-38.us-west-2.compute.internal
Aug 21 17:38:12.832: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-3-38.us-west-2.compute.internal
Aug 21 17:38:12.832: INFO: Pod sonobuoy-e2e-job-b129cff7f8104912 requesting resource cpu=0m on Node ip-10-0-2-169.us-west-2.compute.internal
Aug 21 17:38:12.832: INFO: Pod sonobuoy-systemd-logs-daemon-set-1990058480d24a87-jppkx requesting resource cpu=0m on Node ip-10-0-3-38.us-west-2.compute.internal
Aug 21 17:38:12.832: INFO: Pod sonobuoy-systemd-logs-daemon-set-1990058480d24a87-rkdd2 requesting resource cpu=0m on Node ip-10-0-1-150.us-west-2.compute.internal
Aug 21 17:38:12.832: INFO: Pod sonobuoy-systemd-logs-daemon-set-1990058480d24a87-xht7r requesting resource cpu=0m on Node ip-10-0-2-169.us-west-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-73045248-c43a-11e9-89d6-e2e196a4cdca.15bd00c550299e45], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bkffv/filler-pod-73045248-c43a-11e9-89d6-e2e196a4cdca to ip-10-0-1-150.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-73045248-c43a-11e9-89d6-e2e196a4cdca.15bd00c592cc15a5], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-73045248-c43a-11e9-89d6-e2e196a4cdca.15bd00c5a74e59a2], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-73045248-c43a-11e9-89d6-e2e196a4cdca.15bd00c5b7e38276], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7306cab6-c43a-11e9-89d6-e2e196a4cdca.15bd00c55092f68d], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bkffv/filler-pod-7306cab6-c43a-11e9-89d6-e2e196a4cdca to ip-10-0-2-169.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7306cab6-c43a-11e9-89d6-e2e196a4cdca.15bd00c595af639e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7306cab6-c43a-11e9-89d6-e2e196a4cdca.15bd00c5aa41b24a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7306cab6-c43a-11e9-89d6-e2e196a4cdca.15bd00c5ba16df85], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7307ceee-c43a-11e9-89d6-e2e196a4cdca.15bd00c550f44da1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bkffv/filler-pod-7307ceee-c43a-11e9-89d6-e2e196a4cdca to ip-10-0-3-38.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7307ceee-c43a-11e9-89d6-e2e196a4cdca.15bd00c595192ee0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7307ceee-c43a-11e9-89d6-e2e196a4cdca.15bd00c5aa48de76], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7307ceee-c43a-11e9-89d6-e2e196a4cdca.15bd00c5ba9df271], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15bd00c641902254], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node ip-10-0-1-150.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-2-169.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-3-38.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:38:17.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-bkffv" for this suite.
Aug 21 17:38:23.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:38:24.192: INFO: namespace: e2e-tests-sched-pred-bkffv, resource: bindings, ignored listing per whitelist
Aug 21 17:38:24.197: INFO: namespace e2e-tests-sched-pred-bkffv deletion completed in 6.219737287s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:11.564 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:38:24.197: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 21 17:38:24.294: INFO: Waiting up to 5m0s for pod "pod-79d72e81-c43a-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-828h7" to be "success or failure"
Aug 21 17:38:24.300: INFO: Pod "pod-79d72e81-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 5.542099ms
Aug 21 17:38:26.306: INFO: Pod "pod-79d72e81-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012027696s
Aug 21 17:38:28.313: INFO: Pod "pod-79d72e81-c43a-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018808218s
STEP: Saw pod success
Aug 21 17:38:28.313: INFO: Pod "pod-79d72e81-c43a-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:38:28.318: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-79d72e81-c43a-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 17:38:28.350: INFO: Waiting for pod pod-79d72e81-c43a-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:38:28.355: INFO: Pod pod-79d72e81-c43a-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:38:28.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-828h7" for this suite.
Aug 21 17:38:34.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:38:34.440: INFO: namespace: e2e-tests-emptydir-828h7, resource: bindings, ignored listing per whitelist
Aug 21 17:38:34.572: INFO: namespace e2e-tests-emptydir-828h7 deletion completed in 6.206313245s

â€¢ [SLOW TEST:10.375 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:38:34.572: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 21 17:38:34.666: INFO: Waiting up to 5m0s for pod "pod-8005dfd4-c43a-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-bq2vz" to be "success or failure"
Aug 21 17:38:34.673: INFO: Pod "pod-8005dfd4-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.410161ms
Aug 21 17:38:36.680: INFO: Pod "pod-8005dfd4-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013170273s
Aug 21 17:38:38.687: INFO: Pod "pod-8005dfd4-c43a-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020137134s
STEP: Saw pod success
Aug 21 17:38:38.687: INFO: Pod "pod-8005dfd4-c43a-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:38:38.692: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-8005dfd4-c43a-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 17:38:38.723: INFO: Waiting for pod pod-8005dfd4-c43a-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:38:38.729: INFO: Pod pod-8005dfd4-c43a-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:38:38.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bq2vz" for this suite.
Aug 21 17:38:44.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:38:44.808: INFO: namespace: e2e-tests-emptydir-bq2vz, resource: bindings, ignored listing per whitelist
Aug 21 17:38:44.955: INFO: namespace e2e-tests-emptydir-bq2vz deletion completed in 6.21830434s

â€¢ [SLOW TEST:10.383 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:38:44.955: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Aug 21 17:38:49.107: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-86394a79-c43a-11e9-89d6-e2e196a4cdca", GenerateName:"", Namespace:"e2e-tests-pods-f58hj", SelfLink:"/api/v1/namespaces/e2e-tests-pods-f58hj/pods/pod-submit-remove-86394a79-c43a-11e9-89d6-e2e196a4cdca", UID:"863bdcfe-c43a-11e9-b0fd-0afb3721cd16", ResourceVersion:"18794", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63702005925, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"55966295"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kpvss", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002cd91c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kpvss", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001c9a188), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-3-38.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0029b7d40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001c9a1b0), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001c9a1b4)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005925, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005927, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005927, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702005925, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.3.38", PodIP:"10.20.12.93", StartTime:(*v1.Time)(0xc002bd1800), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc002bd1820), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://792385e07834ed96489926093f08ca61d9c2a2391cfd289e6203ae06797879e9"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:38:56.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f58hj" for this suite.
Aug 21 17:39:02.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:39:02.808: INFO: namespace: e2e-tests-pods-f58hj, resource: bindings, ignored listing per whitelist
Aug 21 17:39:02.949: INFO: namespace e2e-tests-pods-f58hj deletion completed in 6.209884212s

â€¢ [SLOW TEST:17.994 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:39:02.949: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-90f1e503-c43a-11e9-89d6-e2e196a4cdca
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-90f1e503-c43a-11e9-89d6-e2e196a4cdca
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:40:11.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-psnnw" for this suite.
Aug 21 17:40:33.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:40:33.674: INFO: namespace: e2e-tests-configmap-psnnw, resource: bindings, ignored listing per whitelist
Aug 21 17:40:33.862: INFO: namespace e2e-tests-configmap-psnnw deletion completed in 22.249190293s

â€¢ [SLOW TEST:90.913 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:40:33.862: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Aug 21 17:40:33.959: INFO: Waiting up to 5m0s for pod "client-containers-c7206fd1-c43a-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-containers-9fl2t" to be "success or failure"
Aug 21 17:40:33.965: INFO: Pod "client-containers-c7206fd1-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 5.762948ms
Aug 21 17:40:35.972: INFO: Pod "client-containers-c7206fd1-c43a-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01290532s
Aug 21 17:40:37.978: INFO: Pod "client-containers-c7206fd1-c43a-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019493645s
STEP: Saw pod success
Aug 21 17:40:37.979: INFO: Pod "client-containers-c7206fd1-c43a-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:40:37.984: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod client-containers-c7206fd1-c43a-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 17:40:38.019: INFO: Waiting for pod client-containers-c7206fd1-c43a-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:40:38.024: INFO: Pod client-containers-c7206fd1-c43a-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:40:38.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9fl2t" for this suite.
Aug 21 17:40:44.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:40:44.234: INFO: namespace: e2e-tests-containers-9fl2t, resource: bindings, ignored listing per whitelist
Aug 21 17:40:44.234: INFO: namespace e2e-tests-containers-9fl2t deletion completed in 6.201565479s

â€¢ [SLOW TEST:10.372 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:40:44.234: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 21 17:40:48.363: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-cd502961-c43a-11e9-89d6-e2e196a4cdca,GenerateName:,Namespace:e2e-tests-events-qcm9m,SelfLink:/api/v1/namespaces/e2e-tests-events-qcm9m/pods/send-events-cd502961-c43a-11e9-89d6-e2e196a4cdca,UID:cd510af8-c43a-11e9-b0fd-0afb3721cd16,ResourceVersion:19099,Generation:0,CreationTimestamp:2019-08-21 17:40:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 324086756,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-c79sz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-c79sz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-c79sz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-150.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:40:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:40:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:40:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 17:40:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.150,PodIP:10.20.3.122,StartTime:2019-08-21 17:40:44 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-21 17:40:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ce03dc545445e801b8c2fc369507f1d94a8f7aa4228469d8e1e86c7e79187ef1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 21 17:40:50.370: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 21 17:40:52.377: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:40:52.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-qcm9m" for this suite.
Aug 21 17:41:30.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:41:30.447: INFO: namespace: e2e-tests-events-qcm9m, resource: bindings, ignored listing per whitelist
Aug 21 17:41:30.604: INFO: namespace e2e-tests-events-qcm9m deletion completed in 38.209096746s

â€¢ [SLOW TEST:46.370 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:41:30.604: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8srvp A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-8srvp;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8srvp A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8srvp.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-8srvp.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8srvp.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8srvp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-8srvp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8srvp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-8srvp.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8srvp.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 142.2.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.2.142_udp@PTR;check="$$(dig +tcp +noall +answer +search 142.2.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.2.142_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8srvp A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-8srvp;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8srvp A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-8srvp;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-8srvp.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-8srvp.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-8srvp.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-8srvp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8srvp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-8srvp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-8srvp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-8srvp.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8srvp.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 142.2.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.2.142_udp@PTR;check="$$(dig +tcp +noall +answer +search 142.2.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.2.142_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 21 17:41:46.784: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.792: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.808: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.821: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.828: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.835: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.883: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.889: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.896: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.904: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.911: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.917: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.924: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.931: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:46.977: INFO: Lookups using e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-8srvp jessie_tcp@dns-test-service.e2e-tests-dns-8srvp jessie_udp@dns-test-service.e2e-tests-dns-8srvp.svc jessie_tcp@dns-test-service.e2e-tests-dns-8srvp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc]

Aug 21 17:41:51.986: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:51.993: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.009: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.024: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.031: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.039: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.088: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.096: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.103: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.110: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.117: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.125: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.132: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.140: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:52.184: INFO: Lookups using e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-8srvp jessie_tcp@dns-test-service.e2e-tests-dns-8srvp jessie_udp@dns-test-service.e2e-tests-dns-8srvp.svc jessie_tcp@dns-test-service.e2e-tests-dns-8srvp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc]

Aug 21 17:41:56.985: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:56.992: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.006: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.021: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.028: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.039: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.087: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.094: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.101: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.110: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.117: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.124: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.131: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.138: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:41:57.180: INFO: Lookups using e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-8srvp jessie_tcp@dns-test-service.e2e-tests-dns-8srvp jessie_udp@dns-test-service.e2e-tests-dns-8srvp.svc jessie_tcp@dns-test-service.e2e-tests-dns-8srvp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc]

Aug 21 17:42:01.989: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:01.997: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.012: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.027: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.037: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.044: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.104: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.111: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.118: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.126: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8srvp from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.133: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.142: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.149: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.160: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc from pod e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca: the server could not find the requested resource (get pods dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca)
Aug 21 17:42:02.232: INFO: Lookups using e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp wheezy_tcp@dns-test-service.e2e-tests-dns-8srvp.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-8srvp jessie_tcp@dns-test-service.e2e-tests-dns-8srvp jessie_udp@dns-test-service.e2e-tests-dns-8srvp.svc jessie_tcp@dns-test-service.e2e-tests-dns-8srvp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-8srvp.svc]

Aug 21 17:42:07.192: INFO: DNS probes using e2e-tests-dns-8srvp/dns-test-e8fa5199-c43a-11e9-89d6-e2e196a4cdca succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:42:07.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-8srvp" for this suite.
Aug 21 17:42:13.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:42:13.429: INFO: namespace: e2e-tests-dns-8srvp, resource: bindings, ignored listing per whitelist
Aug 21 17:42:13.545: INFO: namespace e2e-tests-dns-8srvp deletion completed in 6.254848848s

â€¢ [SLOW TEST:42.941 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:42:13.546: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zc4vz
Aug 21 17:42:17.709: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zc4vz
STEP: checking the pod's current state and verifying that restartCount is present
Aug 21 17:42:17.715: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:46:18.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zc4vz" for this suite.
Aug 21 17:46:24.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:46:24.697: INFO: namespace: e2e-tests-container-probe-zc4vz, resource: bindings, ignored listing per whitelist
Aug 21 17:46:24.778: INFO: namespace e2e-tests-container-probe-zc4vz deletion completed in 6.210087435s

â€¢ [SLOW TEST:251.233 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:46:24.778: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 17:46:24.874: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9849af3e-c43b-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-crgsb" to be "success or failure"
Aug 21 17:46:24.881: INFO: Pod "downwardapi-volume-9849af3e-c43b-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.668714ms
Aug 21 17:46:26.887: INFO: Pod "downwardapi-volume-9849af3e-c43b-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013131828s
Aug 21 17:46:28.894: INFO: Pod "downwardapi-volume-9849af3e-c43b-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019830768s
STEP: Saw pod success
Aug 21 17:46:28.894: INFO: Pod "downwardapi-volume-9849af3e-c43b-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:46:28.900: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downwardapi-volume-9849af3e-c43b-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 17:46:28.930: INFO: Waiting for pod downwardapi-volume-9849af3e-c43b-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:46:28.935: INFO: Pod downwardapi-volume-9849af3e-c43b-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:46:28.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-crgsb" for this suite.
Aug 21 17:46:34.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:46:35.149: INFO: namespace: e2e-tests-projected-crgsb, resource: bindings, ignored listing per whitelist
Aug 21 17:46:35.163: INFO: namespace e2e-tests-projected-crgsb deletion completed in 6.219508966s

â€¢ [SLOW TEST:10.384 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:46:35.163: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 21 17:46:39.811: INFO: Successfully updated pod "annotationupdate9e7a38f7-c43b-11e9-89d6-e2e196a4cdca"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:46:41.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h49cz" for this suite.
Aug 21 17:47:03.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:47:03.983: INFO: namespace: e2e-tests-projected-h49cz, resource: bindings, ignored listing per whitelist
Aug 21 17:47:04.059: INFO: namespace e2e-tests-projected-h49cz deletion completed in 22.213957746s

â€¢ [SLOW TEST:28.897 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:47:04.059: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 17:47:04.160: INFO: Waiting up to 5m0s for pod "downwardapi-volume-afb427a0-c43b-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-cfwqt" to be "success or failure"
Aug 21 17:47:04.173: INFO: Pod "downwardapi-volume-afb427a0-c43b-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 13.480177ms
Aug 21 17:47:06.181: INFO: Pod "downwardapi-volume-afb427a0-c43b-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021640471s
Aug 21 17:47:08.188: INFO: Pod "downwardapi-volume-afb427a0-c43b-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028409516s
STEP: Saw pod success
Aug 21 17:47:08.188: INFO: Pod "downwardapi-volume-afb427a0-c43b-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:47:08.194: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downwardapi-volume-afb427a0-c43b-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 17:47:08.225: INFO: Waiting for pod downwardapi-volume-afb427a0-c43b-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:47:08.230: INFO: Pod downwardapi-volume-afb427a0-c43b-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:47:08.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cfwqt" for this suite.
Aug 21 17:47:14.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:47:14.388: INFO: namespace: e2e-tests-downward-api-cfwqt, resource: bindings, ignored listing per whitelist
Aug 21 17:47:14.460: INFO: namespace e2e-tests-downward-api-cfwqt deletion completed in 6.222061068s

â€¢ [SLOW TEST:10.401 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:47:14.461: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Aug 21 17:47:14.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 --namespace=e2e-tests-kubectl-dd9sb run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 21 17:47:17.128: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 21 17:47:17.128: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:47:19.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dd9sb" for this suite.
Aug 21 17:47:33.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:47:33.224: INFO: namespace: e2e-tests-kubectl-dd9sb, resource: bindings, ignored listing per whitelist
Aug 21 17:47:33.476: INFO: namespace e2e-tests-kubectl-dd9sb deletion completed in 14.323798254s

â€¢ [SLOW TEST:19.015 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:47:33.476: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 21 17:47:33.681: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-lj72w,SelfLink:/api/v1/namespaces/e2e-tests-watch-lj72w/configmaps/e2e-watch-test-resource-version,UID:c1486242-c43b-11e9-b0fd-0afb3721cd16,ResourceVersion:20074,Generation:0,CreationTimestamp:2019-08-21 17:47:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 21 17:47:33.681: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-lj72w,SelfLink:/api/v1/namespaces/e2e-tests-watch-lj72w/configmaps/e2e-watch-test-resource-version,UID:c1486242-c43b-11e9-b0fd-0afb3721cd16,ResourceVersion:20075,Generation:0,CreationTimestamp:2019-08-21 17:47:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:47:33.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-lj72w" for this suite.
Aug 21 17:47:39.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:47:39.924: INFO: namespace: e2e-tests-watch-lj72w, resource: bindings, ignored listing per whitelist
Aug 21 17:47:39.949: INFO: namespace e2e-tests-watch-lj72w deletion completed in 6.260123983s

â€¢ [SLOW TEST:6.473 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:47:39.949: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-c51a4a74-c43b-11e9-89d6-e2e196a4cdca
STEP: Creating secret with name s-test-opt-upd-c51a4ad1-c43b-11e9-89d6-e2e196a4cdca
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c51a4a74-c43b-11e9-89d6-e2e196a4cdca
STEP: Updating secret s-test-opt-upd-c51a4ad1-c43b-11e9-89d6-e2e196a4cdca
STEP: Creating secret with name s-test-opt-create-c51a4af1-c43b-11e9-89d6-e2e196a4cdca
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:47:48.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-b5kch" for this suite.
Aug 21 17:48:10.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:48:10.333: INFO: namespace: e2e-tests-secrets-b5kch, resource: bindings, ignored listing per whitelist
Aug 21 17:48:10.449: INFO: namespace e2e-tests-secrets-b5kch deletion completed in 22.214540766s

â€¢ [SLOW TEST:30.500 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:48:10.450: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:48:10.585: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d74a5eb1-c43b-11e9-b0fd-0afb3721cd16", Controller:(*bool)(0xc002c55b9e), BlockOwnerDeletion:(*bool)(0xc002c55b9f)}}
Aug 21 17:48:10.592: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"d747cd5d-c43b-11e9-b0fd-0afb3721cd16", Controller:(*bool)(0xc0018cf00e), BlockOwnerDeletion:(*bool)(0xc0018cf00f)}}
Aug 21 17:48:10.599: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d74962ae-c43b-11e9-b0fd-0afb3721cd16", Controller:(*bool)(0xc002c55d86), BlockOwnerDeletion:(*bool)(0xc002c55d87)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:48:15.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jftb2" for this suite.
Aug 21 17:48:21.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:48:21.872: INFO: namespace: e2e-tests-gc-jftb2, resource: bindings, ignored listing per whitelist
Aug 21 17:48:21.917: INFO: namespace e2e-tests-gc-jftb2 deletion completed in 6.293348799s

â€¢ [SLOW TEST:11.467 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:48:21.917: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:48:22.020: INFO: (0) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.317006ms)
Aug 21 17:48:22.028: INFO: (1) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.373659ms)
Aug 21 17:48:22.035: INFO: (2) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.771936ms)
Aug 21 17:48:22.042: INFO: (3) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.766274ms)
Aug 21 17:48:22.049: INFO: (4) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.800121ms)
Aug 21 17:48:22.056: INFO: (5) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.360136ms)
Aug 21 17:48:22.063: INFO: (6) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.08208ms)
Aug 21 17:48:22.073: INFO: (7) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.601374ms)
Aug 21 17:48:22.080: INFO: (8) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.823303ms)
Aug 21 17:48:22.087: INFO: (9) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.430856ms)
Aug 21 17:48:22.094: INFO: (10) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.60573ms)
Aug 21 17:48:22.107: INFO: (11) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.915833ms)
Aug 21 17:48:22.121: INFO: (12) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 13.925096ms)
Aug 21 17:48:22.127: INFO: (13) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.679071ms)
Aug 21 17:48:22.134: INFO: (14) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.137632ms)
Aug 21 17:48:22.141: INFO: (15) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.351425ms)
Aug 21 17:48:22.147: INFO: (16) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.524836ms)
Aug 21 17:48:22.154: INFO: (17) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.537471ms)
Aug 21 17:48:22.161: INFO: (18) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.001966ms)
Aug 21 17:48:22.167: INFO: (19) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.405682ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:48:22.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5b4ln" for this suite.
Aug 21 17:48:28.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:48:28.300: INFO: namespace: e2e-tests-proxy-5b4ln, resource: bindings, ignored listing per whitelist
Aug 21 17:48:28.394: INFO: namespace e2e-tests-proxy-5b4ln deletion completed in 6.216912874s

â€¢ [SLOW TEST:6.477 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:48:28.394: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e1f8f0f5-c43b-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 17:48:28.501: INFO: Waiting up to 5m0s for pod "pod-secrets-e1fa6969-c43b-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-secrets-8wmzc" to be "success or failure"
Aug 21 17:48:28.508: INFO: Pod "pod-secrets-e1fa6969-c43b-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.737058ms
Aug 21 17:48:30.514: INFO: Pod "pod-secrets-e1fa6969-c43b-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013509393s
Aug 21 17:48:32.521: INFO: Pod "pod-secrets-e1fa6969-c43b-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020244884s
STEP: Saw pod success
Aug 21 17:48:32.521: INFO: Pod "pod-secrets-e1fa6969-c43b-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:48:32.527: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-secrets-e1fa6969-c43b-11e9-89d6-e2e196a4cdca container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 17:48:32.561: INFO: Waiting for pod pod-secrets-e1fa6969-c43b-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:48:32.567: INFO: Pod pod-secrets-e1fa6969-c43b-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:48:32.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8wmzc" for this suite.
Aug 21 17:48:38.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:48:38.649: INFO: namespace: e2e-tests-secrets-8wmzc, resource: bindings, ignored listing per whitelist
Aug 21 17:48:38.793: INFO: namespace e2e-tests-secrets-8wmzc deletion completed in 6.217555407s

â€¢ [SLOW TEST:10.399 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:48:38.793: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:48:38.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hmb6g" for this suite.
Aug 21 17:49:00.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:49:00.952: INFO: namespace: e2e-tests-pods-hmb6g, resource: bindings, ignored listing per whitelist
Aug 21 17:49:01.120: INFO: namespace e2e-tests-pods-hmb6g deletion completed in 22.208113261s

â€¢ [SLOW TEST:22.326 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:49:01.120: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f579d8d7-c43b-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:49:01.224: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f57b8d0a-c43b-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-4s9rn" to be "success or failure"
Aug 21 17:49:01.231: INFO: Pod "pod-projected-configmaps-f57b8d0a-c43b-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.69741ms
Aug 21 17:49:03.237: INFO: Pod "pod-projected-configmaps-f57b8d0a-c43b-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013388523s
Aug 21 17:49:05.244: INFO: Pod "pod-projected-configmaps-f57b8d0a-c43b-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020239535s
STEP: Saw pod success
Aug 21 17:49:05.244: INFO: Pod "pod-projected-configmaps-f57b8d0a-c43b-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:49:05.250: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-projected-configmaps-f57b8d0a-c43b-11e9-89d6-e2e196a4cdca container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 17:49:05.281: INFO: Waiting for pod pod-projected-configmaps-f57b8d0a-c43b-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:49:05.287: INFO: Pod pod-projected-configmaps-f57b8d0a-c43b-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:49:05.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4s9rn" for this suite.
Aug 21 17:49:11.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:49:11.357: INFO: namespace: e2e-tests-projected-4s9rn, resource: bindings, ignored listing per whitelist
Aug 21 17:49:11.501: INFO: namespace e2e-tests-projected-4s9rn deletion completed in 6.2064028s

â€¢ [SLOW TEST:10.382 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:49:11.501: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Aug 21 17:49:11.587: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-507288067 proxy --unix-socket=/tmp/kubectl-proxy-unix652767110/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:49:11.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d45v6" for this suite.
Aug 21 17:49:17.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:49:17.814: INFO: namespace: e2e-tests-kubectl-d45v6, resource: bindings, ignored listing per whitelist
Aug 21 17:49:17.897: INFO: namespace e2e-tests-kubectl-d45v6 deletion completed in 6.248546647s

â€¢ [SLOW TEST:6.395 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:49:17.897: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 21 17:49:17.979: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:49:22.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6hbgv" for this suite.
Aug 21 17:49:28.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:49:28.872: INFO: namespace: e2e-tests-init-container-6hbgv, resource: bindings, ignored listing per whitelist
Aug 21 17:49:29.043: INFO: namespace e2e-tests-init-container-6hbgv deletion completed in 6.210381337s

â€¢ [SLOW TEST:11.146 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:49:29.044: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:49:53.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-kknzz" for this suite.
Aug 21 17:49:59.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:49:59.595: INFO: namespace: e2e-tests-container-runtime-kknzz, resource: bindings, ignored listing per whitelist
Aug 21 17:49:59.682: INFO: namespace e2e-tests-container-runtime-kknzz deletion completed in 6.202744512s

â€¢ [SLOW TEST:30.639 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:49:59.682: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1862d8e2-c43c-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:49:59.793: INFO: Waiting up to 5m0s for pod "pod-configmaps-18644ecd-c43c-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-configmap-p2dwf" to be "success or failure"
Aug 21 17:49:59.799: INFO: Pod "pod-configmaps-18644ecd-c43c-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.334999ms
Aug 21 17:50:01.806: INFO: Pod "pod-configmaps-18644ecd-c43c-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013633574s
Aug 21 17:50:03.813: INFO: Pod "pod-configmaps-18644ecd-c43c-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02032218s
STEP: Saw pod success
Aug 21 17:50:03.813: INFO: Pod "pod-configmaps-18644ecd-c43c-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:50:03.819: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-configmaps-18644ecd-c43c-11e9-89d6-e2e196a4cdca container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 17:50:03.852: INFO: Waiting for pod pod-configmaps-18644ecd-c43c-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:50:03.857: INFO: Pod pod-configmaps-18644ecd-c43c-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:50:03.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p2dwf" for this suite.
Aug 21 17:50:09.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:50:10.078: INFO: namespace: e2e-tests-configmap-p2dwf, resource: bindings, ignored listing per whitelist
Aug 21 17:50:10.141: INFO: namespace e2e-tests-configmap-p2dwf deletion completed in 6.275109921s

â€¢ [SLOW TEST:10.458 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:50:10.141: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-rjvsl/configmap-test-1ea5094a-c43c-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:50:10.298: INFO: Waiting up to 5m0s for pod "pod-configmaps-1ea6f381-c43c-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-configmap-rjvsl" to be "success or failure"
Aug 21 17:50:10.311: INFO: Pod "pod-configmaps-1ea6f381-c43c-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 12.045613ms
Aug 21 17:50:12.317: INFO: Pod "pod-configmaps-1ea6f381-c43c-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018335964s
Aug 21 17:50:14.323: INFO: Pod "pod-configmaps-1ea6f381-c43c-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024854378s
STEP: Saw pod success
Aug 21 17:50:14.323: INFO: Pod "pod-configmaps-1ea6f381-c43c-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:50:14.329: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-configmaps-1ea6f381-c43c-11e9-89d6-e2e196a4cdca container env-test: <nil>
STEP: delete the pod
Aug 21 17:50:14.361: INFO: Waiting for pod pod-configmaps-1ea6f381-c43c-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:50:14.366: INFO: Pod pod-configmaps-1ea6f381-c43c-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:50:14.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rjvsl" for this suite.
Aug 21 17:50:20.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:50:20.430: INFO: namespace: e2e-tests-configmap-rjvsl, resource: bindings, ignored listing per whitelist
Aug 21 17:50:20.642: INFO: namespace e2e-tests-configmap-rjvsl deletion completed in 6.268226584s

â€¢ [SLOW TEST:10.501 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:50:20.642: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qvswx
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Aug 21 17:50:20.756: INFO: Found 0 stateful pods, waiting for 3
Aug 21 17:50:30.763: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:50:30.763: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:50:30.763: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 21 17:50:30.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-qvswx ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 17:50:31.034: INFO: stderr: ""
Aug 21 17:50:31.034: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 17:50:31.034: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 21 17:50:41.082: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 21 17:50:41.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-qvswx ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:50:41.344: INFO: stderr: ""
Aug 21 17:50:41.344: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 17:50:41.344: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 17:50:41.383: INFO: Waiting for StatefulSet e2e-tests-statefulset-qvswx/ss2 to complete update
Aug 21 17:50:41.384: INFO: Waiting for Pod e2e-tests-statefulset-qvswx/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 21 17:50:41.384: INFO: Waiting for Pod e2e-tests-statefulset-qvswx/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 21 17:50:41.384: INFO: Waiting for Pod e2e-tests-statefulset-qvswx/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 21 17:50:51.396: INFO: Waiting for StatefulSet e2e-tests-statefulset-qvswx/ss2 to complete update
Aug 21 17:50:51.396: INFO: Waiting for Pod e2e-tests-statefulset-qvswx/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 21 17:50:51.396: INFO: Waiting for Pod e2e-tests-statefulset-qvswx/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 21 17:51:01.397: INFO: Waiting for StatefulSet e2e-tests-statefulset-qvswx/ss2 to complete update
Aug 21 17:51:01.397: INFO: Waiting for Pod e2e-tests-statefulset-qvswx/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Aug 21 17:51:11.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-qvswx ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 21 17:51:11.657: INFO: stderr: ""
Aug 21 17:51:11.657: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 21 17:51:11.657: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 21 17:51:21.704: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 21 17:51:31.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 exec --namespace=e2e-tests-statefulset-qvswx ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 21 17:51:31.984: INFO: stderr: ""
Aug 21 17:51:31.984: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 21 17:51:31.984: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 21 17:51:42.024: INFO: Waiting for StatefulSet e2e-tests-statefulset-qvswx/ss2 to complete update
Aug 21 17:51:42.024: INFO: Waiting for Pod e2e-tests-statefulset-qvswx/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Aug 21 17:51:42.024: INFO: Waiting for Pod e2e-tests-statefulset-qvswx/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Aug 21 17:51:42.024: INFO: Waiting for Pod e2e-tests-statefulset-qvswx/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Aug 21 17:51:52.038: INFO: Waiting for StatefulSet e2e-tests-statefulset-qvswx/ss2 to complete update
Aug 21 17:51:52.038: INFO: Waiting for Pod e2e-tests-statefulset-qvswx/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 21 17:52:02.039: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qvswx
Aug 21 17:52:02.045: INFO: Scaling statefulset ss2 to 0
Aug 21 17:52:22.075: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 17:52:22.081: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:52:22.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qvswx" for this suite.
Aug 21 17:52:28.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:52:28.291: INFO: namespace: e2e-tests-statefulset-qvswx, resource: bindings, ignored listing per whitelist
Aug 21 17:52:28.388: INFO: namespace e2e-tests-statefulset-qvswx deletion completed in 6.225197892s

â€¢ [SLOW TEST:127.746 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:52:28.388: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 17:52:28.484: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71044447-c43c-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-qqx88" to be "success or failure"
Aug 21 17:52:28.490: INFO: Pod "downwardapi-volume-71044447-c43c-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.84608ms
Aug 21 17:52:30.498: INFO: Pod "downwardapi-volume-71044447-c43c-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014323196s
Aug 21 17:52:32.504: INFO: Pod "downwardapi-volume-71044447-c43c-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020319124s
STEP: Saw pod success
Aug 21 17:52:32.504: INFO: Pod "downwardapi-volume-71044447-c43c-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:52:32.509: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downwardapi-volume-71044447-c43c-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 17:52:32.540: INFO: Waiting for pod downwardapi-volume-71044447-c43c-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:52:32.546: INFO: Pod downwardapi-volume-71044447-c43c-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:52:32.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qqx88" for this suite.
Aug 21 17:52:38.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:52:38.594: INFO: namespace: e2e-tests-downward-api-qqx88, resource: bindings, ignored listing per whitelist
Aug 21 17:52:38.767: INFO: namespace e2e-tests-downward-api-qqx88 deletion completed in 6.21241168s

â€¢ [SLOW TEST:10.379 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:52:38.767: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0821 17:52:39.431909      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 17:52:39.431: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:52:39.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wb7vm" for this suite.
Aug 21 17:52:45.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:52:45.526: INFO: namespace: e2e-tests-gc-wb7vm, resource: bindings, ignored listing per whitelist
Aug 21 17:52:45.648: INFO: namespace e2e-tests-gc-wb7vm deletion completed in 6.209113172s

â€¢ [SLOW TEST:6.881 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:52:45.649: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0821 17:52:55.851222      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 17:52:55.851: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:52:55.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4bcv4" for this suite.
Aug 21 17:53:01.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:53:01.943: INFO: namespace: e2e-tests-gc-4bcv4, resource: bindings, ignored listing per whitelist
Aug 21 17:53:02.082: INFO: namespace e2e-tests-gc-4bcv4 deletion completed in 6.222807363s

â€¢ [SLOW TEST:16.433 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:53:02.082: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2dphd
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-2dphd
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-2dphd
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-2dphd
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-2dphd
Aug 21 17:53:06.231: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2dphd, name: ss-0, uid: 8526fdd2-c43c-11e9-bb91-06b2a5b3abd6, status phase: Pending. Waiting for statefulset controller to delete.
Aug 21 17:53:09.274: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2dphd, name: ss-0, uid: 8526fdd2-c43c-11e9-bb91-06b2a5b3abd6, status phase: Failed. Waiting for statefulset controller to delete.
Aug 21 17:53:09.282: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2dphd, name: ss-0, uid: 8526fdd2-c43c-11e9-bb91-06b2a5b3abd6, status phase: Failed. Waiting for statefulset controller to delete.
Aug 21 17:53:09.287: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-2dphd
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-2dphd
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-2dphd and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 21 17:53:29.379: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2dphd
Aug 21 17:53:29.385: INFO: Scaling statefulset ss to 0
Aug 21 17:53:39.408: INFO: Waiting for statefulset status.replicas updated to 0
Aug 21 17:53:39.414: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:53:39.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2dphd" for this suite.
Aug 21 17:53:45.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:53:45.592: INFO: namespace: e2e-tests-statefulset-2dphd, resource: bindings, ignored listing per whitelist
Aug 21 17:53:45.643: INFO: namespace e2e-tests-statefulset-2dphd deletion completed in 6.198162304s

â€¢ [SLOW TEST:43.561 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:53:45.643: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:53:45.764: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 21 17:53:45.784: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:45.784: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:45.784: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:45.791: INFO: Number of nodes with available pods: 0
Aug 21 17:53:45.791: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:53:46.801: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:46.801: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:46.801: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:46.807: INFO: Number of nodes with available pods: 0
Aug 21 17:53:46.807: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:53:47.801: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:47.801: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:47.801: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:47.807: INFO: Number of nodes with available pods: 0
Aug 21 17:53:47.807: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:53:48.800: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:48.800: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:48.800: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:48.806: INFO: Number of nodes with available pods: 3
Aug 21 17:53:48.806: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 21 17:53:48.844: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:48.844: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:48.844: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:48.854: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:48.855: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:48.855: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:49.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:49.861: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:49.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:49.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:49.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:49.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:50.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:50.861: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:50.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:50.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:50.869: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:50.869: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:51.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:51.861: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:51.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:51.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:51.869: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:51.869: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:52.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:52.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:52.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:52.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:52.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:52.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:53.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:53.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:53.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:53.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:53.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:53.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:54.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:54.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:54.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:54.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:54.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:54.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:55.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:55.861: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:55.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:55.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:55.869: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:55.869: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:56.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:56.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:56.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:56.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:56.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:56.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:57.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:57.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:57.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:57.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:57.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:57.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:58.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:58.861: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:58.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:58.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:58.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:58.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:59.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:59.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:59.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:53:59.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:59.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:53:59.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:00.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:00.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:00.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:00.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:00.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:00.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:01.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:01.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:01.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:01.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:01.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:01.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:02.863: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:02.863: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:02.863: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:02.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:02.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:02.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:03.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:03.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:03.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:03.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:03.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:03.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:04.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:04.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:04.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:04.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:04.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:04.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:05.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:05.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:05.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:05.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:05.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:05.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:06.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:06.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:06.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:06.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:06.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:06.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:07.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:07.861: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:07.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:07.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:07.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:07.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:08.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:08.861: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:08.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:08.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:08.869: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:08.869: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:09.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:09.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:09.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:09.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:09.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:09.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:10.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:10.861: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:10.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:10.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:10.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:10.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:11.872: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:11.872: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:11.872: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:11.881: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:11.881: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:11.881: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:12.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:12.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:12.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:12.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:12.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:12.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:13.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:13.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:13.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:13.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:13.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:13.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:14.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:14.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:14.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:14.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:14.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:14.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:15.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:15.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:15.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:15.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:15.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:15.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:16.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:16.861: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:16.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:16.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:16.869: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:16.869: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:17.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:17.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:17.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:17.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:17.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:17.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:18.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:18.861: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:18.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:18.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:18.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:18.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:19.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:19.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:19.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:19.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:19.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:19.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:20.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:20.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:20.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:20.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:20.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:20.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:21.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:21.862: INFO: Wrong image for pod: daemon-set-h5rcd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:21.862: INFO: Pod daemon-set-h5rcd is not available
Aug 21 17:54:21.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:21.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:21.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:21.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:22.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:22.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:22.862: INFO: Pod daemon-set-hsdsg is not available
Aug 21 17:54:22.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:22.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:22.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:23.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:23.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:23.862: INFO: Pod daemon-set-hsdsg is not available
Aug 21 17:54:23.872: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:23.872: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:23.872: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:24.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:24.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:24.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:24.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:24.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:25.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:25.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:25.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:25.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:25.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:26.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:26.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:26.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:26.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:26.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:27.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:27.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:27.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:27.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:27.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:28.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:28.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:28.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:28.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:28.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:29.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:29.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:29.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:29.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:29.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:30.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:30.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:30.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:30.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:30.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:31.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:31.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:31.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:31.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:31.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:32.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:32.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:32.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:32.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:32.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:33.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:33.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:33.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:33.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:33.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:34.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:34.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:34.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:34.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:34.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:35.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:35.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:35.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:35.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:35.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:36.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:36.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:36.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:36.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:36.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:37.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:37.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:37.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:37.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:37.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:38.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:38.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:38.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:38.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:38.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:39.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:39.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:39.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:39.869: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:39.869: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:40.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:40.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:40.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:40.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:40.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:41.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:41.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:41.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:41.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:41.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:42.863: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:42.863: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:42.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:42.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:42.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:43.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:43.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:43.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:43.869: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:43.869: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:44.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:44.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:44.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:44.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:44.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:45.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:45.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:45.873: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:45.873: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:45.873: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:46.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:46.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:46.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:46.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:46.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:47.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:47.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:47.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:47.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:47.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:48.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:48.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:48.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:48.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:48.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:49.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:49.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:49.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:49.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:49.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:50.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:50.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:50.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:50.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:50.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:51.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:51.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:51.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:51.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:51.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:52.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:52.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:52.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:52.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:52.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:53.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:53.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:53.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:53.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:53.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:54.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:54.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:54.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:54.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:54.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:55.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:55.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:55.862: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:54:55.873: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:55.873: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:55.873: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:56.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:56.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:56.861: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:54:56.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:56.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:56.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:57.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:57.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:57.862: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:54:57.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:57.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:57.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:58.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:58.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:58.862: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:54:58.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:58.869: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:58.869: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:59.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:59.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:54:59.861: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:54:59.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:59.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:54:59.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:00.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:00.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:00.862: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:55:00.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:00.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:00.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:01.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:01.861: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:01.861: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:55:01.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:01.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:01.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:02.863: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:02.863: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:02.863: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:55:02.872: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:02.872: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:02.872: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:03.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:03.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:03.862: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:55:03.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:03.869: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:03.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:04.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:04.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:04.862: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:55:04.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:04.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:04.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:05.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:05.862: INFO: Wrong image for pod: daemon-set-h8525. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:05.862: INFO: Pod daemon-set-h8525 is not available
Aug 21 17:55:05.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:05.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:05.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:06.862: INFO: Pod daemon-set-686lr is not available
Aug 21 17:55:06.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:06.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:06.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:06.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:07.862: INFO: Pod daemon-set-686lr is not available
Aug 21 17:55:07.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:07.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:07.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:07.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:08.862: INFO: Pod daemon-set-686lr is not available
Aug 21 17:55:08.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:08.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:08.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:08.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:09.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:09.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:09.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:09.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:10.864: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:10.873: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:10.873: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:10.873: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:11.864: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:11.872: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:11.872: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:11.872: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:12.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:12.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:12.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:12.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:13.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:13.872: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:13.872: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:13.872: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:14.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:14.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:14.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:14.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:15.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:15.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:15.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:15.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:16.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:16.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:16.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:16.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:17.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:17.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:17.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:17.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:18.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:18.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:18.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:18.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:19.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:19.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:19.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:19.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:20.863: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:20.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:20.872: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:20.872: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:21.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:21.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:21.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:21.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:22.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:22.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:22.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:22.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:23.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:23.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:23.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:23.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:24.863: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:24.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:24.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:24.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:25.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:25.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:25.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:25.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:26.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:26.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:26.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:26.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:27.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:27.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:27.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:27.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:28.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:28.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:28.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:28.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:29.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:29.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:29.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:29.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:30.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:30.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:30.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:30.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:31.861: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:31.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:31.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:31.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:32.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:32.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:32.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:32.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:33.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:33.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:33.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:33.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:34.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:34.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:34.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:34.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:35.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:35.872: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:35.872: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:35.872: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:36.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:36.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:36.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:36.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:37.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:37.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:37.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:37.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:38.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:38.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:38.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:38.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:39.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:39.870: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:39.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:39.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:40.862: INFO: Wrong image for pod: daemon-set-99ttb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 21 17:55:40.862: INFO: Pod daemon-set-99ttb is not available
Aug 21 17:55:40.871: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:40.871: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:40.871: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:41.861: INFO: Pod daemon-set-vwlbg is not available
Aug 21 17:55:41.869: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:41.870: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:41.870: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 21 17:55:41.879: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:41.879: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:41.880: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:41.886: INFO: Number of nodes with available pods: 2
Aug 21 17:55:41.886: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:55:42.896: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:42.896: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:42.896: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:42.902: INFO: Number of nodes with available pods: 2
Aug 21 17:55:42.902: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:55:43.895: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:43.895: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:43.896: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:43.902: INFO: Number of nodes with available pods: 2
Aug 21 17:55:43.902: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 17:55:44.896: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:44.896: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:44.896: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 17:55:44.902: INFO: Number of nodes with available pods: 3
Aug 21 17:55:44.902: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-b8zh5, will wait for the garbage collector to delete the pods
Aug 21 17:55:45.009: INFO: Deleting DaemonSet.extensions daemon-set took: 20.656577ms
Aug 21 17:55:45.109: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.253753ms
Aug 21 17:55:55.015: INFO: Number of nodes with available pods: 0
Aug 21 17:55:55.015: INFO: Number of running nodes: 0, number of available pods: 0
Aug 21 17:55:55.021: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-b8zh5/daemonsets","resourceVersion":"22193"},"items":null}

Aug 21 17:55:55.027: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-b8zh5/pods","resourceVersion":"22193"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:55:55.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-b8zh5" for this suite.
Aug 21 17:56:01.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:56:01.236: INFO: namespace: e2e-tests-daemonsets-b8zh5, resource: bindings, ignored listing per whitelist
Aug 21 17:56:01.285: INFO: namespace e2e-tests-daemonsets-b8zh5 deletion completed in 6.218864505s

â€¢ [SLOW TEST:135.642 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:56:01.285: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:56:01.408: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Aug 21 17:56:01.419: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4kffw/daemonsets","resourceVersion":"22255"},"items":null}

Aug 21 17:56:01.426: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4kffw/pods","resourceVersion":"22255"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:56:01.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4kffw" for this suite.
Aug 21 17:56:07.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:56:07.617: INFO: namespace: e2e-tests-daemonsets-4kffw, resource: bindings, ignored listing per whitelist
Aug 21 17:56:07.681: INFO: namespace e2e-tests-daemonsets-4kffw deletion completed in 6.215233275s

S [SKIPPING] [6.396 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Aug 21 17:56:01.408: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:56:07.681: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 17:56:07.781: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f3ba483b-c43c-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-sgdvv" to be "success or failure"
Aug 21 17:56:07.787: INFO: Pod "downwardapi-volume-f3ba483b-c43c-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.580533ms
Aug 21 17:56:09.794: INFO: Pod "downwardapi-volume-f3ba483b-c43c-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013453893s
Aug 21 17:56:11.800: INFO: Pod "downwardapi-volume-f3ba483b-c43c-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019577963s
STEP: Saw pod success
Aug 21 17:56:11.800: INFO: Pod "downwardapi-volume-f3ba483b-c43c-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:56:11.806: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downwardapi-volume-f3ba483b-c43c-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 17:56:11.836: INFO: Waiting for pod downwardapi-volume-f3ba483b-c43c-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:56:11.841: INFO: Pod downwardapi-volume-f3ba483b-c43c-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:56:11.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sgdvv" for this suite.
Aug 21 17:56:17.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:56:17.985: INFO: namespace: e2e-tests-downward-api-sgdvv, resource: bindings, ignored listing per whitelist
Aug 21 17:56:18.051: INFO: namespace e2e-tests-downward-api-sgdvv deletion completed in 6.202125487s

â€¢ [SLOW TEST:10.370 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:56:18.051: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 17:56:18.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-4l4t9'
Aug 21 17:56:18.211: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 21 17:56:18.211: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Aug 21 17:56:18.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-4l4t9'
Aug 21 17:56:18.304: INFO: stderr: ""
Aug 21 17:56:18.304: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:56:18.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4l4t9" for this suite.
Aug 21 17:56:40.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:56:40.368: INFO: namespace: e2e-tests-kubectl-4l4t9, resource: bindings, ignored listing per whitelist
Aug 21 17:56:40.531: INFO: namespace e2e-tests-kubectl-4l4t9 deletion completed in 22.217463614s

â€¢ [SLOW TEST:22.480 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:56:40.531: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-0755b6a2-c43d-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 17:56:40.683: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-07574f53-c43d-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-8rqw8" to be "success or failure"
Aug 21 17:56:40.689: INFO: Pod "pod-projected-secrets-07574f53-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.052225ms
Aug 21 17:56:42.695: INFO: Pod "pod-projected-secrets-07574f53-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01284347s
Aug 21 17:56:44.702: INFO: Pod "pod-projected-secrets-07574f53-c43d-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019501781s
STEP: Saw pod success
Aug 21 17:56:44.702: INFO: Pod "pod-projected-secrets-07574f53-c43d-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:56:44.708: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-projected-secrets-07574f53-c43d-11e9-89d6-e2e196a4cdca container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 21 17:56:44.739: INFO: Waiting for pod pod-projected-secrets-07574f53-c43d-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:56:44.744: INFO: Pod pod-projected-secrets-07574f53-c43d-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:56:44.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8rqw8" for this suite.
Aug 21 17:56:50.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:56:50.930: INFO: namespace: e2e-tests-projected-8rqw8, resource: bindings, ignored listing per whitelist
Aug 21 17:56:50.961: INFO: namespace e2e-tests-projected-8rqw8 deletion completed in 6.209691799s

â€¢ [SLOW TEST:10.431 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:56:50.962: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-0d85cf1f-c43d-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 17:56:51.063: INFO: Waiting up to 5m0s for pod "pod-configmaps-0d873f7a-c43d-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-configmap-4m7h4" to be "success or failure"
Aug 21 17:56:51.069: INFO: Pod "pod-configmaps-0d873f7a-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.447746ms
Aug 21 17:56:53.076: INFO: Pod "pod-configmaps-0d873f7a-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013134252s
Aug 21 17:56:55.082: INFO: Pod "pod-configmaps-0d873f7a-c43d-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019296389s
STEP: Saw pod success
Aug 21 17:56:55.082: INFO: Pod "pod-configmaps-0d873f7a-c43d-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 17:56:55.087: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-configmaps-0d873f7a-c43d-11e9-89d6-e2e196a4cdca container configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 17:56:55.117: INFO: Waiting for pod pod-configmaps-0d873f7a-c43d-11e9-89d6-e2e196a4cdca to disappear
Aug 21 17:56:55.123: INFO: Pod pod-configmaps-0d873f7a-c43d-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:56:55.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4m7h4" for this suite.
Aug 21 17:57:01.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:57:01.318: INFO: namespace: e2e-tests-configmap-4m7h4, resource: bindings, ignored listing per whitelist
Aug 21 17:57:01.354: INFO: namespace e2e-tests-configmap-4m7h4 deletion completed in 6.222667885s

â€¢ [SLOW TEST:10.392 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:57:01.354: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-z5z6c
Aug 21 17:57:05.473: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-z5z6c
STEP: checking the pod's current state and verifying that restartCount is present
Aug 21 17:57:05.479: INFO: Initial restart count of pod liveness-http is 0
Aug 21 17:57:19.532: INFO: Restart count of pod e2e-tests-container-probe-z5z6c/liveness-http is now 1 (14.05332906s elapsed)
Aug 21 17:57:37.592: INFO: Restart count of pod e2e-tests-container-probe-z5z6c/liveness-http is now 2 (32.112808587s elapsed)
Aug 21 17:57:57.659: INFO: Restart count of pod e2e-tests-container-probe-z5z6c/liveness-http is now 3 (52.179859937s elapsed)
Aug 21 17:58:17.729: INFO: Restart count of pod e2e-tests-container-probe-z5z6c/liveness-http is now 4 (1m12.24980261s elapsed)
Aug 21 17:59:27.959: INFO: Restart count of pod e2e-tests-container-probe-z5z6c/liveness-http is now 5 (2m22.480054664s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:59:27.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-z5z6c" for this suite.
Aug 21 17:59:34.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:59:34.082: INFO: namespace: e2e-tests-container-probe-z5z6c, resource: bindings, ignored listing per whitelist
Aug 21 17:59:34.204: INFO: namespace e2e-tests-container-probe-z5z6c deletion completed in 6.217617736s

â€¢ [SLOW TEST:152.850 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:59:34.204: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 17:59:34.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 version'
Aug 21 17:59:34.400: INFO: stderr: ""
Aug 21 17:59:34.400: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.9\", GitCommit:\"3e4f6a92de5f259ef313ad876bb008897f6a98f0\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:14:29Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:59:34.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wqzdq" for this suite.
Aug 21 17:59:40.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 17:59:40.469: INFO: namespace: e2e-tests-kubectl-wqzdq, resource: bindings, ignored listing per whitelist
Aug 21 17:59:40.612: INFO: namespace e2e-tests-kubectl-wqzdq deletion completed in 6.202861721s

â€¢ [SLOW TEST:6.407 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 17:59:40.612: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Aug 21 17:59:40.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:41.059: INFO: stderr: ""
Aug 21 17:59:41.059: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 17:59:41.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:41.125: INFO: stderr: ""
Aug 21 17:59:41.125: INFO: stdout: "update-demo-nautilus-9vc52 update-demo-nautilus-v89xf "
Aug 21 17:59:41.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-9vc52 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:41.201: INFO: stderr: ""
Aug 21 17:59:41.201: INFO: stdout: ""
Aug 21 17:59:41.201: INFO: update-demo-nautilus-9vc52 is created but not running
Aug 21 17:59:46.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:46.273: INFO: stderr: ""
Aug 21 17:59:46.273: INFO: stdout: "update-demo-nautilus-9vc52 update-demo-nautilus-v89xf "
Aug 21 17:59:46.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-9vc52 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:46.344: INFO: stderr: ""
Aug 21 17:59:46.344: INFO: stdout: "true"
Aug 21 17:59:46.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-9vc52 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:46.411: INFO: stderr: ""
Aug 21 17:59:46.411: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 17:59:46.411: INFO: validating pod update-demo-nautilus-9vc52
Aug 21 17:59:46.425: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 17:59:46.425: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 17:59:46.425: INFO: update-demo-nautilus-9vc52 is verified up and running
Aug 21 17:59:46.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-v89xf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:46.490: INFO: stderr: ""
Aug 21 17:59:46.490: INFO: stdout: "true"
Aug 21 17:59:46.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-v89xf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:46.559: INFO: stderr: ""
Aug 21 17:59:46.559: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 17:59:46.559: INFO: validating pod update-demo-nautilus-v89xf
Aug 21 17:59:46.573: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 17:59:46.574: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 17:59:46.574: INFO: update-demo-nautilus-v89xf is verified up and running
STEP: scaling down the replication controller
Aug 21 17:59:46.574: INFO: scanned /root for discovery docs: <nil>
Aug 21 17:59:46.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:47.684: INFO: stderr: ""
Aug 21 17:59:47.684: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 17:59:47.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:47.755: INFO: stderr: ""
Aug 21 17:59:47.755: INFO: stdout: "update-demo-nautilus-9vc52 update-demo-nautilus-v89xf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 21 17:59:52.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:52.826: INFO: stderr: ""
Aug 21 17:59:52.826: INFO: stdout: "update-demo-nautilus-v89xf "
Aug 21 17:59:52.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-v89xf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:52.905: INFO: stderr: ""
Aug 21 17:59:52.905: INFO: stdout: "true"
Aug 21 17:59:52.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-v89xf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:52.978: INFO: stderr: ""
Aug 21 17:59:52.978: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 17:59:52.978: INFO: validating pod update-demo-nautilus-v89xf
Aug 21 17:59:52.984: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 17:59:52.984: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 17:59:52.984: INFO: update-demo-nautilus-v89xf is verified up and running
STEP: scaling up the replication controller
Aug 21 17:59:52.985: INFO: scanned /root for discovery docs: <nil>
Aug 21 17:59:52.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:54.095: INFO: stderr: ""
Aug 21 17:59:54.095: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 17:59:54.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:54.171: INFO: stderr: ""
Aug 21 17:59:54.171: INFO: stdout: "update-demo-nautilus-8j2dw update-demo-nautilus-v89xf "
Aug 21 17:59:54.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-8j2dw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:54.242: INFO: stderr: ""
Aug 21 17:59:54.242: INFO: stdout: ""
Aug 21 17:59:54.242: INFO: update-demo-nautilus-8j2dw is created but not running
Aug 21 17:59:59.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:59.315: INFO: stderr: ""
Aug 21 17:59:59.315: INFO: stdout: "update-demo-nautilus-8j2dw update-demo-nautilus-v89xf "
Aug 21 17:59:59.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-8j2dw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:59.384: INFO: stderr: ""
Aug 21 17:59:59.385: INFO: stdout: "true"
Aug 21 17:59:59.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-8j2dw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:59.457: INFO: stderr: ""
Aug 21 17:59:59.457: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 17:59:59.457: INFO: validating pod update-demo-nautilus-8j2dw
Aug 21 17:59:59.467: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 17:59:59.467: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 17:59:59.467: INFO: update-demo-nautilus-8j2dw is verified up and running
Aug 21 17:59:59.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-v89xf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:59.536: INFO: stderr: ""
Aug 21 17:59:59.536: INFO: stdout: "true"
Aug 21 17:59:59.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-v89xf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:59.601: INFO: stderr: ""
Aug 21 17:59:59.601: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 17:59:59.601: INFO: validating pod update-demo-nautilus-v89xf
Aug 21 17:59:59.607: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 17:59:59.607: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 17:59:59.607: INFO: update-demo-nautilus-v89xf is verified up and running
STEP: using delete to clean up resources
Aug 21 17:59:59.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:59.680: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 17:59:59.680: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 21 17:59:59.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-x8ltp'
Aug 21 17:59:59.757: INFO: stderr: "No resources found.\n"
Aug 21 17:59:59.757: INFO: stdout: ""
Aug 21 17:59:59.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -l name=update-demo --namespace=e2e-tests-kubectl-x8ltp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 21 17:59:59.828: INFO: stderr: ""
Aug 21 17:59:59.828: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 17:59:59.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x8ltp" for this suite.
Aug 21 18:00:19.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:00:19.926: INFO: namespace: e2e-tests-kubectl-x8ltp, resource: bindings, ignored listing per whitelist
Aug 21 18:00:20.060: INFO: namespace e2e-tests-kubectl-x8ltp deletion completed in 20.22317325s

â€¢ [SLOW TEST:39.448 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:00:20.060: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 18:00:20.157: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a27b599-c43d-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-2rjzj" to be "success or failure"
Aug 21 18:00:20.163: INFO: Pod "downwardapi-volume-8a27b599-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 5.982314ms
Aug 21 18:00:22.170: INFO: Pod "downwardapi-volume-8a27b599-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012511371s
Aug 21 18:00:24.177: INFO: Pod "downwardapi-volume-8a27b599-c43d-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019355186s
STEP: Saw pod success
Aug 21 18:00:24.177: INFO: Pod "downwardapi-volume-8a27b599-c43d-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:00:24.183: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downwardapi-volume-8a27b599-c43d-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 18:00:24.232: INFO: Waiting for pod downwardapi-volume-8a27b599-c43d-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:00:24.237: INFO: Pod downwardapi-volume-8a27b599-c43d-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:00:24.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2rjzj" for this suite.
Aug 21 18:00:30.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:00:30.391: INFO: namespace: e2e-tests-downward-api-2rjzj, resource: bindings, ignored listing per whitelist
Aug 21 18:00:30.464: INFO: namespace e2e-tests-downward-api-2rjzj deletion completed in 6.218691328s

â€¢ [SLOW TEST:10.404 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:00:30.464: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 18:00:30.564: INFO: Waiting up to 5m0s for pod "downwardapi-volume-905badc1-c43d-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-fnvhv" to be "success or failure"
Aug 21 18:00:30.571: INFO: Pod "downwardapi-volume-905badc1-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.198156ms
Aug 21 18:00:32.578: INFO: Pod "downwardapi-volume-905badc1-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01404765s
Aug 21 18:00:34.585: INFO: Pod "downwardapi-volume-905badc1-c43d-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021285463s
STEP: Saw pod success
Aug 21 18:00:34.585: INFO: Pod "downwardapi-volume-905badc1-c43d-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:00:34.591: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downwardapi-volume-905badc1-c43d-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 18:00:34.625: INFO: Waiting for pod downwardapi-volume-905badc1-c43d-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:00:34.631: INFO: Pod downwardapi-volume-905badc1-c43d-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:00:34.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fnvhv" for this suite.
Aug 21 18:00:40.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:00:40.827: INFO: namespace: e2e-tests-downward-api-fnvhv, resource: bindings, ignored listing per whitelist
Aug 21 18:00:40.878: INFO: namespace e2e-tests-downward-api-fnvhv deletion completed in 6.237934876s

â€¢ [SLOW TEST:10.414 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:00:40.878: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Aug 21 18:00:40.971: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-507288067 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:00:41.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dsh9h" for this suite.
Aug 21 18:00:47.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:00:47.190: INFO: namespace: e2e-tests-kubectl-dsh9h, resource: bindings, ignored listing per whitelist
Aug 21 18:00:47.264: INFO: namespace e2e-tests-kubectl-dsh9h deletion completed in 6.213363118s

â€¢ [SLOW TEST:6.386 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:00:47.264: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 21 18:00:54.409: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:00:54.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-7swrh" for this suite.
Aug 21 18:01:16.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:01:16.512: INFO: namespace: e2e-tests-replicaset-7swrh, resource: bindings, ignored listing per whitelist
Aug 21 18:01:16.651: INFO: namespace e2e-tests-replicaset-7swrh deletion completed in 22.214454596s

â€¢ [SLOW TEST:29.387 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:01:16.651: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Aug 21 18:01:16.801: INFO: Waiting up to 5m0s for pod "client-containers-abeaebd8-c43d-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-containers-dhdj9" to be "success or failure"
Aug 21 18:01:16.807: INFO: Pod "client-containers-abeaebd8-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 5.765643ms
Aug 21 18:01:18.813: INFO: Pod "client-containers-abeaebd8-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012241282s
Aug 21 18:01:20.819: INFO: Pod "client-containers-abeaebd8-c43d-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018615432s
STEP: Saw pod success
Aug 21 18:01:20.819: INFO: Pod "client-containers-abeaebd8-c43d-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:01:20.825: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod client-containers-abeaebd8-c43d-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 18:01:20.855: INFO: Waiting for pod client-containers-abeaebd8-c43d-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:01:20.861: INFO: Pod client-containers-abeaebd8-c43d-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:01:20.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-dhdj9" for this suite.
Aug 21 18:01:26.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:01:26.970: INFO: namespace: e2e-tests-containers-dhdj9, resource: bindings, ignored listing per whitelist
Aug 21 18:01:27.087: INFO: namespace e2e-tests-containers-dhdj9 deletion completed in 6.218463702s

â€¢ [SLOW TEST:10.436 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:01:27.087: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Aug 21 18:01:27.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-zgbsf'
Aug 21 18:01:27.368: INFO: stderr: ""
Aug 21 18:01:27.368: INFO: stdout: "pod/pause created\n"
Aug 21 18:01:27.368: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 21 18:01:27.368: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-zgbsf" to be "running and ready"
Aug 21 18:01:27.374: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.036007ms
Aug 21 18:01:29.381: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012584281s
Aug 21 18:01:31.388: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.019457079s
Aug 21 18:01:31.388: INFO: Pod "pause" satisfied condition "running and ready"
Aug 21 18:01:31.388: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 21 18:01:31.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-zgbsf'
Aug 21 18:01:31.471: INFO: stderr: ""
Aug 21 18:01:31.471: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 21 18:01:31.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pod pause -L testing-label --namespace=e2e-tests-kubectl-zgbsf'
Aug 21 18:01:31.540: INFO: stderr: ""
Aug 21 18:01:31.540: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 21 18:01:31.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 label pods pause testing-label- --namespace=e2e-tests-kubectl-zgbsf'
Aug 21 18:01:31.614: INFO: stderr: ""
Aug 21 18:01:31.614: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 21 18:01:31.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pod pause -L testing-label --namespace=e2e-tests-kubectl-zgbsf'
Aug 21 18:01:31.682: INFO: stderr: ""
Aug 21 18:01:31.682: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Aug 21 18:01:31.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zgbsf'
Aug 21 18:01:31.774: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 21 18:01:31.774: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 21 18:01:31.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-zgbsf'
Aug 21 18:01:31.854: INFO: stderr: "No resources found.\n"
Aug 21 18:01:31.854: INFO: stdout: ""
Aug 21 18:01:31.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -l name=pause --namespace=e2e-tests-kubectl-zgbsf -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 21 18:01:31.926: INFO: stderr: ""
Aug 21 18:01:31.926: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:01:31.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zgbsf" for this suite.
Aug 21 18:01:37.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:01:38.031: INFO: namespace: e2e-tests-kubectl-zgbsf, resource: bindings, ignored listing per whitelist
Aug 21 18:01:38.160: INFO: namespace e2e-tests-kubectl-zgbsf deletion completed in 6.22605786s

â€¢ [SLOW TEST:11.073 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:01:38.161: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 21 18:01:38.259: INFO: Waiting up to 5m0s for pod "downward-api-b8b50903-c43d-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-9frpb" to be "success or failure"
Aug 21 18:01:38.266: INFO: Pod "downward-api-b8b50903-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.448338ms
Aug 21 18:01:40.272: INFO: Pod "downward-api-b8b50903-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013171183s
Aug 21 18:01:42.280: INFO: Pod "downward-api-b8b50903-c43d-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02037129s
STEP: Saw pod success
Aug 21 18:01:42.280: INFO: Pod "downward-api-b8b50903-c43d-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:01:42.285: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downward-api-b8b50903-c43d-11e9-89d6-e2e196a4cdca container dapi-container: <nil>
STEP: delete the pod
Aug 21 18:01:42.317: INFO: Waiting for pod downward-api-b8b50903-c43d-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:01:42.323: INFO: Pod downward-api-b8b50903-c43d-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:01:42.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9frpb" for this suite.
Aug 21 18:01:48.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:01:48.468: INFO: namespace: e2e-tests-downward-api-9frpb, resource: bindings, ignored listing per whitelist
Aug 21 18:01:48.550: INFO: namespace e2e-tests-downward-api-9frpb deletion completed in 6.219711467s

â€¢ [SLOW TEST:10.390 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:01:48.550: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 18:01:48.647: INFO: (0) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.127555ms)
Aug 21 18:01:48.654: INFO: (1) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.084847ms)
Aug 21 18:01:48.660: INFO: (2) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.748726ms)
Aug 21 18:01:48.668: INFO: (3) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.05283ms)
Aug 21 18:01:48.674: INFO: (4) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.627123ms)
Aug 21 18:01:48.681: INFO: (5) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.405977ms)
Aug 21 18:01:48.687: INFO: (6) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.696911ms)
Aug 21 18:01:48.694: INFO: (7) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.640963ms)
Aug 21 18:01:48.701: INFO: (8) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.328823ms)
Aug 21 18:01:48.708: INFO: (9) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.312446ms)
Aug 21 18:01:48.714: INFO: (10) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.277781ms)
Aug 21 18:01:48.720: INFO: (11) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.380511ms)
Aug 21 18:01:48.727: INFO: (12) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.69807ms)
Aug 21 18:01:48.734: INFO: (13) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.512974ms)
Aug 21 18:01:48.740: INFO: (14) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.54092ms)
Aug 21 18:01:48.747: INFO: (15) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.357346ms)
Aug 21 18:01:48.753: INFO: (16) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.4019ms)
Aug 21 18:01:48.760: INFO: (17) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.419926ms)
Aug 21 18:01:48.766: INFO: (18) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.746356ms)
Aug 21 18:01:48.773: INFO: (19) /api/v1/nodes/ip-10-0-1-150.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.429685ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:01:48.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wzd5g" for this suite.
Aug 21 18:01:54.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:01:54.897: INFO: namespace: e2e-tests-proxy-wzd5g, resource: bindings, ignored listing per whitelist
Aug 21 18:01:54.982: INFO: namespace e2e-tests-proxy-wzd5g deletion completed in 6.20065638s

â€¢ [SLOW TEST:6.431 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:01:54.982: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Aug 21 18:01:55.083: INFO: Waiting up to 5m0s for pod "client-containers-c2bc536e-c43d-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-containers-kjvlr" to be "success or failure"
Aug 21 18:01:55.091: INFO: Pod "client-containers-c2bc536e-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.815358ms
Aug 21 18:01:57.097: INFO: Pod "client-containers-c2bc536e-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013898894s
Aug 21 18:01:59.104: INFO: Pod "client-containers-c2bc536e-c43d-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020964467s
STEP: Saw pod success
Aug 21 18:01:59.104: INFO: Pod "client-containers-c2bc536e-c43d-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:01:59.109: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod client-containers-c2bc536e-c43d-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 18:01:59.140: INFO: Waiting for pod client-containers-c2bc536e-c43d-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:01:59.146: INFO: Pod client-containers-c2bc536e-c43d-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:01:59.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-kjvlr" for this suite.
Aug 21 18:02:05.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:02:05.375: INFO: namespace: e2e-tests-containers-kjvlr, resource: bindings, ignored listing per whitelist
Aug 21 18:02:05.380: INFO: namespace e2e-tests-containers-kjvlr deletion completed in 6.225935769s

â€¢ [SLOW TEST:10.398 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:02:05.380: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-c8ee72f3-c43d-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 18:02:05.483: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c8effbe6-c43d-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-9469n" to be "success or failure"
Aug 21 18:02:05.490: INFO: Pod "pod-projected-secrets-c8effbe6-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.297331ms
Aug 21 18:02:07.502: INFO: Pod "pod-projected-secrets-c8effbe6-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018802231s
Aug 21 18:02:09.509: INFO: Pod "pod-projected-secrets-c8effbe6-c43d-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025589907s
STEP: Saw pod success
Aug 21 18:02:09.509: INFO: Pod "pod-projected-secrets-c8effbe6-c43d-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:02:09.515: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-projected-secrets-c8effbe6-c43d-11e9-89d6-e2e196a4cdca container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 21 18:02:09.548: INFO: Waiting for pod pod-projected-secrets-c8effbe6-c43d-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:02:09.554: INFO: Pod pod-projected-secrets-c8effbe6-c43d-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:02:09.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9469n" for this suite.
Aug 21 18:02:15.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:02:15.666: INFO: namespace: e2e-tests-projected-9469n, resource: bindings, ignored listing per whitelist
Aug 21 18:02:15.766: INFO: namespace e2e-tests-projected-9469n deletion completed in 6.20457047s

â€¢ [SLOW TEST:10.387 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:02:15.767: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 18:02:15.864: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf1f31ab-c43d-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-rqdbs" to be "success or failure"
Aug 21 18:02:15.870: INFO: Pod "downwardapi-volume-cf1f31ab-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.197584ms
Aug 21 18:02:17.877: INFO: Pod "downwardapi-volume-cf1f31ab-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01314798s
Aug 21 18:02:19.884: INFO: Pod "downwardapi-volume-cf1f31ab-c43d-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019951163s
STEP: Saw pod success
Aug 21 18:02:19.884: INFO: Pod "downwardapi-volume-cf1f31ab-c43d-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:02:19.890: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downwardapi-volume-cf1f31ab-c43d-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 18:02:19.922: INFO: Waiting for pod downwardapi-volume-cf1f31ab-c43d-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:02:19.928: INFO: Pod downwardapi-volume-cf1f31ab-c43d-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:02:19.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rqdbs" for this suite.
Aug 21 18:02:25.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:02:26.115: INFO: namespace: e2e-tests-projected-rqdbs, resource: bindings, ignored listing per whitelist
Aug 21 18:02:26.173: INFO: namespace e2e-tests-projected-rqdbs deletion completed in 6.23661461s

â€¢ [SLOW TEST:10.406 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:02:26.173: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 21 18:02:26.282: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-a,UID:d555be25-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23502,Generation:0,CreationTimestamp:2019-08-21 18:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 21 18:02:26.282: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-a,UID:d555be25-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23502,Generation:0,CreationTimestamp:2019-08-21 18:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 21 18:02:36.295: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-a,UID:d555be25-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23522,Generation:0,CreationTimestamp:2019-08-21 18:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 21 18:02:36.295: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-a,UID:d555be25-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23522,Generation:0,CreationTimestamp:2019-08-21 18:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 21 18:02:46.308: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-a,UID:d555be25-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23542,Generation:0,CreationTimestamp:2019-08-21 18:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 21 18:02:46.308: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-a,UID:d555be25-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23542,Generation:0,CreationTimestamp:2019-08-21 18:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 21 18:02:56.324: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-a,UID:d555be25-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23562,Generation:0,CreationTimestamp:2019-08-21 18:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 21 18:02:56.324: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-a,UID:d555be25-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23562,Generation:0,CreationTimestamp:2019-08-21 18:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 21 18:03:06.338: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-b,UID:ed358e3e-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23582,Generation:0,CreationTimestamp:2019-08-21 18:03:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 21 18:03:06.338: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-b,UID:ed358e3e-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23582,Generation:0,CreationTimestamp:2019-08-21 18:03:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 21 18:03:16.354: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-b,UID:ed358e3e-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23602,Generation:0,CreationTimestamp:2019-08-21 18:03:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 21 18:03:16.354: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-27dqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-27dqb/configmaps/e2e-watch-test-configmap-b,UID:ed358e3e-c43d-11e9-b0fd-0afb3721cd16,ResourceVersion:23602,Generation:0,CreationTimestamp:2019-08-21 18:03:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:03:26.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-27dqb" for this suite.
Aug 21 18:03:32.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:03:32.522: INFO: namespace: e2e-tests-watch-27dqb, resource: bindings, ignored listing per whitelist
Aug 21 18:03:32.570: INFO: namespace e2e-tests-watch-27dqb deletion completed in 6.20467561s

â€¢ [SLOW TEST:66.398 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:03:32.571: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 18:03:32.673: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fce78b3e-c43d-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-jss5k" to be "success or failure"
Aug 21 18:03:32.680: INFO: Pod "downwardapi-volume-fce78b3e-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.375286ms
Aug 21 18:03:34.687: INFO: Pod "downwardapi-volume-fce78b3e-c43d-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013122399s
Aug 21 18:03:36.694: INFO: Pod "downwardapi-volume-fce78b3e-c43d-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020379613s
STEP: Saw pod success
Aug 21 18:03:36.694: INFO: Pod "downwardapi-volume-fce78b3e-c43d-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:03:36.700: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downwardapi-volume-fce78b3e-c43d-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 18:03:36.731: INFO: Waiting for pod downwardapi-volume-fce78b3e-c43d-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:03:36.737: INFO: Pod downwardapi-volume-fce78b3e-c43d-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:03:36.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jss5k" for this suite.
Aug 21 18:03:42.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:03:42.881: INFO: namespace: e2e-tests-projected-jss5k, resource: bindings, ignored listing per whitelist
Aug 21 18:03:42.947: INFO: namespace e2e-tests-projected-jss5k deletion completed in 6.201957063s

â€¢ [SLOW TEST:10.377 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:03:42.947: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-03159cf8-c43e-11e9-89d6-e2e196a4cdca
Aug 21 18:03:43.043: INFO: Pod name my-hostname-basic-03159cf8-c43e-11e9-89d6-e2e196a4cdca: Found 0 pods out of 1
Aug 21 18:03:48.050: INFO: Pod name my-hostname-basic-03159cf8-c43e-11e9-89d6-e2e196a4cdca: Found 1 pods out of 1
Aug 21 18:03:48.050: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-03159cf8-c43e-11e9-89d6-e2e196a4cdca" are running
Aug 21 18:03:48.056: INFO: Pod "my-hostname-basic-03159cf8-c43e-11e9-89d6-e2e196a4cdca-lwf55" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 18:03:43 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 18:03:45 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 18:03:45 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-21 18:03:43 +0000 UTC Reason: Message:}])
Aug 21 18:03:48.056: INFO: Trying to dial the pod
Aug 21 18:03:53.078: INFO: Controller my-hostname-basic-03159cf8-c43e-11e9-89d6-e2e196a4cdca: Got expected result from replica 1 [my-hostname-basic-03159cf8-c43e-11e9-89d6-e2e196a4cdca-lwf55]: "my-hostname-basic-03159cf8-c43e-11e9-89d6-e2e196a4cdca-lwf55", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:03:53.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-9xkpt" for this suite.
Aug 21 18:03:59.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:03:59.195: INFO: namespace: e2e-tests-replication-controller-9xkpt, resource: bindings, ignored listing per whitelist
Aug 21 18:03:59.297: INFO: namespace e2e-tests-replication-controller-9xkpt deletion completed in 6.211362544s

â€¢ [SLOW TEST:16.350 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:03:59.297: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:04:05.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-plvf9" for this suite.
Aug 21 18:04:11.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:04:11.547: INFO: namespace: e2e-tests-namespaces-plvf9, resource: bindings, ignored listing per whitelist
Aug 21 18:04:11.686: INFO: namespace e2e-tests-namespaces-plvf9 deletion completed in 6.206535869s
STEP: Destroying namespace "e2e-tests-nsdeletetest-g8m6w" for this suite.
Aug 21 18:04:11.692: INFO: Namespace e2e-tests-nsdeletetest-g8m6w was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-s48wx" for this suite.
Aug 21 18:04:17.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:04:17.858: INFO: namespace: e2e-tests-nsdeletetest-s48wx, resource: bindings, ignored listing per whitelist
Aug 21 18:04:17.892: INFO: namespace e2e-tests-nsdeletetest-s48wx deletion completed in 6.199994481s

â€¢ [SLOW TEST:18.594 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:04:17.892: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-c8nf
STEP: Creating a pod to test atomic-volume-subpath
Aug 21 18:04:18.000: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-c8nf" in namespace "e2e-tests-subpath-f4hkd" to be "success or failure"
Aug 21 18:04:18.010: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.862805ms
Aug 21 18:04:20.017: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017568602s
Aug 21 18:04:22.024: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024587511s
Aug 21 18:04:24.031: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Running", Reason="", readiness=false. Elapsed: 6.031568723s
Aug 21 18:04:26.038: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Running", Reason="", readiness=false. Elapsed: 8.038384844s
Aug 21 18:04:28.045: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Running", Reason="", readiness=false. Elapsed: 10.04508647s
Aug 21 18:04:30.052: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Running", Reason="", readiness=false. Elapsed: 12.051938703s
Aug 21 18:04:32.058: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Running", Reason="", readiness=false. Elapsed: 14.058524486s
Aug 21 18:04:34.065: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Running", Reason="", readiness=false. Elapsed: 16.065401168s
Aug 21 18:04:36.077: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Running", Reason="", readiness=false. Elapsed: 18.077723482s
Aug 21 18:04:38.084: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Running", Reason="", readiness=false. Elapsed: 20.084810313s
Aug 21 18:04:40.091: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Running", Reason="", readiness=false. Elapsed: 22.091607878s
Aug 21 18:04:42.098: INFO: Pod "pod-subpath-test-secret-c8nf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.098638403s
STEP: Saw pod success
Aug 21 18:04:42.098: INFO: Pod "pod-subpath-test-secret-c8nf" satisfied condition "success or failure"
Aug 21 18:04:42.104: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-subpath-test-secret-c8nf container test-container-subpath-secret-c8nf: <nil>
STEP: delete the pod
Aug 21 18:04:42.142: INFO: Waiting for pod pod-subpath-test-secret-c8nf to disappear
Aug 21 18:04:42.149: INFO: Pod pod-subpath-test-secret-c8nf no longer exists
STEP: Deleting pod pod-subpath-test-secret-c8nf
Aug 21 18:04:42.149: INFO: Deleting pod "pod-subpath-test-secret-c8nf" in namespace "e2e-tests-subpath-f4hkd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:04:42.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-f4hkd" for this suite.
Aug 21 18:04:48.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:04:48.253: INFO: namespace: e2e-tests-subpath-f4hkd, resource: bindings, ignored listing per whitelist
Aug 21 18:04:48.413: INFO: namespace e2e-tests-subpath-f4hkd deletion completed in 6.250083791s

â€¢ [SLOW TEST:30.521 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:04:48.413: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 18:04:48.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-p69zq'
Aug 21 18:04:48.584: INFO: stderr: ""
Aug 21 18:04:48.584: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Aug 21 18:04:48.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-p69zq'
Aug 21 18:05:06.728: INFO: stderr: ""
Aug 21 18:05:06.728: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:05:06.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p69zq" for this suite.
Aug 21 18:05:12.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:05:13.019: INFO: namespace: e2e-tests-kubectl-p69zq, resource: bindings, ignored listing per whitelist
Aug 21 18:05:13.019: INFO: namespace e2e-tests-kubectl-p69zq deletion completed in 6.269827233s

â€¢ [SLOW TEST:24.606 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:05:13.020: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0821 18:05:19.167195      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 21 18:05:19.167: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:05:19.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6vhhb" for this suite.
Aug 21 18:05:25.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:05:25.224: INFO: namespace: e2e-tests-gc-6vhhb, resource: bindings, ignored listing per whitelist
Aug 21 18:05:25.409: INFO: namespace e2e-tests-gc-6vhhb deletion completed in 6.233467658s

â€¢ [SLOW TEST:12.389 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:05:25.409: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 18:05:25.513: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40296b61-c43e-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-downward-api-vp56b" to be "success or failure"
Aug 21 18:05:25.520: INFO: Pod "downwardapi-volume-40296b61-c43e-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.328604ms
Aug 21 18:05:27.527: INFO: Pod "downwardapi-volume-40296b61-c43e-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013927432s
Aug 21 18:05:29.533: INFO: Pod "downwardapi-volume-40296b61-c43e-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020538089s
STEP: Saw pod success
Aug 21 18:05:29.533: INFO: Pod "downwardapi-volume-40296b61-c43e-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:05:29.539: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod downwardapi-volume-40296b61-c43e-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 18:05:29.587: INFO: Waiting for pod downwardapi-volume-40296b61-c43e-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:05:29.595: INFO: Pod downwardapi-volume-40296b61-c43e-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:05:29.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vp56b" for this suite.
Aug 21 18:05:35.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:05:35.690: INFO: namespace: e2e-tests-downward-api-vp56b, resource: bindings, ignored listing per whitelist
Aug 21 18:05:35.827: INFO: namespace e2e-tests-downward-api-vp56b deletion completed in 6.224225024s

â€¢ [SLOW TEST:10.418 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:05:35.827: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 18:05:35.931: INFO: Waiting up to 5m0s for pod "downwardapi-volume-465ec4fe-c43e-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-5q5kz" to be "success or failure"
Aug 21 18:05:35.937: INFO: Pod "downwardapi-volume-465ec4fe-c43e-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 5.678166ms
Aug 21 18:05:37.944: INFO: Pod "downwardapi-volume-465ec4fe-c43e-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012824851s
Aug 21 18:05:39.952: INFO: Pod "downwardapi-volume-465ec4fe-c43e-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020153036s
STEP: Saw pod success
Aug 21 18:05:39.952: INFO: Pod "downwardapi-volume-465ec4fe-c43e-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:05:39.958: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downwardapi-volume-465ec4fe-c43e-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 18:05:39.988: INFO: Waiting for pod downwardapi-volume-465ec4fe-c43e-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:05:39.995: INFO: Pod downwardapi-volume-465ec4fe-c43e-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:05:39.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5q5kz" for this suite.
Aug 21 18:05:46.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:05:46.168: INFO: namespace: e2e-tests-projected-5q5kz, resource: bindings, ignored listing per whitelist
Aug 21 18:05:46.258: INFO: namespace e2e-tests-projected-5q5kz deletion completed in 6.250770862s

â€¢ [SLOW TEST:10.430 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:05:46.258: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Aug 21 18:05:46.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:05:46.528: INFO: stderr: ""
Aug 21 18:05:46.528: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 18:05:46.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:05:46.601: INFO: stderr: ""
Aug 21 18:05:46.601: INFO: stdout: "update-demo-nautilus-dgnxm update-demo-nautilus-kb7fx "
Aug 21 18:05:46.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-dgnxm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:05:46.671: INFO: stderr: ""
Aug 21 18:05:46.671: INFO: stdout: ""
Aug 21 18:05:46.671: INFO: update-demo-nautilus-dgnxm is created but not running
Aug 21 18:05:51.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:05:51.740: INFO: stderr: ""
Aug 21 18:05:51.740: INFO: stdout: "update-demo-nautilus-dgnxm update-demo-nautilus-kb7fx "
Aug 21 18:05:51.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-dgnxm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:05:51.806: INFO: stderr: ""
Aug 21 18:05:51.806: INFO: stdout: "true"
Aug 21 18:05:51.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-dgnxm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:05:51.876: INFO: stderr: ""
Aug 21 18:05:51.876: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 18:05:51.876: INFO: validating pod update-demo-nautilus-dgnxm
Aug 21 18:05:51.891: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 18:05:51.891: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 18:05:51.891: INFO: update-demo-nautilus-dgnxm is verified up and running
Aug 21 18:05:51.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-kb7fx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:05:51.969: INFO: stderr: ""
Aug 21 18:05:51.969: INFO: stdout: "true"
Aug 21 18:05:51.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-nautilus-kb7fx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:05:52.044: INFO: stderr: ""
Aug 21 18:05:52.044: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 21 18:05:52.044: INFO: validating pod update-demo-nautilus-kb7fx
Aug 21 18:05:52.059: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 21 18:05:52.059: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 21 18:05:52.059: INFO: update-demo-nautilus-kb7fx is verified up and running
STEP: rolling-update to new replication controller
Aug 21 18:05:52.060: INFO: scanned /root for discovery docs: <nil>
Aug 21 18:05:52.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:06:14.698: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 21 18:06:14.698: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 21 18:06:14.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:06:14.771: INFO: stderr: ""
Aug 21 18:06:14.771: INFO: stdout: "update-demo-kitten-4f68l update-demo-kitten-4snd2 "
Aug 21 18:06:14.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-kitten-4f68l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:06:14.837: INFO: stderr: ""
Aug 21 18:06:14.837: INFO: stdout: "true"
Aug 21 18:06:14.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-kitten-4f68l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:06:14.908: INFO: stderr: ""
Aug 21 18:06:14.908: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 21 18:06:14.908: INFO: validating pod update-demo-kitten-4f68l
Aug 21 18:06:14.919: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 21 18:06:14.919: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 21 18:06:14.919: INFO: update-demo-kitten-4f68l is verified up and running
Aug 21 18:06:14.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-kitten-4snd2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:06:14.993: INFO: stderr: ""
Aug 21 18:06:14.993: INFO: stdout: "true"
Aug 21 18:06:14.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods update-demo-kitten-4snd2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvp6v'
Aug 21 18:06:15.058: INFO: stderr: ""
Aug 21 18:06:15.058: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 21 18:06:15.058: INFO: validating pod update-demo-kitten-4snd2
Aug 21 18:06:15.074: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 21 18:06:15.074: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 21 18:06:15.075: INFO: update-demo-kitten-4snd2 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:06:15.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rvp6v" for this suite.
Aug 21 18:06:37.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:06:37.279: INFO: namespace: e2e-tests-kubectl-rvp6v, resource: bindings, ignored listing per whitelist
Aug 21 18:06:37.300: INFO: namespace e2e-tests-kubectl-rvp6v deletion completed in 22.216957085s

â€¢ [SLOW TEST:51.042 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:06:37.300: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 21 18:06:41.958: INFO: Successfully updated pod "labelsupdate6b028134-c43e-11e9-89d6-e2e196a4cdca"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:06:43.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5vxzd" for this suite.
Aug 21 18:07:06.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:07:06.083: INFO: namespace: e2e-tests-projected-5vxzd, resource: bindings, ignored listing per whitelist
Aug 21 18:07:06.206: INFO: namespace e2e-tests-projected-5vxzd deletion completed in 22.213651622s

â€¢ [SLOW TEST:28.906 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:07:06.206: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 21 18:07:06.314: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7c3d7b95-c43e-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-8csl8" to be "success or failure"
Aug 21 18:07:06.323: INFO: Pod "downwardapi-volume-7c3d7b95-c43e-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 8.957508ms
Aug 21 18:07:08.331: INFO: Pod "downwardapi-volume-7c3d7b95-c43e-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016998222s
Aug 21 18:07:10.338: INFO: Pod "downwardapi-volume-7c3d7b95-c43e-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023602315s
STEP: Saw pod success
Aug 21 18:07:10.338: INFO: Pod "downwardapi-volume-7c3d7b95-c43e-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:07:10.343: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod downwardapi-volume-7c3d7b95-c43e-11e9-89d6-e2e196a4cdca container client-container: <nil>
STEP: delete the pod
Aug 21 18:07:10.380: INFO: Waiting for pod downwardapi-volume-7c3d7b95-c43e-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:07:10.385: INFO: Pod downwardapi-volume-7c3d7b95-c43e-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:07:10.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8csl8" for this suite.
Aug 21 18:07:16.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:07:16.555: INFO: namespace: e2e-tests-projected-8csl8, resource: bindings, ignored listing per whitelist
Aug 21 18:07:16.602: INFO: namespace e2e-tests-projected-8csl8 deletion completed in 6.208832721s

â€¢ [SLOW TEST:10.396 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:07:16.602: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 18:07:16.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-wvf7k'
Aug 21 18:07:16.772: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 21 18:07:16.772: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Aug 21 18:07:16.788: INFO: scanned /root for discovery docs: <nil>
Aug 21 18:07:16.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-wvf7k'
Aug 21 18:07:32.633: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 21 18:07:32.633: INFO: stdout: "Created e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f\nScaling up e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 21 18:07:32.633: INFO: stdout: "Created e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f\nScaling up e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 21 18:07:32.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wvf7k'
Aug 21 18:07:32.715: INFO: stderr: ""
Aug 21 18:07:32.715: INFO: stdout: "e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f-9b8w5 "
Aug 21 18:07:32.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f-9b8w5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wvf7k'
Aug 21 18:07:32.787: INFO: stderr: ""
Aug 21 18:07:32.787: INFO: stdout: "true"
Aug 21 18:07:32.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 get pods e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f-9b8w5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wvf7k'
Aug 21 18:07:32.935: INFO: stderr: ""
Aug 21 18:07:32.935: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 21 18:07:32.935: INFO: e2e-test-nginx-rc-859eddadc1c76cbca5b0dc0848418a7f-9b8w5 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Aug 21 18:07:32.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wvf7k'
Aug 21 18:07:33.024: INFO: stderr: ""
Aug 21 18:07:33.024: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:07:33.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wvf7k" for this suite.
Aug 21 18:07:39.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:07:39.137: INFO: namespace: e2e-tests-kubectl-wvf7k, resource: bindings, ignored listing per whitelist
Aug 21 18:07:39.294: INFO: namespace e2e-tests-kubectl-wvf7k deletion completed in 6.257640245s

â€¢ [SLOW TEST:22.692 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:07:39.295: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-8ff6de62-c43e-11e9-89d6-e2e196a4cdca
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:07:43.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rtkjj" for this suite.
Aug 21 18:08:05.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:08:05.658: INFO: namespace: e2e-tests-configmap-rtkjj, resource: bindings, ignored listing per whitelist
Aug 21 18:08:05.671: INFO: namespace e2e-tests-configmap-rtkjj deletion completed in 22.215824535s

â€¢ [SLOW TEST:26.377 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:08:05.671: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Aug 21 18:08:05.826: INFO: Waiting up to 5m0s for pod "var-expansion-9fb71ad3-c43e-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-var-expansion-h84r2" to be "success or failure"
Aug 21 18:08:05.832: INFO: Pod "var-expansion-9fb71ad3-c43e-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.61027ms
Aug 21 18:08:07.839: INFO: Pod "var-expansion-9fb71ad3-c43e-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013505786s
Aug 21 18:08:09.846: INFO: Pod "var-expansion-9fb71ad3-c43e-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020326101s
STEP: Saw pod success
Aug 21 18:08:09.846: INFO: Pod "var-expansion-9fb71ad3-c43e-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:08:09.851: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod var-expansion-9fb71ad3-c43e-11e9-89d6-e2e196a4cdca container dapi-container: <nil>
STEP: delete the pod
Aug 21 18:08:09.882: INFO: Waiting for pod var-expansion-9fb71ad3-c43e-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:08:09.887: INFO: Pod var-expansion-9fb71ad3-c43e-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:08:09.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-h84r2" for this suite.
Aug 21 18:08:15.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:08:15.950: INFO: namespace: e2e-tests-var-expansion-h84r2, resource: bindings, ignored listing per whitelist
Aug 21 18:08:16.113: INFO: namespace e2e-tests-var-expansion-h84r2 deletion completed in 6.216228562s

â€¢ [SLOW TEST:10.442 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:08:16.114: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a5e7e105-c43e-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 18:08:16.217: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a5e97f82-c43e-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-58kbl" to be "success or failure"
Aug 21 18:08:16.226: INFO: Pod "pod-projected-secrets-a5e97f82-c43e-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 8.974425ms
Aug 21 18:08:18.233: INFO: Pod "pod-projected-secrets-a5e97f82-c43e-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015372628s
Aug 21 18:08:20.239: INFO: Pod "pod-projected-secrets-a5e97f82-c43e-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021814223s
STEP: Saw pod success
Aug 21 18:08:20.239: INFO: Pod "pod-projected-secrets-a5e97f82-c43e-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:08:20.245: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-projected-secrets-a5e97f82-c43e-11e9-89d6-e2e196a4cdca container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 21 18:08:20.280: INFO: Waiting for pod pod-projected-secrets-a5e97f82-c43e-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:08:20.285: INFO: Pod pod-projected-secrets-a5e97f82-c43e-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:08:20.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-58kbl" for this suite.
Aug 21 18:08:26.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:08:26.415: INFO: namespace: e2e-tests-projected-58kbl, resource: bindings, ignored listing per whitelist
Aug 21 18:08:26.513: INFO: namespace e2e-tests-projected-58kbl deletion completed in 6.219221225s

â€¢ [SLOW TEST:10.399 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:08:26.513: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 18:08:26.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 version --client'
Aug 21 18:08:26.647: INFO: stderr: ""
Aug 21 18:08:26.647: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Aug 21 18:08:26.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-kwfc4'
Aug 21 18:08:26.842: INFO: stderr: ""
Aug 21 18:08:26.842: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 21 18:08:26.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 create -f - --namespace=e2e-tests-kubectl-kwfc4'
Aug 21 18:08:27.035: INFO: stderr: ""
Aug 21 18:08:27.035: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 21 18:08:28.041: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 18:08:28.041: INFO: Found 0 / 1
Aug 21 18:08:29.042: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 18:08:29.042: INFO: Found 0 / 1
Aug 21 18:08:30.047: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 18:08:30.047: INFO: Found 1 / 1
Aug 21 18:08:30.047: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 21 18:08:30.054: INFO: Selector matched 1 pods for map[app:redis]
Aug 21 18:08:30.054: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 21 18:08:30.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 describe pod redis-master-8kt7v --namespace=e2e-tests-kubectl-kwfc4'
Aug 21 18:08:30.146: INFO: stderr: ""
Aug 21 18:08:30.146: INFO: stdout: "Name:               redis-master-8kt7v\nNamespace:          e2e-tests-kubectl-kwfc4\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-0-3-38.us-west-2.compute.internal/10.0.3.38\nStart Time:         Wed, 21 Aug 2019 18:08:26 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.20.12.140\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://40fb8bfa2e71fac971fb51b3b7dabfce21c97b3fb0473d25836af4185d5a6e61\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 21 Aug 2019 18:08:28 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-lzvtw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-lzvtw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-lzvtw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From                                              Message\n  ----    ------     ----  ----                                              -------\n  Normal  Scheduled  4s    default-scheduler                                 Successfully assigned e2e-tests-kubectl-kwfc4/redis-master-8kt7v to ip-10-0-3-38.us-west-2.compute.internal\n  Normal  Pulled     2s    kubelet, ip-10-0-3-38.us-west-2.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-10-0-3-38.us-west-2.compute.internal  Created container\n  Normal  Started    2s    kubelet, ip-10-0-3-38.us-west-2.compute.internal  Started container\n"
Aug 21 18:08:30.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 describe rc redis-master --namespace=e2e-tests-kubectl-kwfc4'
Aug 21 18:08:30.238: INFO: stderr: ""
Aug 21 18:08:30.238: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-kwfc4\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-8kt7v\n"
Aug 21 18:08:30.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 describe service redis-master --namespace=e2e-tests-kubectl-kwfc4'
Aug 21 18:08:30.330: INFO: stderr: ""
Aug 21 18:08:30.330: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-kwfc4\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.21.51.8\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.20.12.140:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 21 18:08:30.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 describe node ip-10-0-1-143.us-west-2.compute.internal'
Aug 21 18:08:30.452: INFO: stderr: ""
Aug 21 18:08:30.452: INFO: stdout: "Name:               ip-10-0-1-143.us-west-2.compute.internal\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t2.medium\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-west-2\n                    failure-domain.beta.kubernetes.io/zone=us-west-2a\n                    kubernetes.io/hostname=ip-10-0-1-143.us-west-2.compute.internal\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 21 Aug 2019 16:11:06 +0000\nTaints:             node-role.kubernetes.io/master=true:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 21 Aug 2019 18:08:24 +0000   Wed, 21 Aug 2019 16:11:06 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 21 Aug 2019 18:08:24 +0000   Wed, 21 Aug 2019 16:11:06 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 21 Aug 2019 18:08:24 +0000   Wed, 21 Aug 2019 16:11:06 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 21 Aug 2019 18:08:24 +0000   Wed, 21 Aug 2019 16:11:46 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   10.0.1.143\n  ExternalIP:   34.219.18.224\n  Hostname:     ip-10-0-1-143.us-west-2.compute.internal\n  InternalDNS:  ip-10-0-1-143.us-west-2.compute.internal\n  ExternalDNS:  ec2-34-219-18-224.us-west-2.compute.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           52417516Ki\n hugepages-2Mi:               0\n memory:                      3880256Ki\n pods:                        200\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           48307982666\n hugepages-2Mi:               0\n memory:                      3777856Ki\n pods:                        200\nSystem Info:\n Machine ID:                 609bbd29e32a4898e604f49bff82a88c\n System UUID:                EC299F32-00DD-640A-1862-6C60DDA55BFF\n Boot ID:                    a98ef70f-9b8a-4183-9d4d-dd743ab891d8\n Kernel Version:             3.10.0-693.11.6.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.3\n Kubelet Version:            v1.13.9\n Kube-Proxy Version:         v1.13.9\nProviderID:                  aws:///us-west-2a/i-0221f04b85ce0b118\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-1990058480d24a87-cnzj2    0 (0%)        0 (0%)      0 (0%)           0 (0%)         94m\n  kube-system                coredns-6cbb58c7bc-rxlg5                                   100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     115m\n  kube-system                k8s-master-ip-10-0-1-143.us-west-2.compute.internal        0 (0%)        0 (0%)      0 (0%)           0 (0%)         116m\n  kube-system                metrics-server-v0.3.1-67cbdf77bc-ll2h7                     53m (2%)      148m (7%)   154Mi (4%)       404Mi (10%)    115m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         153m (7%)   148m (7%)\n  memory                      224Mi (6%)  574Mi (15%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Aug 21 18:08:30.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 describe namespace e2e-tests-kubectl-kwfc4'
Aug 21 18:08:30.532: INFO: stderr: ""
Aug 21 18:08:30.532: INFO: stdout: "Name:         e2e-tests-kubectl-kwfc4\nLabels:       e2e-framework=kubectl\n              e2e-run=7b7dd514-c431-11e9-89d6-e2e196a4cdca\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:08:30.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kwfc4" for this suite.
Aug 21 18:08:52.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:08:52.740: INFO: namespace: e2e-tests-kubectl-kwfc4, resource: bindings, ignored listing per whitelist
Aug 21 18:08:52.775: INFO: namespace e2e-tests-kubectl-kwfc4 deletion completed in 22.227216504s

â€¢ [SLOW TEST:26.263 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:08:52.775: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 21 18:08:52.916: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:52.916: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:52.916: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:52.925: INFO: Number of nodes with available pods: 0
Aug 21 18:08:52.925: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:08:53.935: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:53.935: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:53.935: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:53.941: INFO: Number of nodes with available pods: 0
Aug 21 18:08:53.941: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:08:54.934: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:54.934: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:54.934: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:54.941: INFO: Number of nodes with available pods: 0
Aug 21 18:08:54.941: INFO: Node ip-10-0-1-150.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:08:55.934: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:55.934: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:55.934: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:55.941: INFO: Number of nodes with available pods: 3
Aug 21 18:08:55.941: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 21 18:08:55.973: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:55.974: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:55.974: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:55.979: INFO: Number of nodes with available pods: 2
Aug 21 18:08:55.980: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:08:56.998: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:56.998: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:56.998: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:57.005: INFO: Number of nodes with available pods: 2
Aug 21 18:08:57.005: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:08:57.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:57.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:57.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:58.000: INFO: Number of nodes with available pods: 2
Aug 21 18:08:58.000: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:08:58.988: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:58.988: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:58.988: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:58.994: INFO: Number of nodes with available pods: 2
Aug 21 18:08:58.994: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:08:59.992: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:59.992: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:59.992: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:08:59.998: INFO: Number of nodes with available pods: 2
Aug 21 18:08:59.998: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:00.990: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:00.990: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:00.990: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:00.997: INFO: Number of nodes with available pods: 2
Aug 21 18:09:00.997: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:01.990: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:01.990: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:01.990: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:02.001: INFO: Number of nodes with available pods: 2
Aug 21 18:09:02.001: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:02.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:02.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:02.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:02.996: INFO: Number of nodes with available pods: 2
Aug 21 18:09:02.996: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:03.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:03.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:03.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:03.996: INFO: Number of nodes with available pods: 2
Aug 21 18:09:03.996: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:04.990: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:04.990: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:04.990: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:04.996: INFO: Number of nodes with available pods: 2
Aug 21 18:09:04.996: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:05.988: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:05.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:05.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:05.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:05.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:06.990: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:06.990: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:06.990: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:06.996: INFO: Number of nodes with available pods: 2
Aug 21 18:09:06.996: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:07.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:07.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:07.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:07.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:07.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:08.994: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:08.994: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:08.994: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:09.000: INFO: Number of nodes with available pods: 2
Aug 21 18:09:09.000: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:09.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:09.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:09.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:09.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:09.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:10.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:10.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:10.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:10.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:10.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:11.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:11.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:11.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:11.997: INFO: Number of nodes with available pods: 2
Aug 21 18:09:11.997: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:12.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:12.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:12.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:12.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:12.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:13.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:13.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:13.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:13.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:13.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:14.988: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:14.988: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:14.988: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:14.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:14.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:15.992: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:15.992: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:15.992: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:15.998: INFO: Number of nodes with available pods: 2
Aug 21 18:09:15.998: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:16.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:16.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:16.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:16.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:16.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:17.988: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:17.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:17.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:17.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:17.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:18.988: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:18.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:18.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:18.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:18.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:19.988: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:19.988: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:19.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:19.994: INFO: Number of nodes with available pods: 2
Aug 21 18:09:19.994: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:20.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:20.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:20.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:20.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:20.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:21.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:21.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:21.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:21.996: INFO: Number of nodes with available pods: 2
Aug 21 18:09:21.996: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:22.988: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:22.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:22.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:22.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:22.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:23.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:23.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:23.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:23.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:23.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:24.988: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:24.988: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:24.988: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:24.994: INFO: Number of nodes with available pods: 2
Aug 21 18:09:24.994: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:25.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:25.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:25.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:25.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:25.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:26.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:26.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:26.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:26.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:26.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:27.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:27.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:27.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:27.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:27.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:28.991: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:28.991: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:28.991: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:28.997: INFO: Number of nodes with available pods: 2
Aug 21 18:09:28.997: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:29.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:29.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:29.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:29.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:29.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:30.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:30.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:30.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:30.995: INFO: Number of nodes with available pods: 2
Aug 21 18:09:30.995: INFO: Node ip-10-0-2-169.us-west-2.compute.internal is running more than one daemon pod
Aug 21 18:09:31.989: INFO: DaemonSet pods can't tolerate node ip-10-0-1-143.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:31.989: INFO: DaemonSet pods can't tolerate node ip-10-0-2-67.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:31.989: INFO: DaemonSet pods can't tolerate node ip-10-0-3-174.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 21 18:09:31.995: INFO: Number of nodes with available pods: 3
Aug 21 18:09:31.995: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2ncrl, will wait for the garbage collector to delete the pods
Aug 21 18:09:32.070: INFO: Deleting DaemonSet.extensions daemon-set took: 13.644796ms
Aug 21 18:09:32.170: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.239461ms
Aug 21 18:10:09.376: INFO: Number of nodes with available pods: 0
Aug 21 18:10:09.376: INFO: Number of running nodes: 0, number of available pods: 0
Aug 21 18:10:09.381: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2ncrl/daemonsets","resourceVersion":"25281"},"items":null}

Aug 21 18:10:09.387: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2ncrl/pods","resourceVersion":"25281"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:10:09.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2ncrl" for this suite.
Aug 21 18:10:15.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:10:15.497: INFO: namespace: e2e-tests-daemonsets-2ncrl, resource: bindings, ignored listing per whitelist
Aug 21 18:10:15.669: INFO: namespace e2e-tests-daemonsets-2ncrl deletion completed in 6.24834073s

â€¢ [SLOW TEST:82.894 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:10:15.670: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ed3430e0-c43e-11e9-89d6-e2e196a4cdca
STEP: Creating configMap with name cm-test-opt-upd-ed343121-c43e-11e9-89d6-e2e196a4cdca
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ed3430e0-c43e-11e9-89d6-e2e196a4cdca
STEP: Updating configmap cm-test-opt-upd-ed343121-c43e-11e9-89d6-e2e196a4cdca
STEP: Creating configMap with name cm-test-opt-create-ed34313d-c43e-11e9-89d6-e2e196a4cdca
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:10:23.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hjsfs" for this suite.
Aug 21 18:10:46.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:10:46.153: INFO: namespace: e2e-tests-projected-hjsfs, resource: bindings, ignored listing per whitelist
Aug 21 18:10:46.211: INFO: namespace e2e-tests-projected-hjsfs deletion completed in 22.215556742s

â€¢ [SLOW TEST:30.542 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:10:46.211: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:10:53.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-c9zvt" for this suite.
Aug 21 18:11:15.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:11:15.521: INFO: namespace: e2e-tests-replication-controller-c9zvt, resource: bindings, ignored listing per whitelist
Aug 21 18:11:15.557: INFO: namespace e2e-tests-replication-controller-c9zvt deletion completed in 22.199691029s

â€¢ [SLOW TEST:29.346 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:11:15.557: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-10dc88e5-c43f-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 18:11:15.658: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-10de0633-c43f-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-l7t4p" to be "success or failure"
Aug 21 18:11:15.666: INFO: Pod "pod-projected-secrets-10de0633-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.815655ms
Aug 21 18:11:17.673: INFO: Pod "pod-projected-secrets-10de0633-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01546546s
Aug 21 18:11:19.680: INFO: Pod "pod-projected-secrets-10de0633-c43f-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022585426s
STEP: Saw pod success
Aug 21 18:11:19.680: INFO: Pod "pod-projected-secrets-10de0633-c43f-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:11:19.687: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-projected-secrets-10de0633-c43f-11e9-89d6-e2e196a4cdca container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 21 18:11:19.720: INFO: Waiting for pod pod-projected-secrets-10de0633-c43f-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:11:19.725: INFO: Pod pod-projected-secrets-10de0633-c43f-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:11:19.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l7t4p" for this suite.
Aug 21 18:11:25.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:11:25.936: INFO: namespace: e2e-tests-projected-l7t4p, resource: bindings, ignored listing per whitelist
Aug 21 18:11:25.941: INFO: namespace e2e-tests-projected-l7t4p deletion completed in 6.208016602s

â€¢ [SLOW TEST:10.384 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:11:25.942: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 21 18:11:26.038: INFO: Waiting up to 5m0s for pod "pod-170cffe4-c43f-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-npp64" to be "success or failure"
Aug 21 18:11:26.044: INFO: Pod "pod-170cffe4-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.205978ms
Aug 21 18:11:28.050: INFO: Pod "pod-170cffe4-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012847188s
Aug 21 18:11:30.057: INFO: Pod "pod-170cffe4-c43f-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019675385s
STEP: Saw pod success
Aug 21 18:11:30.057: INFO: Pod "pod-170cffe4-c43f-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:11:30.063: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-170cffe4-c43f-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 18:11:30.104: INFO: Waiting for pod pod-170cffe4-c43f-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:11:30.109: INFO: Pod pod-170cffe4-c43f-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:11:30.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-npp64" for this suite.
Aug 21 18:11:36.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:11:36.314: INFO: namespace: e2e-tests-emptydir-npp64, resource: bindings, ignored listing per whitelist
Aug 21 18:11:36.332: INFO: namespace e2e-tests-emptydir-npp64 deletion completed in 6.213799776s

â€¢ [SLOW TEST:10.390 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:11:36.332: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1d3ed5a7-c43f-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume secrets
Aug 21 18:11:36.436: INFO: Waiting up to 5m0s for pod "pod-secrets-1d406646-c43f-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-secrets-ghmvj" to be "success or failure"
Aug 21 18:11:36.443: INFO: Pod "pod-secrets-1d406646-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.044597ms
Aug 21 18:11:38.450: INFO: Pod "pod-secrets-1d406646-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013656081s
Aug 21 18:11:40.456: INFO: Pod "pod-secrets-1d406646-c43f-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019600381s
STEP: Saw pod success
Aug 21 18:11:40.456: INFO: Pod "pod-secrets-1d406646-c43f-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:11:40.461: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-secrets-1d406646-c43f-11e9-89d6-e2e196a4cdca container secret-volume-test: <nil>
STEP: delete the pod
Aug 21 18:11:40.492: INFO: Waiting for pod pod-secrets-1d406646-c43f-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:11:40.498: INFO: Pod pod-secrets-1d406646-c43f-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:11:40.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ghmvj" for this suite.
Aug 21 18:11:46.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:11:46.612: INFO: namespace: e2e-tests-secrets-ghmvj, resource: bindings, ignored listing per whitelist
Aug 21 18:11:46.719: INFO: namespace e2e-tests-secrets-ghmvj deletion completed in 6.212997877s

â€¢ [SLOW TEST:10.387 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:11:46.719: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-tcz2
STEP: Creating a pod to test atomic-volume-subpath
Aug 21 18:11:46.831: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-tcz2" in namespace "e2e-tests-subpath-pqzjj" to be "success or failure"
Aug 21 18:11:46.838: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.736506ms
Aug 21 18:11:48.846: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015172296s
Aug 21 18:11:50.853: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021787648s
Aug 21 18:11:52.859: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Running", Reason="", readiness=false. Elapsed: 6.027705533s
Aug 21 18:11:54.865: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Running", Reason="", readiness=false. Elapsed: 8.034184515s
Aug 21 18:11:56.872: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Running", Reason="", readiness=false. Elapsed: 10.040711491s
Aug 21 18:11:58.879: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Running", Reason="", readiness=false. Elapsed: 12.048073097s
Aug 21 18:12:00.886: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Running", Reason="", readiness=false. Elapsed: 14.054992646s
Aug 21 18:12:02.893: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Running", Reason="", readiness=false. Elapsed: 16.061943279s
Aug 21 18:12:04.899: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Running", Reason="", readiness=false. Elapsed: 18.068111391s
Aug 21 18:12:06.907: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Running", Reason="", readiness=false. Elapsed: 20.075526703s
Aug 21 18:12:08.914: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Running", Reason="", readiness=false. Elapsed: 22.08268888s
Aug 21 18:12:10.921: INFO: Pod "pod-subpath-test-configmap-tcz2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.089525587s
STEP: Saw pod success
Aug 21 18:12:10.921: INFO: Pod "pod-subpath-test-configmap-tcz2" satisfied condition "success or failure"
Aug 21 18:12:10.927: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-subpath-test-configmap-tcz2 container test-container-subpath-configmap-tcz2: <nil>
STEP: delete the pod
Aug 21 18:12:10.960: INFO: Waiting for pod pod-subpath-test-configmap-tcz2 to disappear
Aug 21 18:12:10.965: INFO: Pod pod-subpath-test-configmap-tcz2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-tcz2
Aug 21 18:12:10.965: INFO: Deleting pod "pod-subpath-test-configmap-tcz2" in namespace "e2e-tests-subpath-pqzjj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:12:10.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-pqzjj" for this suite.
Aug 21 18:12:17.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:12:17.138: INFO: namespace: e2e-tests-subpath-pqzjj, resource: bindings, ignored listing per whitelist
Aug 21 18:12:17.207: INFO: namespace e2e-tests-subpath-pqzjj deletion completed in 6.228565167s

â€¢ [SLOW TEST:30.488 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:12:17.207: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 21 18:12:17.355: INFO: Waiting up to 5m0s for pod "pod-35a33147-c43f-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-p6ns5" to be "success or failure"
Aug 21 18:12:17.365: INFO: Pod "pod-35a33147-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 10.159517ms
Aug 21 18:12:19.372: INFO: Pod "pod-35a33147-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016929085s
Aug 21 18:12:21.378: INFO: Pod "pod-35a33147-c43f-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023720998s
STEP: Saw pod success
Aug 21 18:12:21.378: INFO: Pod "pod-35a33147-c43f-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:12:21.384: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-35a33147-c43f-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 18:12:21.415: INFO: Waiting for pod pod-35a33147-c43f-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:12:21.421: INFO: Pod pod-35a33147-c43f-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:12:21.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p6ns5" for this suite.
Aug 21 18:12:27.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:12:27.616: INFO: namespace: e2e-tests-emptydir-p6ns5, resource: bindings, ignored listing per whitelist
Aug 21 18:12:27.649: INFO: namespace e2e-tests-emptydir-p6ns5 deletion completed in 6.220032046s

â€¢ [SLOW TEST:10.442 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:12:27.650: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 21 18:12:27.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-q2zwq'
Aug 21 18:12:27.977: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 21 18:12:27.977: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 21 18:12:27.994: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-ls7mk]
Aug 21 18:12:27.994: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-ls7mk" in namespace "e2e-tests-kubectl-q2zwq" to be "running and ready"
Aug 21 18:12:28.000: INFO: Pod "e2e-test-nginx-rc-ls7mk": Phase="Pending", Reason="", readiness=false. Elapsed: 6.332296ms
Aug 21 18:12:30.012: INFO: Pod "e2e-test-nginx-rc-ls7mk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018129397s
Aug 21 18:12:32.019: INFO: Pod "e2e-test-nginx-rc-ls7mk": Phase="Running", Reason="", readiness=true. Elapsed: 4.024835207s
Aug 21 18:12:32.019: INFO: Pod "e2e-test-nginx-rc-ls7mk" satisfied condition "running and ready"
Aug 21 18:12:32.019: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-ls7mk]
Aug 21 18:12:32.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-q2zwq'
Aug 21 18:12:32.109: INFO: stderr: ""
Aug 21 18:12:32.109: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Aug 21 18:12:32.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-507288067 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-q2zwq'
Aug 21 18:12:32.195: INFO: stderr: ""
Aug 21 18:12:32.195: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:12:32.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q2zwq" for this suite.
Aug 21 18:12:38.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:12:38.437: INFO: namespace: e2e-tests-kubectl-q2zwq, resource: bindings, ignored listing per whitelist
Aug 21 18:12:38.454: INFO: namespace e2e-tests-kubectl-q2zwq deletion completed in 6.236190171s

â€¢ [SLOW TEST:10.804 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:12:38.454: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-xk7jt
Aug 21 18:12:42.563: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-xk7jt
STEP: checking the pod's current state and verifying that restartCount is present
Aug 21 18:12:42.568: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:16:43.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xk7jt" for this suite.
Aug 21 18:16:49.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:16:49.557: INFO: namespace: e2e-tests-container-probe-xk7jt, resource: bindings, ignored listing per whitelist
Aug 21 18:16:49.615: INFO: namespace e2e-tests-container-probe-xk7jt deletion completed in 6.206056072s

â€¢ [SLOW TEST:251.161 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:16:49.615: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d7f96527-c43f-11e9-89d6-e2e196a4cdca
STEP: Creating a pod to test consume configMaps
Aug 21 18:16:49.713: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d7fae1b7-c43f-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-projected-r8ndj" to be "success or failure"
Aug 21 18:16:49.720: INFO: Pod "pod-projected-configmaps-d7fae1b7-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.480274ms
Aug 21 18:16:51.726: INFO: Pod "pod-projected-configmaps-d7fae1b7-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012918531s
Aug 21 18:16:53.733: INFO: Pod "pod-projected-configmaps-d7fae1b7-c43f-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020031164s
STEP: Saw pod success
Aug 21 18:16:53.733: INFO: Pod "pod-projected-configmaps-d7fae1b7-c43f-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:16:53.739: INFO: Trying to get logs from node ip-10-0-3-38.us-west-2.compute.internal pod pod-projected-configmaps-d7fae1b7-c43f-11e9-89d6-e2e196a4cdca container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 21 18:16:53.770: INFO: Waiting for pod pod-projected-configmaps-d7fae1b7-c43f-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:16:53.775: INFO: Pod pod-projected-configmaps-d7fae1b7-c43f-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:16:53.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r8ndj" for this suite.
Aug 21 18:16:59.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:16:59.849: INFO: namespace: e2e-tests-projected-r8ndj, resource: bindings, ignored listing per whitelist
Aug 21 18:17:00.004: INFO: namespace e2e-tests-projected-r8ndj deletion completed in 6.219662048s

â€¢ [SLOW TEST:10.389 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:17:00.004: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 18:17:00.136: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 21 18:17:05.143: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 21 18:17:05.143: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 21 18:17:09.186: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-d9vmr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d9vmr/deployments/test-cleanup-deployment,UID:e1302783-c43f-11e9-b0fd-0afb3721cd16,ResourceVersion:26446,Generation:1,CreationTimestamp:2019-08-21 18:17:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-21 18:17:05 +0000 UTC 2019-08-21 18:17:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-21 18:17:07 +0000 UTC 2019-08-21 18:17:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-7dbbfcf846" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 21 18:17:09.192: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-d9vmr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d9vmr/replicasets/test-cleanup-deployment-7dbbfcf846,UID:e131add8-c43f-11e9-bb91-06b2a5b3abd6,ResourceVersion:26437,Generation:1,CreationTimestamp:2019-08-21 18:17:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment e1302783-c43f-11e9-b0fd-0afb3721cd16 0xc0017fac37 0xc0017fac38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 21 18:17:09.198: INFO: Pod "test-cleanup-deployment-7dbbfcf846-rbp89" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-rbp89,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-d9vmr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d9vmr/pods/test-cleanup-deployment-7dbbfcf846-rbp89,UID:e1322d21-c43f-11e9-bb91-06b2a5b3abd6,ResourceVersion:26436,Generation:0,CreationTimestamp:2019-08-21 18:17:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 e131add8-c43f-11e9-bb91-06b2a5b3abd6 0xc0010fc2d7 0xc0010fc2d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-95m5j {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-95m5j,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-95m5j true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-3-38.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 18:17:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 18:17:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 18:17:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-21 18:17:05 +0000 UTC  }],Message:,Reason:,HostIP:10.0.3.38,PodIP:10.20.12.146,StartTime:2019-08-21 18:17:05 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-21 18:17:07 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e5d3a1abb53e29050c55bc958dc2bdfc3aec4f540fa64d4d87164d0086041448}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:17:09.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-d9vmr" for this suite.
Aug 21 18:17:15.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:17:15.252: INFO: namespace: e2e-tests-deployment-d9vmr, resource: bindings, ignored listing per whitelist
Aug 21 18:17:15.412: INFO: namespace e2e-tests-deployment-d9vmr deletion completed in 6.205583298s

â€¢ [SLOW TEST:15.408 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:17:15.412: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 21 18:17:15.493: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 21 18:17:15.510: INFO: Waiting for terminating namespaces to be deleted...
Aug 21 18:17:15.515: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-150.us-west-2.compute.internal before test
Aug 21 18:17:15.522: INFO: sonobuoy-systemd-logs-daemon-set-1990058480d24a87-rkdd2 from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 18:17:15.522: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 21 18:17:15.522: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 21 18:17:15.522: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-2-169.us-west-2.compute.internal before test
Aug 21 18:17:15.537: INFO: sonobuoy-e2e-job-b129cff7f8104912 from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 18:17:15.537: INFO: 	Container e2e ready: true, restart count 0
Aug 21 18:17:15.537: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 21 18:17:15.537: INFO: sonobuoy-systemd-logs-daemon-set-1990058480d24a87-xht7r from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 18:17:15.537: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 21 18:17:15.537: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 21 18:17:15.537: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-3-38.us-west-2.compute.internal before test
Aug 21 18:17:15.546: INFO: sonobuoy-systemd-logs-daemon-set-1990058480d24a87-jppkx from heptio-sonobuoy started at 2019-08-21 16:33:41 +0000 UTC (2 container statuses recorded)
Aug 21 18:17:15.546: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 21 18:17:15.546: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 21 18:17:15.546: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-21 16:33:33 +0000 UTC (1 container statuses recorded)
Aug 21 18:17:15.546: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15bd02e6c59c17ff], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:17:16.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-dnt9m" for this suite.
Aug 21 18:17:22.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:17:22.726: INFO: namespace: e2e-tests-sched-pred-dnt9m, resource: bindings, ignored listing per whitelist
Aug 21 18:17:22.814: INFO: namespace e2e-tests-sched-pred-dnt9m deletion completed in 6.219713844s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:7.402 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:17:22.814: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 21 18:17:22.916: INFO: Waiting up to 5m0s for pod "pod-ebc48923-c43f-11e9-89d6-e2e196a4cdca" in namespace "e2e-tests-emptydir-kgj8w" to be "success or failure"
Aug 21 18:17:22.923: INFO: Pod "pod-ebc48923-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.322261ms
Aug 21 18:17:24.930: INFO: Pod "pod-ebc48923-c43f-11e9-89d6-e2e196a4cdca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014808846s
Aug 21 18:17:26.937: INFO: Pod "pod-ebc48923-c43f-11e9-89d6-e2e196a4cdca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021281055s
STEP: Saw pod success
Aug 21 18:17:26.937: INFO: Pod "pod-ebc48923-c43f-11e9-89d6-e2e196a4cdca" satisfied condition "success or failure"
Aug 21 18:17:26.943: INFO: Trying to get logs from node ip-10-0-1-150.us-west-2.compute.internal pod pod-ebc48923-c43f-11e9-89d6-e2e196a4cdca container test-container: <nil>
STEP: delete the pod
Aug 21 18:17:26.980: INFO: Waiting for pod pod-ebc48923-c43f-11e9-89d6-e2e196a4cdca to disappear
Aug 21 18:17:26.985: INFO: Pod pod-ebc48923-c43f-11e9-89d6-e2e196a4cdca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:17:26.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kgj8w" for this suite.
Aug 21 18:17:33.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:17:33.031: INFO: namespace: e2e-tests-emptydir-kgj8w, resource: bindings, ignored listing per whitelist
Aug 21 18:17:33.205: INFO: namespace e2e-tests-emptydir-kgj8w deletion completed in 6.211628004s

â€¢ [SLOW TEST:10.391 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:17:33.205: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:17:37.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tnwhl" for this suite.
Aug 21 18:18:17.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:18:17.473: INFO: namespace: e2e-tests-kubelet-test-tnwhl, resource: bindings, ignored listing per whitelist
Aug 21 18:18:17.547: INFO: namespace e2e-tests-kubelet-test-tnwhl deletion completed in 40.206781591s

â€¢ [SLOW TEST:44.342 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 21 18:18:17.547: INFO: >>> kubeConfig: /tmp/kubeconfig-507288067
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 21 18:18:17.627: INFO: Creating ReplicaSet my-hostname-basic-0c6304e1-c440-11e9-89d6-e2e196a4cdca
Aug 21 18:18:17.647: INFO: Pod name my-hostname-basic-0c6304e1-c440-11e9-89d6-e2e196a4cdca: Found 1 pods out of 1
Aug 21 18:18:17.647: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0c6304e1-c440-11e9-89d6-e2e196a4cdca" is running
Aug 21 18:18:21.660: INFO: Pod "my-hostname-basic-0c6304e1-c440-11e9-89d6-e2e196a4cdca-7c6nc" is running (conditions: [])
Aug 21 18:18:21.660: INFO: Trying to dial the pod
Aug 21 18:18:26.686: INFO: Controller my-hostname-basic-0c6304e1-c440-11e9-89d6-e2e196a4cdca: Got expected result from replica 1 [my-hostname-basic-0c6304e1-c440-11e9-89d6-e2e196a4cdca-7c6nc]: "my-hostname-basic-0c6304e1-c440-11e9-89d6-e2e196a4cdca-7c6nc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 21 18:18:26.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-v7hff" for this suite.
Aug 21 18:18:32.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 21 18:18:32.896: INFO: namespace: e2e-tests-replicaset-v7hff, resource: bindings, ignored listing per whitelist
Aug 21 18:18:32.901: INFO: namespace e2e-tests-replicaset-v7hff deletion completed in 6.207274708s

â€¢ [SLOW TEST:15.354 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
Aug 21 18:18:32.901: INFO: Running AfterSuite actions on all nodes
Aug 21 18:18:32.903: INFO: Running AfterSuite actions on node 1
Aug 21 18:18:32.903: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6270.345 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h44m31.662763636s
Test Suite Passed
