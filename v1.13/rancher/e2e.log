I0222 20:58:42.735875      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-203049355
I0222 20:58:42.736064      15 e2e.go:224] Starting e2e run "a1c4307c-36e4-11e9-b6f8-82efa66823a4" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550869120 - Will randomize all specs
Will run 201 of 1946 specs

Feb 22 20:58:43.522: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 20:58:43.530: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 22 20:58:43.580: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 22 20:58:43.639: INFO: The status of Pod rke-ingress-controller-deploy-job-z8lq7 is Succeeded, skipping waiting
Feb 22 20:58:43.639: INFO: The status of Pod rke-kube-dns-addon-deploy-job-67wm7 is Succeeded, skipping waiting
Feb 22 20:58:43.639: INFO: The status of Pod rke-metrics-addon-deploy-job-c95v9 is Succeeded, skipping waiting
Feb 22 20:58:43.641: INFO: The status of Pod rke-network-plugin-deploy-job-wbhjp is Succeeded, skipping waiting
Feb 22 20:58:43.641: INFO: 6 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 22 20:58:43.641: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Feb 22 20:58:43.641: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 22 20:58:43.658: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Feb 22 20:58:43.658: INFO: e2e test version: v1.13.0
Feb 22 20:58:43.660: INFO: kube-apiserver version: v1.13.1
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 20:58:43.661: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
Feb 22 20:58:43.799: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 20:58:43.822: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a3ad8c9e-36e4-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-wtn4j" to be "success or failure"
Feb 22 20:58:43.859: INFO: Pod "downwardapi-volume-a3ad8c9e-36e4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 36.615513ms
Feb 22 20:58:45.865: INFO: Pod "downwardapi-volume-a3ad8c9e-36e4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042944937s
Feb 22 20:58:47.871: INFO: Pod "downwardapi-volume-a3ad8c9e-36e4-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048600074s
STEP: Saw pod success
Feb 22 20:58:47.871: INFO: Pod "downwardapi-volume-a3ad8c9e-36e4-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 20:58:47.875: INFO: Trying to get logs from node conformance113-1 pod downwardapi-volume-a3ad8c9e-36e4-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 20:58:47.920: INFO: Waiting for pod downwardapi-volume-a3ad8c9e-36e4-11e9-b6f8-82efa66823a4 to disappear
Feb 22 20:58:47.925: INFO: Pod downwardapi-volume-a3ad8c9e-36e4-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 20:58:47.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wtn4j" for this suite.
Feb 22 20:58:53.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 20:58:54.001: INFO: namespace: e2e-tests-downward-api-wtn4j, resource: bindings, ignored listing per whitelist
Feb 22 20:58:54.137: INFO: namespace e2e-tests-downward-api-wtn4j deletion completed in 6.206286128s

• [SLOW TEST:10.476 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 20:58:54.138: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 22 20:58:58.805: INFO: Successfully updated pod "labelsupdatea9e39a19-36e4-11e9-b6f8-82efa66823a4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 20:59:00.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zjngf" for this suite.
Feb 22 20:59:22.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 20:59:22.947: INFO: namespace: e2e-tests-projected-zjngf, resource: bindings, ignored listing per whitelist
Feb 22 20:59:23.031: INFO: namespace e2e-tests-projected-zjngf deletion completed in 22.197380474s

• [SLOW TEST:28.894 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 20:59:23.035: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 20:59:27.251: INFO: Waiting up to 5m0s for pod "client-envvars-bd8fe3c3-36e4-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-pods-72q7x" to be "success or failure"
Feb 22 20:59:27.271: INFO: Pod "client-envvars-bd8fe3c3-36e4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.706829ms
Feb 22 20:59:29.276: INFO: Pod "client-envvars-bd8fe3c3-36e4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025096809s
Feb 22 20:59:31.282: INFO: Pod "client-envvars-bd8fe3c3-36e4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030968223s
Feb 22 20:59:33.287: INFO: Pod "client-envvars-bd8fe3c3-36e4-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036294354s
STEP: Saw pod success
Feb 22 20:59:33.287: INFO: Pod "client-envvars-bd8fe3c3-36e4-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 20:59:33.292: INFO: Trying to get logs from node conformance113-1 pod client-envvars-bd8fe3c3-36e4-11e9-b6f8-82efa66823a4 container env3cont: <nil>
STEP: delete the pod
Feb 22 20:59:33.347: INFO: Waiting for pod client-envvars-bd8fe3c3-36e4-11e9-b6f8-82efa66823a4 to disappear
Feb 22 20:59:33.358: INFO: Pod client-envvars-bd8fe3c3-36e4-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 20:59:33.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-72q7x" for this suite.
Feb 22 21:00:30.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:00:32.538: INFO: namespace: e2e-tests-pods-72q7x, resource: bindings, ignored listing per whitelist
Feb 22 21:00:32.679: INFO: namespace e2e-tests-pods-72q7x deletion completed in 59.316143164s

• [SLOW TEST:69.645 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:00:32.681: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:00:49.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-9bvvw" for this suite.
Feb 22 21:00:59.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:00:59.978: INFO: namespace: e2e-tests-namespaces-9bvvw, resource: bindings, ignored listing per whitelist
Feb 22 21:01:00.018: INFO: namespace e2e-tests-namespaces-9bvvw deletion completed in 10.214590665s
STEP: Destroying namespace "e2e-tests-nsdeletetest-k4scg" for this suite.
Feb 22 21:01:00.023: INFO: Namespace e2e-tests-nsdeletetest-k4scg was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-2tztj" for this suite.
Feb 22 21:01:16.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:01:16.387: INFO: namespace: e2e-tests-nsdeletetest-2tztj, resource: bindings, ignored listing per whitelist
Feb 22 21:01:16.466: INFO: namespace e2e-tests-nsdeletetest-2tztj deletion completed in 16.442624241s

• [SLOW TEST:43.785 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:01:16.466: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fec1e850-36e4-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 21:01:16.639: INFO: Waiting up to 5m0s for pod "pod-secrets-fec39244-36e4-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-secrets-q4p8s" to be "success or failure"
Feb 22 21:01:16.651: INFO: Pod "pod-secrets-fec39244-36e4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.875102ms
Feb 22 21:01:22.755: INFO: Pod "pod-secrets-fec39244-36e4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.115050694s
Feb 22 21:01:24.768: INFO: Pod "pod-secrets-fec39244-36e4-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.128667791s
STEP: Saw pod success
Feb 22 21:01:24.769: INFO: Pod "pod-secrets-fec39244-36e4-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:01:24.773: INFO: Trying to get logs from node conformance113-2 pod pod-secrets-fec39244-36e4-11e9-b6f8-82efa66823a4 container secret-env-test: <nil>
STEP: delete the pod
Feb 22 21:01:24.851: INFO: Waiting for pod pod-secrets-fec39244-36e4-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:01:24.857: INFO: Pod pod-secrets-fec39244-36e4-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:01:24.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-q4p8s" for this suite.
Feb 22 21:01:35.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:01:36.985: INFO: namespace: e2e-tests-secrets-q4p8s, resource: bindings, ignored listing per whitelist
Feb 22 21:01:37.021: INFO: namespace e2e-tests-secrets-q4p8s deletion completed in 12.156415941s

• [SLOW TEST:20.555 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:01:37.021: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:01:37.924: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b74a5ab-36e5-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-f7xrp" to be "success or failure"
Feb 22 21:01:37.937: INFO: Pod "downwardapi-volume-0b74a5ab-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.068608ms
Feb 22 21:01:44.400: INFO: Pod "downwardapi-volume-0b74a5ab-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.475799798s
Feb 22 21:01:46.406: INFO: Pod "downwardapi-volume-0b74a5ab-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.481722496s
Feb 22 21:01:48.740: INFO: Pod "downwardapi-volume-0b74a5ab-36e5-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.815750487s
STEP: Saw pod success
Feb 22 21:01:48.740: INFO: Pod "downwardapi-volume-0b74a5ab-36e5-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:01:48.744: INFO: Trying to get logs from node conformance113-3 pod downwardapi-volume-0b74a5ab-36e5-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 21:01:48.828: INFO: Waiting for pod downwardapi-volume-0b74a5ab-36e5-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:01:48.842: INFO: Pod downwardapi-volume-0b74a5ab-36e5-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:01:48.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f7xrp" for this suite.
Feb 22 21:01:54.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:01:55.006: INFO: namespace: e2e-tests-projected-f7xrp, resource: bindings, ignored listing per whitelist
Feb 22 21:01:55.094: INFO: namespace e2e-tests-projected-f7xrp deletion completed in 6.240475012s

• [SLOW TEST:18.073 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:01:55.095: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-dfqh7
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 22 21:01:55.221: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 22 21:03:53.793: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.8:8080/dial?request=hostName&protocol=udp&host=10.42.2.6&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-dfqh7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:03:53.793: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:03:54.781: INFO: Waiting for endpoints: map[]
Feb 22 21:03:54.880: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.8:8080/dial?request=hostName&protocol=udp&host=10.42.1.6&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-dfqh7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:03:54.880: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:03:58.545: INFO: Waiting for endpoints: map[]
Feb 22 21:03:58.549: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.8:8080/dial?request=hostName&protocol=udp&host=10.42.0.7&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-dfqh7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:03:58.549: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:03:59.205: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:03:59.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-dfqh7" for this suite.
Feb 22 21:04:31.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:04:31.751: INFO: namespace: e2e-tests-pod-network-test-dfqh7, resource: bindings, ignored listing per whitelist
Feb 22 21:04:31.896: INFO: namespace e2e-tests-pod-network-test-dfqh7 deletion completed in 32.253750007s

• [SLOW TEST:156.801 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:04:31.897: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:04:50.982: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7c12b358-36e5-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-n9h94" to be "success or failure"
Feb 22 21:04:50.988: INFO: Pod "downwardapi-volume-7c12b358-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.571581ms
Feb 22 21:04:52.993: INFO: Pod "downwardapi-volume-7c12b358-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010968813s
Feb 22 21:04:54.999: INFO: Pod "downwardapi-volume-7c12b358-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017351172s
Feb 22 21:05:02.776: INFO: Pod "downwardapi-volume-7c12b358-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.794018489s
Feb 22 21:05:04.781: INFO: Pod "downwardapi-volume-7c12b358-36e5-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 13.799168645s
STEP: Saw pod success
Feb 22 21:05:04.781: INFO: Pod "downwardapi-volume-7c12b358-36e5-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:05:04.786: INFO: Trying to get logs from node conformance113-1 pod downwardapi-volume-7c12b358-36e5-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 21:05:08.484: INFO: Waiting for pod downwardapi-volume-7c12b358-36e5-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:05:08.490: INFO: Pod downwardapi-volume-7c12b358-36e5-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:05:08.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n9h94" for this suite.
Feb 22 21:05:23.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:05:23.530: INFO: namespace: e2e-tests-projected-n9h94, resource: bindings, ignored listing per whitelist
Feb 22 21:05:23.607: INFO: namespace e2e-tests-projected-n9h94 deletion completed in 15.11026275s

• [SLOW TEST:51.710 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:05:23.607: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-924ef31c-36e5-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 21:05:24.183: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9250eaf8-36e5-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-mvmts" to be "success or failure"
Feb 22 21:05:24.203: INFO: Pod "pod-projected-secrets-9250eaf8-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.244477ms
Feb 22 21:05:26.208: INFO: Pod "pod-projected-secrets-9250eaf8-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024310466s
Feb 22 21:05:29.124: INFO: Pod "pod-projected-secrets-9250eaf8-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.94087857s
Feb 22 21:05:31.130: INFO: Pod "pod-projected-secrets-9250eaf8-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.946055421s
Feb 22 21:05:36.364: INFO: Pod "pod-projected-secrets-9250eaf8-36e5-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.180846061s
STEP: Saw pod success
Feb 22 21:05:36.365: INFO: Pod "pod-projected-secrets-9250eaf8-36e5-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:05:36.371: INFO: Trying to get logs from node conformance113-3 pod pod-projected-secrets-9250eaf8-36e5-11e9-b6f8-82efa66823a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 21:05:36.413: INFO: Waiting for pod pod-projected-secrets-9250eaf8-36e5-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:05:36.437: INFO: Pod pod-projected-secrets-9250eaf8-36e5-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:05:36.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mvmts" for this suite.
Feb 22 21:05:54.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:05:54.595: INFO: namespace: e2e-tests-projected-mvmts, resource: bindings, ignored listing per whitelist
Feb 22 21:05:54.698: INFO: namespace e2e-tests-projected-mvmts deletion completed in 18.235204984s

• [SLOW TEST:31.091 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:05:54.699: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:05:58.523: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a6c25b39-36e5-11e9-a687-fac827d478c7", Controller:(*bool)(0xc001684506), BlockOwnerDeletion:(*bool)(0xc001684507)}}
Feb 22 21:05:58.586: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a6bf8a5b-36e5-11e9-a687-fac827d478c7", Controller:(*bool)(0xc001684712), BlockOwnerDeletion:(*bool)(0xc001684713)}}
Feb 22 21:05:58.603: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a6c14fc8-36e5-11e9-a687-fac827d478c7", Controller:(*bool)(0xc001684946), BlockOwnerDeletion:(*bool)(0xc001684947)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:06:06.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-q7rhb" for this suite.
Feb 22 21:06:23.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:06:23.886: INFO: namespace: e2e-tests-gc-q7rhb, resource: bindings, ignored listing per whitelist
Feb 22 21:06:23.907: INFO: namespace e2e-tests-gc-q7rhb deletion completed in 15.617966769s

• [SLOW TEST:29.208 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:06:23.908: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 22 21:06:24.065: INFO: Waiting up to 5m0s for pod "pod-b6006f9a-36e5-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-6b6zz" to be "success or failure"
Feb 22 21:06:24.083: INFO: Pod "pod-b6006f9a-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.432977ms
Feb 22 21:06:26.088: INFO: Pod "pod-b6006f9a-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023036424s
Feb 22 21:06:28.617: INFO: Pod "pod-b6006f9a-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.551622979s
Feb 22 21:06:30.622: INFO: Pod "pod-b6006f9a-36e5-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.556698871s
STEP: Saw pod success
Feb 22 21:06:30.622: INFO: Pod "pod-b6006f9a-36e5-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:06:30.626: INFO: Trying to get logs from node conformance113-1 pod pod-b6006f9a-36e5-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 21:06:30.658: INFO: Waiting for pod pod-b6006f9a-36e5-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:06:30.677: INFO: Pod pod-b6006f9a-36e5-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:06:30.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6b6zz" for this suite.
Feb 22 21:06:36.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:06:36.781: INFO: namespace: e2e-tests-emptydir-6b6zz, resource: bindings, ignored listing per whitelist
Feb 22 21:06:36.920: INFO: namespace e2e-tests-emptydir-6b6zz deletion completed in 6.219097737s

• [SLOW TEST:13.013 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:06:36.921: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 22 21:06:38.208: INFO: Waiting up to 5m0s for pod "client-containers-be6f34f5-36e5-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-containers-dz4db" to be "success or failure"
Feb 22 21:06:38.230: INFO: Pod "client-containers-be6f34f5-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.269012ms
Feb 22 21:06:43.896: INFO: Pod "client-containers-be6f34f5-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.688081153s
Feb 22 21:06:47.099: INFO: Pod "client-containers-be6f34f5-36e5-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.890249846s
STEP: Saw pod success
Feb 22 21:06:47.099: INFO: Pod "client-containers-be6f34f5-36e5-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:06:47.108: INFO: Trying to get logs from node conformance113-2 pod client-containers-be6f34f5-36e5-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 21:06:47.201: INFO: Waiting for pod client-containers-be6f34f5-36e5-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:06:47.206: INFO: Pod client-containers-be6f34f5-36e5-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:06:47.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-dz4db" for this suite.
Feb 22 21:06:53.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:06:53.308: INFO: namespace: e2e-tests-containers-dz4db, resource: bindings, ignored listing per whitelist
Feb 22 21:06:53.788: INFO: namespace e2e-tests-containers-dz4db deletion completed in 6.573227645s

• [SLOW TEST:16.867 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:06:53.790: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-tftq
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 21:07:11.390: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-tftq" in namespace "e2e-tests-subpath-xc7vj" to be "success or failure"
Feb 22 21:07:11.402: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Pending", Reason="", readiness=false. Elapsed: 12.200315ms
Feb 22 21:07:13.408: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017463928s
Feb 22 21:07:15.412: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022201268s
Feb 22 21:07:19.385: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Pending", Reason="", readiness=false. Elapsed: 7.995179423s
Feb 22 21:07:21.483: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Running", Reason="", readiness=false. Elapsed: 10.092682048s
Feb 22 21:07:23.487: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Running", Reason="", readiness=false. Elapsed: 12.097222288s
Feb 22 21:07:27.868: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Running", Reason="", readiness=false. Elapsed: 16.478316051s
Feb 22 21:07:29.874: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Running", Reason="", readiness=false. Elapsed: 18.483591767s
Feb 22 21:07:32.459: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Running", Reason="", readiness=false. Elapsed: 21.068368765s
Feb 22 21:07:34.463: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Running", Reason="", readiness=false. Elapsed: 23.072894444s
Feb 22 21:07:36.469: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Running", Reason="", readiness=false. Elapsed: 25.078557922s
Feb 22 21:07:39.207: INFO: Pod "pod-subpath-test-secret-tftq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 27.817294835s
STEP: Saw pod success
Feb 22 21:07:39.208: INFO: Pod "pod-subpath-test-secret-tftq" satisfied condition "success or failure"
Feb 22 21:07:39.212: INFO: Trying to get logs from node conformance113-1 pod pod-subpath-test-secret-tftq container test-container-subpath-secret-tftq: <nil>
STEP: delete the pod
Feb 22 21:07:42.358: INFO: Waiting for pod pod-subpath-test-secret-tftq to disappear
Feb 22 21:07:42.364: INFO: Pod pod-subpath-test-secret-tftq no longer exists
STEP: Deleting pod pod-subpath-test-secret-tftq
Feb 22 21:07:42.364: INFO: Deleting pod "pod-subpath-test-secret-tftq" in namespace "e2e-tests-subpath-xc7vj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:07:42.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xc7vj" for this suite.
Feb 22 21:07:50.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:07:50.538: INFO: namespace: e2e-tests-subpath-xc7vj, resource: bindings, ignored listing per whitelist
Feb 22 21:07:50.657: INFO: namespace e2e-tests-subpath-xc7vj deletion completed in 6.261255907s

• [SLOW TEST:56.868 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:07:50.658: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e9b337ed-36e5-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:07:50.808: INFO: Waiting up to 5m0s for pod "pod-configmaps-e9b65d10-36e5-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-configmap-sj4jz" to be "success or failure"
Feb 22 21:07:50.821: INFO: Pod "pod-configmaps-e9b65d10-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.228024ms
Feb 22 21:07:57.012: INFO: Pod "pod-configmaps-e9b65d10-36e5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.203606559s
Feb 22 21:08:00.644: INFO: Pod "pod-configmaps-e9b65d10-36e5-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.835984055s
STEP: Saw pod success
Feb 22 21:08:00.644: INFO: Pod "pod-configmaps-e9b65d10-36e5-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:08:00.651: INFO: Trying to get logs from node conformance113-1 pod pod-configmaps-e9b65d10-36e5-11e9-b6f8-82efa66823a4 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:08:00.683: INFO: Waiting for pod pod-configmaps-e9b65d10-36e5-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:08:00.688: INFO: Pod pod-configmaps-e9b65d10-36e5-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:08:00.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sj4jz" for this suite.
Feb 22 21:08:08.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:08:08.803: INFO: namespace: e2e-tests-configmap-sj4jz, resource: bindings, ignored listing per whitelist
Feb 22 21:08:08.891: INFO: namespace e2e-tests-configmap-sj4jz deletion completed in 8.193650981s

• [SLOW TEST:18.234 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:08:08.892: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:08:09.049: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 22 21:08:09.074: INFO: Number of nodes with available pods: 0
Feb 22 21:08:09.074: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 22 21:08:09.133: INFO: Number of nodes with available pods: 0
Feb 22 21:08:09.133: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:10.138: INFO: Number of nodes with available pods: 0
Feb 22 21:08:10.138: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:11.783: INFO: Number of nodes with available pods: 0
Feb 22 21:08:11.783: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:12.138: INFO: Number of nodes with available pods: 0
Feb 22 21:08:12.138: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:13.138: INFO: Number of nodes with available pods: 0
Feb 22 21:08:13.138: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:14.141: INFO: Number of nodes with available pods: 0
Feb 22 21:08:14.141: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:15.139: INFO: Number of nodes with available pods: 1
Feb 22 21:08:15.139: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 22 21:08:19.723: INFO: Number of nodes with available pods: 1
Feb 22 21:08:19.723: INFO: Number of running nodes: 0, number of available pods: 1
Feb 22 21:08:20.728: INFO: Number of nodes with available pods: 0
Feb 22 21:08:20.728: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 22 21:08:20.749: INFO: Number of nodes with available pods: 0
Feb 22 21:08:20.750: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:21.755: INFO: Number of nodes with available pods: 0
Feb 22 21:08:21.755: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:23.849: INFO: Number of nodes with available pods: 0
Feb 22 21:08:23.849: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:24.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:24.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:25.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:25.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:26.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:26.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:27.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:27.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:28.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:28.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:29.780: INFO: Number of nodes with available pods: 0
Feb 22 21:08:29.780: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:30.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:30.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:31.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:31.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:34.874: INFO: Number of nodes with available pods: 0
Feb 22 21:08:34.874: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:37.107: INFO: Number of nodes with available pods: 0
Feb 22 21:08:37.107: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:37.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:37.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:38.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:38.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:39.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:39.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:40.905: INFO: Number of nodes with available pods: 0
Feb 22 21:08:40.905: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:42.563: INFO: Number of nodes with available pods: 0
Feb 22 21:08:42.563: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:42.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:42.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:43.755: INFO: Number of nodes with available pods: 0
Feb 22 21:08:43.755: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:44.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:44.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:45.755: INFO: Number of nodes with available pods: 0
Feb 22 21:08:45.755: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:46.754: INFO: Number of nodes with available pods: 0
Feb 22 21:08:46.754: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:47.885: INFO: Number of nodes with available pods: 0
Feb 22 21:08:47.885: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:48.957: INFO: Number of nodes with available pods: 0
Feb 22 21:08:48.957: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:49.756: INFO: Number of nodes with available pods: 0
Feb 22 21:08:49.756: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:50.976: INFO: Number of nodes with available pods: 0
Feb 22 21:08:50.977: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:52.317: INFO: Number of nodes with available pods: 0
Feb 22 21:08:52.317: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:52.756: INFO: Number of nodes with available pods: 0
Feb 22 21:08:52.756: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:53.969: INFO: Number of nodes with available pods: 0
Feb 22 21:08:53.969: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:08:57.933: INFO: Number of nodes with available pods: 1
Feb 22 21:08:57.933: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-6rf4b, will wait for the garbage collector to delete the pods
Feb 22 21:09:01.655: INFO: Deleting DaemonSet.extensions daemon-set took: 15.518873ms
Feb 22 21:09:01.755: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.194722ms
Feb 22 21:09:39.778: INFO: Number of nodes with available pods: 0
Feb 22 21:09:39.778: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 21:09:39.788: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6rf4b/daemonsets","resourceVersion":"3974"},"items":null}

Feb 22 21:09:39.793: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6rf4b/pods","resourceVersion":"3974"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:09:39.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-6rf4b" for this suite.
Feb 22 21:09:47.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:09:47.953: INFO: namespace: e2e-tests-daemonsets-6rf4b, resource: bindings, ignored listing per whitelist
Feb 22 21:09:48.110: INFO: namespace e2e-tests-daemonsets-6rf4b deletion completed in 8.235470901s

• [SLOW TEST:99.218 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:09:48.111: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-qgtz4
I0222 21:09:48.249181      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-qgtz4, replica count: 1
I0222 21:09:49.299848      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 21:09:50.300065      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 21:09:51.300301      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 21:09:52.300546      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 21:09:53.300721      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 22 21:09:53.426: INFO: Created: latency-svc-sr5m6
Feb 22 21:09:53.461: INFO: Got endpoints: latency-svc-sr5m6 [60.681104ms]
Feb 22 21:09:53.493: INFO: Created: latency-svc-twpfj
Feb 22 21:09:53.553: INFO: Got endpoints: latency-svc-twpfj [91.107942ms]
Feb 22 21:09:53.563: INFO: Created: latency-svc-56x27
Feb 22 21:09:53.578: INFO: Got endpoints: latency-svc-56x27 [115.590407ms]
Feb 22 21:09:53.593: INFO: Created: latency-svc-wkg6p
Feb 22 21:09:53.599: INFO: Got endpoints: latency-svc-wkg6p [134.891059ms]
Feb 22 21:09:53.612: INFO: Created: latency-svc-xfkjq
Feb 22 21:09:53.621: INFO: Got endpoints: latency-svc-xfkjq [158.773794ms]
Feb 22 21:09:53.636: INFO: Created: latency-svc-r6mwf
Feb 22 21:09:53.647: INFO: Got endpoints: latency-svc-r6mwf [184.527583ms]
Feb 22 21:09:53.663: INFO: Created: latency-svc-5hf2x
Feb 22 21:09:53.664: INFO: Got endpoints: latency-svc-5hf2x [200.952078ms]
Feb 22 21:09:53.679: INFO: Created: latency-svc-pswvq
Feb 22 21:09:53.689: INFO: Got endpoints: latency-svc-pswvq [226.50254ms]
Feb 22 21:09:53.701: INFO: Created: latency-svc-k4x6w
Feb 22 21:09:53.719: INFO: Created: latency-svc-rlvm8
Feb 22 21:09:53.723: INFO: Got endpoints: latency-svc-k4x6w [259.41938ms]
Feb 22 21:09:53.750: INFO: Created: latency-svc-nmkkc
Feb 22 21:09:53.759: INFO: Got endpoints: latency-svc-rlvm8 [295.357963ms]
Feb 22 21:09:53.769: INFO: Got endpoints: latency-svc-nmkkc [305.549298ms]
Feb 22 21:09:53.780: INFO: Created: latency-svc-k5w7b
Feb 22 21:09:53.799: INFO: Got endpoints: latency-svc-k5w7b [335.392302ms]
Feb 22 21:09:53.806: INFO: Created: latency-svc-m8bhl
Feb 22 21:09:53.824: INFO: Got endpoints: latency-svc-m8bhl [360.149332ms]
Feb 22 21:09:53.831: INFO: Created: latency-svc-h95k6
Feb 22 21:09:54.719: INFO: Created: latency-svc-jrxws
Feb 22 21:09:55.408: INFO: Got endpoints: latency-svc-h95k6 [1.944469862s]
Feb 22 21:09:56.956: INFO: Got endpoints: latency-svc-jrxws [3.491503068s]
Feb 22 21:10:00.447: INFO: Created: latency-svc-jnwfm
Feb 22 21:10:00.499: INFO: Got endpoints: latency-svc-jnwfm [7.035630675s]
Feb 22 21:10:00.511: INFO: Created: latency-svc-jqgbv
Feb 22 21:10:00.546: INFO: Created: latency-svc-w4qmp
Feb 22 21:10:00.578: INFO: Got endpoints: latency-svc-jqgbv [7.025646372s]
Feb 22 21:10:00.590: INFO: Created: latency-svc-b44sp
Feb 22 21:10:00.622: INFO: Got endpoints: latency-svc-w4qmp [7.044181523s]
Feb 22 21:10:00.638: INFO: Got endpoints: latency-svc-b44sp [7.039029871s]
Feb 22 21:10:00.666: INFO: Created: latency-svc-lmrgb
Feb 22 21:10:00.670: INFO: Got endpoints: latency-svc-lmrgb [7.048326827s]
Feb 22 21:10:00.685: INFO: Created: latency-svc-tcqff
Feb 22 21:10:00.707: INFO: Created: latency-svc-wntwj
Feb 22 21:10:00.718: INFO: Got endpoints: latency-svc-tcqff [7.070459162s]
Feb 22 21:10:00.736: INFO: Got endpoints: latency-svc-wntwj [7.072194295s]
Feb 22 21:10:00.743: INFO: Created: latency-svc-w2swr
Feb 22 21:10:00.773: INFO: Got endpoints: latency-svc-w2swr [7.083200185s]
Feb 22 21:10:00.779: INFO: Created: latency-svc-7zqkm
Feb 22 21:10:00.818: INFO: Got endpoints: latency-svc-7zqkm [7.09510046s]
Feb 22 21:10:00.829: INFO: Created: latency-svc-546wn
Feb 22 21:10:00.834: INFO: Got endpoints: latency-svc-546wn [7.074839197s]
Feb 22 21:10:00.854: INFO: Created: latency-svc-8jdrq
Feb 22 21:10:00.882: INFO: Got endpoints: latency-svc-8jdrq [7.112553067s]
Feb 22 21:10:00.906: INFO: Created: latency-svc-bkn89
Feb 22 21:10:00.940: INFO: Created: latency-svc-8wpdg
Feb 22 21:10:00.950: INFO: Got endpoints: latency-svc-bkn89 [7.150794991s]
Feb 22 21:10:00.958: INFO: Created: latency-svc-v4hpq
Feb 22 21:10:00.973: INFO: Got endpoints: latency-svc-8wpdg [7.149481287s]
Feb 22 21:10:00.985: INFO: Got endpoints: latency-svc-v4hpq [5.576498269s]
Feb 22 21:10:01.004: INFO: Created: latency-svc-wc5rd
Feb 22 21:10:01.027: INFO: Got endpoints: latency-svc-wc5rd [4.071140235s]
Feb 22 21:10:01.033: INFO: Created: latency-svc-kgf84
Feb 22 21:10:01.060: INFO: Got endpoints: latency-svc-kgf84 [560.608375ms]
Feb 22 21:10:01.066: INFO: Created: latency-svc-x4gl8
Feb 22 21:10:01.098: INFO: Got endpoints: latency-svc-x4gl8 [519.321157ms]
Feb 22 21:10:01.109: INFO: Created: latency-svc-ftsvw
Feb 22 21:10:01.122: INFO: Got endpoints: latency-svc-ftsvw [499.457263ms]
Feb 22 21:10:01.128: INFO: Created: latency-svc-vqbd9
Feb 22 21:10:01.149: INFO: Created: latency-svc-lml4k
Feb 22 21:10:01.161: INFO: Got endpoints: latency-svc-vqbd9 [522.168593ms]
Feb 22 21:10:01.170: INFO: Got endpoints: latency-svc-lml4k [499.890587ms]
Feb 22 21:10:01.205: INFO: Created: latency-svc-kmxcz
Feb 22 21:10:01.226: INFO: Got endpoints: latency-svc-kmxcz [507.701581ms]
Feb 22 21:10:01.227: INFO: Created: latency-svc-jrrx2
Feb 22 21:10:01.234: INFO: Got endpoints: latency-svc-jrrx2 [497.937669ms]
Feb 22 21:10:01.254: INFO: Created: latency-svc-bb7mv
Feb 22 21:10:01.273: INFO: Got endpoints: latency-svc-bb7mv [499.832066ms]
Feb 22 21:10:01.280: INFO: Created: latency-svc-hpqjq
Feb 22 21:10:01.292: INFO: Got endpoints: latency-svc-hpqjq [473.848066ms]
Feb 22 21:10:01.307: INFO: Created: latency-svc-ps6m2
Feb 22 21:10:01.314: INFO: Got endpoints: latency-svc-ps6m2 [480.30914ms]
Feb 22 21:10:01.332: INFO: Created: latency-svc-gdnrs
Feb 22 21:10:01.354: INFO: Got endpoints: latency-svc-gdnrs [472.106448ms]
Feb 22 21:10:01.361: INFO: Created: latency-svc-t6mxg
Feb 22 21:10:01.388: INFO: Got endpoints: latency-svc-t6mxg [438.423228ms]
Feb 22 21:10:01.418: INFO: Created: latency-svc-h6jw6
Feb 22 21:10:01.488: INFO: Got endpoints: latency-svc-h6jw6 [514.619848ms]
Feb 22 21:10:01.506: INFO: Created: latency-svc-vz8q5
Feb 22 21:10:01.512: INFO: Got endpoints: latency-svc-vz8q5 [526.956109ms]
Feb 22 21:10:01.533: INFO: Created: latency-svc-nc4bq
Feb 22 21:10:01.556: INFO: Got endpoints: latency-svc-nc4bq [529.202299ms]
Feb 22 21:10:01.558: INFO: Created: latency-svc-ntvvc
Feb 22 21:10:01.585: INFO: Created: latency-svc-dhx5m
Feb 22 21:10:01.590: INFO: Got endpoints: latency-svc-ntvvc [529.958407ms]
Feb 22 21:10:01.616: INFO: Got endpoints: latency-svc-dhx5m [517.834142ms]
Feb 22 21:10:01.666: INFO: Created: latency-svc-sdlgw
Feb 22 21:10:01.676: INFO: Got endpoints: latency-svc-sdlgw [554.49848ms]
Feb 22 21:10:01.693: INFO: Created: latency-svc-zbg8n
Feb 22 21:10:01.711: INFO: Got endpoints: latency-svc-zbg8n [550.021742ms]
Feb 22 21:10:01.726: INFO: Created: latency-svc-tmjx2
Feb 22 21:10:01.745: INFO: Got endpoints: latency-svc-tmjx2 [574.9257ms]
Feb 22 21:10:01.749: INFO: Created: latency-svc-m5d8d
Feb 22 21:10:01.758: INFO: Got endpoints: latency-svc-m5d8d [47.330948ms]
Feb 22 21:10:01.776: INFO: Created: latency-svc-vf5s7
Feb 22 21:10:01.779: INFO: Got endpoints: latency-svc-vf5s7 [553.62324ms]
Feb 22 21:10:01.793: INFO: Created: latency-svc-29ktk
Feb 22 21:10:01.802: INFO: Got endpoints: latency-svc-29ktk [567.37742ms]
Feb 22 21:10:01.814: INFO: Created: latency-svc-gkb5g
Feb 22 21:10:01.820: INFO: Got endpoints: latency-svc-gkb5g [547.344191ms]
Feb 22 21:10:01.933: INFO: Created: latency-svc-pwr82
Feb 22 21:10:01.933: INFO: Got endpoints: latency-svc-pwr82 [641.151785ms]
Feb 22 21:10:01.939: INFO: Created: latency-svc-w2ck2
Feb 22 21:10:01.951: INFO: Got endpoints: latency-svc-w2ck2 [637.128761ms]
Feb 22 21:10:01.966: INFO: Created: latency-svc-jrttt
Feb 22 21:10:01.966: INFO: Created: latency-svc-jzjhf
Feb 22 21:10:01.977: INFO: Created: latency-svc-qc6q9
Feb 22 21:10:01.987: INFO: Got endpoints: latency-svc-jrttt [498.820162ms]
Feb 22 21:10:01.988: INFO: Got endpoints: latency-svc-jzjhf [633.830379ms]
Feb 22 21:10:01.988: INFO: Got endpoints: latency-svc-qc6q9 [599.783086ms]
Feb 22 21:10:02.011: INFO: Created: latency-svc-nbfqg
Feb 22 21:10:02.015: INFO: Created: latency-svc-cfdvx
Feb 22 21:10:02.015: INFO: Got endpoints: latency-svc-cfdvx [459.020251ms]
Feb 22 21:10:02.016: INFO: Got endpoints: latency-svc-nbfqg [503.918619ms]
Feb 22 21:10:02.037: INFO: Created: latency-svc-qjh8l
Feb 22 21:10:02.063: INFO: Created: latency-svc-cxhfw
Feb 22 21:10:02.064: INFO: Got endpoints: latency-svc-qjh8l [473.81658ms]
Feb 22 21:10:02.078: INFO: Created: latency-svc-d59xc
Feb 22 21:10:02.078: INFO: Created: latency-svc-nkkxc
Feb 22 21:10:02.097: INFO: Created: latency-svc-4mjfs
Feb 22 21:10:02.144: INFO: Got endpoints: latency-svc-d59xc [399.06793ms]
Feb 22 21:10:02.144: INFO: Got endpoints: latency-svc-cxhfw [528.343834ms]
Feb 22 21:10:02.144: INFO: Got endpoints: latency-svc-nkkxc [468.063854ms]
Feb 22 21:10:02.162: INFO: Created: latency-svc-zbs8q
Feb 22 21:10:02.170: INFO: Got endpoints: latency-svc-4mjfs [411.33416ms]
Feb 22 21:10:02.186: INFO: Created: latency-svc-n2dqc
Feb 22 21:10:02.194: INFO: Got endpoints: latency-svc-zbs8q [414.638297ms]
Feb 22 21:10:02.207: INFO: Created: latency-svc-xrzbx
Feb 22 21:10:02.215: INFO: Got endpoints: latency-svc-n2dqc [413.397248ms]
Feb 22 21:10:02.217: INFO: Got endpoints: latency-svc-xrzbx [396.038547ms]
Feb 22 21:10:02.232: INFO: Created: latency-svc-2kb4x
Feb 22 21:10:02.239: INFO: Got endpoints: latency-svc-2kb4x [305.650033ms]
Feb 22 21:10:02.251: INFO: Created: latency-svc-br7rz
Feb 22 21:10:02.255: INFO: Got endpoints: latency-svc-br7rz [303.644375ms]
Feb 22 21:10:02.272: INFO: Created: latency-svc-59nl6
Feb 22 21:10:02.278: INFO: Got endpoints: latency-svc-59nl6 [290.774368ms]
Feb 22 21:10:02.291: INFO: Created: latency-svc-tpxlp
Feb 22 21:10:02.303: INFO: Got endpoints: latency-svc-tpxlp [315.092047ms]
Feb 22 21:10:02.316: INFO: Created: latency-svc-7dvpv
Feb 22 21:10:02.322: INFO: Got endpoints: latency-svc-7dvpv [333.709912ms]
Feb 22 21:10:02.348: INFO: Created: latency-svc-v9brk
Feb 22 21:10:02.358: INFO: Got endpoints: latency-svc-v9brk [341.722917ms]
Feb 22 21:10:02.375: INFO: Created: latency-svc-8nd7q
Feb 22 21:10:02.378: INFO: Got endpoints: latency-svc-8nd7q [362.119888ms]
Feb 22 21:10:02.401: INFO: Created: latency-svc-kpqk8
Feb 22 21:10:02.413: INFO: Created: latency-svc-7f27m
Feb 22 21:10:02.431: INFO: Got endpoints: latency-svc-kpqk8 [366.082232ms]
Feb 22 21:10:02.466: INFO: Got endpoints: latency-svc-7f27m [321.679012ms]
Feb 22 21:10:02.484: INFO: Created: latency-svc-qxsxl
Feb 22 21:10:05.319: INFO: Got endpoints: latency-svc-qxsxl [3.174302454s]
Feb 22 21:10:08.121: INFO: Created: latency-svc-k4lh2
Feb 22 21:10:12.337: INFO: Got endpoints: latency-svc-k4lh2 [10.192475478s]
Feb 22 21:10:12.394: INFO: Created: latency-svc-5km8r
Feb 22 21:10:12.408: INFO: Got endpoints: latency-svc-5km8r [10.238796103s]
Feb 22 21:10:12.436: INFO: Created: latency-svc-6jz2k
Feb 22 21:10:12.458: INFO: Got endpoints: latency-svc-6jz2k [10.263941893s]
Feb 22 21:10:12.468: INFO: Created: latency-svc-w4g5m
Feb 22 21:10:12.483: INFO: Got endpoints: latency-svc-w4g5m [10.26821012s]
Feb 22 21:10:12.499: INFO: Created: latency-svc-f6m4p
Feb 22 21:10:12.509: INFO: Got endpoints: latency-svc-f6m4p [10.291784788s]
Feb 22 21:10:12.528: INFO: Created: latency-svc-gzz57
Feb 22 21:10:12.539: INFO: Got endpoints: latency-svc-gzz57 [10.3003323s]
Feb 22 21:10:12.556: INFO: Created: latency-svc-sjpn6
Feb 22 21:10:12.570: INFO: Got endpoints: latency-svc-sjpn6 [10.314622588s]
Feb 22 21:10:12.579: INFO: Created: latency-svc-hls4h
Feb 22 21:10:12.588: INFO: Got endpoints: latency-svc-hls4h [10.310540316s]
Feb 22 21:10:12.604: INFO: Created: latency-svc-b8rrv
Feb 22 21:10:12.610: INFO: Got endpoints: latency-svc-b8rrv [10.306081183s]
Feb 22 21:10:12.629: INFO: Created: latency-svc-rtrt9
Feb 22 21:10:12.635: INFO: Got endpoints: latency-svc-rtrt9 [10.313215042s]
Feb 22 21:10:12.660: INFO: Created: latency-svc-hqbcl
Feb 22 21:10:12.673: INFO: Got endpoints: latency-svc-hqbcl [10.314600742s]
Feb 22 21:10:12.693: INFO: Created: latency-svc-rqjxr
Feb 22 21:10:12.697: INFO: Created: latency-svc-hxv89
Feb 22 21:10:12.700: INFO: Got endpoints: latency-svc-rqjxr [10.322561381s]
Feb 22 21:10:12.718: INFO: Got endpoints: latency-svc-hxv89 [10.287578468s]
Feb 22 21:10:12.726: INFO: Created: latency-svc-cn8pv
Feb 22 21:10:12.736: INFO: Got endpoints: latency-svc-cn8pv [10.270023055s]
Feb 22 21:10:12.763: INFO: Created: latency-svc-qwh9n
Feb 22 21:10:12.836: INFO: Got endpoints: latency-svc-qwh9n [7.517494403s]
Feb 22 21:10:12.842: INFO: Created: latency-svc-hlfpv
Feb 22 21:10:12.879: INFO: Got endpoints: latency-svc-hlfpv [470.458022ms]
Feb 22 21:10:12.890: INFO: Created: latency-svc-vpt5w
Feb 22 21:10:12.897: INFO: Got endpoints: latency-svc-vpt5w [560.333802ms]
Feb 22 21:10:12.911: INFO: Created: latency-svc-vh7v9
Feb 22 21:10:12.919: INFO: Got endpoints: latency-svc-vh7v9 [461.272011ms]
Feb 22 21:10:12.927: INFO: Created: latency-svc-8mjdl
Feb 22 21:10:12.938: INFO: Got endpoints: latency-svc-8mjdl [453.978165ms]
Feb 22 21:10:12.945: INFO: Created: latency-svc-lf4ms
Feb 22 21:10:12.959: INFO: Created: latency-svc-wbmvp
Feb 22 21:10:12.962: INFO: Got endpoints: latency-svc-lf4ms [453.620586ms]
Feb 22 21:10:12.973: INFO: Created: latency-svc-zlgsj
Feb 22 21:10:12.990: INFO: Created: latency-svc-fmtpq
Feb 22 21:10:13.002: INFO: Got endpoints: latency-svc-wbmvp [462.542377ms]
Feb 22 21:10:13.006: INFO: Got endpoints: latency-svc-zlgsj [435.80317ms]
Feb 22 21:10:13.022: INFO: Created: latency-svc-z5xqq
Feb 22 21:10:13.024: INFO: Got endpoints: latency-svc-fmtpq [435.989907ms]
Feb 22 21:10:13.054: INFO: Created: latency-svc-fzmqb
Feb 22 21:10:13.054: INFO: Got endpoints: latency-svc-z5xqq [444.500179ms]
Feb 22 21:10:13.068: INFO: Got endpoints: latency-svc-fzmqb [432.8044ms]
Feb 22 21:10:13.085: INFO: Created: latency-svc-ljkc7
Feb 22 21:10:13.089: INFO: Got endpoints: latency-svc-ljkc7 [416.392642ms]
Feb 22 21:10:13.101: INFO: Created: latency-svc-dtpp2
Feb 22 21:10:13.115: INFO: Created: latency-svc-5tpvq
Feb 22 21:10:13.121: INFO: Got endpoints: latency-svc-dtpp2 [420.969106ms]
Feb 22 21:10:13.134: INFO: Created: latency-svc-tjnwl
Feb 22 21:10:13.150: INFO: Got endpoints: latency-svc-5tpvq [431.335036ms]
Feb 22 21:10:13.161: INFO: Got endpoints: latency-svc-tjnwl [425.155905ms]
Feb 22 21:10:13.177: INFO: Created: latency-svc-4sz6j
Feb 22 21:10:13.194: INFO: Got endpoints: latency-svc-4sz6j [357.863393ms]
Feb 22 21:10:13.206: INFO: Created: latency-svc-k4mfp
Feb 22 21:10:13.227: INFO: Got endpoints: latency-svc-k4mfp [347.705311ms]
Feb 22 21:10:13.249: INFO: Created: latency-svc-72r97
Feb 22 21:10:13.266: INFO: Got endpoints: latency-svc-72r97 [368.518426ms]
Feb 22 21:10:13.278: INFO: Created: latency-svc-pjxx5
Feb 22 21:10:13.286: INFO: Got endpoints: latency-svc-pjxx5 [366.141655ms]
Feb 22 21:10:13.293: INFO: Created: latency-svc-wmp25
Feb 22 21:10:13.299: INFO: Got endpoints: latency-svc-wmp25 [360.945558ms]
Feb 22 21:10:13.321: INFO: Created: latency-svc-4h26j
Feb 22 21:10:13.331: INFO: Got endpoints: latency-svc-4h26j [368.669216ms]
Feb 22 21:10:13.798: INFO: Created: latency-svc-zwcw9
Feb 22 21:10:13.815: INFO: Created: latency-svc-fqcgz
Feb 22 21:10:13.820: INFO: Got endpoints: latency-svc-zwcw9 [818.668528ms]
Feb 22 21:10:13.834: INFO: Got endpoints: latency-svc-fqcgz [827.882917ms]
Feb 22 21:10:13.863: INFO: Created: latency-svc-pbkrk
Feb 22 21:10:13.863: INFO: Created: latency-svc-48q6z
Feb 22 21:10:13.863: INFO: Got endpoints: latency-svc-48q6z [838.685635ms]
Feb 22 21:10:13.882: INFO: Got endpoints: latency-svc-pbkrk [828.020034ms]
Feb 22 21:10:13.891: INFO: Created: latency-svc-ntxnh
Feb 22 21:10:13.898: INFO: Got endpoints: latency-svc-ntxnh [830.186233ms]
Feb 22 21:10:13.918: INFO: Created: latency-svc-cqj8g
Feb 22 21:10:13.925: INFO: Got endpoints: latency-svc-cqj8g [835.281699ms]
Feb 22 21:10:13.927: INFO: Created: latency-svc-6lncc
Feb 22 21:10:13.941: INFO: Got endpoints: latency-svc-6lncc [819.752731ms]
Feb 22 21:10:13.958: INFO: Created: latency-svc-dz4gj
Feb 22 21:10:13.961: INFO: Got endpoints: latency-svc-dz4gj [811.028121ms]
Feb 22 21:10:13.978: INFO: Created: latency-svc-m5w9q
Feb 22 21:10:13.990: INFO: Got endpoints: latency-svc-m5w9q [828.469489ms]
Feb 22 21:10:13.993: INFO: Created: latency-svc-5gkmj
Feb 22 21:10:13.999: INFO: Got endpoints: latency-svc-5gkmj [804.549299ms]
Feb 22 21:10:14.026: INFO: Created: latency-svc-x4mzp
Feb 22 21:10:14.036: INFO: Got endpoints: latency-svc-x4mzp [809.21382ms]
Feb 22 21:10:14.042: INFO: Created: latency-svc-wdwxn
Feb 22 21:10:14.062: INFO: Created: latency-svc-lt9f2
Feb 22 21:10:14.116: INFO: Got endpoints: latency-svc-wdwxn [849.87038ms]
Feb 22 21:10:14.134: INFO: Created: latency-svc-fhxxv
Feb 22 21:10:14.139: INFO: Got endpoints: latency-svc-lt9f2 [853.193872ms]
Feb 22 21:10:14.164: INFO: Got endpoints: latency-svc-fhxxv [865.607391ms]
Feb 22 21:10:14.194: INFO: Created: latency-svc-hh5kj
Feb 22 21:10:14.231: INFO: Got endpoints: latency-svc-hh5kj [900.247334ms]
Feb 22 21:10:14.271: INFO: Created: latency-svc-qf2n9
Feb 22 21:10:14.280: INFO: Got endpoints: latency-svc-qf2n9 [459.022742ms]
Feb 22 21:10:14.308: INFO: Created: latency-svc-lr5qt
Feb 22 21:10:14.320: INFO: Got endpoints: latency-svc-lr5qt [486.442127ms]
Feb 22 21:10:17.984: INFO: Created: latency-svc-2mml5
Feb 22 21:10:21.058: INFO: Got endpoints: latency-svc-2mml5 [7.194215044s]
Feb 22 21:10:24.885: INFO: Created: latency-svc-5sgnv
Feb 22 21:10:24.891: INFO: Created: latency-svc-xxp5k
Feb 22 21:10:25.067: INFO: Got endpoints: latency-svc-5sgnv [11.184883257s]
Feb 22 21:10:25.078: INFO: Got endpoints: latency-svc-xxp5k [11.17941657s]
Feb 22 21:10:25.105: INFO: Created: latency-svc-q8hst
Feb 22 21:10:25.111: INFO: Got endpoints: latency-svc-q8hst [11.186130281s]
Feb 22 21:10:25.130: INFO: Created: latency-svc-nr9rj
Feb 22 21:10:25.163: INFO: Got endpoints: latency-svc-nr9rj [11.221502983s]
Feb 22 21:10:25.176: INFO: Created: latency-svc-8xw5l
Feb 22 21:10:25.186: INFO: Got endpoints: latency-svc-8xw5l [11.224655238s]
Feb 22 21:10:25.197: INFO: Created: latency-svc-2zshz
Feb 22 21:10:25.206: INFO: Got endpoints: latency-svc-2zshz [11.216529687s]
Feb 22 21:10:25.216: INFO: Created: latency-svc-4khzl
Feb 22 21:10:25.223: INFO: Got endpoints: latency-svc-4khzl [11.223368584s]
Feb 22 21:10:25.252: INFO: Created: latency-svc-x5j8v
Feb 22 21:10:25.264: INFO: Got endpoints: latency-svc-x5j8v [11.227491324s]
Feb 22 21:10:25.270: INFO: Created: latency-svc-pqt9x
Feb 22 21:10:25.278: INFO: Got endpoints: latency-svc-pqt9x [11.162363176s]
Feb 22 21:10:25.292: INFO: Created: latency-svc-xlv9f
Feb 22 21:10:25.297: INFO: Got endpoints: latency-svc-xlv9f [11.158038179s]
Feb 22 21:10:25.336: INFO: Created: latency-svc-6hgqp
Feb 22 21:10:25.336: INFO: Got endpoints: latency-svc-6hgqp [11.172014412s]
Feb 22 21:10:25.364: INFO: Created: latency-svc-m9lbq
Feb 22 21:10:25.381: INFO: Got endpoints: latency-svc-m9lbq [11.15001491s]
Feb 22 21:10:25.396: INFO: Created: latency-svc-6gp5z
Feb 22 21:10:25.408: INFO: Created: latency-svc-n72bq
Feb 22 21:10:25.414: INFO: Got endpoints: latency-svc-6gp5z [11.134237958s]
Feb 22 21:10:25.427: INFO: Got endpoints: latency-svc-n72bq [11.107058985s]
Feb 22 21:10:25.438: INFO: Created: latency-svc-mwjc7
Feb 22 21:10:25.447: INFO: Got endpoints: latency-svc-mwjc7 [4.389187418s]
Feb 22 21:10:25.460: INFO: Created: latency-svc-d7sqg
Feb 22 21:10:25.466: INFO: Got endpoints: latency-svc-d7sqg [398.763182ms]
Feb 22 21:10:25.479: INFO: Created: latency-svc-lzbw7
Feb 22 21:10:25.500: INFO: Created: latency-svc-k72zz
Feb 22 21:10:25.520: INFO: Got endpoints: latency-svc-lzbw7 [442.523397ms]
Feb 22 21:10:25.532: INFO: Created: latency-svc-htxn8
Feb 22 21:10:25.536: INFO: Got endpoints: latency-svc-k72zz [373.509558ms]
Feb 22 21:10:25.549: INFO: Got endpoints: latency-svc-htxn8 [438.387058ms]
Feb 22 21:10:25.556: INFO: Created: latency-svc-cgkrt
Feb 22 21:10:25.569: INFO: Created: latency-svc-5xng9
Feb 22 21:10:25.575: INFO: Got endpoints: latency-svc-cgkrt [389.231325ms]
Feb 22 21:10:25.585: INFO: Got endpoints: latency-svc-5xng9 [378.96287ms]
Feb 22 21:10:25.589: INFO: Created: latency-svc-2rp9j
Feb 22 21:10:25.600: INFO: Got endpoints: latency-svc-2rp9j [377.554845ms]
Feb 22 21:10:25.608: INFO: Created: latency-svc-nm2mz
Feb 22 21:10:25.614: INFO: Created: latency-svc-px96n
Feb 22 21:10:25.625: INFO: Got endpoints: latency-svc-nm2mz [361.394623ms]
Feb 22 21:10:25.637: INFO: Created: latency-svc-ffrfm
Feb 22 21:10:25.646: INFO: Got endpoints: latency-svc-px96n [367.93615ms]
Feb 22 21:10:25.652: INFO: Created: latency-svc-46hvv
Feb 22 21:10:25.665: INFO: Got endpoints: latency-svc-ffrfm [367.933154ms]
Feb 22 21:10:25.679: INFO: Got endpoints: latency-svc-46hvv [342.390126ms]
Feb 22 21:10:25.680: INFO: Created: latency-svc-hcds4
Feb 22 21:10:25.695: INFO: Got endpoints: latency-svc-hcds4 [313.428942ms]
Feb 22 21:10:25.705: INFO: Created: latency-svc-gpnqn
Feb 22 21:10:25.706: INFO: Got endpoints: latency-svc-gpnqn [292.268703ms]
Feb 22 21:10:25.727: INFO: Created: latency-svc-t8wl2
Feb 22 21:10:25.733: INFO: Got endpoints: latency-svc-t8wl2 [305.62663ms]
Feb 22 21:10:25.742: INFO: Created: latency-svc-b5kmn
Feb 22 21:10:25.751: INFO: Got endpoints: latency-svc-b5kmn [304.27884ms]
Feb 22 21:10:25.755: INFO: Created: latency-svc-l9rnf
Feb 22 21:10:25.768: INFO: Got endpoints: latency-svc-l9rnf [301.574087ms]
Feb 22 21:10:25.774: INFO: Created: latency-svc-xkchw
Feb 22 21:10:25.786: INFO: Got endpoints: latency-svc-xkchw [265.501506ms]
Feb 22 21:10:25.803: INFO: Created: latency-svc-lvlmn
Feb 22 21:10:25.818: INFO: Got endpoints: latency-svc-lvlmn [281.266738ms]
Feb 22 21:10:25.829: INFO: Created: latency-svc-lgpkb
Feb 22 21:10:25.839: INFO: Got endpoints: latency-svc-lgpkb [289.815615ms]
Feb 22 21:10:25.852: INFO: Created: latency-svc-799sr
Feb 22 21:10:25.863: INFO: Got endpoints: latency-svc-799sr [287.978446ms]
Feb 22 21:10:25.876: INFO: Created: latency-svc-bs694
Feb 22 21:10:25.891: INFO: Got endpoints: latency-svc-bs694 [305.911268ms]
Feb 22 21:10:25.892: INFO: Created: latency-svc-7j56b
Feb 22 21:10:25.902: INFO: Created: latency-svc-brs27
Feb 22 21:10:25.914: INFO: Got endpoints: latency-svc-7j56b [313.730729ms]
Feb 22 21:10:25.921: INFO: Got endpoints: latency-svc-brs27 [295.580881ms]
Feb 22 21:10:25.925: INFO: Created: latency-svc-tl5xq
Feb 22 21:10:25.939: INFO: Got endpoints: latency-svc-tl5xq [293.091872ms]
Feb 22 21:10:25.945: INFO: Created: latency-svc-kvcdn
Feb 22 21:10:25.962: INFO: Got endpoints: latency-svc-kvcdn [296.426659ms]
Feb 22 21:10:25.965: INFO: Created: latency-svc-lvzqz
Feb 22 21:10:25.979: INFO: Got endpoints: latency-svc-lvzqz [299.925187ms]
Feb 22 21:10:25.993: INFO: Created: latency-svc-sx62g
Feb 22 21:10:26.000: INFO: Got endpoints: latency-svc-sx62g [304.744847ms]
Feb 22 21:10:26.016: INFO: Created: latency-svc-29289
Feb 22 21:10:26.066: INFO: Got endpoints: latency-svc-29289 [359.659654ms]
Feb 22 21:10:27.262: INFO: Created: latency-svc-d69mw
Feb 22 21:10:30.185: INFO: Created: latency-svc-f55r7
Feb 22 21:10:30.698: INFO: Got endpoints: latency-svc-d69mw [4.964737771s]
Feb 22 21:10:31.118: INFO: Got endpoints: latency-svc-f55r7 [5.366568876s]
Feb 22 21:10:31.152: INFO: Created: latency-svc-5xs5n
Feb 22 21:10:31.179: INFO: Created: latency-svc-ls22x
Feb 22 21:10:31.216: INFO: Got endpoints: latency-svc-ls22x [5.430569212s]
Feb 22 21:10:31.217: INFO: Got endpoints: latency-svc-5xs5n [5.449287089s]
Feb 22 21:10:31.227: INFO: Created: latency-svc-lmc9j
Feb 22 21:10:31.418: INFO: Got endpoints: latency-svc-lmc9j [5.600527441s]
Feb 22 21:10:31.440: INFO: Created: latency-svc-trkqf
Feb 22 21:10:31.486: INFO: Got endpoints: latency-svc-trkqf [5.646674014s]
Feb 22 21:10:31.491: INFO: Created: latency-svc-qb69h
Feb 22 21:10:31.542: INFO: Got endpoints: latency-svc-qb69h [5.678782559s]
Feb 22 21:10:31.554: INFO: Created: latency-svc-cf99q
Feb 22 21:10:31.567: INFO: Got endpoints: latency-svc-cf99q [5.675632428s]
Feb 22 21:10:31.599: INFO: Created: latency-svc-9rbl8
Feb 22 21:10:31.631: INFO: Got endpoints: latency-svc-9rbl8 [5.716867888s]
Feb 22 21:10:31.636: INFO: Created: latency-svc-7chqh
Feb 22 21:10:31.686: INFO: Got endpoints: latency-svc-7chqh [5.765043786s]
Feb 22 21:10:31.701: INFO: Created: latency-svc-ctnkb
Feb 22 21:10:31.714: INFO: Got endpoints: latency-svc-ctnkb [5.774381449s]
Feb 22 21:10:31.726: INFO: Created: latency-svc-jjc6j
Feb 22 21:10:31.760: INFO: Got endpoints: latency-svc-jjc6j [5.798081145s]
Feb 22 21:10:31.765: INFO: Created: latency-svc-78prv
Feb 22 21:10:31.822: INFO: Got endpoints: latency-svc-78prv [5.842961345s]
Feb 22 21:10:31.832: INFO: Created: latency-svc-tzbk8
Feb 22 21:10:31.873: INFO: Got endpoints: latency-svc-tzbk8 [5.873225418s]
Feb 22 21:10:31.881: INFO: Created: latency-svc-hkcf9
Feb 22 21:10:31.914: INFO: Got endpoints: latency-svc-hkcf9 [5.848312102s]
Feb 22 21:10:31.923: INFO: Created: latency-svc-9t9zg
Feb 22 21:10:31.946: INFO: Got endpoints: latency-svc-9t9zg [1.248337357s]
Feb 22 21:10:31.960: INFO: Created: latency-svc-jjv8f
Feb 22 21:10:31.989: INFO: Got endpoints: latency-svc-jjv8f [871.489112ms]
Feb 22 21:10:31.998: INFO: Created: latency-svc-69flv
Feb 22 21:10:32.051: INFO: Got endpoints: latency-svc-69flv [834.7096ms]
Feb 22 21:10:32.058: INFO: Created: latency-svc-2v2bh
Feb 22 21:10:32.099: INFO: Got endpoints: latency-svc-2v2bh [881.773139ms]
Feb 22 21:10:32.107: INFO: Created: latency-svc-fr6kn
Feb 22 21:10:32.145: INFO: Got endpoints: latency-svc-fr6kn [725.997426ms]
Feb 22 21:10:32.157: INFO: Created: latency-svc-wc5l2
Feb 22 21:10:32.172: INFO: Got endpoints: latency-svc-wc5l2 [685.578275ms]
Feb 22 21:10:32.177: INFO: Created: latency-svc-2brnj
Feb 22 21:10:32.193: INFO: Got endpoints: latency-svc-2brnj [651.100489ms]
Feb 22 21:10:32.207: INFO: Created: latency-svc-86mp2
Feb 22 21:10:32.213: INFO: Got endpoints: latency-svc-86mp2 [645.521885ms]
Feb 22 21:10:32.219: INFO: Created: latency-svc-46xjl
Feb 22 21:10:35.806: INFO: Got endpoints: latency-svc-46xjl [4.175156789s]
Feb 22 21:10:35.861: INFO: Created: latency-svc-7t99t
Feb 22 21:10:35.905: INFO: Created: latency-svc-2596l
Feb 22 21:10:35.911: INFO: Got endpoints: latency-svc-7t99t [4.224990606s]
Feb 22 21:10:35.937: INFO: Got endpoints: latency-svc-2596l [4.222963289s]
Feb 22 21:10:35.937: INFO: Latencies: [47.330948ms 91.107942ms 115.590407ms 134.891059ms 158.773794ms 184.527583ms 200.952078ms 226.50254ms 259.41938ms 265.501506ms 281.266738ms 287.978446ms 289.815615ms 290.774368ms 292.268703ms 293.091872ms 295.357963ms 295.580881ms 296.426659ms 299.925187ms 301.574087ms 303.644375ms 304.27884ms 304.744847ms 305.549298ms 305.62663ms 305.650033ms 305.911268ms 313.428942ms 313.730729ms 315.092047ms 321.679012ms 333.709912ms 335.392302ms 341.722917ms 342.390126ms 347.705311ms 357.863393ms 359.659654ms 360.149332ms 360.945558ms 361.394623ms 362.119888ms 366.082232ms 366.141655ms 367.933154ms 367.93615ms 368.518426ms 368.669216ms 373.509558ms 377.554845ms 378.96287ms 389.231325ms 396.038547ms 398.763182ms 399.06793ms 411.33416ms 413.397248ms 414.638297ms 416.392642ms 420.969106ms 425.155905ms 431.335036ms 432.8044ms 435.80317ms 435.989907ms 438.387058ms 438.423228ms 442.523397ms 444.500179ms 453.620586ms 453.978165ms 459.020251ms 459.022742ms 461.272011ms 462.542377ms 468.063854ms 470.458022ms 472.106448ms 473.81658ms 473.848066ms 480.30914ms 486.442127ms 497.937669ms 498.820162ms 499.457263ms 499.832066ms 499.890587ms 503.918619ms 507.701581ms 514.619848ms 517.834142ms 519.321157ms 522.168593ms 526.956109ms 528.343834ms 529.202299ms 529.958407ms 547.344191ms 550.021742ms 553.62324ms 554.49848ms 560.333802ms 560.608375ms 567.37742ms 574.9257ms 599.783086ms 633.830379ms 637.128761ms 641.151785ms 645.521885ms 651.100489ms 685.578275ms 725.997426ms 804.549299ms 809.21382ms 811.028121ms 818.668528ms 819.752731ms 827.882917ms 828.020034ms 828.469489ms 830.186233ms 834.7096ms 835.281699ms 838.685635ms 849.87038ms 853.193872ms 865.607391ms 871.489112ms 881.773139ms 900.247334ms 1.248337357s 1.944469862s 3.174302454s 3.491503068s 4.071140235s 4.175156789s 4.222963289s 4.224990606s 4.389187418s 4.964737771s 5.366568876s 5.430569212s 5.449287089s 5.576498269s 5.600527441s 5.646674014s 5.675632428s 5.678782559s 5.716867888s 5.765043786s 5.774381449s 5.798081145s 5.842961345s 5.848312102s 5.873225418s 7.025646372s 7.035630675s 7.039029871s 7.044181523s 7.048326827s 7.070459162s 7.072194295s 7.074839197s 7.083200185s 7.09510046s 7.112553067s 7.149481287s 7.150794991s 7.194215044s 7.517494403s 10.192475478s 10.238796103s 10.263941893s 10.26821012s 10.270023055s 10.287578468s 10.291784788s 10.3003323s 10.306081183s 10.310540316s 10.313215042s 10.314600742s 10.314622588s 10.322561381s 11.107058985s 11.134237958s 11.15001491s 11.158038179s 11.162363176s 11.172014412s 11.17941657s 11.184883257s 11.186130281s 11.216529687s 11.221502983s 11.223368584s 11.224655238s 11.227491324s]
Feb 22 21:10:35.937: INFO: 50 %ile: 553.62324ms
Feb 22 21:10:35.937: INFO: 90 %ile: 10.306081183s
Feb 22 21:10:35.937: INFO: 99 %ile: 11.224655238s
Feb 22 21:10:35.937: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:10:35.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-qgtz4" for this suite.
Feb 22 21:12:51.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:12:52.062: INFO: namespace: e2e-tests-svc-latency-qgtz4, resource: bindings, ignored listing per whitelist
Feb 22 21:12:52.204: INFO: namespace e2e-tests-svc-latency-qgtz4 deletion completed in 2m16.249188981s

• [SLOW TEST:184.093 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:12:52.205: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-kwzk4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 22 21:12:52.327: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 22 21:13:36.485: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.11:8080/dial?request=hostName&protocol=http&host=10.42.1.13&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-kwzk4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:13:36.485: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:13:36.711: INFO: Waiting for endpoints: map[]
Feb 22 21:13:36.715: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.11:8080/dial?request=hostName&protocol=http&host=10.42.0.10&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-kwzk4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:13:36.715: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:13:37.041: INFO: Waiting for endpoints: map[]
Feb 22 21:13:37.046: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.11:8080/dial?request=hostName&protocol=http&host=10.42.2.9&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-kwzk4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:13:37.046: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:13:37.318: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:13:37.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-kwzk4" for this suite.
Feb 22 21:14:02.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:14:02.377: INFO: namespace: e2e-tests-pod-network-test-kwzk4, resource: bindings, ignored listing per whitelist
Feb 22 21:14:02.486: INFO: namespace e2e-tests-pod-network-test-kwzk4 deletion completed in 25.159261442s

• [SLOW TEST:70.281 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:14:02.487: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0222 21:14:47.053690      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 21:14:47.053: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:14:47.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xddr9" for this suite.
Feb 22 21:15:05.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:15:05.892: INFO: namespace: e2e-tests-gc-xddr9, resource: bindings, ignored listing per whitelist
Feb 22 21:15:13.957: INFO: namespace e2e-tests-gc-xddr9 deletion completed in 26.880796053s

• [SLOW TEST:71.471 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:15:13.958: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:15:14.083: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:15:20.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-vkzmk" for this suite.
Feb 22 21:15:26.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:15:26.780: INFO: namespace: e2e-tests-custom-resource-definition-vkzmk, resource: bindings, ignored listing per whitelist
Feb 22 21:15:26.828: INFO: namespace e2e-tests-custom-resource-definition-vkzmk deletion completed in 6.200276724s

• [SLOW TEST:12.870 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:15:26.828: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 22 21:15:26.938: INFO: Waiting up to 5m0s for pod "downward-api-f995683b-36e6-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-pctjt" to be "success or failure"
Feb 22 21:15:26.953: INFO: Pod "downward-api-f995683b-36e6-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.690597ms
Feb 22 21:15:28.959: INFO: Pod "downward-api-f995683b-36e6-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018431448s
Feb 22 21:15:31.051: INFO: Pod "downward-api-f995683b-36e6-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110384637s
STEP: Saw pod success
Feb 22 21:15:31.051: INFO: Pod "downward-api-f995683b-36e6-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:15:31.056: INFO: Trying to get logs from node conformance113-1 pod downward-api-f995683b-36e6-11e9-b6f8-82efa66823a4 container dapi-container: <nil>
STEP: delete the pod
Feb 22 21:15:31.128: INFO: Waiting for pod downward-api-f995683b-36e6-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:15:31.134: INFO: Pod downward-api-f995683b-36e6-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:15:31.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pctjt" for this suite.
Feb 22 21:15:49.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:15:50.034: INFO: namespace: e2e-tests-downward-api-pctjt, resource: bindings, ignored listing per whitelist
Feb 22 21:15:55.309: INFO: namespace e2e-tests-downward-api-pctjt deletion completed in 24.164882343s

• [SLOW TEST:28.481 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:15:55.313: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 22 21:16:05.669: INFO: namespace e2e-tests-kubectl-vvx6t
Feb 22 21:16:05.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-vvx6t'
Feb 22 21:16:06.321: INFO: stderr: ""
Feb 22 21:16:06.321: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 22 21:16:07.326: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:16:07.326: INFO: Found 0 / 1
Feb 22 21:16:08.343: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:16:08.343: INFO: Found 0 / 1
Feb 22 21:16:10.069: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:16:10.069: INFO: Found 0 / 1
Feb 22 21:16:10.328: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:16:10.328: INFO: Found 0 / 1
Feb 22 21:16:11.329: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:16:11.329: INFO: Found 0 / 1
Feb 22 21:16:12.327: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:16:12.327: INFO: Found 1 / 1
Feb 22 21:16:12.327: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 22 21:16:12.330: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:16:12.331: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 22 21:16:12.331: INFO: wait on redis-master startup in e2e-tests-kubectl-vvx6t 
Feb 22 21:16:12.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 logs redis-master-pmr5t redis-master --namespace=e2e-tests-kubectl-vvx6t'
Feb 22 21:16:17.582: INFO: stderr: ""
Feb 22 21:16:17.582: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Feb 21:16:11.481 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Feb 21:16:11.481 # Server started, Redis version 3.2.12\n1:M 22 Feb 21:16:11.483 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Feb 21:16:11.483 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 22 21:16:17.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-vvx6t'
Feb 22 21:16:18.151: INFO: stderr: ""
Feb 22 21:16:18.151: INFO: stdout: "service/rm2 exposed\n"
Feb 22 21:16:18.167: INFO: Service rm2 in namespace e2e-tests-kubectl-vvx6t found.
STEP: exposing service
Feb 22 21:16:26.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-vvx6t'
Feb 22 21:16:26.991: INFO: stderr: ""
Feb 22 21:16:26.991: INFO: stdout: "service/rm3 exposed\n"
Feb 22 21:16:26.996: INFO: Service rm3 in namespace e2e-tests-kubectl-vvx6t found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:16:29.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vvx6t" for this suite.
Feb 22 21:17:03.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:17:03.978: INFO: namespace: e2e-tests-kubectl-vvx6t, resource: bindings, ignored listing per whitelist
Feb 22 21:17:04.002: INFO: namespace e2e-tests-kubectl-vvx6t deletion completed in 34.984360313s

• [SLOW TEST:68.690 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:17:04.003: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 21:17:04.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-hn8lf'
Feb 22 21:17:04.232: INFO: stderr: ""
Feb 22 21:17:04.232: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 22 21:17:24.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-hn8lf -o json'
Feb 22 21:17:28.952: INFO: stderr: ""
Feb 22 21:17:28.952: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.42.0.12/32\"\n        },\n        \"creationTimestamp\": \"2019-02-22T21:17:04Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-hn8lf\",\n        \"resourceVersion\": \"6664\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-hn8lf/pods/e2e-test-nginx-pod\",\n        \"uid\": \"3392e005-36e7-11e9-a687-fac827d478c7\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-bpr2c\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"conformance113-3\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-bpr2c\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-bpr2c\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-22T21:17:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-22T21:17:21Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-22T21:17:21Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-22T21:17:04Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://6c1ffe3ea415d2aef0f9cd74bf344622ba79e0419066af0bdb442017894012f7\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-22T21:17:20Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"104.248.0.151\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.0.12\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-22T21:17:04Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 22 21:17:28.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 replace -f - --namespace=e2e-tests-kubectl-hn8lf'
Feb 22 21:17:29.242: INFO: stderr: ""
Feb 22 21:17:29.242: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb 22 21:17:29.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-hn8lf'
Feb 22 21:17:39.318: INFO: stderr: ""
Feb 22 21:17:39.318: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:17:39.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hn8lf" for this suite.
Feb 22 21:17:45.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:17:45.459: INFO: namespace: e2e-tests-kubectl-hn8lf, resource: bindings, ignored listing per whitelist
Feb 22 21:17:45.585: INFO: namespace e2e-tests-kubectl-hn8lf deletion completed in 6.223680895s

• [SLOW TEST:41.583 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:17:45.586: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:17:45.683: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c48430d-36e7-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-nk86k" to be "success or failure"
Feb 22 21:17:45.690: INFO: Pod "downwardapi-volume-4c48430d-36e7-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.616062ms
Feb 22 21:17:47.695: INFO: Pod "downwardapi-volume-4c48430d-36e7-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011703052s
STEP: Saw pod success
Feb 22 21:17:47.695: INFO: Pod "downwardapi-volume-4c48430d-36e7-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:17:47.701: INFO: Trying to get logs from node conformance113-1 pod downwardapi-volume-4c48430d-36e7-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 21:17:47.740: INFO: Waiting for pod downwardapi-volume-4c48430d-36e7-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:17:47.745: INFO: Pod downwardapi-volume-4c48430d-36e7-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:17:47.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nk86k" for this suite.
Feb 22 21:17:58.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:17:58.303: INFO: namespace: e2e-tests-downward-api-nk86k, resource: bindings, ignored listing per whitelist
Feb 22 21:17:58.426: INFO: namespace e2e-tests-downward-api-nk86k deletion completed in 10.67087092s

• [SLOW TEST:12.840 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:17:58.426: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:18:00.080: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54dd02b8-36e7-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-s8spx" to be "success or failure"
Feb 22 21:18:00.093: INFO: Pod "downwardapi-volume-54dd02b8-36e7-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.174846ms
Feb 22 21:18:05.577: INFO: Pod "downwardapi-volume-54dd02b8-36e7-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.496688326s
Feb 22 21:18:07.582: INFO: Pod "downwardapi-volume-54dd02b8-36e7-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.501835511s
STEP: Saw pod success
Feb 22 21:18:07.582: INFO: Pod "downwardapi-volume-54dd02b8-36e7-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:18:07.589: INFO: Trying to get logs from node conformance113-2 pod downwardapi-volume-54dd02b8-36e7-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 21:18:11.028: INFO: Waiting for pod downwardapi-volume-54dd02b8-36e7-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:18:11.032: INFO: Pod downwardapi-volume-54dd02b8-36e7-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:18:11.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s8spx" for this suite.
Feb 22 21:18:22.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:18:22.698: INFO: namespace: e2e-tests-downward-api-s8spx, resource: bindings, ignored listing per whitelist
Feb 22 21:18:25.509: INFO: namespace e2e-tests-downward-api-s8spx deletion completed in 14.471606642s

• [SLOW TEST:27.083 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:18:25.511: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb 22 21:18:26.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-wrtxc'
Feb 22 21:18:27.058: INFO: stderr: ""
Feb 22 21:18:27.058: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 22 21:18:28.064: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:18:28.064: INFO: Found 0 / 1
Feb 22 21:18:29.065: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:18:29.065: INFO: Found 0 / 1
Feb 22 21:18:30.065: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:18:30.065: INFO: Found 0 / 1
Feb 22 21:18:31.066: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:18:31.066: INFO: Found 0 / 1
Feb 22 21:18:32.223: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:18:32.223: INFO: Found 0 / 1
Feb 22 21:18:33.094: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:18:33.094: INFO: Found 1 / 1
Feb 22 21:18:33.094: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 22 21:18:33.099: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:18:33.099: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 22 21:18:33.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 logs redis-master-xq2bw redis-master --namespace=e2e-tests-kubectl-wrtxc'
Feb 22 21:18:33.216: INFO: stderr: ""
Feb 22 21:18:33.216: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Feb 21:18:31.911 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Feb 21:18:31.911 # Server started, Redis version 3.2.12\n1:M 22 Feb 21:18:31.911 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Feb 21:18:31.911 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 22 21:18:33.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 log redis-master-xq2bw redis-master --namespace=e2e-tests-kubectl-wrtxc --tail=1'
Feb 22 21:18:33.337: INFO: stderr: ""
Feb 22 21:18:33.337: INFO: stdout: "1:M 22 Feb 21:18:31.911 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 22 21:18:33.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 log redis-master-xq2bw redis-master --namespace=e2e-tests-kubectl-wrtxc --limit-bytes=1'
Feb 22 21:18:33.477: INFO: stderr: ""
Feb 22 21:18:33.477: INFO: stdout: " "
STEP: exposing timestamps
Feb 22 21:18:33.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 log redis-master-xq2bw redis-master --namespace=e2e-tests-kubectl-wrtxc --tail=1 --timestamps'
Feb 22 21:18:33.586: INFO: stderr: ""
Feb 22 21:18:33.586: INFO: stdout: "2019-02-22T21:18:31.912113371Z 1:M 22 Feb 21:18:31.911 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 22 21:18:36.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 log redis-master-xq2bw redis-master --namespace=e2e-tests-kubectl-wrtxc --since=1s'
Feb 22 21:18:42.798: INFO: stderr: ""
Feb 22 21:18:42.798: INFO: stdout: ""
Feb 22 21:18:42.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 log redis-master-xq2bw redis-master --namespace=e2e-tests-kubectl-wrtxc --since=24h'
Feb 22 21:18:42.906: INFO: stderr: ""
Feb 22 21:18:42.906: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Feb 21:18:31.911 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Feb 21:18:31.911 # Server started, Redis version 3.2.12\n1:M 22 Feb 21:18:31.911 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Feb 21:18:31.911 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb 22 21:18:42.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wrtxc'
Feb 22 21:18:43.015: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 21:18:43.015: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 22 21:18:43.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-wrtxc'
Feb 22 21:18:43.207: INFO: stderr: "No resources found.\n"
Feb 22 21:18:43.207: INFO: stdout: ""
Feb 22 21:18:43.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -l name=nginx --namespace=e2e-tests-kubectl-wrtxc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 21:18:43.330: INFO: stderr: ""
Feb 22 21:18:43.330: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:18:43.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wrtxc" for this suite.
Feb 22 21:18:51.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:18:51.954: INFO: namespace: e2e-tests-kubectl-wrtxc, resource: bindings, ignored listing per whitelist
Feb 22 21:18:52.085: INFO: namespace e2e-tests-kubectl-wrtxc deletion completed in 8.748861717s

• [SLOW TEST:26.575 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:18:52.086: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-73eb1638-36e7-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 21:18:52.185: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-73ecc24d-36e7-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-z7sbk" to be "success or failure"
Feb 22 21:18:52.197: INFO: Pod "pod-projected-secrets-73ecc24d-36e7-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.658666ms
Feb 22 21:18:56.839: INFO: Pod "pod-projected-secrets-73ecc24d-36e7-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.654632152s
Feb 22 21:18:58.846: INFO: Pod "pod-projected-secrets-73ecc24d-36e7-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.660947711s
STEP: Saw pod success
Feb 22 21:18:58.846: INFO: Pod "pod-projected-secrets-73ecc24d-36e7-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:18:58.851: INFO: Trying to get logs from node conformance113-1 pod pod-projected-secrets-73ecc24d-36e7-11e9-b6f8-82efa66823a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 21:18:58.877: INFO: Waiting for pod pod-projected-secrets-73ecc24d-36e7-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:18:58.882: INFO: Pod pod-projected-secrets-73ecc24d-36e7-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:18:58.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z7sbk" for this suite.
Feb 22 21:19:07.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:19:11.532: INFO: namespace: e2e-tests-projected-z7sbk, resource: bindings, ignored listing per whitelist
Feb 22 21:19:11.545: INFO: namespace e2e-tests-projected-z7sbk deletion completed in 12.65870742s

• [SLOW TEST:19.459 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:19:11.546: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:19:11.739: INFO: (0) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.534688ms)
Feb 22 21:19:11.755: INFO: (1) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 15.791721ms)
Feb 22 21:19:11.764: INFO: (2) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.716252ms)
Feb 22 21:19:11.770: INFO: (3) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.208955ms)
Feb 22 21:19:11.784: INFO: (4) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 13.309321ms)
Feb 22 21:19:11.791: INFO: (5) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.518318ms)
Feb 22 21:19:11.796: INFO: (6) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.012718ms)
Feb 22 21:19:11.802: INFO: (7) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.889904ms)
Feb 22 21:19:11.808: INFO: (8) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.292658ms)
Feb 22 21:19:11.832: INFO: (9) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 23.331626ms)
Feb 22 21:19:11.840: INFO: (10) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.781259ms)
Feb 22 21:19:11.846: INFO: (11) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.939535ms)
Feb 22 21:19:11.852: INFO: (12) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.563674ms)
Feb 22 21:19:11.858: INFO: (13) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.934346ms)
Feb 22 21:19:11.866: INFO: (14) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.804431ms)
Feb 22 21:19:11.872: INFO: (15) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.183563ms)
Feb 22 21:19:11.879: INFO: (16) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.44159ms)
Feb 22 21:19:11.885: INFO: (17) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.692193ms)
Feb 22 21:19:11.890: INFO: (18) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.750899ms)
Feb 22 21:19:11.896: INFO: (19) /api/v1/nodes/conformance113-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.527122ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:19:11.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-ppzvh" for this suite.
Feb 22 21:19:20.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:19:20.528: INFO: namespace: e2e-tests-proxy-ppzvh, resource: bindings, ignored listing per whitelist
Feb 22 21:19:20.621: INFO: namespace e2e-tests-proxy-ppzvh deletion completed in 8.719493809s

• [SLOW TEST:9.076 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:19:20.621: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-84fdcfd3-36e7-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:19:20.830: INFO: Waiting up to 5m0s for pod "pod-configmaps-84ffbc48-36e7-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-configmap-mwjdw" to be "success or failure"
Feb 22 21:19:20.833: INFO: Pod "pod-configmaps-84ffbc48-36e7-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.472805ms
Feb 22 21:19:22.838: INFO: Pod "pod-configmaps-84ffbc48-36e7-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008164836s
Feb 22 21:19:26.084: INFO: Pod "pod-configmaps-84ffbc48-36e7-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.253987326s
Feb 22 21:19:28.089: INFO: Pod "pod-configmaps-84ffbc48-36e7-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.259440225s
STEP: Saw pod success
Feb 22 21:19:28.089: INFO: Pod "pod-configmaps-84ffbc48-36e7-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:19:28.094: INFO: Trying to get logs from node conformance113-2 pod pod-configmaps-84ffbc48-36e7-11e9-b6f8-82efa66823a4 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:19:28.126: INFO: Waiting for pod pod-configmaps-84ffbc48-36e7-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:19:28.133: INFO: Pod pod-configmaps-84ffbc48-36e7-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:19:28.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mwjdw" for this suite.
Feb 22 21:19:36.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:19:36.362: INFO: namespace: e2e-tests-configmap-mwjdw, resource: bindings, ignored listing per whitelist
Feb 22 21:19:36.449: INFO: namespace e2e-tests-configmap-mwjdw deletion completed in 8.245264055s

• [SLOW TEST:15.828 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:19:36.450: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 22 21:19:51.388: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:19:52.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-n64f8" for this suite.
Feb 22 21:20:24.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:20:24.625: INFO: namespace: e2e-tests-replicaset-n64f8, resource: bindings, ignored listing per whitelist
Feb 22 21:20:24.738: INFO: namespace e2e-tests-replicaset-n64f8 deletion completed in 31.875771882s

• [SLOW TEST:48.288 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:20:24.738: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 22 21:20:24.825: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-203049355 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:20:24.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g5tmg" for this suite.
Feb 22 21:20:32.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:20:33.112: INFO: namespace: e2e-tests-kubectl-g5tmg, resource: bindings, ignored listing per whitelist
Feb 22 21:20:33.131: INFO: namespace e2e-tests-kubectl-g5tmg deletion completed in 8.2206504s

• [SLOW TEST:8.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:20:33.131: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:20:33.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 version --client'
Feb 22 21:20:33.344: INFO: stderr: ""
Feb 22 21:20:33.344: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 22 21:20:33.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-grq8n'
Feb 22 21:20:33.590: INFO: stderr: ""
Feb 22 21:20:33.590: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 22 21:20:33.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-grq8n'
Feb 22 21:20:33.878: INFO: stderr: ""
Feb 22 21:20:33.878: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 22 21:20:34.884: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:20:34.884: INFO: Found 0 / 1
Feb 22 21:20:36.395: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:20:36.395: INFO: Found 1 / 1
Feb 22 21:20:36.395: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 22 21:20:36.407: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:20:36.407: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 22 21:20:36.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 describe pod redis-master-ppdlx --namespace=e2e-tests-kubectl-grq8n'
Feb 22 21:20:40.560: INFO: stderr: ""
Feb 22 21:20:40.560: INFO: stdout: "Name:               redis-master-ppdlx\nNamespace:          e2e-tests-kubectl-grq8n\nPriority:           0\nPriorityClassName:  <none>\nNode:               conformance113-2/134.209.32.79\nStart Time:         Fri, 22 Feb 2019 21:20:33 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.42.2.14/32\nStatus:             Running\nIP:                 10.42.2.14\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://f532e149c6d4787a08453827bd2e541175624394a34132e6c9da80ace0277e5b\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 22 Feb 2019 21:20:34 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-8m79b (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-8m79b:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-8m79b\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                       Message\n  ----    ------     ----  ----                       -------\n  Normal  Scheduled  7s    default-scheduler          Successfully assigned e2e-tests-kubectl-grq8n/redis-master-ppdlx to conformance113-2\n  Normal  Pulled     6s    kubelet, conformance113-2  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    6s    kubelet, conformance113-2  Created container\n  Normal  Started    6s    kubelet, conformance113-2  Started container\n"
Feb 22 21:20:40.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 describe rc redis-master --namespace=e2e-tests-kubectl-grq8n'
Feb 22 21:20:40.681: INFO: stderr: ""
Feb 22 21:20:40.681: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-grq8n\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  7s    replication-controller  Created pod: redis-master-ppdlx\n"
Feb 22 21:20:40.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 describe service redis-master --namespace=e2e-tests-kubectl-grq8n'
Feb 22 21:20:40.792: INFO: stderr: ""
Feb 22 21:20:40.792: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-grq8n\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.43.122.162\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.42.2.14:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 22 21:20:40.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 describe node conformance113-1'
Feb 22 21:20:40.917: INFO: stderr: ""
Feb 22 21:20:40.917: INFO: stdout: "Name:               conformance113-1\nRoles:              controlplane,etcd,worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    cattle.io/creator=norman\n                    kubernetes.io/hostname=conformance113-1\n                    node-role.kubernetes.io/controlplane=true\n                    node-role.kubernetes.io/etcd=true\n                    node-role.kubernetes.io/worker=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"ce:69:5d:95:c4:7e\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 159.65.166.126\n                    node.alpha.kubernetes.io/ttl: 0\n                    rke.cattle.io/external-ip: 159.65.166.126\n                    rke.cattle.io/internal-ip: 159.65.166.126\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 22 Feb 2019 20:46:12 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 22 Feb 2019 21:20:33 +0000   Fri, 22 Feb 2019 20:46:12 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 22 Feb 2019 21:20:33 +0000   Fri, 22 Feb 2019 20:46:12 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 22 Feb 2019 21:20:33 +0000   Fri, 22 Feb 2019 20:46:12 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 22 Feb 2019 21:20:33 +0000   Fri, 22 Feb 2019 20:46:52 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  159.65.166.126\n  Hostname:    conformance113-1\nCapacity:\n cpu:                1\n ephemeral-storage:  60795880Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3080328Ki\n pods:               110\nAllocatable:\n cpu:                1\n ephemeral-storage:  56029482916\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2977928Ki\n pods:               110\nSystem Info:\n Machine ID:                 3d6ff2f75c7d3ae927580249a28e7e05\n System UUID:                B7E3CBC2-53BA-4E34-9BDD-7D63DA264B5B\n Boot ID:                    0c9e845c-9e8c-40b4-8934-eb9e130c805a\n Kernel Version:             4.4.0-142-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.2\n Kubelet Version:            v1.13.1\n Kube-Proxy Version:         v1.13.1\nPodCIDR:                     10.42.1.0/24\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  cattle-system              cattle-node-agent-rmztj                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\n  cattle-system              kube-api-auth-2kjsw                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         22m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-86xv2    0 (0%)        0 (0%)      0 (0%)           0 (0%)         22m\n  ingress-nginx              default-http-backend-7f8fbb85db-stsz7                      10m (1%)      10m (1%)    20Mi (0%)        20Mi (0%)      33m\n  ingress-nginx              nginx-ingress-controller-z44fs                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                canal-hqx48                                                250m (25%)    0 (0%)      0 (0%)           0 (0%)         34m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                260m (26%)  10m (1%)\n  memory             20Mi (0%)   20Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age   From                          Message\n  ----    ------                   ----  ----                          -------\n  Normal  Starting                 34m   kubelet, conformance113-1     Starting kubelet.\n  Normal  NodeHasSufficientMemory  34m   kubelet, conformance113-1     Node conformance113-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    34m   kubelet, conformance113-1     Node conformance113-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     34m   kubelet, conformance113-1     Node conformance113-1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  34m   kubelet, conformance113-1     Updated Node Allocatable limit across pods\n  Normal  Starting                 34m   kube-proxy, conformance113-1  Starting kube-proxy.\n  Normal  NodeReady                33m   kubelet, conformance113-1     Node conformance113-1 status is now: NodeReady\n"
Feb 22 21:20:40.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 describe namespace e2e-tests-kubectl-grq8n'
Feb 22 21:20:41.023: INFO: stderr: ""
Feb 22 21:20:41.023: INFO: stdout: "Name:         e2e-tests-kubectl-grq8n\nLabels:       e2e-framework=kubectl\n              e2e-run=a1c4307c-36e4-11e9-b6f8-82efa66823a4\nAnnotations:  cattle.io/status:\n                {\"Conditions\":[{\"Type\":\"ResourceQuotaInit\",\"Status\":\"True\",\"Message\":\"\",\"LastUpdateTime\":\"2019-02-22T21:20:34Z\"},{\"Type\":\"InitialRolesPopu...\n              lifecycle.cattle.io/create.namespace-auth: true\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:20:41.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-grq8n" for this suite.
Feb 22 21:21:11.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:21:11.592: INFO: namespace: e2e-tests-kubectl-grq8n, resource: bindings, ignored listing per whitelist
Feb 22 21:21:11.645: INFO: namespace e2e-tests-kubectl-grq8n deletion completed in 30.615063579s

• [SLOW TEST:38.514 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:21:11.645: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:21:22.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-whqpw" for this suite.
Feb 22 21:22:20.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:22:20.221: INFO: namespace: e2e-tests-kubelet-test-whqpw, resource: bindings, ignored listing per whitelist
Feb 22 21:22:20.369: INFO: namespace e2e-tests-kubelet-test-whqpw deletion completed in 58.210194287s

• [SLOW TEST:68.724 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:22:20.370: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-9r4np
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9r4np to expose endpoints map[]
Feb 22 21:22:20.502: INFO: Get endpoints failed (6.838869ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 22 21:22:21.508: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9r4np exposes endpoints map[] (1.013034061s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-9r4np
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9r4np to expose endpoints map[pod1:[100]]
Feb 22 21:22:26.284: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9r4np exposes endpoints map[pod1:[100]] (4.761207474s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-9r4np
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9r4np to expose endpoints map[pod1:[100] pod2:[101]]
Feb 22 21:22:28.588: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9r4np exposes endpoints map[pod1:[100] pod2:[101]] (2.293091732s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-9r4np
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9r4np to expose endpoints map[pod2:[101]]
Feb 22 21:22:32.844: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9r4np exposes endpoints map[pod2:[101]] (3.784852511s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-9r4np
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9r4np to expose endpoints map[]
Feb 22 21:22:33.880: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9r4np exposes endpoints map[] (1.024842635s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:22:33.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9r4np" for this suite.
Feb 22 21:22:57.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:22:58.044: INFO: namespace: e2e-tests-services-9r4np, resource: bindings, ignored listing per whitelist
Feb 22 21:22:58.165: INFO: namespace e2e-tests-services-9r4np deletion completed in 24.227868537s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:37.795 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:22:58.166: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 22 21:22:58.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-l7rsj'
Feb 22 21:22:58.539: INFO: stderr: ""
Feb 22 21:22:58.539: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 21:22:58.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-l7rsj'
Feb 22 21:22:59.067: INFO: stderr: ""
Feb 22 21:22:59.067: INFO: stdout: "update-demo-nautilus-hbmlz "
STEP: Replicas for name=update-demo: expected=2 actual=1
Feb 22 21:23:04.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-l7rsj'
Feb 22 21:23:04.206: INFO: stderr: ""
Feb 22 21:23:04.206: INFO: stdout: "update-demo-nautilus-hbmlz update-demo-nautilus-jgpth "
Feb 22 21:23:04.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-hbmlz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l7rsj'
Feb 22 21:23:04.307: INFO: stderr: ""
Feb 22 21:23:04.307: INFO: stdout: "true"
Feb 22 21:23:04.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-hbmlz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l7rsj'
Feb 22 21:23:04.398: INFO: stderr: ""
Feb 22 21:23:04.398: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:23:04.398: INFO: validating pod update-demo-nautilus-hbmlz
Feb 22 21:23:04.406: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:23:04.406: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:23:04.406: INFO: update-demo-nautilus-hbmlz is verified up and running
Feb 22 21:23:04.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-jgpth -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l7rsj'
Feb 22 21:23:04.497: INFO: stderr: ""
Feb 22 21:23:04.497: INFO: stdout: "true"
Feb 22 21:23:04.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-jgpth -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l7rsj'
Feb 22 21:23:04.591: INFO: stderr: ""
Feb 22 21:23:04.591: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:23:04.591: INFO: validating pod update-demo-nautilus-jgpth
Feb 22 21:23:06.914: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:23:06.914: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:23:06.914: INFO: update-demo-nautilus-jgpth is verified up and running
STEP: using delete to clean up resources
Feb 22 21:23:06.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l7rsj'
Feb 22 21:23:08.695: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 21:23:08.695: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 22 21:23:08.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-l7rsj'
Feb 22 21:23:08.932: INFO: stderr: "No resources found.\n"
Feb 22 21:23:08.932: INFO: stdout: ""
Feb 22 21:23:08.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -l name=update-demo --namespace=e2e-tests-kubectl-l7rsj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 21:23:09.108: INFO: stderr: ""
Feb 22 21:23:09.108: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:23:09.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l7rsj" for this suite.
Feb 22 21:23:33.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:23:33.248: INFO: namespace: e2e-tests-kubectl-l7rsj, resource: bindings, ignored listing per whitelist
Feb 22 21:23:33.392: INFO: namespace e2e-tests-kubectl-l7rsj deletion completed in 24.274532597s

• [SLOW TEST:35.225 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:23:33.392: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-1d412ef4-36e8-11e9-b6f8-82efa66823a4
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:23:38.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xb4bw" for this suite.
Feb 22 21:24:00.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:24:00.409: INFO: namespace: e2e-tests-configmap-xb4bw, resource: bindings, ignored listing per whitelist
Feb 22 21:24:00.699: INFO: namespace e2e-tests-configmap-xb4bw deletion completed in 22.347829269s

• [SLOW TEST:27.307 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:24:00.700: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 22 21:24:00.876: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-203049355 proxy --unix-socket=/tmp/kubectl-proxy-unix923146606/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:24:00.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xbrm9" for this suite.
Feb 22 21:24:13.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:24:13.095: INFO: namespace: e2e-tests-kubectl-xbrm9, resource: bindings, ignored listing per whitelist
Feb 22 21:24:13.286: INFO: namespace e2e-tests-kubectl-xbrm9 deletion completed in 12.314622149s

• [SLOW TEST:12.587 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:24:13.287: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-336ad0e4-36e8-11e9-b6f8-82efa66823a4
STEP: Creating configMap with name cm-test-opt-upd-336ad189-36e8-11e9-b6f8-82efa66823a4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-336ad0e4-36e8-11e9-b6f8-82efa66823a4
STEP: Updating configmap cm-test-opt-upd-336ad189-36e8-11e9-b6f8-82efa66823a4
STEP: Creating configMap with name cm-test-opt-create-336ad1a0-36e8-11e9-b6f8-82efa66823a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:25:24.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2h662" for this suite.
Feb 22 21:25:48.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:25:49.293: INFO: namespace: e2e-tests-projected-2h662, resource: bindings, ignored listing per whitelist
Feb 22 21:25:49.445: INFO: namespace e2e-tests-projected-2h662 deletion completed in 25.168098854s

• [SLOW TEST:96.158 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:25:49.447: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 22 21:25:50.217: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-a,UID:6d1895c2-36e8-11e9-a687-fac827d478c7,ResourceVersion:7986,Generation:0,CreationTimestamp:2019-02-22 21:25:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 22 21:25:50.217: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-a,UID:6d1895c2-36e8-11e9-a687-fac827d478c7,ResourceVersion:7986,Generation:0,CreationTimestamp:2019-02-22 21:25:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 22 21:26:00.243: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-a,UID:6d1895c2-36e8-11e9-a687-fac827d478c7,ResourceVersion:8004,Generation:0,CreationTimestamp:2019-02-22 21:25:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 22 21:26:00.243: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-a,UID:6d1895c2-36e8-11e9-a687-fac827d478c7,ResourceVersion:8004,Generation:0,CreationTimestamp:2019-02-22 21:25:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 22 21:26:10.998: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-a,UID:6d1895c2-36e8-11e9-a687-fac827d478c7,ResourceVersion:8017,Generation:0,CreationTimestamp:2019-02-22 21:25:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 22 21:26:10.998: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-a,UID:6d1895c2-36e8-11e9-a687-fac827d478c7,ResourceVersion:8017,Generation:0,CreationTimestamp:2019-02-22 21:25:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 22 21:26:21.067: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-a,UID:6d1895c2-36e8-11e9-a687-fac827d478c7,ResourceVersion:8036,Generation:0,CreationTimestamp:2019-02-22 21:25:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 22 21:26:21.067: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-a,UID:6d1895c2-36e8-11e9-a687-fac827d478c7,ResourceVersion:8036,Generation:0,CreationTimestamp:2019-02-22 21:25:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 22 21:26:33.030: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-b,UID:868d3673-36e8-11e9-a687-fac827d478c7,ResourceVersion:8054,Generation:0,CreationTimestamp:2019-02-22 21:26:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 22 21:26:33.030: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-b,UID:868d3673-36e8-11e9-a687-fac827d478c7,ResourceVersion:8054,Generation:0,CreationTimestamp:2019-02-22 21:26:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 22 21:26:47.484: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-b,UID:868d3673-36e8-11e9-a687-fac827d478c7,ResourceVersion:8073,Generation:0,CreationTimestamp:2019-02-22 21:26:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 22 21:26:47.484: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-dbrjv,SelfLink:/api/v1/namespaces/e2e-tests-watch-dbrjv/configmaps/e2e-watch-test-configmap-b,UID:868d3673-36e8-11e9-a687-fac827d478c7,ResourceVersion:8073,Generation:0,CreationTimestamp:2019-02-22 21:26:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:26:57.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-dbrjv" for this suite.
Feb 22 21:27:03.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:27:03.803: INFO: namespace: e2e-tests-watch-dbrjv, resource: bindings, ignored listing per whitelist
Feb 22 21:27:03.921: INFO: namespace e2e-tests-watch-dbrjv deletion completed in 6.407997102s

• [SLOW TEST:74.475 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:27:03.922: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:27:04.079: INFO: Waiting up to 5m0s for pod "downwardapi-volume-991bda7f-36e8-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-zmwpl" to be "success or failure"
Feb 22 21:27:04.102: INFO: Pod "downwardapi-volume-991bda7f-36e8-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 23.324791ms
Feb 22 21:27:06.197: INFO: Pod "downwardapi-volume-991bda7f-36e8-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.118641853s
Feb 22 21:27:08.217: INFO: Pod "downwardapi-volume-991bda7f-36e8-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.138407452s
STEP: Saw pod success
Feb 22 21:27:08.217: INFO: Pod "downwardapi-volume-991bda7f-36e8-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:27:08.232: INFO: Trying to get logs from node conformance113-1 pod downwardapi-volume-991bda7f-36e8-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 21:27:08.286: INFO: Waiting for pod downwardapi-volume-991bda7f-36e8-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:27:08.294: INFO: Pod downwardapi-volume-991bda7f-36e8-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:27:08.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zmwpl" for this suite.
Feb 22 21:27:14.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:27:14.746: INFO: namespace: e2e-tests-projected-zmwpl, resource: bindings, ignored listing per whitelist
Feb 22 21:27:14.894: INFO: namespace e2e-tests-projected-zmwpl deletion completed in 6.563981041s

• [SLOW TEST:10.973 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:27:14.896: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:27:15.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-qkqpm" for this suite.
Feb 22 21:27:23.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:27:23.725: INFO: namespace: e2e-tests-services-qkqpm, resource: bindings, ignored listing per whitelist
Feb 22 21:27:23.761: INFO: namespace e2e-tests-services-qkqpm deletion completed in 8.669975159s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:8.865 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:27:23.763: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:27:24.048: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 22 21:27:24.071: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 22 21:27:29.628: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 22 21:27:29.629: INFO: Creating deployment "test-rolling-update-deployment"
Feb 22 21:27:29.700: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 22 21:27:29.715: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 22 21:27:35.145: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 22 21:27:35.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467649, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467649, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467649, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467649, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:27:37.177: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 22 21:27:37.193: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-snzp9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-snzp9/deployments/test-rolling-update-deployment,UID:a85b596e-36e8-11e9-a687-fac827d478c7,ResourceVersion:8231,Generation:1,CreationTimestamp:2019-02-22 21:27:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-22 21:27:29 +0000 UTC 2019-02-22 21:27:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-22 21:27:36 +0000 UTC 2019-02-22 21:27:29 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 22 21:27:37.210: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-snzp9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-snzp9/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:a86983ec-36e8-11e9-96d9-6a889f07183f,ResourceVersion:8222,Generation:1,CreationTimestamp:2019-02-22 21:27:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a85b596e-36e8-11e9-a687-fac827d478c7 0xc000d9e857 0xc000d9e858}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 22 21:27:37.210: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 22 21:27:37.210: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-snzp9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-snzp9/replicasets/test-rolling-update-controller,UID:a507d3ba-36e8-11e9-a687-fac827d478c7,ResourceVersion:8230,Generation:2,CreationTimestamp:2019-02-22 21:27:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a85b596e-36e8-11e9-a687-fac827d478c7 0xc000d9e7a7 0xc000d9e7a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 21:27:37.233: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-9vtbz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-9vtbz,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-snzp9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-snzp9/pods/test-rolling-update-deployment-68b55d7bc6-9vtbz,UID:a86ad08b-36e8-11e9-96d9-6a889f07183f,ResourceVersion:8221,Generation:0,CreationTimestamp:2019-02-22 21:27:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.18/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 a86983ec-36e8-11e9-96d9-6a889f07183f 0xc001190237 0xc001190238}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t89wf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t89wf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-t89wf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011902b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0011902d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:27:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:27:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:27:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:27:29 +0000 UTC  }],Message:,Reason:,HostIP:104.248.0.151,PodIP:10.42.0.18,StartTime:2019-02-22 21:27:29 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-22 21:27:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://8def8fe361da6dc6884849c9e51fe8b00adb1baea2171ea3f5cdcbf1c7119c30}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:27:37.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-snzp9" for this suite.
Feb 22 21:27:45.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:27:45.515: INFO: namespace: e2e-tests-deployment-snzp9, resource: bindings, ignored listing per whitelist
Feb 22 21:27:45.793: INFO: namespace e2e-tests-deployment-snzp9 deletion completed in 8.513129455s

• [SLOW TEST:22.030 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:27:45.795: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 22 21:27:46.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:27:46.663: INFO: stderr: ""
Feb 22 21:27:46.663: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 21:27:46.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:27:47.189: INFO: stderr: ""
Feb 22 21:27:47.189: INFO: stdout: "update-demo-nautilus-d9d5h update-demo-nautilus-r7tqz "
Feb 22 21:27:47.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-d9d5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:27:47.809: INFO: stderr: ""
Feb 22 21:27:47.809: INFO: stdout: ""
Feb 22 21:27:47.809: INFO: update-demo-nautilus-d9d5h is created but not running
Feb 22 21:27:52.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:27:53.063: INFO: stderr: ""
Feb 22 21:27:53.063: INFO: stdout: "update-demo-nautilus-d9d5h update-demo-nautilus-r7tqz "
Feb 22 21:27:53.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-d9d5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:27:55.252: INFO: stderr: ""
Feb 22 21:27:55.252: INFO: stdout: "true"
Feb 22 21:27:55.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-d9d5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:27:57.636: INFO: stderr: ""
Feb 22 21:27:57.636: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:27:57.636: INFO: validating pod update-demo-nautilus-d9d5h
Feb 22 21:27:57.647: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:27:57.647: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:27:57.647: INFO: update-demo-nautilus-d9d5h is verified up and running
Feb 22 21:27:57.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-r7tqz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:27:57.748: INFO: stderr: ""
Feb 22 21:27:57.748: INFO: stdout: "true"
Feb 22 21:27:57.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-r7tqz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:27:57.849: INFO: stderr: ""
Feb 22 21:27:57.849: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:27:57.850: INFO: validating pod update-demo-nautilus-r7tqz
Feb 22 21:27:57.882: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:27:57.882: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:27:57.882: INFO: update-demo-nautilus-r7tqz is verified up and running
STEP: scaling down the replication controller
Feb 22 21:27:57.886: INFO: scanned /root for discovery docs: <nil>
Feb 22 21:27:57.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:27:59.115: INFO: stderr: ""
Feb 22 21:27:59.115: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 21:27:59.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:27:59.292: INFO: stderr: ""
Feb 22 21:27:59.292: INFO: stdout: "update-demo-nautilus-d9d5h update-demo-nautilus-r7tqz "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 22 21:28:04.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:05.673: INFO: stderr: ""
Feb 22 21:28:05.673: INFO: stdout: "update-demo-nautilus-d9d5h "
Feb 22 21:28:05.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-d9d5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:05.775: INFO: stderr: ""
Feb 22 21:28:05.775: INFO: stdout: "true"
Feb 22 21:28:05.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-d9d5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:05.897: INFO: stderr: ""
Feb 22 21:28:05.897: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:28:05.897: INFO: validating pod update-demo-nautilus-d9d5h
Feb 22 21:28:05.922: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:28:05.922: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:28:05.922: INFO: update-demo-nautilus-d9d5h is verified up and running
STEP: scaling up the replication controller
Feb 22 21:28:05.927: INFO: scanned /root for discovery docs: <nil>
Feb 22 21:28:05.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:07.147: INFO: stderr: ""
Feb 22 21:28:07.147: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 21:28:07.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:07.381: INFO: stderr: ""
Feb 22 21:28:07.381: INFO: stdout: "update-demo-nautilus-86sl7 update-demo-nautilus-d9d5h "
Feb 22 21:28:07.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-86sl7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:07.646: INFO: stderr: ""
Feb 22 21:28:07.646: INFO: stdout: ""
Feb 22 21:28:07.646: INFO: update-demo-nautilus-86sl7 is created but not running
Feb 22 21:28:12.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:12.770: INFO: stderr: ""
Feb 22 21:28:12.770: INFO: stdout: "update-demo-nautilus-86sl7 update-demo-nautilus-d9d5h "
Feb 22 21:28:12.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-86sl7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:12.880: INFO: stderr: ""
Feb 22 21:28:12.880: INFO: stdout: "true"
Feb 22 21:28:12.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-86sl7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:12.981: INFO: stderr: ""
Feb 22 21:28:12.981: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:28:12.981: INFO: validating pod update-demo-nautilus-86sl7
Feb 22 21:28:12.993: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:28:12.993: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:28:12.993: INFO: update-demo-nautilus-86sl7 is verified up and running
Feb 22 21:28:12.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-d9d5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:13.099: INFO: stderr: ""
Feb 22 21:28:13.099: INFO: stdout: "true"
Feb 22 21:28:13.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-d9d5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:13.237: INFO: stderr: ""
Feb 22 21:28:13.237: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:28:13.237: INFO: validating pod update-demo-nautilus-d9d5h
Feb 22 21:28:13.277: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:28:13.277: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:28:13.277: INFO: update-demo-nautilus-d9d5h is verified up and running
STEP: using delete to clean up resources
Feb 22 21:28:13.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:13.385: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 21:28:13.385: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 22 21:28:13.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-bjn59'
Feb 22 21:28:13.623: INFO: stderr: "No resources found.\n"
Feb 22 21:28:13.623: INFO: stdout: ""
Feb 22 21:28:13.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -l name=update-demo --namespace=e2e-tests-kubectl-bjn59 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 21:28:13.931: INFO: stderr: ""
Feb 22 21:28:13.931: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:28:13.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bjn59" for this suite.
Feb 22 21:28:42.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:28:42.541: INFO: namespace: e2e-tests-kubectl-bjn59, resource: bindings, ignored listing per whitelist
Feb 22 21:28:42.773: INFO: namespace e2e-tests-kubectl-bjn59 deletion completed in 28.434498646s

• [SLOW TEST:56.979 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:28:42.777: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0222 21:28:55.388795      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 21:28:55.388: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:28:55.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jmswr" for this suite.
Feb 22 21:29:09.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:29:09.575: INFO: namespace: e2e-tests-gc-jmswr, resource: bindings, ignored listing per whitelist
Feb 22 21:29:10.039: INFO: namespace e2e-tests-gc-jmswr deletion completed in 12.647206298s

• [SLOW TEST:27.263 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:29:10.041: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-e44c7a51-36e8-11e9-b6f8-82efa66823a4
STEP: Creating secret with name secret-projected-all-test-volume-e44c7a40-36e8-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 22 21:29:10.261: INFO: Waiting up to 5m0s for pod "projected-volume-e44c7a07-36e8-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-hz7rq" to be "success or failure"
Feb 22 21:29:10.291: INFO: Pod "projected-volume-e44c7a07-36e8-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 30.542709ms
Feb 22 21:29:13.223: INFO: Pod "projected-volume-e44c7a07-36e8-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.961979381s
Feb 22 21:29:15.230: INFO: Pod "projected-volume-e44c7a07-36e8-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.969493397s
STEP: Saw pod success
Feb 22 21:29:15.230: INFO: Pod "projected-volume-e44c7a07-36e8-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:29:15.236: INFO: Trying to get logs from node conformance113-2 pod projected-volume-e44c7a07-36e8-11e9-b6f8-82efa66823a4 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 22 21:29:15.373: INFO: Waiting for pod projected-volume-e44c7a07-36e8-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:29:15.385: INFO: Pod projected-volume-e44c7a07-36e8-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:29:15.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hz7rq" for this suite.
Feb 22 21:29:26.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:29:26.369: INFO: namespace: e2e-tests-projected-hz7rq, resource: bindings, ignored listing per whitelist
Feb 22 21:29:26.631: INFO: namespace e2e-tests-projected-hz7rq deletion completed in 11.238573708s

• [SLOW TEST:16.590 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:29:26.632: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 21:29:26.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5dxqn'
Feb 22 21:29:26.976: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 22 21:29:26.976: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb 22 21:29:27.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-5dxqn'
Feb 22 21:29:27.183: INFO: stderr: ""
Feb 22 21:29:27.183: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:29:27.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5dxqn" for this suite.
Feb 22 21:29:35.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:29:35.530: INFO: namespace: e2e-tests-kubectl-5dxqn, resource: bindings, ignored listing per whitelist
Feb 22 21:29:35.597: INFO: namespace e2e-tests-kubectl-5dxqn deletion completed in 8.406650845s

• [SLOW TEST:8.965 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:29:35.597: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:29:35.757: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f382b0fa-36e8-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-d4hbg" to be "success or failure"
Feb 22 21:29:35.777: INFO: Pod "downwardapi-volume-f382b0fa-36e8-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.369021ms
Feb 22 21:29:37.801: INFO: Pod "downwardapi-volume-f382b0fa-36e8-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043643729s
STEP: Saw pod success
Feb 22 21:29:37.801: INFO: Pod "downwardapi-volume-f382b0fa-36e8-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:29:37.806: INFO: Trying to get logs from node conformance113-1 pod downwardapi-volume-f382b0fa-36e8-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 21:29:38.345: INFO: Waiting for pod downwardapi-volume-f382b0fa-36e8-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:29:38.350: INFO: Pod downwardapi-volume-f382b0fa-36e8-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:29:38.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d4hbg" for this suite.
Feb 22 21:29:48.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:29:48.449: INFO: namespace: e2e-tests-projected-d4hbg, resource: bindings, ignored listing per whitelist
Feb 22 21:29:48.816: INFO: namespace e2e-tests-projected-d4hbg deletion completed in 10.455143673s

• [SLOW TEST:13.218 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:29:48.817: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:30:53.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xwrsr" for this suite.
Feb 22 21:31:22.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:31:23.063: INFO: namespace: e2e-tests-container-probe-xwrsr, resource: bindings, ignored listing per whitelist
Feb 22 21:31:23.402: INFO: namespace e2e-tests-container-probe-xwrsr deletion completed in 30.219609596s

• [SLOW TEST:94.586 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:31:23.405: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-33cbaa0f-36e9-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:31:23.610: INFO: Waiting up to 5m0s for pod "pod-configmaps-33cee05a-36e9-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-configmap-cddqb" to be "success or failure"
Feb 22 21:31:23.628: INFO: Pod "pod-configmaps-33cee05a-36e9-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.684293ms
Feb 22 21:31:25.635: INFO: Pod "pod-configmaps-33cee05a-36e9-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024647063s
Feb 22 21:31:27.642: INFO: Pod "pod-configmaps-33cee05a-36e9-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031510484s
STEP: Saw pod success
Feb 22 21:31:27.642: INFO: Pod "pod-configmaps-33cee05a-36e9-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:31:27.649: INFO: Trying to get logs from node conformance113-3 pod pod-configmaps-33cee05a-36e9-11e9-b6f8-82efa66823a4 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:31:29.702: INFO: Waiting for pod pod-configmaps-33cee05a-36e9-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:31:29.710: INFO: Pod pod-configmaps-33cee05a-36e9-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:31:29.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cddqb" for this suite.
Feb 22 21:31:43.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:31:44.031: INFO: namespace: e2e-tests-configmap-cddqb, resource: bindings, ignored listing per whitelist
Feb 22 21:31:44.128: INFO: namespace e2e-tests-configmap-cddqb deletion completed in 14.406286793s

• [SLOW TEST:20.723 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:31:44.130: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 22 21:31:52.578: INFO: Successfully updated pod "annotationupdate40c9c8f5-36e9-11e9-b6f8-82efa66823a4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:31:54.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8lknx" for this suite.
Feb 22 21:32:26.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:32:27.407: INFO: namespace: e2e-tests-projected-8lknx, resource: bindings, ignored listing per whitelist
Feb 22 21:32:27.436: INFO: namespace e2e-tests-projected-8lknx deletion completed in 32.542203402s

• [SLOW TEST:43.306 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:32:27.437: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-5c02a416-36e9-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:32:31.252: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5c1bcc7f-36e9-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-bzqr6" to be "success or failure"
Feb 22 21:32:31.282: INFO: Pod "pod-projected-configmaps-5c1bcc7f-36e9-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 30.167474ms
Feb 22 21:32:34.520: INFO: Pod "pod-projected-configmaps-5c1bcc7f-36e9-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 3.267840888s
STEP: Saw pod success
Feb 22 21:32:34.520: INFO: Pod "pod-projected-configmaps-5c1bcc7f-36e9-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:32:34.536: INFO: Trying to get logs from node conformance113-2 pod pod-projected-configmaps-5c1bcc7f-36e9-11e9-b6f8-82efa66823a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:32:34.688: INFO: Waiting for pod pod-projected-configmaps-5c1bcc7f-36e9-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:32:34.704: INFO: Pod pod-projected-configmaps-5c1bcc7f-36e9-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:32:34.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bzqr6" for this suite.
Feb 22 21:32:46.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:32:46.865: INFO: namespace: e2e-tests-projected-bzqr6, resource: bindings, ignored listing per whitelist
Feb 22 21:32:47.708: INFO: namespace e2e-tests-projected-bzqr6 deletion completed in 12.99339282s

• [SLOW TEST:20.271 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:32:47.709: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
W0222 21:32:49.089380      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 21:32:49.089: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:32:49.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-849c9" for this suite.
Feb 22 21:33:01.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:33:01.534: INFO: namespace: e2e-tests-gc-849c9, resource: bindings, ignored listing per whitelist
Feb 22 21:33:01.679: INFO: namespace e2e-tests-gc-849c9 deletion completed in 12.575523991s

• [SLOW TEST:13.971 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:33:01.680: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:33:10.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-5thfr" for this suite.
Feb 22 21:33:22.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:33:26.824: INFO: namespace: e2e-tests-emptydir-wrapper-5thfr, resource: bindings, ignored listing per whitelist
Feb 22 21:33:26.833: INFO: namespace e2e-tests-emptydir-wrapper-5thfr deletion completed in 16.262544952s

• [SLOW TEST:25.153 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:33:26.834: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-7d593a04-36e9-11e9-b6f8-82efa66823a4
STEP: Creating secret with name s-test-opt-upd-7d593a43-36e9-11e9-b6f8-82efa66823a4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7d593a04-36e9-11e9-b6f8-82efa66823a4
STEP: Updating secret s-test-opt-upd-7d593a43-36e9-11e9-b6f8-82efa66823a4
STEP: Creating secret with name s-test-opt-create-7d593a58-36e9-11e9-b6f8-82efa66823a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:34:57.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hdgkj" for this suite.
Feb 22 21:35:23.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:35:23.573: INFO: namespace: e2e-tests-secrets-hdgkj, resource: bindings, ignored listing per whitelist
Feb 22 21:35:27.068: INFO: namespace e2e-tests-secrets-hdgkj deletion completed in 29.674648834s

• [SLOW TEST:120.234 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:35:27.069: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 22 21:35:27.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 cluster-info'
Feb 22 21:35:27.410: INFO: stderr: ""
Feb 22 21:35:27.410: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:35:27.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b2qc4" for this suite.
Feb 22 21:35:35.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:35:35.548: INFO: namespace: e2e-tests-kubectl-b2qc4, resource: bindings, ignored listing per whitelist
Feb 22 21:35:35.724: INFO: namespace e2e-tests-kubectl-b2qc4 deletion completed in 8.308121589s

• [SLOW TEST:8.656 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:35:35.727: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-ca28f178-36e9-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:35:35.873: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ca2aaf8a-36e9-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-5h54f" to be "success or failure"
Feb 22 21:35:35.904: INFO: Pod "pod-projected-configmaps-ca2aaf8a-36e9-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 30.646484ms
Feb 22 21:35:39.380: INFO: Pod "pod-projected-configmaps-ca2aaf8a-36e9-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 3.507166821s
STEP: Saw pod success
Feb 22 21:35:39.380: INFO: Pod "pod-projected-configmaps-ca2aaf8a-36e9-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:35:39.396: INFO: Trying to get logs from node conformance113-3 pod pod-projected-configmaps-ca2aaf8a-36e9-11e9-b6f8-82efa66823a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:35:39.645: INFO: Waiting for pod pod-projected-configmaps-ca2aaf8a-36e9-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:35:39.679: INFO: Pod pod-projected-configmaps-ca2aaf8a-36e9-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:35:39.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5h54f" for this suite.
Feb 22 21:35:48.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:35:48.865: INFO: namespace: e2e-tests-projected-5h54f, resource: bindings, ignored listing per whitelist
Feb 22 21:35:49.128: INFO: namespace e2e-tests-projected-5h54f deletion completed in 9.409926659s

• [SLOW TEST:13.401 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:35:49.128: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 22 21:35:49.955: INFO: Waiting up to 5m0s for pod "client-containers-d28cdbb5-36e9-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-containers-lw6nr" to be "success or failure"
Feb 22 21:35:49.960: INFO: Pod "client-containers-d28cdbb5-36e9-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.473462ms
Feb 22 21:35:51.967: INFO: Pod "client-containers-d28cdbb5-36e9-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011762901s
Feb 22 21:35:53.972: INFO: Pod "client-containers-d28cdbb5-36e9-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016940285s
Feb 22 21:35:59.198: INFO: Pod "client-containers-d28cdbb5-36e9-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.243317126s
Feb 22 21:36:03.120: INFO: Pod "client-containers-d28cdbb5-36e9-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 13.165362522s
STEP: Saw pod success
Feb 22 21:36:03.120: INFO: Pod "client-containers-d28cdbb5-36e9-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:36:03.126: INFO: Trying to get logs from node conformance113-1 pod client-containers-d28cdbb5-36e9-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 21:36:03.162: INFO: Waiting for pod client-containers-d28cdbb5-36e9-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:36:03.166: INFO: Pod client-containers-d28cdbb5-36e9-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:36:03.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-lw6nr" for this suite.
Feb 22 21:36:11.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:36:11.470: INFO: namespace: e2e-tests-containers-lw6nr, resource: bindings, ignored listing per whitelist
Feb 22 21:36:11.577: INFO: namespace e2e-tests-containers-lw6nr deletion completed in 8.381034664s

• [SLOW TEST:22.449 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:36:11.578: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 22 21:36:11.744: INFO: Waiting up to 5m0s for pod "pod-df8b6e07-36e9-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-5n7tr" to be "success or failure"
Feb 22 21:36:11.771: INFO: Pod "pod-df8b6e07-36e9-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 26.855827ms
Feb 22 21:36:13.789: INFO: Pod "pod-df8b6e07-36e9-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045186926s
Feb 22 21:36:15.795: INFO: Pod "pod-df8b6e07-36e9-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051352332s
STEP: Saw pod success
Feb 22 21:36:15.795: INFO: Pod "pod-df8b6e07-36e9-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:36:15.803: INFO: Trying to get logs from node conformance113-2 pod pod-df8b6e07-36e9-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 21:36:15.878: INFO: Waiting for pod pod-df8b6e07-36e9-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:36:15.882: INFO: Pod pod-df8b6e07-36e9-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:36:15.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5n7tr" for this suite.
Feb 22 21:36:25.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:36:25.959: INFO: namespace: e2e-tests-emptydir-5n7tr, resource: bindings, ignored listing per whitelist
Feb 22 21:36:26.138: INFO: namespace e2e-tests-emptydir-5n7tr deletion completed in 10.249716209s

• [SLOW TEST:14.560 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:36:26.138: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:36:26.222: INFO: Creating ReplicaSet my-hostname-basic-e82f9fe4-36e9-11e9-b6f8-82efa66823a4
Feb 22 21:36:26.243: INFO: Pod name my-hostname-basic-e82f9fe4-36e9-11e9-b6f8-82efa66823a4: Found 0 pods out of 1
Feb 22 21:36:33.161: INFO: Pod name my-hostname-basic-e82f9fe4-36e9-11e9-b6f8-82efa66823a4: Found 1 pods out of 1
Feb 22 21:36:33.161: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e82f9fe4-36e9-11e9-b6f8-82efa66823a4" is running
Feb 22 21:36:33.213: INFO: Pod "my-hostname-basic-e82f9fe4-36e9-11e9-b6f8-82efa66823a4-jjrv8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 21:36:26 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 21:36:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 21:36:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 21:36:26 +0000 UTC Reason: Message:}])
Feb 22 21:36:33.213: INFO: Trying to dial the pod
Feb 22 21:36:40.417: INFO: Controller my-hostname-basic-e82f9fe4-36e9-11e9-b6f8-82efa66823a4: Got expected result from replica 1 [my-hostname-basic-e82f9fe4-36e9-11e9-b6f8-82efa66823a4-jjrv8]: "my-hostname-basic-e82f9fe4-36e9-11e9-b6f8-82efa66823a4-jjrv8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:36:40.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-6zjwr" for this suite.
Feb 22 21:36:50.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:36:50.677: INFO: namespace: e2e-tests-replicaset-6zjwr, resource: bindings, ignored listing per whitelist
Feb 22 21:36:50.794: INFO: namespace e2e-tests-replicaset-6zjwr deletion completed in 10.370840071s

• [SLOW TEST:24.656 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:36:50.795: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:37:27.022: INFO: Container started at 2019-02-22 21:36:59 +0000 UTC, pod became ready at 2019-02-22 21:37:21 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:37:27.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qt65g" for this suite.
Feb 22 21:37:56.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:37:56.611: INFO: namespace: e2e-tests-container-probe-qt65g, resource: bindings, ignored listing per whitelist
Feb 22 21:37:56.751: INFO: namespace e2e-tests-container-probe-qt65g deletion completed in 29.720074883s

• [SLOW TEST:65.956 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:37:56.752: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9lkhh in namespace e2e-tests-proxy-87rqz
I0222 21:37:56.901084      15 runners.go:184] Created replication controller with name: proxy-service-9lkhh, namespace: e2e-tests-proxy-87rqz, replica count: 1
I0222 21:37:57.951681      15 runners.go:184] proxy-service-9lkhh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 21:37:58.951963      15 runners.go:184] proxy-service-9lkhh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 21:37:59.952232      15 runners.go:184] proxy-service-9lkhh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 21:38:00.952523      15 runners.go:184] proxy-service-9lkhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0222 21:38:01.952858      15 runners.go:184] proxy-service-9lkhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0222 21:38:02.953161      15 runners.go:184] proxy-service-9lkhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0222 21:38:03.953368      15 runners.go:184] proxy-service-9lkhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0222 21:38:04.953649      15 runners.go:184] proxy-service-9lkhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0222 21:38:05.953827      15 runners.go:184] proxy-service-9lkhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0222 21:38:06.954091      15 runners.go:184] proxy-service-9lkhh Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 22 21:38:06.970: INFO: setup took 10.126352959s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 22 21:38:07.000: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 29.962368ms)
Feb 22 21:38:07.002: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 31.213672ms)
Feb 22 21:38:07.006: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 33.8839ms)
Feb 22 21:38:07.010: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 37.854604ms)
Feb 22 21:38:07.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 43.778905ms)
Feb 22 21:38:07.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 44.197879ms)
Feb 22 21:38:07.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 44.732165ms)
Feb 22 21:38:07.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 44.909311ms)
Feb 22 21:38:07.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 44.425523ms)
Feb 22 21:38:07.016: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 43.742527ms)
Feb 22 21:38:07.019: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 46.708853ms)
Feb 22 21:38:07.021: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 50.860639ms)
Feb 22 21:38:07.022: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 50.473161ms)
Feb 22 21:38:07.022: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 49.336099ms)
Feb 22 21:38:07.022: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 49.069851ms)
Feb 22 21:38:07.023: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 50.586467ms)
Feb 22 21:38:07.042: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 19.028486ms)
Feb 22 21:38:07.047: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 23.842381ms)
Feb 22 21:38:07.048: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 24.475625ms)
Feb 22 21:38:07.048: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 24.421425ms)
Feb 22 21:38:07.049: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 25.555475ms)
Feb 22 21:38:07.049: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 25.319206ms)
Feb 22 21:38:07.049: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 25.062235ms)
Feb 22 21:38:07.049: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 25.008381ms)
Feb 22 21:38:07.049: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 25.83446ms)
Feb 22 21:38:07.051: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 27.003947ms)
Feb 22 21:38:07.051: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 26.790631ms)
Feb 22 21:38:07.051: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 26.796747ms)
Feb 22 21:38:07.051: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 27.573639ms)
Feb 22 21:38:07.052: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 27.624039ms)
Feb 22 21:38:07.054: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 29.868532ms)
Feb 22 21:38:07.054: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 30.367124ms)
Feb 22 21:38:07.079: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 23.5022ms)
Feb 22 21:38:07.079: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 24.49454ms)
Feb 22 21:38:07.079: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 24.172675ms)
Feb 22 21:38:07.079: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 24.459056ms)
Feb 22 21:38:07.079: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 24.959924ms)
Feb 22 21:38:07.080: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 25.178984ms)
Feb 22 21:38:07.080: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 25.169739ms)
Feb 22 21:38:07.080: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 25.013123ms)
Feb 22 21:38:07.080: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 25.863118ms)
Feb 22 21:38:07.081: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 25.749792ms)
Feb 22 21:38:07.081: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 26.077249ms)
Feb 22 21:38:07.081: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 26.391141ms)
Feb 22 21:38:07.087: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 32.046033ms)
Feb 22 21:38:07.087: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 32.465968ms)
Feb 22 21:38:07.088: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 32.817951ms)
Feb 22 21:38:07.088: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 33.21635ms)
Feb 22 21:38:07.104: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 16.121016ms)
Feb 22 21:38:07.109: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 20.705776ms)
Feb 22 21:38:07.111: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 21.953929ms)
Feb 22 21:38:07.111: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 22.298286ms)
Feb 22 21:38:07.112: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 22.420061ms)
Feb 22 21:38:07.113: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 23.428657ms)
Feb 22 21:38:07.113: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 24.243463ms)
Feb 22 21:38:07.113: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 24.011936ms)
Feb 22 21:38:07.113: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 24.073044ms)
Feb 22 21:38:07.113: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 24.860047ms)
Feb 22 21:38:07.114: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 25.997152ms)
Feb 22 21:38:07.115: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 25.997282ms)
Feb 22 21:38:07.120: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 31.429863ms)
Feb 22 21:38:07.121: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 31.687183ms)
Feb 22 21:38:07.121: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 32.233117ms)
Feb 22 21:38:07.122: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 32.853702ms)
Feb 22 21:38:07.140: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 17.863544ms)
Feb 22 21:38:07.149: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 26.17871ms)
Feb 22 21:38:07.152: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 29.762535ms)
Feb 22 21:38:07.152: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 29.921581ms)
Feb 22 21:38:07.152: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 30.224182ms)
Feb 22 21:38:07.152: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 30.129805ms)
Feb 22 21:38:07.153: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 30.083619ms)
Feb 22 21:38:07.153: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 30.881868ms)
Feb 22 21:38:07.153: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 30.781561ms)
Feb 22 21:38:07.153: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 30.841685ms)
Feb 22 21:38:07.154: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 32.288612ms)
Feb 22 21:38:07.163: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 41.227859ms)
Feb 22 21:38:07.174: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 51.579876ms)
Feb 22 21:38:07.174: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 51.50887ms)
Feb 22 21:38:07.174: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 51.907123ms)
Feb 22 21:38:07.175: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 52.320864ms)
Feb 22 21:38:07.187: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 12.509801ms)
Feb 22 21:38:07.188: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 12.765254ms)
Feb 22 21:38:07.188: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 13.165217ms)
Feb 22 21:38:07.188: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 13.219256ms)
Feb 22 21:38:07.194: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 18.22767ms)
Feb 22 21:38:07.203: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 27.605765ms)
Feb 22 21:38:07.204: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 28.114477ms)
Feb 22 21:38:07.204: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 28.597014ms)
Feb 22 21:38:07.205: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 29.45292ms)
Feb 22 21:38:07.205: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 29.779556ms)
Feb 22 21:38:07.210: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 34.743348ms)
Feb 22 21:38:07.214: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 39.069896ms)
Feb 22 21:38:07.215: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 39.304733ms)
Feb 22 21:38:07.215: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 39.68627ms)
Feb 22 21:38:07.215: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 39.5671ms)
Feb 22 21:38:07.215: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 39.653446ms)
Feb 22 21:38:07.235: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 19.099641ms)
Feb 22 21:38:07.239: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 22.387743ms)
Feb 22 21:38:07.240: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 23.870585ms)
Feb 22 21:38:07.241: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 24.78115ms)
Feb 22 21:38:07.243: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 26.610222ms)
Feb 22 21:38:07.243: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 27.008793ms)
Feb 22 21:38:07.243: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 27.526063ms)
Feb 22 21:38:07.243: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 27.617428ms)
Feb 22 21:38:07.244: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 27.66909ms)
Feb 22 21:38:07.244: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 27.31473ms)
Feb 22 21:38:07.244: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 28.230338ms)
Feb 22 21:38:07.245: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 28.436431ms)
Feb 22 21:38:07.248: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 31.55881ms)
Feb 22 21:38:07.250: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 33.513804ms)
Feb 22 21:38:07.250: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 33.872757ms)
Feb 22 21:38:07.250: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 34.124079ms)
Feb 22 21:38:07.270: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 19.080659ms)
Feb 22 21:38:07.271: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 19.947218ms)
Feb 22 21:38:07.275: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 24.291656ms)
Feb 22 21:38:07.275: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 23.86418ms)
Feb 22 21:38:07.278: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 26.268298ms)
Feb 22 21:38:07.278: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 27.146655ms)
Feb 22 21:38:07.279: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 27.584487ms)
Feb 22 21:38:07.279: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 27.645387ms)
Feb 22 21:38:07.279: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 27.761582ms)
Feb 22 21:38:07.279: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 28.428228ms)
Feb 22 21:38:07.280: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 28.744066ms)
Feb 22 21:38:07.280: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 29.066359ms)
Feb 22 21:38:07.280: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 29.050834ms)
Feb 22 21:38:07.280: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 29.273654ms)
Feb 22 21:38:07.283: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 31.642508ms)
Feb 22 21:38:07.283: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 32.080667ms)
Feb 22 21:38:07.303: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 19.998759ms)
Feb 22 21:38:07.319: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 34.892123ms)
Feb 22 21:38:07.319: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 35.082823ms)
Feb 22 21:38:07.319: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 35.34663ms)
Feb 22 21:38:07.319: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 35.081357ms)
Feb 22 21:38:07.320: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 35.842218ms)
Feb 22 21:38:07.320: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 36.786734ms)
Feb 22 21:38:07.321: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 36.630329ms)
Feb 22 21:38:07.321: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 36.724776ms)
Feb 22 21:38:07.321: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 36.703187ms)
Feb 22 21:38:07.321: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 36.660536ms)
Feb 22 21:38:07.321: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 37.612764ms)
Feb 22 21:38:07.326: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 42.487541ms)
Feb 22 21:38:07.339: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 55.139251ms)
Feb 22 21:38:07.339: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 55.61909ms)
Feb 22 21:38:07.340: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 55.967708ms)
Feb 22 21:38:07.367: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 27.133558ms)
Feb 22 21:38:07.368: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 27.972679ms)
Feb 22 21:38:07.368: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 27.894499ms)
Feb 22 21:38:07.368: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 27.930764ms)
Feb 22 21:38:07.376: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 35.92561ms)
Feb 22 21:38:07.379: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 37.773564ms)
Feb 22 21:38:07.379: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 37.772065ms)
Feb 22 21:38:07.379: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 37.794167ms)
Feb 22 21:38:07.379: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 37.691078ms)
Feb 22 21:38:07.379: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 37.87438ms)
Feb 22 21:38:07.379: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 38.14172ms)
Feb 22 21:38:07.380: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 38.564466ms)
Feb 22 21:38:07.380: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 39.154643ms)
Feb 22 21:38:07.380: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 39.491648ms)
Feb 22 21:38:07.380: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 39.181631ms)
Feb 22 21:38:07.383: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 42.154041ms)
Feb 22 21:38:07.396: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 12.555702ms)
Feb 22 21:38:07.397: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 13.921296ms)
Feb 22 21:38:07.398: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 14.799684ms)
Feb 22 21:38:07.399: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 15.370315ms)
Feb 22 21:38:07.400: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 16.408083ms)
Feb 22 21:38:07.401: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 17.129433ms)
Feb 22 21:38:07.407: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 23.157572ms)
Feb 22 21:38:07.407: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 23.245219ms)
Feb 22 21:38:07.407: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 23.463109ms)
Feb 22 21:38:07.407: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 23.798367ms)
Feb 22 21:38:07.407: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 23.890578ms)
Feb 22 21:38:07.410: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 26.824352ms)
Feb 22 21:38:07.412: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 28.400391ms)
Feb 22 21:38:07.412: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 28.592034ms)
Feb 22 21:38:07.413: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 29.333588ms)
Feb 22 21:38:07.413: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 29.352851ms)
Feb 22 21:38:07.428: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 14.884376ms)
Feb 22 21:38:07.429: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 15.593507ms)
Feb 22 21:38:07.438: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 23.719486ms)
Feb 22 21:38:07.439: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 24.95003ms)
Feb 22 21:38:07.439: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 25.210595ms)
Feb 22 21:38:07.440: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 26.009639ms)
Feb 22 21:38:07.441: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 27.043701ms)
Feb 22 21:38:07.441: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 27.59988ms)
Feb 22 21:38:07.441: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 27.430551ms)
Feb 22 21:38:07.441: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 27.963658ms)
Feb 22 21:38:07.442: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 27.45561ms)
Feb 22 21:38:07.455: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 41.678231ms)
Feb 22 21:38:07.456: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 41.586818ms)
Feb 22 21:38:07.456: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 41.884799ms)
Feb 22 21:38:07.457: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 42.674386ms)
Feb 22 21:38:07.457: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 42.953386ms)
Feb 22 21:38:07.473: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 15.812472ms)
Feb 22 21:38:07.473: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 15.632829ms)
Feb 22 21:38:07.476: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 18.23692ms)
Feb 22 21:38:07.476: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 18.719891ms)
Feb 22 21:38:07.476: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 18.933566ms)
Feb 22 21:38:07.485: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 27.826574ms)
Feb 22 21:38:07.491: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 32.886527ms)
Feb 22 21:38:07.491: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 33.701765ms)
Feb 22 21:38:07.491: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 33.598683ms)
Feb 22 21:38:07.491: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 34.185765ms)
Feb 22 21:38:07.492: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 34.634133ms)
Feb 22 21:38:07.492: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 34.611871ms)
Feb 22 21:38:07.497: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 39.56006ms)
Feb 22 21:38:07.498: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 40.814798ms)
Feb 22 21:38:07.499: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 41.226825ms)
Feb 22 21:38:07.499: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 41.581195ms)
Feb 22 21:38:07.515: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 15.938953ms)
Feb 22 21:38:07.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 18.719759ms)
Feb 22 21:38:07.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 19.355092ms)
Feb 22 21:38:07.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 19.439767ms)
Feb 22 21:38:07.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 20.151953ms)
Feb 22 21:38:07.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 20.85928ms)
Feb 22 21:38:07.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 20.341905ms)
Feb 22 21:38:07.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 20.346029ms)
Feb 22 21:38:07.521: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 21.319962ms)
Feb 22 21:38:07.521: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 21.199188ms)
Feb 22 21:38:07.521: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 21.521036ms)
Feb 22 21:38:07.522: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 23.154958ms)
Feb 22 21:38:07.525: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 24.182346ms)
Feb 22 21:38:07.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 25.642432ms)
Feb 22 21:38:07.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 25.870822ms)
Feb 22 21:38:07.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 26.279237ms)
Feb 22 21:38:07.544: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 17.836294ms)
Feb 22 21:38:07.544: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 18.053632ms)
Feb 22 21:38:07.550: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 23.228947ms)
Feb 22 21:38:07.552: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 25.336258ms)
Feb 22 21:38:07.553: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 25.723695ms)
Feb 22 21:38:07.553: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 25.946646ms)
Feb 22 21:38:07.553: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 26.443528ms)
Feb 22 21:38:07.553: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 26.705369ms)
Feb 22 21:38:07.553: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 26.9769ms)
Feb 22 21:38:07.554: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 27.415282ms)
Feb 22 21:38:07.554: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 27.696699ms)
Feb 22 21:38:07.561: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 34.718366ms)
Feb 22 21:38:07.561: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 34.277391ms)
Feb 22 21:38:07.564: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 37.791773ms)
Feb 22 21:38:07.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 38.054801ms)
Feb 22 21:38:07.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 38.34739ms)
Feb 22 21:38:07.577: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 11.523531ms)
Feb 22 21:38:07.585: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 19.499764ms)
Feb 22 21:38:07.585: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 19.570755ms)
Feb 22 21:38:07.587: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 21.232036ms)
Feb 22 21:38:07.587: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 21.458246ms)
Feb 22 21:38:07.588: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 21.754431ms)
Feb 22 21:38:07.588: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 22.148505ms)
Feb 22 21:38:07.588: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 22.857174ms)
Feb 22 21:38:07.589: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 22.80333ms)
Feb 22 21:38:07.589: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 22.948643ms)
Feb 22 21:38:07.590: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 24.130167ms)
Feb 22 21:38:07.599: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 33.413031ms)
Feb 22 21:38:07.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 33.418268ms)
Feb 22 21:38:07.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 33.965508ms)
Feb 22 21:38:07.600: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 34.289389ms)
Feb 22 21:38:07.601: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 34.490508ms)
Feb 22 21:38:07.617: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 15.69751ms)
Feb 22 21:38:07.618: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 17.063274ms)
Feb 22 21:38:07.625: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 23.34217ms)
Feb 22 21:38:07.625: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 23.892834ms)
Feb 22 21:38:07.625: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 24.221412ms)
Feb 22 21:38:07.625: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 23.530423ms)
Feb 22 21:38:07.629: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 27.939445ms)
Feb 22 21:38:07.629: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 27.193186ms)
Feb 22 21:38:07.629: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 27.53495ms)
Feb 22 21:38:07.630: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 28.193982ms)
Feb 22 21:38:07.641: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 39.701233ms)
Feb 22 21:38:07.641: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 39.320551ms)
Feb 22 21:38:07.642: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 40.749959ms)
Feb 22 21:38:07.642: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 40.983838ms)
Feb 22 21:38:07.643: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 40.991059ms)
Feb 22 21:38:07.643: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 41.5584ms)
Feb 22 21:38:07.663: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 20.021961ms)
Feb 22 21:38:07.664: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 19.999298ms)
Feb 22 21:38:07.666: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 23.192037ms)
Feb 22 21:38:07.668: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 24.179161ms)
Feb 22 21:38:07.668: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 23.311237ms)
Feb 22 21:38:07.668: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 23.127938ms)
Feb 22 21:38:07.668: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 24.495691ms)
Feb 22 21:38:07.669: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 25.165109ms)
Feb 22 21:38:07.669: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 25.182934ms)
Feb 22 21:38:07.670: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 26.075248ms)
Feb 22 21:38:07.670: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 25.630278ms)
Feb 22 21:38:07.672: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 27.081212ms)
Feb 22 21:38:07.673: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 29.636909ms)
Feb 22 21:38:07.674: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 29.069527ms)
Feb 22 21:38:07.675: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 30.210652ms)
Feb 22 21:38:07.675: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 30.183875ms)
Feb 22 21:38:07.688: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 13.135209ms)
Feb 22 21:38:07.689: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 13.478001ms)
Feb 22 21:38:07.693: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 17.326479ms)
Feb 22 21:38:07.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 18.315748ms)
Feb 22 21:38:07.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 19.497696ms)
Feb 22 21:38:07.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 19.3968ms)
Feb 22 21:38:07.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 21.008135ms)
Feb 22 21:38:07.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 20.836729ms)
Feb 22 21:38:07.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 21.826383ms)
Feb 22 21:38:07.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 21.24565ms)
Feb 22 21:38:07.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 21.891048ms)
Feb 22 21:38:07.698: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 22.314027ms)
Feb 22 21:38:07.701: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 24.997629ms)
Feb 22 21:38:07.701: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 25.474865ms)
Feb 22 21:38:07.701: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 25.547817ms)
Feb 22 21:38:07.702: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 25.924255ms)
Feb 22 21:38:07.718: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 16.121579ms)
Feb 22 21:38:07.725: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:1080/proxy/... (200; 22.145171ms)
Feb 22 21:38:07.725: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm/proxy/rewriteme"... (200; 22.273957ms)
Feb 22 21:38:07.727: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:443/proxy/... (200; 25.22184ms)
Feb 22 21:38:07.727: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:1080/proxy/rewri... (200; 24.834881ms)
Feb 22 21:38:07.727: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:462/proxy/: tls qux (200; 24.773954ms)
Feb 22 21:38:07.728: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/https:proxy-service-9lkhh-tcwhm:460/proxy/: tls baz (200; 25.335695ms)
Feb 22 21:38:07.729: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 26.21562ms)
Feb 22 21:38:07.729: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/proxy-service-9lkhh-tcwhm:162/proxy/: bar (200; 26.625302ms)
Feb 22 21:38:07.729: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname1/proxy/: tls baz (200; 27.371969ms)
Feb 22 21:38:07.730: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname1/proxy/: foo (200; 28.666722ms)
Feb 22 21:38:07.731: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/https:proxy-service-9lkhh:tlsportname2/proxy/: tls qux (200; 28.019147ms)
Feb 22 21:38:07.731: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/pods/http:proxy-service-9lkhh-tcwhm:160/proxy/: foo (200; 28.382228ms)
Feb 22 21:38:07.731: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname2/proxy/: bar (200; 28.94342ms)
Feb 22 21:38:07.731: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/proxy-service-9lkhh:portname2/proxy/: bar (200; 29.043345ms)
Feb 22 21:38:07.731: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-87rqz/services/http:proxy-service-9lkhh:portname1/proxy/: foo (200; 28.748032ms)
STEP: deleting ReplicationController proxy-service-9lkhh in namespace e2e-tests-proxy-87rqz, will wait for the garbage collector to delete the pods
Feb 22 21:38:07.820: INFO: Deleting ReplicationController proxy-service-9lkhh took: 33.063329ms
Feb 22 21:38:07.920: INFO: Terminating ReplicationController proxy-service-9lkhh pods took: 100.215563ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:38:10.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-87rqz" for this suite.
Feb 22 21:38:25.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:38:26.009: INFO: namespace: e2e-tests-proxy-87rqz, resource: bindings, ignored listing per whitelist
Feb 22 21:38:26.089: INFO: namespace e2e-tests-proxy-87rqz deletion completed in 15.743382191s

• [SLOW TEST:29.337 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:38:26.090: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 22 21:38:26.264: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:38:31.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bwg46" for this suite.
Feb 22 21:38:37.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:38:37.671: INFO: namespace: e2e-tests-init-container-bwg46, resource: bindings, ignored listing per whitelist
Feb 22 21:38:38.013: INFO: namespace e2e-tests-init-container-bwg46 deletion completed in 6.511327429s

• [SLOW TEST:11.923 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:38:38.018: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-36d6d862-36ea-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:38:38.223: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-36d9a69a-36ea-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-j9cp4" to be "success or failure"
Feb 22 21:38:38.242: INFO: Pod "pod-projected-configmaps-36d9a69a-36ea-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.879121ms
Feb 22 21:38:40.248: INFO: Pod "pod-projected-configmaps-36d9a69a-36ea-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02433283s
Feb 22 21:38:42.277: INFO: Pod "pod-projected-configmaps-36d9a69a-36ea-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053813556s
STEP: Saw pod success
Feb 22 21:38:42.277: INFO: Pod "pod-projected-configmaps-36d9a69a-36ea-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:38:42.283: INFO: Trying to get logs from node conformance113-1 pod pod-projected-configmaps-36d9a69a-36ea-11e9-b6f8-82efa66823a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:38:46.841: INFO: Waiting for pod pod-projected-configmaps-36d9a69a-36ea-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:38:46.847: INFO: Pod pod-projected-configmaps-36d9a69a-36ea-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:38:46.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j9cp4" for this suite.
Feb 22 21:38:54.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:38:54.716: INFO: namespace: e2e-tests-projected-j9cp4, resource: bindings, ignored listing per whitelist
Feb 22 21:38:54.754: INFO: namespace e2e-tests-projected-j9cp4 deletion completed in 6.261676453s

• [SLOW TEST:16.737 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:38:54.755: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:38:54.869: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 22 21:38:59.880: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 22 21:38:59.880: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 22 21:38:59.923: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-fcvcb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fcvcb/deployments/test-cleanup-deployment,UID:43c91301-36ea-11e9-a687-fac827d478c7,ResourceVersion:10314,Generation:1,CreationTimestamp:2019-02-22 21:38:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 22 21:38:59.930: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:38:59.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fcvcb" for this suite.
Feb 22 21:39:06.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:39:06.217: INFO: namespace: e2e-tests-deployment-fcvcb, resource: bindings, ignored listing per whitelist
Feb 22 21:39:06.402: INFO: namespace e2e-tests-deployment-fcvcb deletion completed in 6.440866387s

• [SLOW TEST:11.647 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:39:06.402: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:39:06.572: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb 22 21:39:06.581: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pvb7t/daemonsets","resourceVersion":"10376"},"items":null}

Feb 22 21:39:06.587: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pvb7t/pods","resourceVersion":"10376"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:39:06.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pvb7t" for this suite.
Feb 22 21:39:15.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:39:16.461: INFO: namespace: e2e-tests-daemonsets-pvb7t, resource: bindings, ignored listing per whitelist
Feb 22 21:39:17.441: INFO: namespace e2e-tests-daemonsets-pvb7t deletion completed in 10.826188883s

S [SKIPPING] [11.039 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 22 21:39:06.572: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:39:17.442: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 22 21:39:17.558: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 21:39:17.571: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 21:39:17.578: INFO: 
Logging pods the kubelet thinks is on node conformance113-1 before test
Feb 22 21:39:17.597: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-22 20:58:03 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.597: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 22 21:39:17.598: INFO: sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-86xv2 from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:17.598: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:39:17.598: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:39:17.598: INFO: default-http-backend-7f8fbb85db-stsz7 from ingress-nginx started at 2019-02-22 20:46:57 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.598: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 22 21:39:17.598: INFO: cattle-node-agent-rmztj from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.599: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:39:17.599: INFO: kube-api-auth-2kjsw from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.599: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:39:17.600: INFO: canal-hqx48 from kube-system started at 2019-02-22 20:46:31 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:17.600: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:39:17.602: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:39:17.602: INFO: nginx-ingress-controller-z44fs from ingress-nginx started at 2019-02-22 20:46:56 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.602: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:39:17.603: INFO: 
Logging pods the kubelet thinks is on node conformance113-2 before test
Feb 22 21:39:17.620: INFO: kube-api-auth-jwcnf from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.620: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:39:17.621: INFO: canal-l9dtf from kube-system started at 2019-02-22 20:46:31 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:17.621: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:39:17.621: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:39:17.621: INFO: rke-kube-dns-addon-deploy-job-67wm7 from kube-system started at 2019-02-22 20:46:31 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.621: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Feb 22 21:39:17.621: INFO: rke-metrics-addon-deploy-job-c95v9 from kube-system started at 2019-02-22 20:46:39 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.621: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Feb 22 21:39:17.621: INFO: rke-ingress-controller-deploy-job-z8lq7 from kube-system started at 2019-02-22 20:46:45 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.621: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Feb 22 21:39:17.621: INFO: cattle-cluster-agent-9b7f6857d-r8pl5 from cattle-system started at 2019-02-22 20:47:12 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.622: INFO: 	Container cluster-register ready: true, restart count 0
Feb 22 21:39:17.622: INFO: sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-zhbmk from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:17.622: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:39:17.622: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:39:17.622: INFO: nginx-ingress-controller-7789l from ingress-nginx started at 2019-02-22 20:46:56 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.622: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:39:17.622: INFO: cattle-node-agent-znhhf from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.622: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:39:17.622: INFO: sonobuoy-e2e-job-9e8ca54401904ae5 from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:17.622: INFO: 	Container e2e ready: true, restart count 0
Feb 22 21:39:17.622: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:39:17.623: INFO: rke-network-plugin-deploy-job-wbhjp from kube-system started at 2019-02-22 20:46:26 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.623: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Feb 22 21:39:17.623: INFO: 
Logging pods the kubelet thinks is on node conformance113-3 before test
Feb 22 21:39:17.633: INFO: metrics-server-7fbd549b78-lkpfr from kube-system started at 2019-02-22 20:46:42 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.633: INFO: 	Container metrics-server ready: true, restart count 0
Feb 22 21:39:17.633: INFO: nginx-ingress-controller-pjzpv from ingress-nginx started at 2019-02-22 20:46:56 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.633: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:39:17.633: INFO: cattle-node-agent-458qr from cattle-system started at 2019-02-22 20:47:12 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.633: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:39:17.633: INFO: sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-4jsmm from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:17.634: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:39:17.634: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:39:17.634: INFO: canal-wwmks from kube-system started at 2019-02-22 20:46:31 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:17.634: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:39:17.634: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:39:17.634: INFO: kube-dns-autoscaler-c89df977f-lnwxn from kube-system started at 2019-02-22 20:46:42 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.634: INFO: 	Container autoscaler ready: true, restart count 0
Feb 22 21:39:17.634: INFO: kube-dns-5fd74c7488-lqd8x from kube-system started at 2019-02-22 20:46:42 +0000 UTC (3 container statuses recorded)
Feb 22 21:39:17.634: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 22 21:39:17.634: INFO: 	Container kubedns ready: true, restart count 0
Feb 22 21:39:17.634: INFO: 	Container sidecar ready: true, restart count 0
Feb 22 21:39:17.634: INFO: kube-api-auth-flm69 from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:17.634: INFO: 	Container kube-api-auth ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-4f953146-36ea-11e9-b6f8-82efa66823a4 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-4f953146-36ea-11e9-b6f8-82efa66823a4 off the node conformance113-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4f953146-36ea-11e9-b6f8-82efa66823a4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:39:23.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-89s8h" for this suite.
Feb 22 21:39:43.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:39:43.891: INFO: namespace: e2e-tests-sched-pred-89s8h, resource: bindings, ignored listing per whitelist
Feb 22 21:39:44.164: INFO: namespace e2e-tests-sched-pred-89s8h deletion completed in 20.369978789s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:26.723 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:39:44.166: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 22 21:39:44.430: INFO: Waiting up to 5m0s for pod "pod-5e50beec-36ea-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-k75bp" to be "success or failure"
Feb 22 21:39:44.442: INFO: Pod "pod-5e50beec-36ea-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.568122ms
Feb 22 21:39:46.448: INFO: Pod "pod-5e50beec-36ea-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017262111s
STEP: Saw pod success
Feb 22 21:39:46.448: INFO: Pod "pod-5e50beec-36ea-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:39:46.452: INFO: Trying to get logs from node conformance113-2 pod pod-5e50beec-36ea-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 21:39:46.517: INFO: Waiting for pod pod-5e50beec-36ea-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:39:46.522: INFO: Pod pod-5e50beec-36ea-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:39:46.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-k75bp" for this suite.
Feb 22 21:39:52.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:39:52.719: INFO: namespace: e2e-tests-emptydir-k75bp, resource: bindings, ignored listing per whitelist
Feb 22 21:39:52.961: INFO: namespace e2e-tests-emptydir-k75bp deletion completed in 6.395146735s

• [SLOW TEST:8.795 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:39:52.962: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 22 21:39:53.081: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 21:39:53.092: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 21:39:53.098: INFO: 
Logging pods the kubelet thinks is on node conformance113-1 before test
Feb 22 21:39:53.107: INFO: sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-86xv2 from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:53.107: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:39:53.107: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:39:53.107: INFO: default-http-backend-7f8fbb85db-stsz7 from ingress-nginx started at 2019-02-22 20:46:57 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.107: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 22 21:39:53.107: INFO: cattle-node-agent-rmztj from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.107: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:39:53.107: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-22 20:58:03 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.107: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 22 21:39:53.108: INFO: canal-hqx48 from kube-system started at 2019-02-22 20:46:31 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:53.108: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:39:53.108: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:39:53.108: INFO: nginx-ingress-controller-z44fs from ingress-nginx started at 2019-02-22 20:46:56 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.108: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:39:53.108: INFO: kube-api-auth-2kjsw from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.108: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:39:53.108: INFO: 
Logging pods the kubelet thinks is on node conformance113-2 before test
Feb 22 21:39:53.132: INFO: canal-l9dtf from kube-system started at 2019-02-22 20:46:31 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:53.133: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:39:53.133: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:39:53.133: INFO: rke-kube-dns-addon-deploy-job-67wm7 from kube-system started at 2019-02-22 20:46:31 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.133: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Feb 22 21:39:53.133: INFO: rke-metrics-addon-deploy-job-c95v9 from kube-system started at 2019-02-22 20:46:39 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.133: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Feb 22 21:39:53.133: INFO: rke-ingress-controller-deploy-job-z8lq7 from kube-system started at 2019-02-22 20:46:45 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.133: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Feb 22 21:39:53.133: INFO: cattle-cluster-agent-9b7f6857d-r8pl5 from cattle-system started at 2019-02-22 20:47:12 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.133: INFO: 	Container cluster-register ready: true, restart count 0
Feb 22 21:39:53.133: INFO: sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-zhbmk from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:53.133: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:39:53.133: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:39:53.134: INFO: nginx-ingress-controller-7789l from ingress-nginx started at 2019-02-22 20:46:56 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.134: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:39:53.134: INFO: cattle-node-agent-znhhf from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.134: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:39:53.134: INFO: sonobuoy-e2e-job-9e8ca54401904ae5 from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:53.134: INFO: 	Container e2e ready: true, restart count 0
Feb 22 21:39:53.134: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:39:53.134: INFO: rke-network-plugin-deploy-job-wbhjp from kube-system started at 2019-02-22 20:46:26 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.134: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Feb 22 21:39:53.134: INFO: kube-api-auth-jwcnf from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.134: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:39:53.134: INFO: 
Logging pods the kubelet thinks is on node conformance113-3 before test
Feb 22 21:39:53.161: INFO: canal-wwmks from kube-system started at 2019-02-22 20:46:31 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:53.162: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:39:53.162: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:39:53.162: INFO: kube-dns-autoscaler-c89df977f-lnwxn from kube-system started at 2019-02-22 20:46:42 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.162: INFO: 	Container autoscaler ready: true, restart count 0
Feb 22 21:39:53.162: INFO: kube-dns-5fd74c7488-lqd8x from kube-system started at 2019-02-22 20:46:42 +0000 UTC (3 container statuses recorded)
Feb 22 21:39:53.163: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 22 21:39:53.163: INFO: 	Container kubedns ready: true, restart count 0
Feb 22 21:39:53.163: INFO: 	Container sidecar ready: true, restart count 0
Feb 22 21:39:53.163: INFO: kube-api-auth-flm69 from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.163: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:39:53.164: INFO: metrics-server-7fbd549b78-lkpfr from kube-system started at 2019-02-22 20:46:42 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.164: INFO: 	Container metrics-server ready: true, restart count 0
Feb 22 21:39:53.164: INFO: nginx-ingress-controller-pjzpv from ingress-nginx started at 2019-02-22 20:46:56 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.164: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:39:53.165: INFO: cattle-node-agent-458qr from cattle-system started at 2019-02-22 20:47:12 +0000 UTC (1 container statuses recorded)
Feb 22 21:39:53.165: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:39:53.165: INFO: sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-4jsmm from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:39:53.165: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:39:53.165: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node conformance113-1
STEP: verifying the node has the label node conformance113-2
STEP: verifying the node has the label node conformance113-3
Feb 22 21:39:57.599: INFO: Pod cattle-cluster-agent-9b7f6857d-r8pl5 requesting resource cpu=0m on Node conformance113-2
Feb 22 21:39:57.599: INFO: Pod cattle-node-agent-458qr requesting resource cpu=0m on Node conformance113-3
Feb 22 21:39:57.599: INFO: Pod cattle-node-agent-rmztj requesting resource cpu=0m on Node conformance113-1
Feb 22 21:39:57.600: INFO: Pod cattle-node-agent-znhhf requesting resource cpu=0m on Node conformance113-2
Feb 22 21:39:57.600: INFO: Pod kube-api-auth-2kjsw requesting resource cpu=0m on Node conformance113-1
Feb 22 21:39:57.600: INFO: Pod kube-api-auth-flm69 requesting resource cpu=0m on Node conformance113-3
Feb 22 21:39:57.600: INFO: Pod kube-api-auth-jwcnf requesting resource cpu=0m on Node conformance113-2
Feb 22 21:39:57.600: INFO: Pod sonobuoy requesting resource cpu=0m on Node conformance113-1
Feb 22 21:39:57.600: INFO: Pod sonobuoy-e2e-job-9e8ca54401904ae5 requesting resource cpu=0m on Node conformance113-2
Feb 22 21:39:57.600: INFO: Pod sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-4jsmm requesting resource cpu=0m on Node conformance113-3
Feb 22 21:39:57.600: INFO: Pod sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-86xv2 requesting resource cpu=0m on Node conformance113-1
Feb 22 21:39:57.600: INFO: Pod sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-zhbmk requesting resource cpu=0m on Node conformance113-2
Feb 22 21:39:57.600: INFO: Pod default-http-backend-7f8fbb85db-stsz7 requesting resource cpu=10m on Node conformance113-1
Feb 22 21:39:57.600: INFO: Pod nginx-ingress-controller-7789l requesting resource cpu=0m on Node conformance113-2
Feb 22 21:39:57.601: INFO: Pod nginx-ingress-controller-pjzpv requesting resource cpu=0m on Node conformance113-3
Feb 22 21:39:57.601: INFO: Pod nginx-ingress-controller-z44fs requesting resource cpu=0m on Node conformance113-1
Feb 22 21:39:57.601: INFO: Pod canal-hqx48 requesting resource cpu=250m on Node conformance113-1
Feb 22 21:39:57.601: INFO: Pod canal-l9dtf requesting resource cpu=250m on Node conformance113-2
Feb 22 21:39:57.601: INFO: Pod canal-wwmks requesting resource cpu=250m on Node conformance113-3
Feb 22 21:39:57.601: INFO: Pod kube-dns-5fd74c7488-lqd8x requesting resource cpu=260m on Node conformance113-3
Feb 22 21:39:57.601: INFO: Pod kube-dns-autoscaler-c89df977f-lnwxn requesting resource cpu=20m on Node conformance113-3
Feb 22 21:39:57.601: INFO: Pod metrics-server-7fbd549b78-lkpfr requesting resource cpu=0m on Node conformance113-3
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-662d86be-36ea-11e9-b6f8-82efa66823a4.1585cd8052755ff8], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-57224/filler-pod-662d86be-36ea-11e9-b6f8-82efa66823a4 to conformance113-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-662d86be-36ea-11e9-b6f8-82efa66823a4.1585cd808d3e808d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-662d86be-36ea-11e9-b6f8-82efa66823a4.1585cd808f5b4c89], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-662d86be-36ea-11e9-b6f8-82efa66823a4.1585cd809e756864], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6633ec51-36ea-11e9-b6f8-82efa66823a4.1585cd80527b08f5], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-57224/filler-pod-6633ec51-36ea-11e9-b6f8-82efa66823a4 to conformance113-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6633ec51-36ea-11e9-b6f8-82efa66823a4.1585cd80865e9768], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6633ec51-36ea-11e9-b6f8-82efa66823a4.1585cd8088c3ac88], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6633ec51-36ea-11e9-b6f8-82efa66823a4.1585cd80937d9240], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-66367340-36ea-11e9-b6f8-82efa66823a4.1585cd805611cbf7], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-57224/filler-pod-66367340-36ea-11e9-b6f8-82efa66823a4 to conformance113-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-66367340-36ea-11e9-b6f8-82efa66823a4.1585cd80a15ac104], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-66367340-36ea-11e9-b6f8-82efa66823a4.1585cd80c26924ea], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-66367340-36ea-11e9-b6f8-82efa66823a4.1585cd80c834e237], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-66367340-36ea-11e9-b6f8-82efa66823a4.1585cd80e75365ca], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1585cd8144674984], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node conformance113-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node conformance113-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node conformance113-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:40:03.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-57224" for this suite.
Feb 22 21:40:09.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:40:09.537: INFO: namespace: e2e-tests-sched-pred-57224, resource: bindings, ignored listing per whitelist
Feb 22 21:40:09.574: INFO: namespace e2e-tests-sched-pred-57224 deletion completed in 6.29872705s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.612 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:40:09.575: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:40:09.917: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d7ccaad-36ea-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-nx58x" to be "success or failure"
Feb 22 21:40:10.009: INFO: Pod "downwardapi-volume-6d7ccaad-36ea-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 91.638974ms
Feb 22 21:40:12.019: INFO: Pod "downwardapi-volume-6d7ccaad-36ea-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102221218s
Feb 22 21:40:14.033: INFO: Pod "downwardapi-volume-6d7ccaad-36ea-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.115830345s
STEP: Saw pod success
Feb 22 21:40:14.033: INFO: Pod "downwardapi-volume-6d7ccaad-36ea-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:40:14.037: INFO: Trying to get logs from node conformance113-3 pod downwardapi-volume-6d7ccaad-36ea-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 21:40:14.097: INFO: Waiting for pod downwardapi-volume-6d7ccaad-36ea-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:40:14.151: INFO: Pod downwardapi-volume-6d7ccaad-36ea-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:40:14.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nx58x" for this suite.
Feb 22 21:40:20.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:40:20.342: INFO: namespace: e2e-tests-downward-api-nx58x, resource: bindings, ignored listing per whitelist
Feb 22 21:40:20.539: INFO: namespace e2e-tests-downward-api-nx58x deletion completed in 6.371699599s

• [SLOW TEST:10.964 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:40:20.539: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-73e75230-36ea-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 21:40:20.659: INFO: Waiting up to 5m0s for pod "pod-secrets-73e8c61d-36ea-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-secrets-gft2g" to be "success or failure"
Feb 22 21:40:20.682: INFO: Pod "pod-secrets-73e8c61d-36ea-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 22.852109ms
Feb 22 21:40:22.709: INFO: Pod "pod-secrets-73e8c61d-36ea-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049623851s
Feb 22 21:40:24.718: INFO: Pod "pod-secrets-73e8c61d-36ea-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058761525s
STEP: Saw pod success
Feb 22 21:40:24.718: INFO: Pod "pod-secrets-73e8c61d-36ea-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:40:24.730: INFO: Trying to get logs from node conformance113-1 pod pod-secrets-73e8c61d-36ea-11e9-b6f8-82efa66823a4 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 21:40:24.793: INFO: Waiting for pod pod-secrets-73e8c61d-36ea-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:40:24.799: INFO: Pod pod-secrets-73e8c61d-36ea-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:40:24.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gft2g" for this suite.
Feb 22 21:40:32.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:40:32.988: INFO: namespace: e2e-tests-secrets-gft2g, resource: bindings, ignored listing per whitelist
Feb 22 21:40:33.136: INFO: namespace e2e-tests-secrets-gft2g deletion completed in 8.328867353s

• [SLOW TEST:12.597 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:40:33.138: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 22 21:40:33.379: INFO: Number of nodes with available pods: 0
Feb 22 21:40:33.379: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:40:34.398: INFO: Number of nodes with available pods: 0
Feb 22 21:40:34.398: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 21:40:35.406: INFO: Number of nodes with available pods: 1
Feb 22 21:40:35.407: INFO: Node conformance113-2 is running more than one daemon pod
Feb 22 21:40:37.351: INFO: Number of nodes with available pods: 3
Feb 22 21:40:37.352: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 22 21:40:37.502: INFO: Number of nodes with available pods: 2
Feb 22 21:40:37.502: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 21:40:38.522: INFO: Number of nodes with available pods: 2
Feb 22 21:40:38.522: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 21:40:39.518: INFO: Number of nodes with available pods: 2
Feb 22 21:40:39.518: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 21:40:40.522: INFO: Number of nodes with available pods: 2
Feb 22 21:40:40.522: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 21:40:41.518: INFO: Number of nodes with available pods: 3
Feb 22 21:40:41.518: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-jr7zq, will wait for the garbage collector to delete the pods
Feb 22 21:40:41.707: INFO: Deleting DaemonSet.extensions daemon-set took: 30.086742ms
Feb 22 21:40:41.808: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.304631ms
Feb 22 21:41:22.138: INFO: Number of nodes with available pods: 0
Feb 22 21:41:22.138: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 21:41:22.142: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-jr7zq/daemonsets","resourceVersion":"10909"},"items":null}

Feb 22 21:41:22.146: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-jr7zq/pods","resourceVersion":"10909"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:41:22.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-jr7zq" for this suite.
Feb 22 21:41:28.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:41:28.282: INFO: namespace: e2e-tests-daemonsets-jr7zq, resource: bindings, ignored listing per whitelist
Feb 22 21:41:28.410: INFO: namespace e2e-tests-daemonsets-jr7zq deletion completed in 6.241752226s

• [SLOW TEST:55.273 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:41:28.411: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 22 21:41:28.504: INFO: PodSpec: initContainers in spec.initContainers
Feb 22 21:42:17.594: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-9c5c25fd-36ea-11e9-b6f8-82efa66823a4", GenerateName:"", Namespace:"e2e-tests-init-container-c86wk", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-c86wk/pods/pod-init-9c5c25fd-36ea-11e9-b6f8-82efa66823a4", UID:"9c5eb6c9-36ea-11e9-a687-fac827d478c7", ResourceVersion:"11072", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686468488, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"504273135"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.1.39/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kjmkv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001784500), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kjmkv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kjmkv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kjmkv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0023afc98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance113-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002166cc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0023afd20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0023afd40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0023afd48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0023afd4c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686468488, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686468488, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686468488, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686468488, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"159.65.166.126", PodIP:"10.42.1.39", StartTime:(*v1.Time)(0xc000ff6e40), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0003ee8c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0003ee930)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://ce37f7374877fdb7ff59a7608f15b97118335965feeeb5ee11937ad9799ce9af"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000ff6e80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000ff6e60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:42:17.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-c86wk" for this suite.
Feb 22 21:42:43.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:42:43.731: INFO: namespace: e2e-tests-init-container-c86wk, resource: bindings, ignored listing per whitelist
Feb 22 21:42:43.852: INFO: namespace e2e-tests-init-container-c86wk deletion completed in 26.228557678s

• [SLOW TEST:75.441 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:42:43.854: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c9566f0b-36ea-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 21:42:43.991: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c958132b-36ea-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-l9lrq" to be "success or failure"
Feb 22 21:42:44.027: INFO: Pod "pod-projected-secrets-c958132b-36ea-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 35.442659ms
Feb 22 21:42:46.036: INFO: Pod "pod-projected-secrets-c958132b-36ea-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045243773s
STEP: Saw pod success
Feb 22 21:42:46.037: INFO: Pod "pod-projected-secrets-c958132b-36ea-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:42:46.042: INFO: Trying to get logs from node conformance113-3 pod pod-projected-secrets-c958132b-36ea-11e9-b6f8-82efa66823a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 21:42:46.100: INFO: Waiting for pod pod-projected-secrets-c958132b-36ea-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:42:46.117: INFO: Pod pod-projected-secrets-c958132b-36ea-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:42:46.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l9lrq" for this suite.
Feb 22 21:42:52.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:42:52.249: INFO: namespace: e2e-tests-projected-l9lrq, resource: bindings, ignored listing per whitelist
Feb 22 21:42:52.400: INFO: namespace e2e-tests-projected-l9lrq deletion completed in 6.261411569s

• [SLOW TEST:8.546 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:42:52.401: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:42:52.536: INFO: (0) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.649068ms)
Feb 22 21:42:52.547: INFO: (1) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 10.442076ms)
Feb 22 21:42:52.553: INFO: (2) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.75873ms)
Feb 22 21:42:52.563: INFO: (3) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 10.685583ms)
Feb 22 21:42:52.574: INFO: (4) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 11.045494ms)
Feb 22 21:42:52.581: INFO: (5) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.835171ms)
Feb 22 21:42:56.145: INFO: (6) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.563346775s)
Feb 22 21:42:56.301: INFO: (7) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 155.712247ms)
Feb 22 21:42:56.314: INFO: (8) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 13.093354ms)
Feb 22 21:42:56.338: INFO: (9) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 23.688371ms)
Feb 22 21:42:56.344: INFO: (10) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.264127ms)
Feb 22 21:42:56.351: INFO: (11) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.048325ms)
Feb 22 21:42:56.359: INFO: (12) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.820058ms)
Feb 22 21:42:56.366: INFO: (13) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.208116ms)
Feb 22 21:42:56.374: INFO: (14) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.06387ms)
Feb 22 21:42:56.382: INFO: (15) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.192768ms)
Feb 22 21:42:56.390: INFO: (16) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.458886ms)
Feb 22 21:42:58.567: INFO: (17) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.176465865s)
Feb 22 21:42:58.588: INFO: (18) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 19.528571ms)
Feb 22 21:42:58.620: INFO: (19) /api/v1/nodes/conformance113-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 31.470094ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:42:58.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-ndcp7" for this suite.
Feb 22 21:43:04.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:43:04.801: INFO: namespace: e2e-tests-proxy-ndcp7, resource: bindings, ignored listing per whitelist
Feb 22 21:43:05.036: INFO: namespace e2e-tests-proxy-ndcp7 deletion completed in 6.405926024s

• [SLOW TEST:12.635 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:43:05.037: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb 22 21:43:05.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-tzmjd'
Feb 22 21:43:05.711: INFO: stderr: ""
Feb 22 21:43:05.711: INFO: stdout: "pod/pause created\n"
Feb 22 21:43:05.711: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 22 21:43:05.711: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-tzmjd" to be "running and ready"
Feb 22 21:43:05.715: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.517205ms
Feb 22 21:43:07.721: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.010024559s
Feb 22 21:43:07.721: INFO: Pod "pause" satisfied condition "running and ready"
Feb 22 21:43:07.721: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 22 21:43:07.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-tzmjd'
Feb 22 21:43:07.851: INFO: stderr: ""
Feb 22 21:43:07.851: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 22 21:43:07.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pod pause -L testing-label --namespace=e2e-tests-kubectl-tzmjd'
Feb 22 21:43:07.943: INFO: stderr: ""
Feb 22 21:43:07.943: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 22 21:43:07.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 label pods pause testing-label- --namespace=e2e-tests-kubectl-tzmjd'
Feb 22 21:43:08.044: INFO: stderr: ""
Feb 22 21:43:08.045: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 22 21:43:08.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pod pause -L testing-label --namespace=e2e-tests-kubectl-tzmjd'
Feb 22 21:43:08.158: INFO: stderr: ""
Feb 22 21:43:08.158: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb 22 21:43:08.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tzmjd'
Feb 22 21:43:08.293: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 21:43:08.293: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 22 21:43:08.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-tzmjd'
Feb 22 21:43:08.417: INFO: stderr: "No resources found.\n"
Feb 22 21:43:08.417: INFO: stdout: ""
Feb 22 21:43:08.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -l name=pause --namespace=e2e-tests-kubectl-tzmjd -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 21:43:08.514: INFO: stderr: ""
Feb 22 21:43:08.514: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:43:08.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tzmjd" for this suite.
Feb 22 21:43:14.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:43:14.671: INFO: namespace: e2e-tests-kubectl-tzmjd, resource: bindings, ignored listing per whitelist
Feb 22 21:43:14.729: INFO: namespace e2e-tests-kubectl-tzmjd deletion completed in 6.207535009s

• [SLOW TEST:9.692 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:43:14.730: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-54x5p
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-54x5p
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-54x5p
Feb 22 21:43:14.872: INFO: Found 0 stateful pods, waiting for 1
Feb 22 21:43:24.911: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 22 21:43:24.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-54x5p ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 21:43:25.248: INFO: stderr: ""
Feb 22 21:43:25.248: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 21:43:25.248: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 21:43:25.259: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 22 21:43:35.287: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 21:43:35.287: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 21:43:35.398: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999109s
Feb 22 21:43:36.406: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.966897983s
Feb 22 21:43:37.416: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.958123711s
Feb 22 21:43:38.424: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.948747121s
Feb 22 21:43:39.431: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.940407092s
Feb 22 21:43:40.437: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.933418568s
Feb 22 21:43:41.446: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.927682401s
Feb 22 21:43:42.455: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.918738354s
Feb 22 21:43:43.463: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.909552431s
Feb 22 21:43:44.472: INFO: Verifying statefulset ss doesn't scale past 3 for another 901.736093ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-54x5p
Feb 22 21:43:48.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-54x5p ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 21:43:48.718: INFO: stderr: ""
Feb 22 21:43:48.718: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 21:43:48.718: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 21:43:48.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-54x5p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 21:43:50.314: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 22 21:43:50.314: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 21:43:50.314: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 21:43:50.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-54x5p ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 21:43:50.760: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 22 21:43:50.760: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 21:43:50.760: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 21:43:50.767: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:43:50.767: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:43:50.767: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 22 21:43:50.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-54x5p ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 21:43:51.052: INFO: stderr: ""
Feb 22 21:43:51.052: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 21:43:51.052: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 21:43:51.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-54x5p ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 21:43:51.497: INFO: stderr: ""
Feb 22 21:43:51.497: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 21:43:51.497: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 21:43:51.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-54x5p ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 21:43:51.974: INFO: stderr: ""
Feb 22 21:43:51.974: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 21:43:51.974: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 21:43:51.974: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 21:43:51.981: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 22 21:44:02.022: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 21:44:02.022: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 21:44:02.022: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 21:44:02.103: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 21:44:02.103: INFO: ss-0  conformance113-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  }]
Feb 22 21:44:02.103: INFO: ss-1  conformance113-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:02.103: INFO: ss-2  conformance113-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:02.103: INFO: 
Feb 22 21:44:02.103: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 21:44:03.110: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 21:44:03.111: INFO: ss-0  conformance113-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  }]
Feb 22 21:44:03.111: INFO: ss-1  conformance113-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:03.111: INFO: ss-2  conformance113-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:03.112: INFO: 
Feb 22 21:44:03.112: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 21:44:04.118: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 21:44:04.118: INFO: ss-0  conformance113-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  }]
Feb 22 21:44:04.118: INFO: ss-1  conformance113-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:04.118: INFO: ss-2  conformance113-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:04.118: INFO: 
Feb 22 21:44:04.118: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 21:44:05.125: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 21:44:05.126: INFO: ss-0  conformance113-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  }]
Feb 22 21:44:05.126: INFO: ss-1  conformance113-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:05.127: INFO: ss-2  conformance113-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:05.127: INFO: 
Feb 22 21:44:05.127: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 21:44:06.135: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 21:44:06.135: INFO: ss-0  conformance113-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  }]
Feb 22 21:44:06.135: INFO: ss-2  conformance113-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:06.135: INFO: 
Feb 22 21:44:06.136: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 22 21:44:07.145: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 21:44:07.146: INFO: ss-0  conformance113-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  }]
Feb 22 21:44:07.146: INFO: ss-2  conformance113-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:07.146: INFO: 
Feb 22 21:44:07.147: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 22 21:44:08.156: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 21:44:08.156: INFO: ss-0  conformance113-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  }]
Feb 22 21:44:08.156: INFO: ss-2  conformance113-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:08.157: INFO: 
Feb 22 21:44:08.157: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 22 21:44:09.164: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 21:44:09.164: INFO: ss-0  conformance113-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  }]
Feb 22 21:44:09.164: INFO: ss-2  conformance113-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:09.165: INFO: 
Feb 22 21:44:09.165: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 22 21:44:10.173: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 21:44:10.173: INFO: ss-0  conformance113-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  }]
Feb 22 21:44:10.173: INFO: ss-2  conformance113-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:10.173: INFO: 
Feb 22 21:44:10.173: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 22 21:44:11.180: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 21:44:11.180: INFO: ss-0  conformance113-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:14 +0000 UTC  }]
Feb 22 21:44:11.180: INFO: ss-2  conformance113-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:43:35 +0000 UTC  }]
Feb 22 21:44:11.180: INFO: 
Feb 22 21:44:11.180: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-54x5p
Feb 22 21:44:12.426: INFO: Scaling statefulset ss to 0
Feb 22 21:44:12.499: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 22 21:44:12.505: INFO: Deleting all statefulset in ns e2e-tests-statefulset-54x5p
Feb 22 21:44:12.510: INFO: Scaling statefulset ss to 0
Feb 22 21:44:12.526: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 21:44:12.531: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:44:12.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-54x5p" for this suite.
Feb 22 21:44:18.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:44:18.813: INFO: namespace: e2e-tests-statefulset-54x5p, resource: bindings, ignored listing per whitelist
Feb 22 21:44:19.437: INFO: namespace e2e-tests-statefulset-54x5p deletion completed in 6.836381795s

• [SLOW TEST:64.708 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:44:19.438: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-nq52q
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-nq52q
STEP: Deleting pre-stop pod
Feb 22 21:44:35.752: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:44:35.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-nq52q" for this suite.
Feb 22 21:45:13.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:45:14.154: INFO: namespace: e2e-tests-prestop-nq52q, resource: bindings, ignored listing per whitelist
Feb 22 21:45:14.170: INFO: namespace e2e-tests-prestop-nq52q deletion completed in 38.380197968s

• [SLOW TEST:54.732 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:45:14.171: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 22 21:45:14.386: INFO: Waiting up to 5m0s for pod "pod-22fcbcf3-36eb-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-nsxws" to be "success or failure"
Feb 22 21:45:14.399: INFO: Pod "pod-22fcbcf3-36eb-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.064776ms
Feb 22 21:45:16.406: INFO: Pod "pod-22fcbcf3-36eb-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019061381s
STEP: Saw pod success
Feb 22 21:45:16.406: INFO: Pod "pod-22fcbcf3-36eb-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:45:16.418: INFO: Trying to get logs from node conformance113-1 pod pod-22fcbcf3-36eb-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 21:45:16.469: INFO: Waiting for pod pod-22fcbcf3-36eb-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:45:16.472: INFO: Pod pod-22fcbcf3-36eb-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:45:16.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nsxws" for this suite.
Feb 22 21:45:24.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:45:24.648: INFO: namespace: e2e-tests-emptydir-nsxws, resource: bindings, ignored listing per whitelist
Feb 22 21:45:24.810: INFO: namespace e2e-tests-emptydir-nsxws deletion completed in 8.331973588s

• [SLOW TEST:10.640 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:45:24.811: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-mhn7j/configmap-test-294c25c9-36eb-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:45:24.985: INFO: Waiting up to 5m0s for pod "pod-configmaps-294dc544-36eb-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-configmap-mhn7j" to be "success or failure"
Feb 22 21:45:25.003: INFO: Pod "pod-configmaps-294dc544-36eb-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.33574ms
Feb 22 21:45:27.010: INFO: Pod "pod-configmaps-294dc544-36eb-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02557861s
STEP: Saw pod success
Feb 22 21:45:27.010: INFO: Pod "pod-configmaps-294dc544-36eb-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:45:27.022: INFO: Trying to get logs from node conformance113-2 pod pod-configmaps-294dc544-36eb-11e9-b6f8-82efa66823a4 container env-test: <nil>
STEP: delete the pod
Feb 22 21:45:27.112: INFO: Waiting for pod pod-configmaps-294dc544-36eb-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:45:27.116: INFO: Pod pod-configmaps-294dc544-36eb-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:45:27.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mhn7j" for this suite.
Feb 22 21:45:33.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:45:33.531: INFO: namespace: e2e-tests-configmap-mhn7j, resource: bindings, ignored listing per whitelist
Feb 22 21:45:33.601: INFO: namespace e2e-tests-configmap-mhn7j deletion completed in 6.472510695s

• [SLOW TEST:8.790 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:45:33.602: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-2e96b4f0-36eb-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:45:33.870: INFO: Waiting up to 5m0s for pod "pod-configmaps-2e989e90-36eb-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-configmap-r4ftf" to be "success or failure"
Feb 22 21:45:33.896: INFO: Pod "pod-configmaps-2e989e90-36eb-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 25.681171ms
Feb 22 21:45:38.440: INFO: Pod "pod-configmaps-2e989e90-36eb-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.569584421s
Feb 22 21:45:40.448: INFO: Pod "pod-configmaps-2e989e90-36eb-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.57768275s
STEP: Saw pod success
Feb 22 21:45:40.448: INFO: Pod "pod-configmaps-2e989e90-36eb-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:45:40.464: INFO: Trying to get logs from node conformance113-3 pod pod-configmaps-2e989e90-36eb-11e9-b6f8-82efa66823a4 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:45:40.556: INFO: Waiting for pod pod-configmaps-2e989e90-36eb-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:45:40.599: INFO: Pod pod-configmaps-2e989e90-36eb-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:45:40.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r4ftf" for this suite.
Feb 22 21:45:46.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:45:47.501: INFO: namespace: e2e-tests-configmap-r4ftf, resource: bindings, ignored listing per whitelist
Feb 22 21:45:50.801: INFO: namespace e2e-tests-configmap-r4ftf deletion completed in 10.183650068s

• [SLOW TEST:17.199 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:45:50.801: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-tjp2s
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 22 21:45:51.030: INFO: Found 0 stateful pods, waiting for 3
Feb 22 21:46:01.068: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:46:01.069: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:46:01.069: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 21:46:11.039: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:46:11.040: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:46:11.040: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 22 21:46:11.113: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 22 21:46:22.889: INFO: Updating stateful set ss2
Feb 22 21:46:23.012: INFO: Waiting for Pod e2e-tests-statefulset-tjp2s/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 22 21:46:33.310: INFO: Found 2 stateful pods, waiting for 3
Feb 22 21:46:43.335: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:46:43.335: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:46:43.335: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 22 21:46:43.379: INFO: Updating stateful set ss2
Feb 22 21:46:43.393: INFO: Waiting for Pod e2e-tests-statefulset-tjp2s/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 22 21:46:53.447: INFO: Updating stateful set ss2
Feb 22 21:46:53.470: INFO: Waiting for StatefulSet e2e-tests-statefulset-tjp2s/ss2 to complete update
Feb 22 21:46:53.471: INFO: Waiting for Pod e2e-tests-statefulset-tjp2s/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 22 21:47:03.501: INFO: Waiting for StatefulSet e2e-tests-statefulset-tjp2s/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 22 21:47:13.484: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tjp2s
Feb 22 21:47:13.490: INFO: Scaling statefulset ss2 to 0
Feb 22 21:47:33.774: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 21:47:33.803: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:47:33.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tjp2s" for this suite.
Feb 22 21:47:39.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:47:40.008: INFO: namespace: e2e-tests-statefulset-tjp2s, resource: bindings, ignored listing per whitelist
Feb 22 21:47:40.127: INFO: namespace e2e-tests-statefulset-tjp2s deletion completed in 6.276366857s

• [SLOW TEST:109.326 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:47:40.127: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 21:47:40.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-c5jhx'
Feb 22 21:47:40.344: INFO: stderr: ""
Feb 22 21:47:40.344: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb 22 21:47:40.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-c5jhx'
Feb 22 21:47:52.441: INFO: stderr: ""
Feb 22 21:47:52.441: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:47:52.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c5jhx" for this suite.
Feb 22 21:48:00.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:48:00.591: INFO: namespace: e2e-tests-kubectl-c5jhx, resource: bindings, ignored listing per whitelist
Feb 22 21:48:00.736: INFO: namespace e2e-tests-kubectl-c5jhx deletion completed in 8.207477209s

• [SLOW TEST:20.609 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:48:00.737: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 22 21:48:02.887: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-863467e5-36eb-11e9-b6f8-82efa66823a4,GenerateName:,Namespace:e2e-tests-events-qs8dv,SelfLink:/api/v1/namespaces/e2e-tests-events-qs8dv/pods/send-events-863467e5-36eb-11e9-b6f8-82efa66823a4,UID:86378378-36eb-11e9-a687-fac827d478c7,ResourceVersion:12388,Generation:0,CreationTimestamp:2019-02-22 21:48:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 830670345,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.45/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qjm8v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qjm8v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-qjm8v true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000f45490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000f454b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:48:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:48:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:48:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:48:00 +0000 UTC  }],Message:,Reason:,HostIP:159.65.166.126,PodIP:10.42.1.45,StartTime:2019-02-22 21:48:00 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-22 21:48:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://5038dbe378747d5a14dbb2667264e0b69c8d50360265375168302a78f3ce004e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 22 21:48:04.911: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 22 21:48:06.917: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:48:06.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-qs8dv" for this suite.
Feb 22 21:48:44.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:48:44.977: INFO: namespace: e2e-tests-events-qs8dv, resource: bindings, ignored listing per whitelist
Feb 22 21:48:45.153: INFO: namespace e2e-tests-events-qs8dv deletion completed in 38.217445669s

• [SLOW TEST:44.416 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:48:45.153: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 22 21:48:47.814: INFO: Successfully updated pod "pod-update-a0ad71b7-36eb-11e9-b6f8-82efa66823a4"
STEP: verifying the updated pod is in kubernetes
Feb 22 21:48:47.822: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:48:47.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8rxpq" for this suite.
Feb 22 21:49:15.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:49:15.900: INFO: namespace: e2e-tests-pods-8rxpq, resource: bindings, ignored listing per whitelist
Feb 22 21:49:16.054: INFO: namespace e2e-tests-pods-8rxpq deletion completed in 28.225540792s

• [SLOW TEST:30.900 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:49:16.054: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 22 21:49:16.166: INFO: Waiting up to 5m0s for pod "var-expansion-b318d7f9-36eb-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-var-expansion-flw9t" to be "success or failure"
Feb 22 21:49:16.181: INFO: Pod "var-expansion-b318d7f9-36eb-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.512293ms
Feb 22 21:49:18.185: INFO: Pod "var-expansion-b318d7f9-36eb-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019183272s
STEP: Saw pod success
Feb 22 21:49:18.185: INFO: Pod "var-expansion-b318d7f9-36eb-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:49:18.189: INFO: Trying to get logs from node conformance113-3 pod var-expansion-b318d7f9-36eb-11e9-b6f8-82efa66823a4 container dapi-container: <nil>
STEP: delete the pod
Feb 22 21:49:18.238: INFO: Waiting for pod var-expansion-b318d7f9-36eb-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:49:18.272: INFO: Pod var-expansion-b318d7f9-36eb-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:49:18.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-flw9t" for this suite.
Feb 22 21:49:24.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:49:24.478: INFO: namespace: e2e-tests-var-expansion-flw9t, resource: bindings, ignored listing per whitelist
Feb 22 21:49:24.481: INFO: namespace e2e-tests-var-expansion-flw9t deletion completed in 6.196676245s

• [SLOW TEST:8.427 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:49:24.481: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 22 21:49:28.606: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x922k PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:49:28.606: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:49:28.807: INFO: Exec stderr: ""
Feb 22 21:49:28.808: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x922k PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:49:28.808: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:49:29.074: INFO: Exec stderr: ""
Feb 22 21:49:29.075: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x922k PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:49:29.075: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:49:29.371: INFO: Exec stderr: ""
Feb 22 21:49:29.372: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x922k PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:49:29.373: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:49:29.619: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 22 21:49:29.620: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x922k PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:49:29.620: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:49:29.917: INFO: Exec stderr: ""
Feb 22 21:49:29.917: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x922k PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:49:29.918: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:49:30.155: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 22 21:49:30.155: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x922k PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:49:30.156: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:49:30.439: INFO: Exec stderr: ""
Feb 22 21:49:30.439: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x922k PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:49:30.439: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:49:30.745: INFO: Exec stderr: ""
Feb 22 21:49:30.745: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x922k PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:49:30.745: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:49:31.030: INFO: Exec stderr: ""
Feb 22 21:49:31.031: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x922k PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:49:31.032: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:49:31.357: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:49:31.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-x922k" for this suite.
Feb 22 21:50:13.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:50:13.452: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-x922k, resource: bindings, ignored listing per whitelist
Feb 22 21:50:13.558: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-x922k deletion completed in 42.192390177s

• [SLOW TEST:49.077 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:50:13.559: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 21:50:16.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-rppkl'
Feb 22 21:50:17.003: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 22 21:50:17.003: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 22 21:50:19.022: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-gfr9d]
Feb 22 21:50:19.022: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-gfr9d" in namespace "e2e-tests-kubectl-rppkl" to be "running and ready"
Feb 22 21:50:19.027: INFO: Pod "e2e-test-nginx-rc-gfr9d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.882686ms
Feb 22 21:50:21.040: INFO: Pod "e2e-test-nginx-rc-gfr9d": Phase="Running", Reason="", readiness=true. Elapsed: 2.0185253s
Feb 22 21:50:21.040: INFO: Pod "e2e-test-nginx-rc-gfr9d" satisfied condition "running and ready"
Feb 22 21:50:21.040: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-gfr9d]
Feb 22 21:50:21.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rppkl'
Feb 22 21:50:21.161: INFO: stderr: ""
Feb 22 21:50:21.161: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb 22 21:50:21.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rppkl'
Feb 22 21:50:21.249: INFO: stderr: ""
Feb 22 21:50:21.249: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:50:21.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rppkl" for this suite.
Feb 22 21:50:45.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:50:47.403: INFO: namespace: e2e-tests-kubectl-rppkl, resource: bindings, ignored listing per whitelist
Feb 22 21:50:47.512: INFO: namespace e2e-tests-kubectl-rppkl deletion completed in 26.257526094s

• [SLOW TEST:33.953 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:50:47.512: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 22 21:50:47.579: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 21:50:47.586: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 21:50:47.588: INFO: 
Logging pods the kubelet thinks is on node conformance113-1 before test
Feb 22 21:50:47.595: INFO: sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-86xv2 from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:50:47.595: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:50:47.596: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:50:47.596: INFO: default-http-backend-7f8fbb85db-stsz7 from ingress-nginx started at 2019-02-22 20:46:57 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.596: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 22 21:50:47.596: INFO: cattle-node-agent-rmztj from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.596: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:50:47.596: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-22 20:58:03 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.596: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 22 21:50:47.596: INFO: canal-hqx48 from kube-system started at 2019-02-22 20:46:31 +0000 UTC (2 container statuses recorded)
Feb 22 21:50:47.596: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:50:47.596: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:50:47.596: INFO: nginx-ingress-controller-z44fs from ingress-nginx started at 2019-02-22 20:46:56 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.596: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:50:47.596: INFO: kube-api-auth-2kjsw from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.596: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:50:47.596: INFO: 
Logging pods the kubelet thinks is on node conformance113-2 before test
Feb 22 21:50:47.604: INFO: rke-network-plugin-deploy-job-wbhjp from kube-system started at 2019-02-22 20:46:26 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.604: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Feb 22 21:50:47.604: INFO: kube-api-auth-jwcnf from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.604: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:50:47.604: INFO: canal-l9dtf from kube-system started at 2019-02-22 20:46:31 +0000 UTC (2 container statuses recorded)
Feb 22 21:50:47.604: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:50:47.604: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:50:47.605: INFO: rke-kube-dns-addon-deploy-job-67wm7 from kube-system started at 2019-02-22 20:46:31 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.605: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Feb 22 21:50:47.605: INFO: rke-metrics-addon-deploy-job-c95v9 from kube-system started at 2019-02-22 20:46:39 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.605: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Feb 22 21:50:47.605: INFO: rke-ingress-controller-deploy-job-z8lq7 from kube-system started at 2019-02-22 20:46:45 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.605: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Feb 22 21:50:47.605: INFO: cattle-cluster-agent-9b7f6857d-r8pl5 from cattle-system started at 2019-02-22 20:47:12 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.605: INFO: 	Container cluster-register ready: true, restart count 0
Feb 22 21:50:47.605: INFO: sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-zhbmk from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:50:47.605: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:50:47.605: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:50:47.605: INFO: nginx-ingress-controller-7789l from ingress-nginx started at 2019-02-22 20:46:56 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.605: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:50:47.605: INFO: cattle-node-agent-znhhf from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.605: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:50:47.606: INFO: sonobuoy-e2e-job-9e8ca54401904ae5 from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:50:47.606: INFO: 	Container e2e ready: true, restart count 0
Feb 22 21:50:47.606: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:50:47.607: INFO: 
Logging pods the kubelet thinks is on node conformance113-3 before test
Feb 22 21:50:47.617: INFO: canal-wwmks from kube-system started at 2019-02-22 20:46:31 +0000 UTC (2 container statuses recorded)
Feb 22 21:50:47.617: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:50:47.617: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:50:47.617: INFO: kube-dns-autoscaler-c89df977f-lnwxn from kube-system started at 2019-02-22 20:46:42 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.617: INFO: 	Container autoscaler ready: true, restart count 0
Feb 22 21:50:47.617: INFO: kube-dns-5fd74c7488-lqd8x from kube-system started at 2019-02-22 20:46:42 +0000 UTC (3 container statuses recorded)
Feb 22 21:50:47.617: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 22 21:50:47.617: INFO: 	Container kubedns ready: true, restart count 0
Feb 22 21:50:47.617: INFO: 	Container sidecar ready: true, restart count 0
Feb 22 21:50:47.618: INFO: kube-api-auth-flm69 from cattle-system started at 2019-02-22 20:47:13 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.618: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:50:47.618: INFO: metrics-server-7fbd549b78-lkpfr from kube-system started at 2019-02-22 20:46:42 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.618: INFO: 	Container metrics-server ready: true, restart count 0
Feb 22 21:50:47.618: INFO: nginx-ingress-controller-pjzpv from ingress-nginx started at 2019-02-22 20:46:56 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.618: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:50:47.618: INFO: cattle-node-agent-458qr from cattle-system started at 2019-02-22 20:47:12 +0000 UTC (1 container statuses recorded)
Feb 22 21:50:47.618: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:50:47.618: INFO: sonobuoy-systemd-logs-daemon-set-e8e342bff21c458c-4jsmm from heptio-sonobuoy started at 2019-02-22 20:58:07 +0000 UTC (2 container statuses recorded)
Feb 22 21:50:47.618: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:50:47.618: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1585ce17aaaed1dc], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:50:48.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-79bbq" for this suite.
Feb 22 21:50:54.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:50:54.719: INFO: namespace: e2e-tests-sched-pred-79bbq, resource: bindings, ignored listing per whitelist
Feb 22 21:50:54.827: INFO: namespace e2e-tests-sched-pred-79bbq deletion completed in 6.175282955s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.315 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:50:54.828: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4mw2p
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 22 21:50:54.896: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 22 21:51:19.071: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.1.46 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4mw2p PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:51:19.071: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:51:20.281: INFO: Found all expected endpoints: [netserver-0]
Feb 22 21:51:20.287: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.0.43 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4mw2p PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:51:20.287: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:51:21.502: INFO: Found all expected endpoints: [netserver-1]
Feb 22 21:51:21.506: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.2.37 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4mw2p PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:51:21.506: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:51:22.731: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:51:22.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4mw2p" for this suite.
Feb 22 21:51:44.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:51:44.798: INFO: namespace: e2e-tests-pod-network-test-4mw2p, resource: bindings, ignored listing per whitelist
Feb 22 21:51:44.886: INFO: namespace e2e-tests-pod-network-test-4mw2p deletion completed in 22.147465209s

• [SLOW TEST:50.058 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:51:44.886: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-2hmxn/configmap-test-0bce59b2-36ec-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:51:44.995: INFO: Waiting up to 5m0s for pod "pod-configmaps-0bcf3c06-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-configmap-2hmxn" to be "success or failure"
Feb 22 21:51:45.000: INFO: Pod "pod-configmaps-0bcf3c06-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.428365ms
Feb 22 21:51:47.005: INFO: Pod "pod-configmaps-0bcf3c06-36ec-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010511833s
STEP: Saw pod success
Feb 22 21:51:47.005: INFO: Pod "pod-configmaps-0bcf3c06-36ec-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:51:47.010: INFO: Trying to get logs from node conformance113-3 pod pod-configmaps-0bcf3c06-36ec-11e9-b6f8-82efa66823a4 container env-test: <nil>
STEP: delete the pod
Feb 22 21:51:47.065: INFO: Waiting for pod pod-configmaps-0bcf3c06-36ec-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:51:47.091: INFO: Pod pod-configmaps-0bcf3c06-36ec-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:51:47.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2hmxn" for this suite.
Feb 22 21:51:53.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:51:53.229: INFO: namespace: e2e-tests-configmap-2hmxn, resource: bindings, ignored listing per whitelist
Feb 22 21:51:53.259: INFO: namespace e2e-tests-configmap-2hmxn deletion completed in 6.160199187s

• [SLOW TEST:8.373 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:51:53.259: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ks2fb
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 22 21:51:53.327: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 22 21:52:18.646: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.48:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ks2fb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:52:18.646: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:52:18.844: INFO: Found all expected endpoints: [netserver-0]
Feb 22 21:52:18.850: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.0.45:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ks2fb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:52:18.850: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:52:19.098: INFO: Found all expected endpoints: [netserver-1]
Feb 22 21:52:19.105: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.2.38:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ks2fb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:52:19.105: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
Feb 22 21:52:19.359: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:52:19.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ks2fb" for this suite.
Feb 22 21:52:43.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:52:43.442: INFO: namespace: e2e-tests-pod-network-test-ks2fb, resource: bindings, ignored listing per whitelist
Feb 22 21:52:43.521: INFO: namespace e2e-tests-pod-network-test-ks2fb deletion completed in 24.155873553s

• [SLOW TEST:50.262 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:52:43.522: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 22 21:52:46.156: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2ebfcd4a-36ec-11e9-b6f8-82efa66823a4"
Feb 22 21:52:46.156: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2ebfcd4a-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-pods-rxspt" to be "terminated due to deadline exceeded"
Feb 22 21:52:46.159: INFO: Pod "pod-update-activedeadlineseconds-2ebfcd4a-36ec-11e9-b6f8-82efa66823a4": Phase="Running", Reason="", readiness=true. Elapsed: 3.021943ms
Feb 22 21:52:48.168: INFO: Pod "pod-update-activedeadlineseconds-2ebfcd4a-36ec-11e9-b6f8-82efa66823a4": Phase="Running", Reason="", readiness=true. Elapsed: 2.012118028s
Feb 22 21:52:50.186: INFO: Pod "pod-update-activedeadlineseconds-2ebfcd4a-36ec-11e9-b6f8-82efa66823a4": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.030111511s
Feb 22 21:52:50.186: INFO: Pod "pod-update-activedeadlineseconds-2ebfcd4a-36ec-11e9-b6f8-82efa66823a4" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:52:50.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rxspt" for this suite.
Feb 22 21:52:56.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:52:56.291: INFO: namespace: e2e-tests-pods-rxspt, resource: bindings, ignored listing per whitelist
Feb 22 21:52:56.392: INFO: namespace e2e-tests-pods-rxspt deletion completed in 6.199037236s

• [SLOW TEST:12.870 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:52:56.392: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3669ad80-36ec-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:52:56.472: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-366aa819-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-ps489" to be "success or failure"
Feb 22 21:52:56.475: INFO: Pod "pod-projected-configmaps-366aa819-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.452297ms
Feb 22 21:52:58.481: INFO: Pod "pod-projected-configmaps-366aa819-36ec-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00848177s
STEP: Saw pod success
Feb 22 21:52:58.481: INFO: Pod "pod-projected-configmaps-366aa819-36ec-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:52:58.485: INFO: Trying to get logs from node conformance113-1 pod pod-projected-configmaps-366aa819-36ec-11e9-b6f8-82efa66823a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:52:58.514: INFO: Waiting for pod pod-projected-configmaps-366aa819-36ec-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:52:58.520: INFO: Pod pod-projected-configmaps-366aa819-36ec-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:52:58.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ps489" for this suite.
Feb 22 21:53:04.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:53:04.568: INFO: namespace: e2e-tests-projected-ps489, resource: bindings, ignored listing per whitelist
Feb 22 21:53:04.683: INFO: namespace e2e-tests-projected-ps489 deletion completed in 6.157365009s

• [SLOW TEST:8.291 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:53:04.683: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-xhn8g/secret-test-3b5e20b7-36ec-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 21:53:04.788: INFO: Waiting up to 5m0s for pod "pod-configmaps-3b5f2e25-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-secrets-xhn8g" to be "success or failure"
Feb 22 21:53:04.792: INFO: Pod "pod-configmaps-3b5f2e25-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.150689ms
Feb 22 21:53:06.797: INFO: Pod "pod-configmaps-3b5f2e25-36ec-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00913363s
STEP: Saw pod success
Feb 22 21:53:06.797: INFO: Pod "pod-configmaps-3b5f2e25-36ec-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:53:06.801: INFO: Trying to get logs from node conformance113-2 pod pod-configmaps-3b5f2e25-36ec-11e9-b6f8-82efa66823a4 container env-test: <nil>
STEP: delete the pod
Feb 22 21:53:06.859: INFO: Waiting for pod pod-configmaps-3b5f2e25-36ec-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:53:06.863: INFO: Pod pod-configmaps-3b5f2e25-36ec-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:53:06.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xhn8g" for this suite.
Feb 22 21:53:12.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:53:12.959: INFO: namespace: e2e-tests-secrets-xhn8g, resource: bindings, ignored listing per whitelist
Feb 22 21:53:13.030: INFO: namespace e2e-tests-secrets-xhn8g deletion completed in 6.16038556s

• [SLOW TEST:8.347 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:53:13.031: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4056d079-36ec-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 21:53:13.210: INFO: Waiting up to 5m0s for pod "pod-secrets-4064ab80-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-secrets-99nv4" to be "success or failure"
Feb 22 21:53:13.218: INFO: Pod "pod-secrets-4064ab80-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.723663ms
Feb 22 21:53:15.226: INFO: Pod "pod-secrets-4064ab80-36ec-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015611564s
STEP: Saw pod success
Feb 22 21:53:15.226: INFO: Pod "pod-secrets-4064ab80-36ec-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:53:15.231: INFO: Trying to get logs from node conformance113-3 pod pod-secrets-4064ab80-36ec-11e9-b6f8-82efa66823a4 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 21:53:15.271: INFO: Waiting for pod pod-secrets-4064ab80-36ec-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:53:15.314: INFO: Pod pod-secrets-4064ab80-36ec-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:53:15.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-99nv4" for this suite.
Feb 22 21:53:21.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:53:21.457: INFO: namespace: e2e-tests-secrets-99nv4, resource: bindings, ignored listing per whitelist
Feb 22 21:53:21.542: INFO: namespace e2e-tests-secrets-99nv4 deletion completed in 6.213746655s
STEP: Destroying namespace "e2e-tests-secret-namespace-m8xql" for this suite.
Feb 22 21:53:27.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:53:27.624: INFO: namespace: e2e-tests-secret-namespace-m8xql, resource: bindings, ignored listing per whitelist
Feb 22 21:53:27.708: INFO: namespace e2e-tests-secret-namespace-m8xql deletion completed in 6.166309401s

• [SLOW TEST:14.678 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:53:27.709: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-hs28
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 21:53:27.816: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hs28" in namespace "e2e-tests-subpath-jcrgr" to be "success or failure"
Feb 22 21:53:27.824: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Pending", Reason="", readiness=false. Elapsed: 8.266351ms
Feb 22 21:53:29.829: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013152883s
Feb 22 21:53:31.843: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Running", Reason="", readiness=false. Elapsed: 4.027070508s
Feb 22 21:53:33.848: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Running", Reason="", readiness=false. Elapsed: 6.03184103s
Feb 22 21:53:35.854: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Running", Reason="", readiness=false. Elapsed: 8.037477048s
Feb 22 21:53:37.860: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Running", Reason="", readiness=false. Elapsed: 10.04366143s
Feb 22 21:53:39.866: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Running", Reason="", readiness=false. Elapsed: 12.04985818s
Feb 22 21:53:41.881: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Running", Reason="", readiness=false. Elapsed: 14.06534238s
Feb 22 21:53:43.886: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Running", Reason="", readiness=false. Elapsed: 16.070006672s
Feb 22 21:53:45.893: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Running", Reason="", readiness=false. Elapsed: 18.076570701s
Feb 22 21:53:47.899: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Running", Reason="", readiness=false. Elapsed: 20.082701901s
Feb 22 21:53:49.905: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Running", Reason="", readiness=false. Elapsed: 22.089061666s
Feb 22 21:53:51.918: INFO: Pod "pod-subpath-test-configmap-hs28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.102356383s
STEP: Saw pod success
Feb 22 21:53:51.919: INFO: Pod "pod-subpath-test-configmap-hs28" satisfied condition "success or failure"
Feb 22 21:53:51.923: INFO: Trying to get logs from node conformance113-3 pod pod-subpath-test-configmap-hs28 container test-container-subpath-configmap-hs28: <nil>
STEP: delete the pod
Feb 22 21:53:51.984: INFO: Waiting for pod pod-subpath-test-configmap-hs28 to disappear
Feb 22 21:53:51.991: INFO: Pod pod-subpath-test-configmap-hs28 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hs28
Feb 22 21:53:51.991: INFO: Deleting pod "pod-subpath-test-configmap-hs28" in namespace "e2e-tests-subpath-jcrgr"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:53:51.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jcrgr" for this suite.
Feb 22 21:53:58.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:53:58.140: INFO: namespace: e2e-tests-subpath-jcrgr, resource: bindings, ignored listing per whitelist
Feb 22 21:53:58.159: INFO: namespace e2e-tests-subpath-jcrgr deletion completed in 6.1607428s

• [SLOW TEST:30.450 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:53:58.159: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:53:58.253: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b3c3c20-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-kq8ms" to be "success or failure"
Feb 22 21:53:58.266: INFO: Pod "downwardapi-volume-5b3c3c20-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.49781ms
Feb 22 21:54:00.272: INFO: Pod "downwardapi-volume-5b3c3c20-36ec-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018845571s
STEP: Saw pod success
Feb 22 21:54:00.272: INFO: Pod "downwardapi-volume-5b3c3c20-36ec-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:54:00.276: INFO: Trying to get logs from node conformance113-2 pod downwardapi-volume-5b3c3c20-36ec-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 21:54:00.310: INFO: Waiting for pod downwardapi-volume-5b3c3c20-36ec-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:54:00.339: INFO: Pod downwardapi-volume-5b3c3c20-36ec-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:54:00.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kq8ms" for this suite.
Feb 22 21:54:06.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:54:06.441: INFO: namespace: e2e-tests-downward-api-kq8ms, resource: bindings, ignored listing per whitelist
Feb 22 21:54:06.482: INFO: namespace e2e-tests-downward-api-kq8ms deletion completed in 6.138131448s

• [SLOW TEST:8.323 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:54:06.483: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:54:06.573: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 22 21:54:11.580: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 22 21:54:11.580: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 22 21:54:13.598: INFO: Creating deployment "test-rollover-deployment"
Feb 22 21:54:13.613: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 22 21:54:15.631: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 22 21:54:15.646: INFO: Ensure that both replica sets have 1 created replica
Feb 22 21:54:15.660: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 22 21:54:15.673: INFO: Updating deployment test-rollover-deployment
Feb 22 21:54:15.673: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 22 21:54:17.691: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 22 21:54:17.700: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 22 21:54:17.707: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:54:17.707: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469255, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:54:19.718: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:54:19.718: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469257, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:54:21.722: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:54:21.722: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469257, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:54:23.724: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:54:23.724: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469257, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:54:25.720: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:54:25.721: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469257, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:54:27.718: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:54:27.718: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469257, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469253, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:54:29.720: INFO: 
Feb 22 21:54:29.720: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 22 21:54:29.732: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-wmk54,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wmk54/deployments/test-rollover-deployment,UID:646629c4-36ec-11e9-a687-fac827d478c7,ResourceVersion:13783,Generation:2,CreationTimestamp:2019-02-22 21:54:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-22 21:54:13 +0000 UTC 2019-02-22 21:54:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-22 21:54:27 +0000 UTC 2019-02-22 21:54:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 22 21:54:29.737: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-wmk54,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wmk54/replicasets/test-rollover-deployment-6b7f9d6597,UID:65a09650-36ec-11e9-96d9-6a889f07183f,ResourceVersion:13774,Generation:2,CreationTimestamp:2019-02-22 21:54:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 646629c4-36ec-11e9-a687-fac827d478c7 0xc0028728f7 0xc0028728f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 22 21:54:29.738: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 22 21:54:29.738: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-wmk54,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wmk54/replicasets/test-rollover-controller,UID:60341b58-36ec-11e9-a687-fac827d478c7,ResourceVersion:13782,Generation:2,CreationTimestamp:2019-02-22 21:54:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 646629c4-36ec-11e9-a687-fac827d478c7 0xc002872767 0xc002872768}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 21:54:29.738: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-wmk54,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wmk54/replicasets/test-rollover-deployment-6586df867b,UID:6469e76c-36ec-11e9-96d9-6a889f07183f,ResourceVersion:13740,Generation:2,CreationTimestamp:2019-02-22 21:54:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 646629c4-36ec-11e9-a687-fac827d478c7 0xc002872827 0xc002872828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 21:54:29.742: INFO: Pod "test-rollover-deployment-6b7f9d6597-wrcsk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-wrcsk,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-wmk54,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wmk54/pods/test-rollover-deployment-6b7f9d6597-wrcsk,UID:65a7e30b-36ec-11e9-96d9-6a889f07183f,ResourceVersion:13753,Generation:0,CreationTimestamp:2019-02-22 21:54:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.41/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 65a09650-36ec-11e9-96d9-6a889f07183f 0xc002873447 0xc002873448}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-v9vp8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v9vp8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-v9vp8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028734c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028734e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:54:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:54:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:54:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:54:15 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:10.42.2.41,StartTime:2019-02-22 21:54:15 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-22 21:54:16 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://a9dec282b53591e28c089d98580eb7371dd089333c0a984902341d7dc6a8cc58}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:54:29.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-wmk54" for this suite.
Feb 22 21:54:35.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:54:35.933: INFO: namespace: e2e-tests-deployment-wmk54, resource: bindings, ignored listing per whitelist
Feb 22 21:54:35.949: INFO: namespace e2e-tests-deployment-wmk54 deletion completed in 6.161614155s

• [SLOW TEST:29.467 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:54:35.950: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 22 21:54:36.045: INFO: Waiting up to 5m0s for pod "pod-71c32bae-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-g5jcw" to be "success or failure"
Feb 22 21:54:36.058: INFO: Pod "pod-71c32bae-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.833564ms
Feb 22 21:54:38.062: INFO: Pod "pod-71c32bae-36ec-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01622714s
STEP: Saw pod success
Feb 22 21:54:38.062: INFO: Pod "pod-71c32bae-36ec-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:54:38.067: INFO: Trying to get logs from node conformance113-3 pod pod-71c32bae-36ec-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 21:54:38.089: INFO: Waiting for pod pod-71c32bae-36ec-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:54:38.094: INFO: Pod pod-71c32bae-36ec-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:54:38.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-g5jcw" for this suite.
Feb 22 21:54:44.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:54:44.361: INFO: namespace: e2e-tests-emptydir-g5jcw, resource: bindings, ignored listing per whitelist
Feb 22 21:54:44.361: INFO: namespace e2e-tests-emptydir-g5jcw deletion completed in 6.226937734s

• [SLOW TEST:8.411 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:54:44.362: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9zx52
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-9zx52
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-9zx52
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-9zx52
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-9zx52
Feb 22 21:54:48.503: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9zx52, name: ss-0, uid: 78da66fb-36ec-11e9-96d9-6a889f07183f, status phase: Failed. Waiting for statefulset controller to delete.
Feb 22 21:54:48.513: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9zx52, name: ss-0, uid: 78da66fb-36ec-11e9-96d9-6a889f07183f, status phase: Failed. Waiting for statefulset controller to delete.
Feb 22 21:54:48.522: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-9zx52
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-9zx52
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-9zx52 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 22 21:54:52.563: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9zx52
Feb 22 21:54:52.569: INFO: Scaling statefulset ss to 0
Feb 22 21:55:02.599: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 21:55:02.604: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:55:02.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9zx52" for this suite.
Feb 22 21:55:08.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:55:08.753: INFO: namespace: e2e-tests-statefulset-9zx52, resource: bindings, ignored listing per whitelist
Feb 22 21:55:08.809: INFO: namespace e2e-tests-statefulset-9zx52 deletion completed in 6.167496098s

• [SLOW TEST:24.447 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:55:08.809: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 22 21:55:12.965: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:55:37.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-7xzxr" for this suite.
Feb 22 21:55:43.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:55:43.208: INFO: namespace: e2e-tests-namespaces-7xzxr, resource: bindings, ignored listing per whitelist
Feb 22 21:55:43.249: INFO: namespace e2e-tests-namespaces-7xzxr deletion completed in 6.18353567s
STEP: Destroying namespace "e2e-tests-nsdeletetest-nch55" for this suite.
Feb 22 21:55:43.252: INFO: Namespace e2e-tests-nsdeletetest-nch55 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-l2fgl" for this suite.
Feb 22 21:55:51.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:55:51.360: INFO: namespace: e2e-tests-nsdeletetest-l2fgl, resource: bindings, ignored listing per whitelist
Feb 22 21:55:51.440: INFO: namespace e2e-tests-nsdeletetest-l2fgl deletion completed in 8.187749919s

• [SLOW TEST:42.632 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:55:51.442: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:55:54.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-7fdcq" for this suite.
Feb 22 21:56:16.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:56:16.743: INFO: namespace: e2e-tests-replication-controller-7fdcq, resource: bindings, ignored listing per whitelist
Feb 22 21:56:16.766: INFO: namespace e2e-tests-replication-controller-7fdcq deletion completed in 22.183349215s

• [SLOW TEST:25.324 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:56:16.767: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 22 21:56:16.858: INFO: Waiting up to 5m0s for pod "pod-adda8190-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-cd8w2" to be "success or failure"
Feb 22 21:56:16.865: INFO: Pod "pod-adda8190-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.380488ms
Feb 22 21:56:18.878: INFO: Pod "pod-adda8190-36ec-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019471636s
STEP: Saw pod success
Feb 22 21:56:18.878: INFO: Pod "pod-adda8190-36ec-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:56:18.881: INFO: Trying to get logs from node conformance113-1 pod pod-adda8190-36ec-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 21:56:18.911: INFO: Waiting for pod pod-adda8190-36ec-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:56:18.917: INFO: Pod pod-adda8190-36ec-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:56:18.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cd8w2" for this suite.
Feb 22 21:56:24.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:56:24.980: INFO: namespace: e2e-tests-emptydir-cd8w2, resource: bindings, ignored listing per whitelist
Feb 22 21:56:25.090: INFO: namespace e2e-tests-emptydir-cd8w2 deletion completed in 6.1675615s

• [SLOW TEST:8.323 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:56:25.090: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 22 21:56:29.209: INFO: Pod pod-hostip-b2ce396f-36ec-11e9-b6f8-82efa66823a4 has hostIP: 134.209.32.79
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:56:29.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6bmlw" for this suite.
Feb 22 21:56:51.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:56:51.406: INFO: namespace: e2e-tests-pods-6bmlw, resource: bindings, ignored listing per whitelist
Feb 22 21:56:51.424: INFO: namespace e2e-tests-pods-6bmlw deletion completed in 22.207533188s

• [SLOW TEST:26.333 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:56:51.424: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c281bb8f-36ec-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:56:51.524: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c283815d-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-rfbv9" to be "success or failure"
Feb 22 21:56:51.557: INFO: Pod "pod-projected-configmaps-c283815d-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 32.838698ms
Feb 22 21:56:53.563: INFO: Pod "pod-projected-configmaps-c283815d-36ec-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039416218s
STEP: Saw pod success
Feb 22 21:56:53.563: INFO: Pod "pod-projected-configmaps-c283815d-36ec-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:56:53.568: INFO: Trying to get logs from node conformance113-3 pod pod-projected-configmaps-c283815d-36ec-11e9-b6f8-82efa66823a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:56:53.631: INFO: Waiting for pod pod-projected-configmaps-c283815d-36ec-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:56:53.648: INFO: Pod pod-projected-configmaps-c283815d-36ec-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:56:53.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rfbv9" for this suite.
Feb 22 21:56:59.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:56:59.714: INFO: namespace: e2e-tests-projected-rfbv9, resource: bindings, ignored listing per whitelist
Feb 22 21:56:59.843: INFO: namespace e2e-tests-projected-rfbv9 deletion completed in 6.184166193s

• [SLOW TEST:8.419 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:56:59.843: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c7845313-36ec-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 21:56:59.916: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c7854ec9-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-tvzgp" to be "success or failure"
Feb 22 21:56:59.927: INFO: Pod "pod-projected-configmaps-c7854ec9-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.399168ms
Feb 22 21:57:01.947: INFO: Pod "pod-projected-configmaps-c7854ec9-36ec-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031568424s
STEP: Saw pod success
Feb 22 21:57:01.947: INFO: Pod "pod-projected-configmaps-c7854ec9-36ec-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:57:01.952: INFO: Trying to get logs from node conformance113-1 pod pod-projected-configmaps-c7854ec9-36ec-11e9-b6f8-82efa66823a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:57:01.990: INFO: Waiting for pod pod-projected-configmaps-c7854ec9-36ec-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:57:01.993: INFO: Pod pod-projected-configmaps-c7854ec9-36ec-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:57:01.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tvzgp" for this suite.
Feb 22 21:57:08.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:57:08.121: INFO: namespace: e2e-tests-projected-tvzgp, resource: bindings, ignored listing per whitelist
Feb 22 21:57:08.154: INFO: namespace e2e-tests-projected-tvzgp deletion completed in 6.156075106s

• [SLOW TEST:8.311 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:57:08.155: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 22 21:57:08.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:08.714: INFO: stderr: ""
Feb 22 21:57:08.714: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 21:57:08.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:08.893: INFO: stderr: ""
Feb 22 21:57:08.893: INFO: stdout: "update-demo-nautilus-2r9tx update-demo-nautilus-hbnfh "
Feb 22 21:57:08.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-2r9tx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:08.992: INFO: stderr: ""
Feb 22 21:57:08.992: INFO: stdout: ""
Feb 22 21:57:08.992: INFO: update-demo-nautilus-2r9tx is created but not running
Feb 22 21:57:13.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:14.100: INFO: stderr: ""
Feb 22 21:57:14.100: INFO: stdout: "update-demo-nautilus-2r9tx update-demo-nautilus-hbnfh "
Feb 22 21:57:14.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-2r9tx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:14.186: INFO: stderr: ""
Feb 22 21:57:14.186: INFO: stdout: "true"
Feb 22 21:57:14.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-2r9tx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:14.288: INFO: stderr: ""
Feb 22 21:57:14.288: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:57:14.288: INFO: validating pod update-demo-nautilus-2r9tx
Feb 22 21:57:14.293: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:57:14.293: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:57:14.293: INFO: update-demo-nautilus-2r9tx is verified up and running
Feb 22 21:57:14.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-hbnfh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:14.383: INFO: stderr: ""
Feb 22 21:57:14.383: INFO: stdout: "true"
Feb 22 21:57:14.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-nautilus-hbnfh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:14.470: INFO: stderr: ""
Feb 22 21:57:14.470: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:57:14.470: INFO: validating pod update-demo-nautilus-hbnfh
Feb 22 21:57:14.475: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:57:14.475: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:57:14.475: INFO: update-demo-nautilus-hbnfh is verified up and running
STEP: rolling-update to new replication controller
Feb 22 21:57:14.476: INFO: scanned /root for discovery docs: <nil>
Feb 22 21:57:14.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:37.731: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 22 21:57:37.731: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 21:57:37.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:37.839: INFO: stderr: ""
Feb 22 21:57:37.839: INFO: stdout: "update-demo-kitten-7fcfr update-demo-kitten-7tjn8 "
Feb 22 21:57:37.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-kitten-7fcfr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:37.930: INFO: stderr: ""
Feb 22 21:57:37.930: INFO: stdout: "true"
Feb 22 21:57:37.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-kitten-7fcfr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:38.021: INFO: stderr: ""
Feb 22 21:57:38.021: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 22 21:57:38.021: INFO: validating pod update-demo-kitten-7fcfr
Feb 22 21:57:38.029: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 22 21:57:38.029: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 22 21:57:38.029: INFO: update-demo-kitten-7fcfr is verified up and running
Feb 22 21:57:38.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-kitten-7tjn8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:38.121: INFO: stderr: ""
Feb 22 21:57:38.121: INFO: stdout: "true"
Feb 22 21:57:38.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods update-demo-kitten-7tjn8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-46mhc'
Feb 22 21:57:38.209: INFO: stderr: ""
Feb 22 21:57:38.209: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 22 21:57:38.209: INFO: validating pod update-demo-kitten-7tjn8
Feb 22 21:57:38.213: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 22 21:57:38.213: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 22 21:57:38.213: INFO: update-demo-kitten-7tjn8 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:57:38.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-46mhc" for this suite.
Feb 22 21:58:00.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:58:00.649: INFO: namespace: e2e-tests-kubectl-46mhc, resource: bindings, ignored listing per whitelist
Feb 22 21:58:00.673: INFO: namespace e2e-tests-kubectl-46mhc deletion completed in 22.259407285s

• [SLOW TEST:52.518 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:58:00.674: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 22 21:58:03.324: INFO: Successfully updated pod "labelsupdateebca0f49-36ec-11e9-b6f8-82efa66823a4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:58:05.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l498m" for this suite.
Feb 22 21:58:27.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:58:27.810: INFO: namespace: e2e-tests-downward-api-l498m, resource: bindings, ignored listing per whitelist
Feb 22 21:58:27.872: INFO: namespace e2e-tests-downward-api-l498m deletion completed in 22.288944319s

• [SLOW TEST:27.198 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:58:27.872: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:58:27.980: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fbff8f6e-36ec-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-g8cqv" to be "success or failure"
Feb 22 21:58:28.002: INFO: Pod "downwardapi-volume-fbff8f6e-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.735033ms
Feb 22 21:58:30.009: INFO: Pod "downwardapi-volume-fbff8f6e-36ec-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028935861s
Feb 22 21:58:32.015: INFO: Pod "downwardapi-volume-fbff8f6e-36ec-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034608924s
STEP: Saw pod success
Feb 22 21:58:32.015: INFO: Pod "downwardapi-volume-fbff8f6e-36ec-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:58:32.020: INFO: Trying to get logs from node conformance113-1 pod downwardapi-volume-fbff8f6e-36ec-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 21:58:32.047: INFO: Waiting for pod downwardapi-volume-fbff8f6e-36ec-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:58:32.052: INFO: Pod downwardapi-volume-fbff8f6e-36ec-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:58:32.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g8cqv" for this suite.
Feb 22 21:58:38.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:58:38.246: INFO: namespace: e2e-tests-projected-g8cqv, resource: bindings, ignored listing per whitelist
Feb 22 21:58:38.324: INFO: namespace e2e-tests-projected-g8cqv deletion completed in 6.266774174s

• [SLOW TEST:10.452 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:58:38.325: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 22 21:58:38.437: INFO: Waiting up to 5m0s for pod "client-containers-023d864a-36ed-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-containers-6hvkp" to be "success or failure"
Feb 22 21:58:38.444: INFO: Pod "client-containers-023d864a-36ed-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.507691ms
Feb 22 21:58:40.451: INFO: Pod "client-containers-023d864a-36ed-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01418707s
STEP: Saw pod success
Feb 22 21:58:40.451: INFO: Pod "client-containers-023d864a-36ed-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 21:58:40.457: INFO: Trying to get logs from node conformance113-2 pod client-containers-023d864a-36ed-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 21:58:40.515: INFO: Waiting for pod client-containers-023d864a-36ed-11e9-b6f8-82efa66823a4 to disappear
Feb 22 21:58:40.519: INFO: Pod client-containers-023d864a-36ed-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:58:40.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6hvkp" for this suite.
Feb 22 21:58:46.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:58:46.641: INFO: namespace: e2e-tests-containers-6hvkp, resource: bindings, ignored listing per whitelist
Feb 22 21:58:46.721: INFO: namespace e2e-tests-containers-6hvkp deletion completed in 6.196345081s

• [SLOW TEST:8.396 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:58:46.721: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:58:46.818: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:58:49.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-688hd" for this suite.
Feb 22 21:59:33.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:59:33.268: INFO: namespace: e2e-tests-pods-688hd, resource: bindings, ignored listing per whitelist
Feb 22 21:59:33.344: INFO: namespace e2e-tests-pods-688hd deletion completed in 44.218541782s

• [SLOW TEST:46.623 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 21:59:33.345: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 21:59:58.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-jqbmz" for this suite.
Feb 22 22:00:04.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:00:04.917: INFO: namespace: e2e-tests-container-runtime-jqbmz, resource: bindings, ignored listing per whitelist
Feb 22 22:00:05.049: INFO: namespace e2e-tests-container-runtime-jqbmz deletion completed in 6.178114536s

• [SLOW TEST:31.705 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:00:05.050: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-35ea7f92-36ed-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 22:00:05.146: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-35ebeb3c-36ed-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-dxq7f" to be "success or failure"
Feb 22 22:00:05.182: INFO: Pod "pod-projected-configmaps-35ebeb3c-36ed-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 36.26152ms
Feb 22 22:00:07.187: INFO: Pod "pod-projected-configmaps-35ebeb3c-36ed-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040699052s
STEP: Saw pod success
Feb 22 22:00:07.187: INFO: Pod "pod-projected-configmaps-35ebeb3c-36ed-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:00:07.190: INFO: Trying to get logs from node conformance113-1 pod pod-projected-configmaps-35ebeb3c-36ed-11e9-b6f8-82efa66823a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:00:07.228: INFO: Waiting for pod pod-projected-configmaps-35ebeb3c-36ed-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:00:07.234: INFO: Pod pod-projected-configmaps-35ebeb3c-36ed-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:00:07.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dxq7f" for this suite.
Feb 22 22:00:13.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:00:13.441: INFO: namespace: e2e-tests-projected-dxq7f, resource: bindings, ignored listing per whitelist
Feb 22 22:00:13.542: INFO: namespace e2e-tests-projected-dxq7f deletion completed in 6.302443266s

• [SLOW TEST:8.492 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:00:13.542: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:00:13.630: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3afa21de-36ed-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-q26kc" to be "success or failure"
Feb 22 22:00:13.642: INFO: Pod "downwardapi-volume-3afa21de-36ed-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.346258ms
Feb 22 22:00:15.646: INFO: Pod "downwardapi-volume-3afa21de-36ed-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016018688s
STEP: Saw pod success
Feb 22 22:00:15.646: INFO: Pod "downwardapi-volume-3afa21de-36ed-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:00:15.649: INFO: Trying to get logs from node conformance113-2 pod downwardapi-volume-3afa21de-36ed-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 22:00:15.691: INFO: Waiting for pod downwardapi-volume-3afa21de-36ed-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:00:15.715: INFO: Pod downwardapi-volume-3afa21de-36ed-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:00:15.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q26kc" for this suite.
Feb 22 22:00:21.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:00:21.766: INFO: namespace: e2e-tests-projected-q26kc, resource: bindings, ignored listing per whitelist
Feb 22 22:00:21.925: INFO: namespace e2e-tests-projected-q26kc deletion completed in 6.206048306s

• [SLOW TEST:8.383 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:00:21.927: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:00:22.060: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 22 22:00:22.212: INFO: Number of nodes with available pods: 0
Feb 22 22:00:22.212: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 22:00:23.231: INFO: Number of nodes with available pods: 0
Feb 22 22:00:23.231: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 22:00:24.234: INFO: Number of nodes with available pods: 1
Feb 22 22:00:24.235: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 22:00:25.225: INFO: Number of nodes with available pods: 3
Feb 22 22:00:25.225: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 22 22:00:25.263: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:25.263: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:25.263: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:26.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:26.285: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:26.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:27.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:27.284: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:27.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:28.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:28.286: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:28.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:29.287: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:29.287: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:29.287: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:30.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:30.286: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:30.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:31.286: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:31.286: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:31.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:32.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:32.285: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:32.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:33.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:33.284: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:33.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:34.292: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:34.292: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:34.293: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:35.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:35.286: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:35.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:36.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:36.285: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:36.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:37.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:37.286: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:37.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:38.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:38.285: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:38.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:39.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:39.286: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:39.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:40.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:40.284: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:40.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:41.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:41.284: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:41.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:42.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:42.285: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:42.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:43.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:43.286: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:43.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:44.621: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:44.622: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:44.622: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:45.389: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:45.389: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:45.389: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:47.143: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:47.143: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:47.143: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:47.371: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:47.372: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:47.372: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:48.345: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:48.345: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:48.345: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:49.282: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:49.282: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:49.282: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:50.282: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:50.282: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:50.282: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:51.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:51.285: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:51.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:52.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:52.284: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:52.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:53.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:53.285: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:53.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:54.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:54.284: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:54.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:55.295: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:55.295: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:55.295: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:56.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:56.285: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:56.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:57.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:57.285: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:57.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:58.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:58.285: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:58.285: INFO: Pod daemon-set-jljkr is not available
Feb 22 22:00:58.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:59.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:59.286: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:00:59.286: INFO: Pod daemon-set-jljkr is not available
Feb 22 22:00:59.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:00.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:00.286: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:00.286: INFO: Pod daemon-set-jljkr is not available
Feb 22 22:01:00.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:01.288: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:01.288: INFO: Wrong image for pod: daemon-set-jljkr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:01.288: INFO: Pod daemon-set-jljkr is not available
Feb 22 22:01:01.288: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:02.285: INFO: Pod daemon-set-dkrtp is not available
Feb 22 22:01:02.286: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:02.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:03.285: INFO: Pod daemon-set-dkrtp is not available
Feb 22 22:01:03.286: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:03.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:04.284: INFO: Pod daemon-set-dkrtp is not available
Feb 22 22:01:04.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:04.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:05.283: INFO: Pod daemon-set-dkrtp is not available
Feb 22 22:01:05.283: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:05.283: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:06.292: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:06.292: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:07.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:07.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:08.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:08.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:09.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:09.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:10.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:10.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:13.955: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:13.955: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:14.286: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:14.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:15.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:15.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:16.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:16.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:17.295: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:17.295: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:18.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:18.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:19.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:19.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:20.286: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:20.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:21.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:21.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:22.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:22.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:23.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:23.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:24.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:24.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:25.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:25.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:26.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:26.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:30.292: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:30.292: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:31.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:31.286: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:32.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:32.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:33.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:33.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:34.285: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:34.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:35.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:35.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:36.284: INFO: Wrong image for pod: daemon-set-hzz4j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:36.285: INFO: Pod daemon-set-hzz4j is not available
Feb 22 22:01:36.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:37.282: INFO: Pod daemon-set-kr8mg is not available
Feb 22 22:01:37.282: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:38.284: INFO: Pod daemon-set-kr8mg is not available
Feb 22 22:01:38.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:39.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:40.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:41.293: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:42.282: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:43.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:44.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:45.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:46.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:47.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:48.465: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:49.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:50.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:51.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:52.293: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:53.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:56.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:57.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:58.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:01:59.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:00.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:01.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:02.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:03.292: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:04.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:05.283: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:06.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:07.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:08.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:09.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:10.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:10.284: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:11.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:11.285: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:12.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:12.285: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:13.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:13.285: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:14.298: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:14.298: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:15.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:15.285: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:16.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:16.286: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:17.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:17.285: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:18.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:18.286: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:19.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:19.285: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:20.284: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:20.285: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:22.255: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:22.255: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:22.285: INFO: Wrong image for pod: daemon-set-wjnj6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 22:02:22.285: INFO: Pod daemon-set-wjnj6 is not available
Feb 22 22:02:23.289: INFO: Pod daemon-set-wkz7n is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 22 22:02:23.347: INFO: Number of nodes with available pods: 2
Feb 22 22:02:23.347: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:02:24.367: INFO: Number of nodes with available pods: 3
Feb 22 22:02:24.368: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-svbhw, will wait for the garbage collector to delete the pods
Feb 22 22:02:24.459: INFO: Deleting DaemonSet.extensions daemon-set took: 18.421ms
Feb 22 22:02:24.560: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.411727ms
Feb 22 22:02:32.064: INFO: Number of nodes with available pods: 0
Feb 22 22:02:32.064: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 22:02:32.068: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-svbhw/daemonsets","resourceVersion":"15652"},"items":null}

Feb 22 22:02:32.071: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-svbhw/pods","resourceVersion":"15652"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:02:32.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-svbhw" for this suite.
Feb 22 22:02:38.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:02:38.154: INFO: namespace: e2e-tests-daemonsets-svbhw, resource: bindings, ignored listing per whitelist
Feb 22 22:02:38.282: INFO: namespace e2e-tests-daemonsets-svbhw deletion completed in 6.187743567s

• [SLOW TEST:136.355 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:02:38.282: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:02:40.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-wcrdd" for this suite.
Feb 22 22:03:24.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:03:25.845: INFO: namespace: e2e-tests-kubelet-test-wcrdd, resource: bindings, ignored listing per whitelist
Feb 22 22:03:25.905: INFO: namespace e2e-tests-kubelet-test-wcrdd deletion completed in 45.495231083s

• [SLOW TEST:47.623 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:03:25.906: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 22 22:03:26.381: INFO: Pod name wrapped-volume-race-addda075-36ed-11e9-b6f8-82efa66823a4: Found 0 pods out of 5
Feb 22 22:03:31.389: INFO: Pod name wrapped-volume-race-addda075-36ed-11e9-b6f8-82efa66823a4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-addda075-36ed-11e9-b6f8-82efa66823a4 in namespace e2e-tests-emptydir-wrapper-hnj85, will wait for the garbage collector to delete the pods
Feb 22 22:03:45.493: INFO: Deleting ReplicationController wrapped-volume-race-addda075-36ed-11e9-b6f8-82efa66823a4 took: 21.917535ms
Feb 22 22:03:46.494: INFO: Terminating ReplicationController wrapped-volume-race-addda075-36ed-11e9-b6f8-82efa66823a4 pods took: 1.000859923s
STEP: Creating RC which spawns configmap-volume pods
Feb 22 22:04:33.439: INFO: Pod name wrapped-volume-race-d5d19fa1-36ed-11e9-b6f8-82efa66823a4: Found 0 pods out of 5
Feb 22 22:04:38.448: INFO: Pod name wrapped-volume-race-d5d19fa1-36ed-11e9-b6f8-82efa66823a4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d5d19fa1-36ed-11e9-b6f8-82efa66823a4 in namespace e2e-tests-emptydir-wrapper-hnj85, will wait for the garbage collector to delete the pods
Feb 22 22:04:56.566: INFO: Deleting ReplicationController wrapped-volume-race-d5d19fa1-36ed-11e9-b6f8-82efa66823a4 took: 26.072112ms
Feb 22 22:04:56.767: INFO: Terminating ReplicationController wrapped-volume-race-d5d19fa1-36ed-11e9-b6f8-82efa66823a4 pods took: 200.579682ms
STEP: Creating RC which spawns configmap-volume pods
Feb 22 22:05:47.169: INFO: Pod name wrapped-volume-race-015fa57b-36ee-11e9-b6f8-82efa66823a4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-015fa57b-36ee-11e9-b6f8-82efa66823a4 in namespace e2e-tests-emptydir-wrapper-hnj85, will wait for the garbage collector to delete the pods
Feb 22 22:06:07.393: INFO: Deleting ReplicationController wrapped-volume-race-015fa57b-36ee-11e9-b6f8-82efa66823a4 took: 16.399702ms
Feb 22 22:06:07.494: INFO: Terminating ReplicationController wrapped-volume-race-015fa57b-36ee-11e9-b6f8-82efa66823a4 pods took: 100.387572ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:06:48.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-hnj85" for this suite.
Feb 22 22:06:56.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:06:56.516: INFO: namespace: e2e-tests-emptydir-wrapper-hnj85, resource: bindings, ignored listing per whitelist
Feb 22 22:06:56.564: INFO: namespace e2e-tests-emptydir-wrapper-hnj85 deletion completed in 8.177019162s

• [SLOW TEST:210.658 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:06:56.565: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 22 22:06:56.711: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-xxmdp,SelfLink:/api/v1/namespaces/e2e-tests-watch-xxmdp/configmaps/e2e-watch-test-resource-version,UID:2b3608c1-36ee-11e9-a687-fac827d478c7,ResourceVersion:17040,Generation:0,CreationTimestamp:2019-02-22 22:06:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 22 22:06:56.711: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-xxmdp,SelfLink:/api/v1/namespaces/e2e-tests-watch-xxmdp/configmaps/e2e-watch-test-resource-version,UID:2b3608c1-36ee-11e9-a687-fac827d478c7,ResourceVersion:17042,Generation:0,CreationTimestamp:2019-02-22 22:06:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:06:56.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xxmdp" for this suite.
Feb 22 22:07:02.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:07:02.865: INFO: namespace: e2e-tests-watch-xxmdp, resource: bindings, ignored listing per whitelist
Feb 22 22:07:02.877: INFO: namespace e2e-tests-watch-xxmdp deletion completed in 6.161667977s

• [SLOW TEST:6.313 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:07:02.878: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-wp9x8
Feb 22 22:07:08.988: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-wp9x8
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 22:07:08.995: INFO: Initial restart count of pod liveness-exec is 0
Feb 22 22:07:54.293: INFO: Restart count of pod e2e-tests-container-probe-wp9x8/liveness-exec is now 1 (45.298123237s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:07:54.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wp9x8" for this suite.
Feb 22 22:08:00.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:08:00.464: INFO: namespace: e2e-tests-container-probe-wp9x8, resource: bindings, ignored listing per whitelist
Feb 22 22:08:00.476: INFO: namespace e2e-tests-container-probe-wp9x8 deletion completed in 6.158668421s

• [SLOW TEST:57.598 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:08:00.477: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-84bwk
Feb 22 22:08:02.581: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-84bwk
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 22:08:02.586: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:12:03.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-84bwk" for this suite.
Feb 22 22:12:09.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:12:09.357: INFO: namespace: e2e-tests-container-probe-84bwk, resource: bindings, ignored listing per whitelist
Feb 22 22:12:09.361: INFO: namespace e2e-tests-container-probe-84bwk deletion completed in 6.19945097s

• [SLOW TEST:248.884 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:12:09.362: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 22 22:12:10.073: INFO: created pod pod-service-account-defaultsa
Feb 22 22:12:10.073: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 22 22:12:10.084: INFO: created pod pod-service-account-mountsa
Feb 22 22:12:10.084: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 22 22:12:10.102: INFO: created pod pod-service-account-nomountsa
Feb 22 22:12:10.102: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 22 22:12:10.109: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 22 22:12:10.109: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 22 22:12:10.112: INFO: created pod pod-service-account-mountsa-mountspec
Feb 22 22:12:10.112: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 22 22:12:10.118: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 22 22:12:10.118: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 22 22:12:10.123: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 22 22:12:10.123: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 22 22:12:10.152: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 22 22:12:10.152: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 22 22:12:10.184: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 22 22:12:10.184: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:12:10.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-rnvqc" for this suite.
Feb 22 22:12:34.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:12:34.461: INFO: namespace: e2e-tests-svcaccounts-rnvqc, resource: bindings, ignored listing per whitelist
Feb 22 22:12:34.575: INFO: namespace e2e-tests-svcaccounts-rnvqc deletion completed in 24.329045298s

• [SLOW TEST:25.213 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:12:34.575: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:12:34.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-mttz9" for this suite.
Feb 22 22:13:00.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:13:00.857: INFO: namespace: e2e-tests-kubelet-test-mttz9, resource: bindings, ignored listing per whitelist
Feb 22 22:13:00.891: INFO: namespace e2e-tests-kubelet-test-mttz9 deletion completed in 26.173177057s

• [SLOW TEST:26.316 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:13:00.891: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-srfh
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 22:13:01.003: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-srfh" in namespace "e2e-tests-subpath-zclpz" to be "success or failure"
Feb 22 22:13:01.018: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Pending", Reason="", readiness=false. Elapsed: 15.062066ms
Feb 22 22:13:03.027: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024145932s
Feb 22 22:13:05.033: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Running", Reason="", readiness=false. Elapsed: 4.029414927s
Feb 22 22:13:07.038: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Running", Reason="", readiness=false. Elapsed: 6.034832066s
Feb 22 22:13:09.051: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Running", Reason="", readiness=false. Elapsed: 8.048006518s
Feb 22 22:13:11.080: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Running", Reason="", readiness=false. Elapsed: 10.076617804s
Feb 22 22:13:13.086: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Running", Reason="", readiness=false. Elapsed: 12.083213585s
Feb 22 22:13:15.094: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Running", Reason="", readiness=false. Elapsed: 14.090968762s
Feb 22 22:13:17.101: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Running", Reason="", readiness=false. Elapsed: 16.097311535s
Feb 22 22:13:19.108: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Running", Reason="", readiness=false. Elapsed: 18.104336001s
Feb 22 22:13:21.123: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Running", Reason="", readiness=false. Elapsed: 20.120199014s
Feb 22 22:13:23.130: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Running", Reason="", readiness=false. Elapsed: 22.127114811s
Feb 22 22:13:25.137: INFO: Pod "pod-subpath-test-projected-srfh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.13368719s
STEP: Saw pod success
Feb 22 22:13:25.137: INFO: Pod "pod-subpath-test-projected-srfh" satisfied condition "success or failure"
Feb 22 22:13:25.142: INFO: Trying to get logs from node conformance113-1 pod pod-subpath-test-projected-srfh container test-container-subpath-projected-srfh: <nil>
STEP: delete the pod
Feb 22 22:13:25.173: INFO: Waiting for pod pod-subpath-test-projected-srfh to disappear
Feb 22 22:13:25.177: INFO: Pod pod-subpath-test-projected-srfh no longer exists
STEP: Deleting pod pod-subpath-test-projected-srfh
Feb 22 22:13:25.177: INFO: Deleting pod "pod-subpath-test-projected-srfh" in namespace "e2e-tests-subpath-zclpz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:13:25.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-zclpz" for this suite.
Feb 22 22:13:31.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:13:31.332: INFO: namespace: e2e-tests-subpath-zclpz, resource: bindings, ignored listing per whitelist
Feb 22 22:13:31.382: INFO: namespace e2e-tests-subpath-zclpz deletion completed in 6.196783336s

• [SLOW TEST:30.490 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:13:31.382: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-168921c6-36ef-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 22:13:31.495: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-168abc33-36ef-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-74mkj" to be "success or failure"
Feb 22 22:13:31.506: INFO: Pod "pod-projected-secrets-168abc33-36ef-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.658772ms
Feb 22 22:13:33.512: INFO: Pod "pod-projected-secrets-168abc33-36ef-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016772131s
Feb 22 22:13:35.517: INFO: Pod "pod-projected-secrets-168abc33-36ef-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022271166s
STEP: Saw pod success
Feb 22 22:13:35.517: INFO: Pod "pod-projected-secrets-168abc33-36ef-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:13:35.522: INFO: Trying to get logs from node conformance113-2 pod pod-projected-secrets-168abc33-36ef-11e9-b6f8-82efa66823a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:13:35.576: INFO: Waiting for pod pod-projected-secrets-168abc33-36ef-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:13:35.579: INFO: Pod pod-projected-secrets-168abc33-36ef-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:13:35.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-74mkj" for this suite.
Feb 22 22:13:41.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:13:41.721: INFO: namespace: e2e-tests-projected-74mkj, resource: bindings, ignored listing per whitelist
Feb 22 22:13:41.751: INFO: namespace e2e-tests-projected-74mkj deletion completed in 6.167798847s

• [SLOW TEST:10.369 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:13:41.752: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1cb68da6-36ef-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 22:13:41.849: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1cb7fb49-36ef-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-z678b" to be "success or failure"
Feb 22 22:13:41.864: INFO: Pod "pod-projected-secrets-1cb7fb49-36ef-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.883618ms
Feb 22 22:13:43.871: INFO: Pod "pod-projected-secrets-1cb7fb49-36ef-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021418513s
STEP: Saw pod success
Feb 22 22:13:43.871: INFO: Pod "pod-projected-secrets-1cb7fb49-36ef-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:13:43.875: INFO: Trying to get logs from node conformance113-3 pod pod-projected-secrets-1cb7fb49-36ef-11e9-b6f8-82efa66823a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:13:43.919: INFO: Waiting for pod pod-projected-secrets-1cb7fb49-36ef-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:13:43.939: INFO: Pod pod-projected-secrets-1cb7fb49-36ef-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:13:43.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z678b" for this suite.
Feb 22 22:13:49.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:13:50.111: INFO: namespace: e2e-tests-projected-z678b, resource: bindings, ignored listing per whitelist
Feb 22 22:13:50.127: INFO: namespace e2e-tests-projected-z678b deletion completed in 6.175390196s

• [SLOW TEST:8.376 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:13:50.128: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-pgdmx
Feb 22 22:13:52.252: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-pgdmx
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 22:13:52.254: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:17:53.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pgdmx" for this suite.
Feb 22 22:17:59.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:17:59.615: INFO: namespace: e2e-tests-container-probe-pgdmx, resource: bindings, ignored listing per whitelist
Feb 22 22:17:59.730: INFO: namespace e2e-tests-container-probe-pgdmx deletion completed in 6.148928549s

• [SLOW TEST:249.602 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:17:59.730: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-b67ae79f-36ef-11e9-b6f8-82efa66823a4
STEP: Creating secret with name s-test-opt-upd-b67ae7d1-36ef-11e9-b6f8-82efa66823a4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b67ae79f-36ef-11e9-b6f8-82efa66823a4
STEP: Updating secret s-test-opt-upd-b67ae7d1-36ef-11e9-b6f8-82efa66823a4
STEP: Creating secret with name s-test-opt-create-b67ae7eb-36ef-11e9-b6f8-82efa66823a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:19:28.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j94lq" for this suite.
Feb 22 22:19:51.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:19:51.034: INFO: namespace: e2e-tests-projected-j94lq, resource: bindings, ignored listing per whitelist
Feb 22 22:19:51.220: INFO: namespace e2e-tests-projected-j94lq deletion completed in 22.232677213s

• [SLOW TEST:111.490 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:19:51.221: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 22 22:19:51.358: INFO: Waiting up to 5m0s for pod "pod-f8f07878-36ef-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-5fwxx" to be "success or failure"
Feb 22 22:19:51.380: INFO: Pod "pod-f8f07878-36ef-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 22.193952ms
Feb 22 22:19:53.388: INFO: Pod "pod-f8f07878-36ef-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030436327s
Feb 22 22:19:55.393: INFO: Pod "pod-f8f07878-36ef-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035207864s
STEP: Saw pod success
Feb 22 22:19:55.393: INFO: Pod "pod-f8f07878-36ef-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:19:55.397: INFO: Trying to get logs from node conformance113-3 pod pod-f8f07878-36ef-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 22:19:55.444: INFO: Waiting for pod pod-f8f07878-36ef-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:19:55.470: INFO: Pod pod-f8f07878-36ef-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:19:55.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5fwxx" for this suite.
Feb 22 22:20:01.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:20:02.154: INFO: namespace: e2e-tests-emptydir-5fwxx, resource: bindings, ignored listing per whitelist
Feb 22 22:20:02.174: INFO: namespace e2e-tests-emptydir-5fwxx deletion completed in 6.694176832s

• [SLOW TEST:10.954 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:20:02.175: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ff7fa5e7-36ef-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 22:20:02.375: INFO: Waiting up to 5m0s for pod "pod-secrets-ff859a80-36ef-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-secrets-hx97t" to be "success or failure"
Feb 22 22:20:02.396: INFO: Pod "pod-secrets-ff859a80-36ef-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.282005ms
Feb 22 22:20:04.402: INFO: Pod "pod-secrets-ff859a80-36ef-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027089487s
Feb 22 22:20:06.408: INFO: Pod "pod-secrets-ff859a80-36ef-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032810152s
STEP: Saw pod success
Feb 22 22:20:06.408: INFO: Pod "pod-secrets-ff859a80-36ef-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:20:06.411: INFO: Trying to get logs from node conformance113-1 pod pod-secrets-ff859a80-36ef-11e9-b6f8-82efa66823a4 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:20:06.439: INFO: Waiting for pod pod-secrets-ff859a80-36ef-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:20:06.445: INFO: Pod pod-secrets-ff859a80-36ef-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:20:06.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hx97t" for this suite.
Feb 22 22:20:12.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:20:12.537: INFO: namespace: e2e-tests-secrets-hx97t, resource: bindings, ignored listing per whitelist
Feb 22 22:20:12.678: INFO: namespace e2e-tests-secrets-hx97t deletion completed in 6.226900362s

• [SLOW TEST:10.503 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:20:12.679: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-05ba76ec-36f0-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 22:20:12.801: INFO: Waiting up to 5m0s for pod "pod-secrets-05be3ef1-36f0-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-secrets-shbmt" to be "success or failure"
Feb 22 22:20:12.810: INFO: Pod "pod-secrets-05be3ef1-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.102493ms
Feb 22 22:20:14.816: INFO: Pod "pod-secrets-05be3ef1-36f0-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01511257s
STEP: Saw pod success
Feb 22 22:20:14.816: INFO: Pod "pod-secrets-05be3ef1-36f0-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:20:14.822: INFO: Trying to get logs from node conformance113-2 pod pod-secrets-05be3ef1-36f0-11e9-b6f8-82efa66823a4 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:20:14.904: INFO: Waiting for pod pod-secrets-05be3ef1-36f0-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:20:14.911: INFO: Pod pod-secrets-05be3ef1-36f0-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:20:14.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-shbmt" for this suite.
Feb 22 22:20:20.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:20:20.977: INFO: namespace: e2e-tests-secrets-shbmt, resource: bindings, ignored listing per whitelist
Feb 22 22:20:21.126: INFO: namespace e2e-tests-secrets-shbmt deletion completed in 6.208886717s

• [SLOW TEST:8.448 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:20:21.126: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 22 22:20:21.282: INFO: Waiting up to 5m0s for pod "pod-0ac6fcac-36f0-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-vl65p" to be "success or failure"
Feb 22 22:20:21.306: INFO: Pod "pod-0ac6fcac-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 23.622088ms
Feb 22 22:20:23.311: INFO: Pod "pod-0ac6fcac-36f0-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028744448s
STEP: Saw pod success
Feb 22 22:20:23.311: INFO: Pod "pod-0ac6fcac-36f0-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:20:23.320: INFO: Trying to get logs from node conformance113-3 pod pod-0ac6fcac-36f0-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 22:20:23.458: INFO: Waiting for pod pod-0ac6fcac-36f0-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:20:23.477: INFO: Pod pod-0ac6fcac-36f0-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:20:23.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vl65p" for this suite.
Feb 22 22:20:29.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:20:29.578: INFO: namespace: e2e-tests-emptydir-vl65p, resource: bindings, ignored listing per whitelist
Feb 22 22:20:29.708: INFO: namespace e2e-tests-emptydir-vl65p deletion completed in 6.215160282s

• [SLOW TEST:8.582 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:20:29.710: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 22 22:20:29.860: INFO: Waiting up to 5m0s for pod "pod-0fe80cc7-36f0-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-twjdf" to be "success or failure"
Feb 22 22:20:29.866: INFO: Pod "pod-0fe80cc7-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.466602ms
Feb 22 22:20:31.886: INFO: Pod "pod-0fe80cc7-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026633673s
Feb 22 22:20:33.893: INFO: Pod "pod-0fe80cc7-36f0-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033633025s
STEP: Saw pod success
Feb 22 22:20:33.893: INFO: Pod "pod-0fe80cc7-36f0-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:20:33.898: INFO: Trying to get logs from node conformance113-1 pod pod-0fe80cc7-36f0-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 22:20:33.928: INFO: Waiting for pod pod-0fe80cc7-36f0-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:20:33.934: INFO: Pod pod-0fe80cc7-36f0-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:20:33.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-twjdf" for this suite.
Feb 22 22:20:39.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:20:40.098: INFO: namespace: e2e-tests-emptydir-twjdf, resource: bindings, ignored listing per whitelist
Feb 22 22:20:40.150: INFO: namespace e2e-tests-emptydir-twjdf deletion completed in 6.211128946s

• [SLOW TEST:10.440 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:20:40.151: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-x8bs
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 22:20:40.271: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-x8bs" in namespace "e2e-tests-subpath-d6lcs" to be "success or failure"
Feb 22 22:20:40.286: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Pending", Reason="", readiness=false. Elapsed: 13.9282ms
Feb 22 22:20:42.300: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028107903s
Feb 22 22:20:44.397: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Running", Reason="", readiness=false. Elapsed: 4.125796918s
Feb 22 22:20:46.493: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Running", Reason="", readiness=false. Elapsed: 6.221487776s
Feb 22 22:20:48.598: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Running", Reason="", readiness=false. Elapsed: 8.326589353s
Feb 22 22:20:50.603: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Running", Reason="", readiness=false. Elapsed: 10.331220697s
Feb 22 22:20:52.618: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Running", Reason="", readiness=false. Elapsed: 12.346810349s
Feb 22 22:20:54.626: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Running", Reason="", readiness=false. Elapsed: 14.354504094s
Feb 22 22:20:56.634: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Running", Reason="", readiness=false. Elapsed: 16.362345256s
Feb 22 22:20:58.642: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Running", Reason="", readiness=false. Elapsed: 18.370082723s
Feb 22 22:21:00.648: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Running", Reason="", readiness=false. Elapsed: 20.376763395s
Feb 22 22:21:02.663: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Running", Reason="", readiness=false. Elapsed: 22.391171985s
Feb 22 22:21:04.668: INFO: Pod "pod-subpath-test-configmap-x8bs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.39605066s
STEP: Saw pod success
Feb 22 22:21:04.668: INFO: Pod "pod-subpath-test-configmap-x8bs" satisfied condition "success or failure"
Feb 22 22:21:04.675: INFO: Trying to get logs from node conformance113-1 pod pod-subpath-test-configmap-x8bs container test-container-subpath-configmap-x8bs: <nil>
STEP: delete the pod
Feb 22 22:21:04.709: INFO: Waiting for pod pod-subpath-test-configmap-x8bs to disappear
Feb 22 22:21:04.714: INFO: Pod pod-subpath-test-configmap-x8bs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-x8bs
Feb 22 22:21:04.714: INFO: Deleting pod "pod-subpath-test-configmap-x8bs" in namespace "e2e-tests-subpath-d6lcs"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:21:04.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-d6lcs" for this suite.
Feb 22 22:21:10.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:21:10.803: INFO: namespace: e2e-tests-subpath-d6lcs, resource: bindings, ignored listing per whitelist
Feb 22 22:21:10.871: INFO: namespace e2e-tests-subpath-d6lcs deletion completed in 6.149751204s

• [SLOW TEST:30.721 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:21:10.872: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-wxj2r
Feb 22 22:21:14.985: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-wxj2r
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 22:21:14.988: INFO: Initial restart count of pod liveness-http is 0
Feb 22 22:21:27.033: INFO: Restart count of pod e2e-tests-container-probe-wxj2r/liveness-http is now 1 (12.045377947s elapsed)
Feb 22 22:21:47.108: INFO: Restart count of pod e2e-tests-container-probe-wxj2r/liveness-http is now 2 (32.120533046s elapsed)
Feb 22 22:22:07.190: INFO: Restart count of pod e2e-tests-container-probe-wxj2r/liveness-http is now 3 (52.202102203s elapsed)
Feb 22 22:22:27.272: INFO: Restart count of pod e2e-tests-container-probe-wxj2r/liveness-http is now 4 (1m12.284202494s elapsed)
Feb 22 22:23:27.505: INFO: Restart count of pod e2e-tests-container-probe-wxj2r/liveness-http is now 5 (2m12.517152228s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:23:27.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wxj2r" for this suite.
Feb 22 22:23:33.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:23:33.808: INFO: namespace: e2e-tests-container-probe-wxj2r, resource: bindings, ignored listing per whitelist
Feb 22 22:23:33.894: INFO: namespace e2e-tests-container-probe-wxj2r deletion completed in 6.324015316s

• [SLOW TEST:143.022 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:23:33.894: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 22 22:23:33.985: INFO: Waiting up to 5m0s for pod "downward-api-7da82e9b-36f0-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-nw59l" to be "success or failure"
Feb 22 22:23:33.992: INFO: Pod "downward-api-7da82e9b-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.868241ms
Feb 22 22:23:35.999: INFO: Pod "downward-api-7da82e9b-36f0-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013368758s
STEP: Saw pod success
Feb 22 22:23:35.999: INFO: Pod "downward-api-7da82e9b-36f0-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:23:36.004: INFO: Trying to get logs from node conformance113-1 pod downward-api-7da82e9b-36f0-11e9-b6f8-82efa66823a4 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:23:36.035: INFO: Waiting for pod downward-api-7da82e9b-36f0-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:23:36.039: INFO: Pod downward-api-7da82e9b-36f0-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:23:36.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nw59l" for this suite.
Feb 22 22:23:42.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:23:42.135: INFO: namespace: e2e-tests-downward-api-nw59l, resource: bindings, ignored listing per whitelist
Feb 22 22:23:42.237: INFO: namespace e2e-tests-downward-api-nw59l deletion completed in 6.190697377s

• [SLOW TEST:8.342 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:23:42.238: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:23:42.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bkkv2" for this suite.
Feb 22 22:23:58.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:23:59.011: INFO: namespace: e2e-tests-pods-bkkv2, resource: bindings, ignored listing per whitelist
Feb 22 22:23:59.047: INFO: namespace e2e-tests-pods-bkkv2 deletion completed in 16.700109933s

• [SLOW TEST:16.809 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:23:59.048: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:23:59.135: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ca5e373-36f0-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-975wf" to be "success or failure"
Feb 22 22:23:59.163: INFO: Pod "downwardapi-volume-8ca5e373-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 27.22671ms
Feb 22 22:24:01.168: INFO: Pod "downwardapi-volume-8ca5e373-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032905535s
Feb 22 22:24:03.174: INFO: Pod "downwardapi-volume-8ca5e373-36f0-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038761581s
STEP: Saw pod success
Feb 22 22:24:03.174: INFO: Pod "downwardapi-volume-8ca5e373-36f0-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:24:03.180: INFO: Trying to get logs from node conformance113-3 pod downwardapi-volume-8ca5e373-36f0-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 22:24:03.252: INFO: Waiting for pod downwardapi-volume-8ca5e373-36f0-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:24:03.267: INFO: Pod downwardapi-volume-8ca5e373-36f0-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:24:03.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-975wf" for this suite.
Feb 22 22:24:09.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:24:09.403: INFO: namespace: e2e-tests-projected-975wf, resource: bindings, ignored listing per whitelist
Feb 22 22:24:09.490: INFO: namespace e2e-tests-projected-975wf deletion completed in 6.21533805s

• [SLOW TEST:10.443 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:24:09.491: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 22 22:24:17.709: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:17.720: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:19.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:19.727: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:21.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:21.727: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:23.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:23.727: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:25.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:25.728: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:27.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:27.739: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:29.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:29.726: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:31.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:31.727: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:33.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:33.733: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:35.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:35.727: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:37.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:38.218: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:39.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:39.734: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:41.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:45.602: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:24:45.731: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:24:45.741: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:24:45.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-x8lhm" for this suite.
Feb 22 22:25:09.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:25:09.887: INFO: namespace: e2e-tests-container-lifecycle-hook-x8lhm, resource: bindings, ignored listing per whitelist
Feb 22 22:25:09.909: INFO: namespace e2e-tests-container-lifecycle-hook-x8lhm deletion completed in 24.160964889s

• [SLOW TEST:60.418 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:25:09.909: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:25:10.001: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b6e2fdb4-36f0-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-jkvzj" to be "success or failure"
Feb 22 22:25:10.006: INFO: Pod "downwardapi-volume-b6e2fdb4-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.909135ms
Feb 22 22:25:12.020: INFO: Pod "downwardapi-volume-b6e2fdb4-36f0-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018777114s
STEP: Saw pod success
Feb 22 22:25:12.020: INFO: Pod "downwardapi-volume-b6e2fdb4-36f0-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:25:12.025: INFO: Trying to get logs from node conformance113-3 pod downwardapi-volume-b6e2fdb4-36f0-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 22:25:12.076: INFO: Waiting for pod downwardapi-volume-b6e2fdb4-36f0-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:25:12.108: INFO: Pod downwardapi-volume-b6e2fdb4-36f0-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:25:12.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jkvzj" for this suite.
Feb 22 22:25:18.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:25:18.228: INFO: namespace: e2e-tests-projected-jkvzj, resource: bindings, ignored listing per whitelist
Feb 22 22:25:18.300: INFO: namespace e2e-tests-projected-jkvzj deletion completed in 6.186524522s

• [SLOW TEST:8.391 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:25:18.301: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 22 22:25:18.390: INFO: Waiting up to 5m0s for pod "pod-bbe27038-36f0-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-6fhwd" to be "success or failure"
Feb 22 22:25:18.397: INFO: Pod "pod-bbe27038-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.089212ms
Feb 22 22:25:20.402: INFO: Pod "pod-bbe27038-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012434761s
Feb 22 22:25:22.417: INFO: Pod "pod-bbe27038-36f0-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026840347s
STEP: Saw pod success
Feb 22 22:25:22.417: INFO: Pod "pod-bbe27038-36f0-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:25:22.420: INFO: Trying to get logs from node conformance113-1 pod pod-bbe27038-36f0-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 22:25:22.448: INFO: Waiting for pod pod-bbe27038-36f0-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:25:22.451: INFO: Pod pod-bbe27038-36f0-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:25:22.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6fhwd" for this suite.
Feb 22 22:25:28.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:25:28.640: INFO: namespace: e2e-tests-emptydir-6fhwd, resource: bindings, ignored listing per whitelist
Feb 22 22:25:28.728: INFO: namespace e2e-tests-emptydir-6fhwd deletion completed in 6.173753998s

• [SLOW TEST:10.428 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:25:28.729: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-c21a48ed-36f0-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 22:25:28.830: INFO: Waiting up to 5m0s for pod "pod-configmaps-c21c42f3-36f0-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-configmap-jsw5z" to be "success or failure"
Feb 22 22:25:28.841: INFO: Pod "pod-configmaps-c21c42f3-36f0-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.488825ms
Feb 22 22:25:30.847: INFO: Pod "pod-configmaps-c21c42f3-36f0-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016747291s
STEP: Saw pod success
Feb 22 22:25:30.847: INFO: Pod "pod-configmaps-c21c42f3-36f0-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:25:30.853: INFO: Trying to get logs from node conformance113-2 pod pod-configmaps-c21c42f3-36f0-11e9-b6f8-82efa66823a4 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:25:30.893: INFO: Waiting for pod pod-configmaps-c21c42f3-36f0-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:25:30.919: INFO: Pod pod-configmaps-c21c42f3-36f0-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:25:30.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jsw5z" for this suite.
Feb 22 22:25:36.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:25:37.061: INFO: namespace: e2e-tests-configmap-jsw5z, resource: bindings, ignored listing per whitelist
Feb 22 22:25:37.111: INFO: namespace e2e-tests-configmap-jsw5z deletion completed in 6.187643845s

• [SLOW TEST:8.382 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:25:37.113: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 22 22:25:37.239: INFO: Number of nodes with available pods: 0
Feb 22 22:25:37.239: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 22:25:38.286: INFO: Number of nodes with available pods: 0
Feb 22 22:25:38.288: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 22:25:39.258: INFO: Number of nodes with available pods: 1
Feb 22 22:25:39.258: INFO: Node conformance113-1 is running more than one daemon pod
Feb 22 22:25:40.259: INFO: Number of nodes with available pods: 3
Feb 22 22:25:40.260: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 22 22:25:40.303: INFO: Number of nodes with available pods: 2
Feb 22 22:25:40.303: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:41.318: INFO: Number of nodes with available pods: 2
Feb 22 22:25:41.319: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:42.332: INFO: Number of nodes with available pods: 2
Feb 22 22:25:42.332: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:43.336: INFO: Number of nodes with available pods: 2
Feb 22 22:25:43.336: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:44.488: INFO: Number of nodes with available pods: 2
Feb 22 22:25:44.489: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:45.580: INFO: Number of nodes with available pods: 2
Feb 22 22:25:45.580: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:46.496: INFO: Number of nodes with available pods: 2
Feb 22 22:25:46.497: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:47.491: INFO: Number of nodes with available pods: 2
Feb 22 22:25:47.491: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:48.331: INFO: Number of nodes with available pods: 2
Feb 22 22:25:48.331: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:49.326: INFO: Number of nodes with available pods: 2
Feb 22 22:25:49.326: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:50.313: INFO: Number of nodes with available pods: 2
Feb 22 22:25:50.313: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:51.319: INFO: Number of nodes with available pods: 2
Feb 22 22:25:51.320: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:52.317: INFO: Number of nodes with available pods: 2
Feb 22 22:25:52.317: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:53.316: INFO: Number of nodes with available pods: 2
Feb 22 22:25:53.317: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:54.325: INFO: Number of nodes with available pods: 2
Feb 22 22:25:54.325: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:55.321: INFO: Number of nodes with available pods: 2
Feb 22 22:25:55.321: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:56.322: INFO: Number of nodes with available pods: 2
Feb 22 22:25:56.322: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:57.322: INFO: Number of nodes with available pods: 2
Feb 22 22:25:57.322: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:58.314: INFO: Number of nodes with available pods: 2
Feb 22 22:25:58.314: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:25:59.315: INFO: Number of nodes with available pods: 2
Feb 22 22:25:59.315: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:00.315: INFO: Number of nodes with available pods: 2
Feb 22 22:26:00.315: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:01.330: INFO: Number of nodes with available pods: 2
Feb 22 22:26:01.330: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:02.315: INFO: Number of nodes with available pods: 2
Feb 22 22:26:02.316: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:03.320: INFO: Number of nodes with available pods: 2
Feb 22 22:26:03.320: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:04.319: INFO: Number of nodes with available pods: 2
Feb 22 22:26:04.319: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:05.333: INFO: Number of nodes with available pods: 2
Feb 22 22:26:05.333: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:06.311: INFO: Number of nodes with available pods: 2
Feb 22 22:26:06.311: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:07.319: INFO: Number of nodes with available pods: 2
Feb 22 22:26:07.319: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:08.315: INFO: Number of nodes with available pods: 2
Feb 22 22:26:08.315: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:09.319: INFO: Number of nodes with available pods: 2
Feb 22 22:26:09.319: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:10.746: INFO: Number of nodes with available pods: 2
Feb 22 22:26:10.746: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:11.311: INFO: Number of nodes with available pods: 2
Feb 22 22:26:11.311: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:12.315: INFO: Number of nodes with available pods: 2
Feb 22 22:26:12.315: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:13.315: INFO: Number of nodes with available pods: 2
Feb 22 22:26:13.315: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:14.315: INFO: Number of nodes with available pods: 2
Feb 22 22:26:14.315: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:15.314: INFO: Number of nodes with available pods: 2
Feb 22 22:26:15.314: INFO: Node conformance113-3 is running more than one daemon pod
Feb 22 22:26:17.147: INFO: Number of nodes with available pods: 3
Feb 22 22:26:17.147: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-4lbq2, will wait for the garbage collector to delete the pods
Feb 22 22:26:17.234: INFO: Deleting DaemonSet.extensions daemon-set took: 24.243576ms
Feb 22 22:26:17.434: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.22396ms
Feb 22 22:27:01.451: INFO: Number of nodes with available pods: 0
Feb 22 22:27:01.451: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 22:27:01.458: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4lbq2/daemonsets","resourceVersion":"20060"},"items":null}

Feb 22 22:27:01.461: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4lbq2/pods","resourceVersion":"20060"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:27:01.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4lbq2" for this suite.
Feb 22 22:27:07.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:27:07.612: INFO: namespace: e2e-tests-daemonsets-4lbq2, resource: bindings, ignored listing per whitelist
Feb 22 22:27:07.631: INFO: namespace e2e-tests-daemonsets-4lbq2 deletion completed in 6.147377953s

• [SLOW TEST:90.518 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:27:07.632: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 22 22:27:08.219: INFO: Waiting up to 5m0s for pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-fv2jq" in namespace "e2e-tests-svcaccounts-5qrpk" to be "success or failure"
Feb 22 22:27:08.229: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-fv2jq": Phase="Pending", Reason="", readiness=false. Elapsed: 9.987157ms
Feb 22 22:27:10.235: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-fv2jq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015792569s
Feb 22 22:27:12.251: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-fv2jq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031756171s
STEP: Saw pod success
Feb 22 22:27:12.251: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-fv2jq" satisfied condition "success or failure"
Feb 22 22:27:12.256: INFO: Trying to get logs from node conformance113-1 pod pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-fv2jq container token-test: <nil>
STEP: delete the pod
Feb 22 22:27:12.287: INFO: Waiting for pod pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-fv2jq to disappear
Feb 22 22:27:12.291: INFO: Pod pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-fv2jq no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 22 22:27:12.296: INFO: Waiting up to 5m0s for pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-5rvnn" in namespace "e2e-tests-svcaccounts-5qrpk" to be "success or failure"
Feb 22 22:27:12.302: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-5rvnn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.694661ms
Feb 22 22:27:14.340: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-5rvnn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044884509s
Feb 22 22:27:16.347: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-5rvnn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051316739s
STEP: Saw pod success
Feb 22 22:27:16.347: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-5rvnn" satisfied condition "success or failure"
Feb 22 22:27:16.352: INFO: Trying to get logs from node conformance113-3 pod pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-5rvnn container root-ca-test: <nil>
STEP: delete the pod
Feb 22 22:27:16.424: INFO: Waiting for pod pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-5rvnn to disappear
Feb 22 22:27:16.434: INFO: Pod pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-5rvnn no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 22 22:27:16.453: INFO: Waiting up to 5m0s for pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-tgw29" in namespace "e2e-tests-svcaccounts-5qrpk" to be "success or failure"
Feb 22 22:27:16.476: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-tgw29": Phase="Pending", Reason="", readiness=false. Elapsed: 22.9143ms
Feb 22 22:27:18.480: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-tgw29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027237473s
Feb 22 22:27:20.485: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-tgw29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031964105s
STEP: Saw pod success
Feb 22 22:27:20.485: INFO: Pod "pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-tgw29" satisfied condition "success or failure"
Feb 22 22:27:20.496: INFO: Trying to get logs from node conformance113-1 pod pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-tgw29 container namespace-test: <nil>
STEP: delete the pod
Feb 22 22:27:20.546: INFO: Waiting for pod pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-tgw29 to disappear
Feb 22 22:27:20.559: INFO: Pod pod-service-account-fd5944b9-36f0-11e9-b6f8-82efa66823a4-tgw29 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:27:20.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-5qrpk" for this suite.
Feb 22 22:27:26.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:27:26.720: INFO: namespace: e2e-tests-svcaccounts-5qrpk, resource: bindings, ignored listing per whitelist
Feb 22 22:27:26.752: INFO: namespace e2e-tests-svcaccounts-5qrpk deletion completed in 6.187492522s

• [SLOW TEST:19.120 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:27:26.753: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:27:30.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-cvz96" for this suite.
Feb 22 22:27:36.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:27:36.947: INFO: namespace: e2e-tests-kubelet-test-cvz96, resource: bindings, ignored listing per whitelist
Feb 22 22:27:37.032: INFO: namespace e2e-tests-kubelet-test-cvz96 deletion completed in 6.170229355s

• [SLOW TEST:10.280 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:27:37.033: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:27:37.119: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e92c538-36f1-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-86pht" to be "success or failure"
Feb 22 22:27:37.128: INFO: Pod "downwardapi-volume-0e92c538-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.641996ms
Feb 22 22:27:39.135: INFO: Pod "downwardapi-volume-0e92c538-36f1-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015183762s
STEP: Saw pod success
Feb 22 22:27:39.135: INFO: Pod "downwardapi-volume-0e92c538-36f1-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:27:39.139: INFO: Trying to get logs from node conformance113-1 pod downwardapi-volume-0e92c538-36f1-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 22:27:39.168: INFO: Waiting for pod downwardapi-volume-0e92c538-36f1-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:27:39.170: INFO: Pod downwardapi-volume-0e92c538-36f1-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:27:39.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-86pht" for this suite.
Feb 22 22:27:45.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:27:45.357: INFO: namespace: e2e-tests-downward-api-86pht, resource: bindings, ignored listing per whitelist
Feb 22 22:27:45.424: INFO: namespace e2e-tests-downward-api-86pht deletion completed in 6.249496073s

• [SLOW TEST:8.391 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:27:45.427: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 22 22:27:45.512: INFO: Waiting up to 5m0s for pod "pod-1393ab49-36f1-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-fssgj" to be "success or failure"
Feb 22 22:27:45.528: INFO: Pod "pod-1393ab49-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.855373ms
Feb 22 22:27:47.534: INFO: Pod "pod-1393ab49-36f1-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021634528s
STEP: Saw pod success
Feb 22 22:27:47.534: INFO: Pod "pod-1393ab49-36f1-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:27:47.539: INFO: Trying to get logs from node conformance113-2 pod pod-1393ab49-36f1-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 22:27:47.598: INFO: Waiting for pod pod-1393ab49-36f1-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:27:47.607: INFO: Pod pod-1393ab49-36f1-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:27:47.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fssgj" for this suite.
Feb 22 22:27:53.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:27:53.750: INFO: namespace: e2e-tests-emptydir-fssgj, resource: bindings, ignored listing per whitelist
Feb 22 22:27:53.809: INFO: namespace e2e-tests-emptydir-fssgj deletion completed in 6.196277524s

• [SLOW TEST:8.381 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:27:53.809: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 22:27:53.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-2qh7w'
Feb 22 22:27:54.305: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 22 22:27:54.305: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb 22 22:27:58.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-2qh7w'
Feb 22 22:27:58.453: INFO: stderr: ""
Feb 22 22:27:58.453: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:27:58.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2qh7w" for this suite.
Feb 22 22:28:20.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:28:20.549: INFO: namespace: e2e-tests-kubectl-2qh7w, resource: bindings, ignored listing per whitelist
Feb 22 22:28:20.713: INFO: namespace e2e-tests-kubectl-2qh7w deletion completed in 22.250622846s

• [SLOW TEST:26.904 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:28:20.715: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-28a0b1c2-36f1-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 22:28:20.841: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-28a21d23-36f1-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-khrt6" to be "success or failure"
Feb 22 22:28:20.853: INFO: Pod "pod-projected-secrets-28a21d23-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.022721ms
Feb 22 22:28:22.859: INFO: Pod "pod-projected-secrets-28a21d23-36f1-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017759995s
STEP: Saw pod success
Feb 22 22:28:22.859: INFO: Pod "pod-projected-secrets-28a21d23-36f1-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:28:22.863: INFO: Trying to get logs from node conformance113-1 pod pod-projected-secrets-28a21d23-36f1-11e9-b6f8-82efa66823a4 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:28:22.890: INFO: Waiting for pod pod-projected-secrets-28a21d23-36f1-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:28:22.895: INFO: Pod pod-projected-secrets-28a21d23-36f1-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:28:22.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-khrt6" for this suite.
Feb 22 22:28:28.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:28:29.037: INFO: namespace: e2e-tests-projected-khrt6, resource: bindings, ignored listing per whitelist
Feb 22 22:28:29.092: INFO: namespace e2e-tests-projected-khrt6 deletion completed in 6.191365464s

• [SLOW TEST:8.377 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:28:29.092: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 22 22:28:29.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 api-versions'
Feb 22 22:28:29.264: INFO: stderr: ""
Feb 22 22:28:29.264: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncluster.cattle.io/v3\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:28:29.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b75cc" for this suite.
Feb 22 22:28:35.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:28:35.444: INFO: namespace: e2e-tests-kubectl-b75cc, resource: bindings, ignored listing per whitelist
Feb 22 22:28:35.504: INFO: namespace e2e-tests-kubectl-b75cc deletion completed in 6.235242242s

• [SLOW TEST:6.412 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:28:35.505: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:28:35.590: INFO: Creating deployment "nginx-deployment"
Feb 22 22:28:35.599: INFO: Waiting for observed generation 1
Feb 22 22:28:37.618: INFO: Waiting for all required pods to come up
Feb 22 22:28:37.625: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 22 22:28:39.673: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 22 22:28:39.680: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 22 22:28:39.692: INFO: Updating deployment nginx-deployment
Feb 22 22:28:39.692: INFO: Waiting for observed generation 2
Feb 22 22:28:41.724: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 22 22:28:41.735: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 22 22:28:41.747: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 22 22:28:41.772: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 22 22:28:41.773: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 22 22:28:41.783: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 22 22:28:41.830: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 22 22:28:41.830: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 22 22:28:41.888: INFO: Updating deployment nginx-deployment
Feb 22 22:28:41.888: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 22 22:28:41.970: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 22 22:28:42.077: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 22 22:28:42.212: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-w5rds,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w5rds/deployments/nginx-deployment,UID:31705bcf-36f1-11e9-a687-fac827d478c7,ResourceVersion:20810,Generation:3,CreationTimestamp:2019-02-22 22:28:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:17,UpdatedReplicas:9,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-02-22 22:28:41 +0000 UTC 2019-02-22 22:28:41 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-22 22:28:42 +0000 UTC 2019-02-22 22:28:35 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 22 22:28:42.372: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-w5rds,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w5rds/replicasets/nginx-deployment-65bbdb5f8,UID:33e0e7e2-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20823,Generation:3,CreationTimestamp:2019-02-22 22:28:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 31705bcf-36f1-11e9-a687-fac827d478c7 0xc000d52b87 0xc000d52b88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 22:28:42.373: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 22 22:28:42.373: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-w5rds,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w5rds/replicasets/nginx-deployment-555b55d965,UID:3172146a-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20818,Generation:3,CreationTimestamp:2019-02-22 22:28:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 31705bcf-36f1-11e9-a687-fac827d478c7 0xc000d52447 0xc000d52448}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:15,FullyLabeledReplicas:15,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 22 22:28:42.401: INFO: Pod "nginx-deployment-555b55d965-2mh5k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2mh5k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-2mh5k,UID:353365de-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20838,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc00180ac87 0xc00180ac88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00180ad20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00180ad50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:41 +0000 UTC  }],Message:,Reason:,HostIP:159.65.166.126,PodIP:,StartTime:2019-02-22 22:28:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.402: INFO: Pod "nginx-deployment-555b55d965-4spl8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4spl8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-4spl8,UID:35300c2b-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20790,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc00180ae27 0xc00180ae28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00180aea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00180aec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:41 +0000 UTC  }],Message:,Reason:,HostIP:104.248.0.151,PodIP:,StartTime:2019-02-22 22:28:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.402: INFO: Pod "nginx-deployment-555b55d965-6p7zp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6p7zp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-6p7zp,UID:35378ba8-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20796,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc00180af77 0xc00180af78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00180aff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00180b010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.402: INFO: Pod "nginx-deployment-555b55d965-82tzj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-82tzj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-82tzj,UID:3182f658-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20661,Generation:0,CreationTimestamp:2019-02-22 22:28:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.98/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc00180b200 0xc00180b201}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00180b270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00180b290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  }],Message:,Reason:,HostIP:159.65.166.126,PodIP:10.42.1.98,StartTime:2019-02-22 22:28:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:28:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://8ceb59c733f0e1a2f5e8b1b236980568e014fd80bc71d2ff139fa7e9985a33a6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.403: INFO: Pod "nginx-deployment-555b55d965-c846q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-c846q,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-c846q,UID:317fbf1d-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20644,Generation:0,CreationTimestamp:2019-02-22 22:28:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.77/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc00180b360 0xc00180b361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00180b3d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00180b3f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  }],Message:,Reason:,HostIP:104.248.0.151,PodIP:10.42.0.77,StartTime:2019-02-22 22:28:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:28:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://77f9f902fd6f8936562b9d9d03b226c1e000d7f413eea22dcaa561faa4ff30e8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.403: INFO: Pod "nginx-deployment-555b55d965-gq9jv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gq9jv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-gq9jv,UID:3188e30e-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20667,Generation:0,CreationTimestamp:2019-02-22 22:28:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.60/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc00180b4e0 0xc00180b4e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00180b5b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00180b5d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:10.42.2.60,StartTime:2019-02-22 22:28:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:28:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://9b67156646586865145fb29ddc816b3284111106d2e16bc4252ed169be0afb26}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.403: INFO: Pod "nginx-deployment-555b55d965-hd6sk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hd6sk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-hd6sk,UID:353b5910-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20826,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc00180b690 0xc00180b691}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00180b740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00180b7b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:,StartTime:2019-02-22 22:28:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.403: INFO: Pod "nginx-deployment-555b55d965-jr8hg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jr8hg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-jr8hg,UID:353b53ba-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20811,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc00180b8d7 0xc00180b8d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00180bbf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00180bcc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.403: INFO: Pod "nginx-deployment-555b55d965-jwjdg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jwjdg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-jwjdg,UID:353752de-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20792,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc00180bd60 0xc00180bd61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00180be20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00180beb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.404: INFO: Pod "nginx-deployment-555b55d965-jzmvz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jzmvz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-jzmvz,UID:353b3be9-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20814,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc00180bf30 0xc00180bf31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3e0a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3e0c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.404: INFO: Pod "nginx-deployment-555b55d965-k7p5b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k7p5b,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-k7p5b,UID:35377617-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20797,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc001a3e2a0 0xc001a3e2a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3e440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3e460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.404: INFO: Pod "nginx-deployment-555b55d965-lqkgr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lqkgr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-lqkgr,UID:3183619e-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20664,Generation:0,CreationTimestamp:2019-02-22 22:28:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.62/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc001a3e4f0 0xc001a3e4f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3e640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3e670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:10.42.2.62,StartTime:2019-02-22 22:28:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:28:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://1108df1e9d9304de95615bace72ae0ada2f9e6476b4c7db0fa832cabfa954320}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.405: INFO: Pod "nginx-deployment-555b55d965-mf2z5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mf2z5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-mf2z5,UID:3537858c-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20822,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc001a3e770 0xc001a3e771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3e7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3e800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:,StartTime:2019-02-22 22:28:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.405: INFO: Pod "nginx-deployment-555b55d965-pdgc9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pdgc9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-pdgc9,UID:3179113e-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20647,Generation:0,CreationTimestamp:2019-02-22 22:28:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.97/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc001a3e987 0xc001a3e988}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3ea20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3ea50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  }],Message:,Reason:,HostIP:159.65.166.126,PodIP:10.42.1.97,StartTime:2019-02-22 22:28:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:28:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://b51dccead380ecbd50217cf86d191f5c8ab280ef1a582bed06fdc047c6b05a1e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.405: INFO: Pod "nginx-deployment-555b55d965-r75vg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-r75vg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-r75vg,UID:353b1c73-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20809,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc001a3ed40 0xc001a3ed41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3edb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3edd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.406: INFO: Pod "nginx-deployment-555b55d965-sn7mp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-sn7mp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-sn7mp,UID:31772c8e-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20610,Generation:0,CreationTimestamp:2019-02-22 22:28:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.59/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc001a3ee50 0xc001a3ee51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3eec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3f6b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:10.42.2.59,StartTime:2019-02-22 22:28:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:28:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://5fc085a458451b78242d5b970ea9b5fb732fa41c2eb8cc79f2c4348241b26f9f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.406: INFO: Pod "nginx-deployment-555b55d965-snjlr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-snjlr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-snjlr,UID:353b4cd9-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20815,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc001a3f770 0xc001a3f771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3f7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3f800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.406: INFO: Pod "nginx-deployment-555b55d965-tb2n2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tb2n2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-tb2n2,UID:31842ce4-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20654,Generation:0,CreationTimestamp:2019-02-22 22:28:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.99/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc001a3f900 0xc001a3f901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3f970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3f990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  }],Message:,Reason:,HostIP:159.65.166.126,PodIP:10.42.1.99,StartTime:2019-02-22 22:28:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:28:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://11646bb26db24187c0ba18e2419df300ed9f70fadd9eb56aff470c038c30d541}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.406: INFO: Pod "nginx-deployment-555b55d965-vq98s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vq98s,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-vq98s,UID:3188f51e-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20670,Generation:0,CreationTimestamp:2019-02-22 22:28:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.61/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc001a3fae0 0xc001a3fae1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a3fb50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a3fb70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:35 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:10.42.2.61,StartTime:2019-02-22 22:28:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:28:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://19582e2b7c13027ad7046856041b7c6e9f3782242119ca719703bd3899526501}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.407: INFO: Pod "nginx-deployment-555b55d965-wtjd8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wtjd8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-555b55d965-wtjd8,UID:3533126c-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20824,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3172146a-36f1-11e9-96d9-6a889f07183f 0xc001954020 0xc001954021}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001954150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001954170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:41 +0000 UTC  }],Message:,Reason:,HostIP:104.248.0.151,PodIP:,StartTime:2019-02-22 22:28:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.407: INFO: Pod "nginx-deployment-65bbdb5f8-4lq6f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4lq6f,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-4lq6f,UID:33e1e162-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20747,Generation:0,CreationTimestamp:2019-02-22 22:28:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.79/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001954267 0xc001954268}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001954300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001954320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  }],Message:,Reason:,HostIP:104.248.0.151,PodIP:,StartTime:2019-02-22 22:28:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.407: INFO: Pod "nginx-deployment-65bbdb5f8-4ppv2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4ppv2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-4ppv2,UID:3534b6f4-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20816,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001954470 0xc001954471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019544f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001954510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:,StartTime:2019-02-22 22:28:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.408: INFO: Pod "nginx-deployment-65bbdb5f8-4rz4t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4rz4t,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-4rz4t,UID:353216f8-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20827,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001954640 0xc001954641}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019546c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019546e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:41 +0000 UTC  }],Message:,Reason:,HostIP:159.65.166.126,PodIP:,StartTime:2019-02-22 22:28:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.408: INFO: Pod "nginx-deployment-65bbdb5f8-5k8xs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5k8xs,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-5k8xs,UID:33e48927-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20742,Generation:0,CreationTimestamp:2019-02-22 22:28:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.63/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001954820 0xc001954821}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019548a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019548c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:10.42.2.63,StartTime:2019-02-22 22:28:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.409: INFO: Pod "nginx-deployment-65bbdb5f8-5wpp4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5wpp4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-5wpp4,UID:3534a22c-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20791,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001954a20 0xc001954a21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001954aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001954ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.411: INFO: Pod "nginx-deployment-65bbdb5f8-d6qvn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-d6qvn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-d6qvn,UID:341c3206-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20745,Generation:0,CreationTimestamp:2019-02-22 22:28:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.64/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001954b40 0xc001954b41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001954c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001954c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:40 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:10.42.2.64,StartTime:2019-02-22 22:28:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.411: INFO: Pod "nginx-deployment-65bbdb5f8-gwrmm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gwrmm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-gwrmm,UID:3538135b-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20800,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001954d00 0xc001954d01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001954d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001954e60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.413: INFO: Pod "nginx-deployment-65bbdb5f8-gzlr4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gzlr4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-gzlr4,UID:35380dae-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20820,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc0019550a0 0xc0019550a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001955120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001955140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:,StartTime:2019-02-22 22:28:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.413: INFO: Pod "nginx-deployment-65bbdb5f8-hmdkp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hmdkp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-hmdkp,UID:35380441-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20795,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001955200 0xc001955201}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001955280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019552a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.413: INFO: Pod "nginx-deployment-65bbdb5f8-j45mw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-j45mw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-j45mw,UID:33e47261-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20740,Generation:0,CreationTimestamp:2019-02-22 22:28:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.100/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001955320 0xc001955321}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019553a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019553c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:39 +0000 UTC  }],Message:,Reason:,HostIP:159.65.166.126,PodIP:10.42.1.100,StartTime:2019-02-22 22:28:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.414: INFO: Pod "nginx-deployment-65bbdb5f8-m4969" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-m4969,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-m4969,UID:33f1cdfe-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20720,Generation:0,CreationTimestamp:2019-02-22 22:28:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc0019554a0 0xc0019554a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001955520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001955540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:40 +0000 UTC  }],Message:,Reason:,HostIP:104.248.0.151,PodIP:,StartTime:2019-02-22 22:28:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.414: INFO: Pod "nginx-deployment-65bbdb5f8-wbb5l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wbb5l,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-wbb5l,UID:3537ee8b-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20799,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001955600 0xc001955601}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019556c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019556e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:28:42.414: INFO: Pod "nginx-deployment-65bbdb5f8-ws6bs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ws6bs,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-w5rds,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5rds/pods/nginx-deployment-65bbdb5f8-ws6bs,UID:353cf39b-36f1-11e9-96d9-6a889f07183f,ResourceVersion:20812,Generation:0,CreationTimestamp:2019-02-22 22:28:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 33e0e7e2-36f1-11e9-96d9-6a889f07183f 0xc001955750 0xc001955751}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ptp77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptp77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-ptp77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019557d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001955800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:28:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:28:42.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-w5rds" for this suite.
Feb 22 22:28:52.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:28:52.834: INFO: namespace: e2e-tests-deployment-w5rds, resource: bindings, ignored listing per whitelist
Feb 22 22:28:53.014: INFO: namespace e2e-tests-deployment-w5rds deletion completed in 10.585762207s

• [SLOW TEST:17.509 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:28:53.015: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:28:53.298: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3bf1f026-36f1-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-fstm8" to be "success or failure"
Feb 22 22:28:53.328: INFO: Pod "downwardapi-volume-3bf1f026-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 30.025968ms
Feb 22 22:28:55.337: INFO: Pod "downwardapi-volume-3bf1f026-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039416516s
Feb 22 22:28:57.341: INFO: Pod "downwardapi-volume-3bf1f026-36f1-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043235307s
STEP: Saw pod success
Feb 22 22:28:57.341: INFO: Pod "downwardapi-volume-3bf1f026-36f1-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:28:57.345: INFO: Trying to get logs from node conformance113-1 pod downwardapi-volume-3bf1f026-36f1-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 22:28:57.373: INFO: Waiting for pod downwardapi-volume-3bf1f026-36f1-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:28:57.376: INFO: Pod downwardapi-volume-3bf1f026-36f1-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:28:57.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fstm8" for this suite.
Feb 22 22:29:03.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:29:03.446: INFO: namespace: e2e-tests-downward-api-fstm8, resource: bindings, ignored listing per whitelist
Feb 22 22:29:03.583: INFO: namespace e2e-tests-downward-api-fstm8 deletion completed in 6.201315438s

• [SLOW TEST:10.568 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:29:03.584: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-422a07a5-36f1-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 22:29:03.677: INFO: Waiting up to 5m0s for pod "pod-secrets-422b97c5-36f1-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-secrets-chf7c" to be "success or failure"
Feb 22 22:29:03.681: INFO: Pod "pod-secrets-422b97c5-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.435167ms
Feb 22 22:29:05.686: INFO: Pod "pod-secrets-422b97c5-36f1-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008789084s
STEP: Saw pod success
Feb 22 22:29:05.686: INFO: Pod "pod-secrets-422b97c5-36f1-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:29:05.688: INFO: Trying to get logs from node conformance113-2 pod pod-secrets-422b97c5-36f1-11e9-b6f8-82efa66823a4 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:29:05.737: INFO: Waiting for pod pod-secrets-422b97c5-36f1-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:29:05.772: INFO: Pod pod-secrets-422b97c5-36f1-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:29:05.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-chf7c" for this suite.
Feb 22 22:29:11.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:29:11.880: INFO: namespace: e2e-tests-secrets-chf7c, resource: bindings, ignored listing per whitelist
Feb 22 22:29:11.970: INFO: namespace e2e-tests-secrets-chf7c deletion completed in 6.193229071s

• [SLOW TEST:8.387 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:29:11.971: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2vgsv A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-2vgsv;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2vgsv A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-2vgsv;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2vgsv.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-2vgsv.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2vgsv.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-2vgsv.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2vgsv.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-2vgsv.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2vgsv.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-2vgsv.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2vgsv.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-2vgsv.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2vgsv.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-2vgsv.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-2vgsv.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 156.119.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.119.156_udp@PTR;check="$$(dig +tcp +noall +answer +search 156.119.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.119.156_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2vgsv A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-2vgsv;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2vgsv A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-2vgsv;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2vgsv.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-2vgsv.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2vgsv.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-2vgsv.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2vgsv.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-2vgsv.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2vgsv.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-2vgsv.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2vgsv.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-2vgsv.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2vgsv.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-2vgsv.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-2vgsv.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 156.119.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.119.156_udp@PTR;check="$$(dig +tcp +noall +answer +search 156.119.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.119.156_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 22:29:28.225: INFO: DNS probes using e2e-tests-dns-2vgsv/dns-test-472e67d2-36f1-11e9-b6f8-82efa66823a4 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:29:28.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-2vgsv" for this suite.
Feb 22 22:29:34.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:29:34.499: INFO: namespace: e2e-tests-dns-2vgsv, resource: bindings, ignored listing per whitelist
Feb 22 22:29:34.635: INFO: namespace e2e-tests-dns-2vgsv deletion completed in 6.26233981s

• [SLOW TEST:22.664 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:29:34.635: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 22 22:29:34.745: INFO: Waiting up to 5m0s for pod "pod-54af154f-36f1-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-flfk7" to be "success or failure"
Feb 22 22:29:34.759: INFO: Pod "pod-54af154f-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.266425ms
Feb 22 22:29:36.764: INFO: Pod "pod-54af154f-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019502779s
Feb 22 22:29:38.770: INFO: Pod "pod-54af154f-36f1-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025100571s
STEP: Saw pod success
Feb 22 22:29:38.770: INFO: Pod "pod-54af154f-36f1-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:29:38.776: INFO: Trying to get logs from node conformance113-1 pod pod-54af154f-36f1-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 22:29:38.825: INFO: Waiting for pod pod-54af154f-36f1-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:29:38.832: INFO: Pod pod-54af154f-36f1-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:29:38.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-flfk7" for this suite.
Feb 22 22:29:44.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:29:45.033: INFO: namespace: e2e-tests-emptydir-flfk7, resource: bindings, ignored listing per whitelist
Feb 22 22:29:45.074: INFO: namespace e2e-tests-emptydir-flfk7 deletion completed in 6.237566734s

• [SLOW TEST:10.440 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:29:45.075: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-5aebe46b-36f1-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 22:29:45.217: INFO: Waiting up to 5m0s for pod "pod-configmaps-5aedc7e0-36f1-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-configmap-jkk48" to be "success or failure"
Feb 22 22:29:45.244: INFO: Pod "pod-configmaps-5aedc7e0-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 27.837589ms
Feb 22 22:29:47.250: INFO: Pod "pod-configmaps-5aedc7e0-36f1-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033075891s
STEP: Saw pod success
Feb 22 22:29:47.250: INFO: Pod "pod-configmaps-5aedc7e0-36f1-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:29:47.255: INFO: Trying to get logs from node conformance113-2 pod pod-configmaps-5aedc7e0-36f1-11e9-b6f8-82efa66823a4 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:29:47.291: INFO: Waiting for pod pod-configmaps-5aedc7e0-36f1-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:29:47.309: INFO: Pod pod-configmaps-5aedc7e0-36f1-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:29:47.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jkk48" for this suite.
Feb 22 22:29:53.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:29:53.462: INFO: namespace: e2e-tests-configmap-jkk48, resource: bindings, ignored listing per whitelist
Feb 22 22:29:53.499: INFO: namespace e2e-tests-configmap-jkk48 deletion completed in 6.182567424s

• [SLOW TEST:8.424 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:29:53.499: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zbspw
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 22 22:29:53.600: INFO: Found 0 stateful pods, waiting for 3
Feb 22 22:30:03.626: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 22:30:03.626: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 22:30:03.626: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 22:30:03.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-zbspw ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 22:30:04.066: INFO: stderr: ""
Feb 22 22:30:04.066: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 22:30:04.066: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 22 22:30:14.302: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 22 22:30:24.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-zbspw ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:30:24.825: INFO: stderr: ""
Feb 22 22:30:24.825: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 22:30:24.825: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 22:30:24.860: INFO: Waiting for StatefulSet e2e-tests-statefulset-zbspw/ss2 to complete update
Feb 22 22:30:24.860: INFO: Waiting for Pod e2e-tests-statefulset-zbspw/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 22 22:30:24.860: INFO: Waiting for Pod e2e-tests-statefulset-zbspw/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 22 22:30:24.860: INFO: Waiting for Pod e2e-tests-statefulset-zbspw/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 22 22:30:36.295: INFO: Waiting for StatefulSet e2e-tests-statefulset-zbspw/ss2 to complete update
Feb 22 22:30:36.296: INFO: Waiting for Pod e2e-tests-statefulset-zbspw/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 22 22:30:36.296: INFO: Waiting for Pod e2e-tests-statefulset-zbspw/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 22 22:30:45.165: INFO: Waiting for StatefulSet e2e-tests-statefulset-zbspw/ss2 to complete update
Feb 22 22:30:45.166: INFO: Waiting for Pod e2e-tests-statefulset-zbspw/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb 22 22:30:54.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-zbspw ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 22:30:55.195: INFO: stderr: ""
Feb 22 22:30:55.195: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 22:30:55.195: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 22:31:05.264: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 22 22:31:15.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-zbspw ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:31:15.664: INFO: stderr: ""
Feb 22 22:31:15.664: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 22:31:15.664: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 22:31:35.705: INFO: Waiting for StatefulSet e2e-tests-statefulset-zbspw/ss2 to complete update
Feb 22 22:31:35.705: INFO: Waiting for Pod e2e-tests-statefulset-zbspw/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 22 22:31:45.728: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zbspw
Feb 22 22:31:45.733: INFO: Scaling statefulset ss2 to 0
Feb 22 22:32:05.759: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 22:32:05.767: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:32:05.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zbspw" for this suite.
Feb 22 22:32:11.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:32:11.972: INFO: namespace: e2e-tests-statefulset-zbspw, resource: bindings, ignored listing per whitelist
Feb 22 22:32:12.008: INFO: namespace e2e-tests-statefulset-zbspw deletion completed in 6.193820317s

• [SLOW TEST:138.509 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:32:12.008: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 22 22:32:14.185: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-b27e868d-36f1-11e9-b6f8-82efa66823a4", GenerateName:"", Namespace:"e2e-tests-pods-d6pz4", SelfLink:"/api/v1/namespaces/e2e-tests-pods-d6pz4/pods/pod-submit-remove-b27e868d-36f1-11e9-b6f8-82efa66823a4", UID:"b280cf38-36f1-11e9-a687-fac827d478c7", ResourceVersion:"22011", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686471532, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"116549996"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.0.87/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kn5t8", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0015a8880), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kn5t8", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000e03918), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance113-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00133fce0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000e03980)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000e039a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000e039a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000e039ac)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686471532, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686471534, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686471534, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686471532, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"104.248.0.151", PodIP:"10.42.0.87", StartTime:(*v1.Time)(0xc000e269e0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000e26a00), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://6d24dd306f5f010ad8cc3771e6473e48e8bf0c429893380792e6fbf6226dbcaf"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 22 22:32:19.217: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:32:19.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-d6pz4" for this suite.
Feb 22 22:32:25.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:32:25.452: INFO: namespace: e2e-tests-pods-d6pz4, resource: bindings, ignored listing per whitelist
Feb 22 22:32:25.466: INFO: namespace e2e-tests-pods-d6pz4 deletion completed in 6.237949494s

• [SLOW TEST:13.458 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:32:25.466: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 22 22:32:25.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 --namespace=e2e-tests-kubectl-l2cgl run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 22 22:32:27.777: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 22 22:32:27.777: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:32:29.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l2cgl" for this suite.
Feb 22 22:32:35.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:32:35.909: INFO: namespace: e2e-tests-kubectl-l2cgl, resource: bindings, ignored listing per whitelist
Feb 22 22:32:35.957: INFO: namespace e2e-tests-kubectl-l2cgl deletion completed in 6.155251082s

• [SLOW TEST:10.490 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:32:35.958: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 22 22:32:36.061: INFO: Waiting up to 5m0s for pod "downward-api-c0c1a2cc-36f1-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-q5pc8" to be "success or failure"
Feb 22 22:32:36.067: INFO: Pod "downward-api-c0c1a2cc-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051123ms
Feb 22 22:32:38.072: INFO: Pod "downward-api-c0c1a2cc-36f1-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01103388s
STEP: Saw pod success
Feb 22 22:32:38.072: INFO: Pod "downward-api-c0c1a2cc-36f1-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:32:38.076: INFO: Trying to get logs from node conformance113-1 pod downward-api-c0c1a2cc-36f1-11e9-b6f8-82efa66823a4 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:32:38.116: INFO: Waiting for pod downward-api-c0c1a2cc-36f1-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:32:38.119: INFO: Pod downward-api-c0c1a2cc-36f1-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:32:38.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q5pc8" for this suite.
Feb 22 22:32:44.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:32:44.270: INFO: namespace: e2e-tests-downward-api-q5pc8, resource: bindings, ignored listing per whitelist
Feb 22 22:32:44.400: INFO: namespace e2e-tests-downward-api-q5pc8 deletion completed in 6.27687098s

• [SLOW TEST:8.442 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:32:44.400: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 22 22:32:44.471: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:32:48.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-m7pjm" for this suite.
Feb 22 22:33:10.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:33:11.001: INFO: namespace: e2e-tests-init-container-m7pjm, resource: bindings, ignored listing per whitelist
Feb 22 22:33:11.032: INFO: namespace e2e-tests-init-container-m7pjm deletion completed in 22.184098007s

• [SLOW TEST:26.632 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:33:11.032: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 22 22:33:17.198: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:33:17.211: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 22:33:19.211: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:33:19.215: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 22:33:21.212: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:33:21.217: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 22:33:23.212: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:33:23.227: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 22:33:25.211: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:33:25.217: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 22:33:27.212: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:33:27.216: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 22:33:29.212: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:33:29.218: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 22:33:31.212: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:33:31.219: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 22:33:33.211: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:33:33.215: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:33:33.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-j7dsl" for this suite.
Feb 22 22:33:55.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:33:55.367: INFO: namespace: e2e-tests-container-lifecycle-hook-j7dsl, resource: bindings, ignored listing per whitelist
Feb 22 22:33:55.415: INFO: namespace e2e-tests-container-lifecycle-hook-j7dsl deletion completed in 22.195756649s

• [SLOW TEST:44.383 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:33:55.416: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-f01d60c1-36f1-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume configMaps
Feb 22 22:33:55.521: INFO: Waiting up to 5m0s for pod "pod-configmaps-f01eddd1-36f1-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-configmap-gflk7" to be "success or failure"
Feb 22 22:33:55.539: INFO: Pod "pod-configmaps-f01eddd1-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.747188ms
Feb 22 22:33:57.544: INFO: Pod "pod-configmaps-f01eddd1-36f1-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023516748s
STEP: Saw pod success
Feb 22 22:33:57.544: INFO: Pod "pod-configmaps-f01eddd1-36f1-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:33:57.549: INFO: Trying to get logs from node conformance113-3 pod pod-configmaps-f01eddd1-36f1-11e9-b6f8-82efa66823a4 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:33:57.583: INFO: Waiting for pod pod-configmaps-f01eddd1-36f1-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:33:57.604: INFO: Pod pod-configmaps-f01eddd1-36f1-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:33:57.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gflk7" for this suite.
Feb 22 22:34:03.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:34:03.716: INFO: namespace: e2e-tests-configmap-gflk7, resource: bindings, ignored listing per whitelist
Feb 22 22:34:03.798: INFO: namespace e2e-tests-configmap-gflk7 deletion completed in 6.187177948s

• [SLOW TEST:8.382 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:34:03.799: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 22 22:34:03.901: INFO: Waiting up to 5m0s for pod "pod-f51bf58c-36f1-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-5kmzn" to be "success or failure"
Feb 22 22:34:03.920: INFO: Pod "pod-f51bf58c-36f1-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.856079ms
Feb 22 22:34:05.949: INFO: Pod "pod-f51bf58c-36f1-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.048371298s
STEP: Saw pod success
Feb 22 22:34:05.949: INFO: Pod "pod-f51bf58c-36f1-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:34:05.953: INFO: Trying to get logs from node conformance113-1 pod pod-f51bf58c-36f1-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 22:34:05.995: INFO: Waiting for pod pod-f51bf58c-36f1-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:34:06.000: INFO: Pod pod-f51bf58c-36f1-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:34:06.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5kmzn" for this suite.
Feb 22 22:34:12.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:34:12.079: INFO: namespace: e2e-tests-emptydir-5kmzn, resource: bindings, ignored listing per whitelist
Feb 22 22:34:12.210: INFO: namespace e2e-tests-emptydir-5kmzn deletion completed in 6.203860771s

• [SLOW TEST:8.412 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:34:12.211: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 22 22:34:12.345: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 22 22:34:12.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:12.578: INFO: stderr: ""
Feb 22 22:34:12.578: INFO: stdout: "service/redis-slave created\n"
Feb 22 22:34:12.578: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 22 22:34:12.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:12.889: INFO: stderr: ""
Feb 22 22:34:12.889: INFO: stdout: "service/redis-master created\n"
Feb 22 22:34:12.889: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 22 22:34:12.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:13.134: INFO: stderr: ""
Feb 22 22:34:13.134: INFO: stdout: "service/frontend created\n"
Feb 22 22:34:13.134: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 22 22:34:13.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:13.370: INFO: stderr: ""
Feb 22 22:34:13.370: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 22 22:34:13.370: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 22 22:34:13.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:13.747: INFO: stderr: ""
Feb 22 22:34:13.747: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 22 22:34:13.747: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 22 22:34:13.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:14.293: INFO: stderr: ""
Feb 22 22:34:14.293: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 22 22:34:14.293: INFO: Waiting for all frontend pods to be Running.
Feb 22 22:34:39.344: INFO: Waiting for frontend to serve content.
Feb 22 22:34:39.394: INFO: Trying to add a new entry to the guestbook.
Feb 22 22:34:39.415: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 22 22:34:39.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:39.618: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:34:39.618: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 22:34:39.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:39.828: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:34:39.828: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 22:34:39.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:39.979: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:34:39.979: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 22:34:39.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:40.133: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:34:40.133: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 22:34:40.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:40.390: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:34:40.390: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 22:34:40.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr6gs'
Feb 22 22:34:40.769: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:34:40.769: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:34:40.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tr6gs" for this suite.
Feb 22 22:36:49.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:36:49.814: INFO: namespace: e2e-tests-kubectl-tr6gs, resource: bindings, ignored listing per whitelist
Feb 22 22:36:49.870: INFO: namespace e2e-tests-kubectl-tr6gs deletion completed in 2m8.344294993s

• [SLOW TEST:157.659 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:36:49.872: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-cv4zb.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-cv4zb.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-cv4zb.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-cv4zb.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-cv4zb.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-cv4zb.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 22:36:58.130: INFO: DNS probes using e2e-tests-dns-cv4zb/dns-test-581a020a-36f2-11e9-b6f8-82efa66823a4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:36:58.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-cv4zb" for this suite.
Feb 22 22:37:04.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:37:04.433: INFO: namespace: e2e-tests-dns-cv4zb, resource: bindings, ignored listing per whitelist
Feb 22 22:37:04.433: INFO: namespace e2e-tests-dns-cv4zb deletion completed in 6.227755949s

• [SLOW TEST:14.562 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:37:04.434: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:37:04.541: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60c85676-36f2-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-projected-ds5mt" to be "success or failure"
Feb 22 22:37:04.559: INFO: Pod "downwardapi-volume-60c85676-36f2-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.279824ms
Feb 22 22:37:06.564: INFO: Pod "downwardapi-volume-60c85676-36f2-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022606368s
STEP: Saw pod success
Feb 22 22:37:06.564: INFO: Pod "downwardapi-volume-60c85676-36f2-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:37:06.568: INFO: Trying to get logs from node conformance113-3 pod downwardapi-volume-60c85676-36f2-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 22:37:06.651: INFO: Waiting for pod downwardapi-volume-60c85676-36f2-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:37:06.669: INFO: Pod downwardapi-volume-60c85676-36f2-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:37:06.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ds5mt" for this suite.
Feb 22 22:37:12.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:37:12.812: INFO: namespace: e2e-tests-projected-ds5mt, resource: bindings, ignored listing per whitelist
Feb 22 22:37:12.895: INFO: namespace e2e-tests-projected-ds5mt deletion completed in 6.20657123s

• [SLOW TEST:8.461 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:37:12.895: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:37:12.973: INFO: Creating deployment "test-recreate-deployment"
Feb 22 22:37:12.988: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 22 22:37:13.003: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 22 22:37:15.013: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 22 22:37:15.017: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 22 22:37:15.031: INFO: Updating deployment test-recreate-deployment
Feb 22 22:37:15.031: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 22 22:37:15.182: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-5ktgq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5ktgq/deployments/test-recreate-deployment,UID:65d251ed-36f2-11e9-a687-fac827d478c7,ResourceVersion:23095,Generation:2,CreationTimestamp:2019-02-22 22:37:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-22 22:37:15 +0000 UTC 2019-02-22 22:37:15 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-22 22:37:15 +0000 UTC 2019-02-22 22:37:13 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 22 22:37:15.188: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-5ktgq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5ktgq/replicasets/test-recreate-deployment-697fbf54bf,UID:6717264a-36f2-11e9-96d9-6a889f07183f,ResourceVersion:23093,Generation:1,CreationTimestamp:2019-02-22 22:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 65d251ed-36f2-11e9-a687-fac827d478c7 0xc001d9b577 0xc001d9b578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 22:37:15.188: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 22 22:37:15.188: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-5ktgq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5ktgq/replicasets/test-recreate-deployment-5dfdcc846d,UID:65d4cdf9-36f2-11e9-96d9-6a889f07183f,ResourceVersion:23084,Generation:2,CreationTimestamp:2019-02-22 22:37:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 65d251ed-36f2-11e9-a687-fac827d478c7 0xc001d9b4b7 0xc001d9b4b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 22:37:15.197: INFO: Pod "test-recreate-deployment-697fbf54bf-ttgc8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-ttgc8,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-5ktgq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5ktgq/pods/test-recreate-deployment-697fbf54bf-ttgc8,UID:671843cd-36f2-11e9-96d9-6a889f07183f,ResourceVersion:23096,Generation:0,CreationTimestamp:2019-02-22 22:37:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 6717264a-36f2-11e9-96d9-6a889f07183f 0xc0010060b7 0xc0010060b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dbqcr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dbqcr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dbqcr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance113-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001006130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001006150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:37:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:37:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:37:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:37:15 +0000 UTC  }],Message:,Reason:,HostIP:134.209.32.79,PodIP:,StartTime:2019-02-22 22:37:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:37:15.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5ktgq" for this suite.
Feb 22 22:37:21.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:37:21.409: INFO: namespace: e2e-tests-deployment-5ktgq, resource: bindings, ignored listing per whitelist
Feb 22 22:37:21.468: INFO: namespace e2e-tests-deployment-5ktgq deletion completed in 6.265068428s

• [SLOW TEST:8.573 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:37:21.469: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 22 22:37:21.598: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wrjh6,SelfLink:/api/v1/namespaces/e2e-tests-watch-wrjh6/configmaps/e2e-watch-test-label-changed,UID:6af11512-36f2-11e9-a687-fac827d478c7,ResourceVersion:23141,Generation:0,CreationTimestamp:2019-02-22 22:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 22 22:37:21.599: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wrjh6,SelfLink:/api/v1/namespaces/e2e-tests-watch-wrjh6/configmaps/e2e-watch-test-label-changed,UID:6af11512-36f2-11e9-a687-fac827d478c7,ResourceVersion:23142,Generation:0,CreationTimestamp:2019-02-22 22:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 22 22:37:21.599: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wrjh6,SelfLink:/api/v1/namespaces/e2e-tests-watch-wrjh6/configmaps/e2e-watch-test-label-changed,UID:6af11512-36f2-11e9-a687-fac827d478c7,ResourceVersion:23143,Generation:0,CreationTimestamp:2019-02-22 22:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 22 22:37:31.673: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wrjh6,SelfLink:/api/v1/namespaces/e2e-tests-watch-wrjh6/configmaps/e2e-watch-test-label-changed,UID:6af11512-36f2-11e9-a687-fac827d478c7,ResourceVersion:23166,Generation:0,CreationTimestamp:2019-02-22 22:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 22 22:37:31.673: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wrjh6,SelfLink:/api/v1/namespaces/e2e-tests-watch-wrjh6/configmaps/e2e-watch-test-label-changed,UID:6af11512-36f2-11e9-a687-fac827d478c7,ResourceVersion:23167,Generation:0,CreationTimestamp:2019-02-22 22:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 22 22:37:31.673: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wrjh6,SelfLink:/api/v1/namespaces/e2e-tests-watch-wrjh6/configmaps/e2e-watch-test-label-changed,UID:6af11512-36f2-11e9-a687-fac827d478c7,ResourceVersion:23168,Generation:0,CreationTimestamp:2019-02-22 22:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:37:31.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wrjh6" for this suite.
Feb 22 22:37:37.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:37:37.774: INFO: namespace: e2e-tests-watch-wrjh6, resource: bindings, ignored listing per whitelist
Feb 22 22:37:37.905: INFO: namespace e2e-tests-watch-wrjh6 deletion completed in 6.226236728s

• [SLOW TEST:16.436 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:37:37.905: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-74baf821-36f2-11e9-b6f8-82efa66823a4
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-74baf821-36f2-11e9-b6f8-82efa66823a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:38:46.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f9m7z" for this suite.
Feb 22 22:38:58.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:38:58.857: INFO: namespace: e2e-tests-configmap-f9m7z, resource: bindings, ignored listing per whitelist
Feb 22 22:38:58.934: INFO: namespace e2e-tests-configmap-f9m7z deletion completed in 12.245054767s

• [SLOW TEST:81.029 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:38:58.934: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 22 22:38:59.081: INFO: Waiting up to 5m0s for pod "client-containers-a50e3e1d-36f2-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-containers-jjmv7" to be "success or failure"
Feb 22 22:38:59.100: INFO: Pod "client-containers-a50e3e1d-36f2-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.49348ms
Feb 22 22:39:01.109: INFO: Pod "client-containers-a50e3e1d-36f2-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027949511s
Feb 22 22:39:03.130: INFO: Pod "client-containers-a50e3e1d-36f2-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048351057s
STEP: Saw pod success
Feb 22 22:39:03.130: INFO: Pod "client-containers-a50e3e1d-36f2-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:39:03.137: INFO: Trying to get logs from node conformance113-1 pod client-containers-a50e3e1d-36f2-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 22:39:03.173: INFO: Waiting for pod client-containers-a50e3e1d-36f2-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:39:03.178: INFO: Pod client-containers-a50e3e1d-36f2-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:39:03.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-jjmv7" for this suite.
Feb 22 22:39:09.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:39:09.394: INFO: namespace: e2e-tests-containers-jjmv7, resource: bindings, ignored listing per whitelist
Feb 22 22:39:09.418: INFO: namespace e2e-tests-containers-jjmv7 deletion completed in 6.233262227s

• [SLOW TEST:10.484 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:39:09.419: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0222 22:39:15.625790      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 22:39:15.625: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:39:15.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-g6xxq" for this suite.
Feb 22 22:39:21.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:39:21.743: INFO: namespace: e2e-tests-gc-g6xxq, resource: bindings, ignored listing per whitelist
Feb 22 22:39:21.879: INFO: namespace e2e-tests-gc-g6xxq deletion completed in 6.236844913s

• [SLOW TEST:12.461 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:39:21.880: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 22 22:39:21.966: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:39:26.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-jzptw" for this suite.
Feb 22 22:39:32.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:39:32.972: INFO: namespace: e2e-tests-init-container-jzptw, resource: bindings, ignored listing per whitelist
Feb 22 22:39:33.023: INFO: namespace e2e-tests-init-container-jzptw deletion completed in 6.25974028s

• [SLOW TEST:11.143 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:39:33.026: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 22 22:39:35.703: INFO: Successfully updated pod "annotationupdateb95d6bde-36f2-11e9-b6f8-82efa66823a4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:39:37.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rgsxm" for this suite.
Feb 22 22:39:59.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:39:59.954: INFO: namespace: e2e-tests-downward-api-rgsxm, resource: bindings, ignored listing per whitelist
Feb 22 22:40:00.145: INFO: namespace e2e-tests-downward-api-rgsxm deletion completed in 22.377316876s

• [SLOW TEST:27.119 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:40:00.146: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 22 22:40:00.307: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 22 22:40:05.315: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:40:06.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-5pfqm" for this suite.
Feb 22 22:40:12.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:40:12.593: INFO: namespace: e2e-tests-replication-controller-5pfqm, resource: bindings, ignored listing per whitelist
Feb 22 22:40:12.640: INFO: namespace e2e-tests-replication-controller-5pfqm deletion completed in 6.27700654s

• [SLOW TEST:12.494 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:40:12.640: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-d0f52fcf-36f2-11e9-b6f8-82efa66823a4
Feb 22 22:40:12.737: INFO: Pod name my-hostname-basic-d0f52fcf-36f2-11e9-b6f8-82efa66823a4: Found 0 pods out of 1
Feb 22 22:40:17.744: INFO: Pod name my-hostname-basic-d0f52fcf-36f2-11e9-b6f8-82efa66823a4: Found 1 pods out of 1
Feb 22 22:40:17.744: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d0f52fcf-36f2-11e9-b6f8-82efa66823a4" are running
Feb 22 22:40:17.748: INFO: Pod "my-hostname-basic-d0f52fcf-36f2-11e9-b6f8-82efa66823a4-mnqwd" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:40:12 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:40:15 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:40:15 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:40:12 +0000 UTC Reason: Message:}])
Feb 22 22:40:17.748: INFO: Trying to dial the pod
Feb 22 22:40:22.774: INFO: Controller my-hostname-basic-d0f52fcf-36f2-11e9-b6f8-82efa66823a4: Got expected result from replica 1 [my-hostname-basic-d0f52fcf-36f2-11e9-b6f8-82efa66823a4-mnqwd]: "my-hostname-basic-d0f52fcf-36f2-11e9-b6f8-82efa66823a4-mnqwd", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:40:22.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-h6h7d" for this suite.
Feb 22 22:40:28.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:40:28.837: INFO: namespace: e2e-tests-replication-controller-h6h7d, resource: bindings, ignored listing per whitelist
Feb 22 22:40:28.979: INFO: namespace e2e-tests-replication-controller-h6h7d deletion completed in 6.198163404s

• [SLOW TEST:16.339 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:40:28.980: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:40:29.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 version'
Feb 22 22:40:29.147: INFO: stderr: ""
Feb 22 22:40:29.147: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.1\", GitCommit:\"eec55b9ba98609a46fee712359c7b5b365bdd920\", GitTreeState:\"clean\", BuildDate:\"2018-12-13T10:31:33Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:40:29.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b9kpw" for this suite.
Feb 22 22:40:35.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:40:35.400: INFO: namespace: e2e-tests-kubectl-b9kpw, resource: bindings, ignored listing per whitelist
Feb 22 22:40:35.415: INFO: namespace e2e-tests-kubectl-b9kpw deletion completed in 6.261527414s

• [SLOW TEST:6.435 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:40:35.416: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:40:37.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-l8mqf" for this suite.
Feb 22 22:41:23.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:41:23.894: INFO: namespace: e2e-tests-kubelet-test-l8mqf, resource: bindings, ignored listing per whitelist
Feb 22 22:41:23.959: INFO: namespace e2e-tests-kubelet-test-l8mqf deletion completed in 46.238150188s

• [SLOW TEST:48.544 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:41:23.960: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0222 22:41:34.148299      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 22:41:34.148: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:41:34.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kh2hv" for this suite.
Feb 22 22:41:40.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:41:40.369: INFO: namespace: e2e-tests-gc-kh2hv, resource: bindings, ignored listing per whitelist
Feb 22 22:41:40.373: INFO: namespace e2e-tests-gc-kh2hv deletion completed in 6.219837777s

• [SLOW TEST:16.413 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:41:40.373: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-054748f1-36f3-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 22:41:40.577: INFO: Waiting up to 5m0s for pod "pod-secrets-054eb0f8-36f3-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-secrets-g4zdq" to be "success or failure"
Feb 22 22:41:40.581: INFO: Pod "pod-secrets-054eb0f8-36f3-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.816544ms
Feb 22 22:41:42.588: INFO: Pod "pod-secrets-054eb0f8-36f3-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010671821s
STEP: Saw pod success
Feb 22 22:41:42.588: INFO: Pod "pod-secrets-054eb0f8-36f3-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:41:42.595: INFO: Trying to get logs from node conformance113-2 pod pod-secrets-054eb0f8-36f3-11e9-b6f8-82efa66823a4 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:41:42.671: INFO: Waiting for pod pod-secrets-054eb0f8-36f3-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:41:42.686: INFO: Pod pod-secrets-054eb0f8-36f3-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:41:42.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g4zdq" for this suite.
Feb 22 22:41:48.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:41:48.985: INFO: namespace: e2e-tests-secrets-g4zdq, resource: bindings, ignored listing per whitelist
Feb 22 22:41:49.000: INFO: namespace e2e-tests-secrets-g4zdq deletion completed in 6.304733013s

• [SLOW TEST:8.627 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:41:49.001: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 22 22:41:49.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 create -f - --namespace=e2e-tests-kubectl-f69sw'
Feb 22 22:41:49.621: INFO: stderr: ""
Feb 22 22:41:49.621: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 22 22:41:50.632: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 22:41:50.632: INFO: Found 0 / 1
Feb 22 22:41:51.630: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 22:41:51.630: INFO: Found 0 / 1
Feb 22 22:41:52.635: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 22:41:52.635: INFO: Found 1 / 1
Feb 22 22:41:52.635: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 22 22:41:52.640: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 22:41:52.640: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 22 22:41:52.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 patch pod redis-master-9lqsp --namespace=e2e-tests-kubectl-f69sw -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 22 22:41:52.791: INFO: stderr: ""
Feb 22 22:41:52.791: INFO: stdout: "pod/redis-master-9lqsp patched\n"
STEP: checking annotations
Feb 22 22:41:52.799: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 22:41:52.799: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:41:52.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f69sw" for this suite.
Feb 22 22:42:14.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:42:14.866: INFO: namespace: e2e-tests-kubectl-f69sw, resource: bindings, ignored listing per whitelist
Feb 22 22:42:15.129: INFO: namespace e2e-tests-kubectl-f69sw deletion completed in 22.317618678s

• [SLOW TEST:26.129 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:42:15.131: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-1a01d58c-36f3-11e9-b6f8-82efa66823a4
STEP: Creating configMap with name cm-test-opt-upd-1a01d5d1-36f3-11e9-b6f8-82efa66823a4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1a01d58c-36f3-11e9-b6f8-82efa66823a4
STEP: Updating configmap cm-test-opt-upd-1a01d5d1-36f3-11e9-b6f8-82efa66823a4
STEP: Creating configMap with name cm-test-opt-create-1a01d5e3-36f3-11e9-b6f8-82efa66823a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:42:23.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6rdn7" for this suite.
Feb 22 22:42:45.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:42:45.747: INFO: namespace: e2e-tests-configmap-6rdn7, resource: bindings, ignored listing per whitelist
Feb 22 22:42:45.823: INFO: namespace e2e-tests-configmap-6rdn7 deletion completed in 22.24049224s

• [SLOW TEST:30.692 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:42:45.824: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-nfjpl
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-nfjpl
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-nfjpl
Feb 22 22:42:46.093: INFO: Found 0 stateful pods, waiting for 1
Feb 22 22:42:56.108: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 22 22:42:56.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 22:42:56.574: INFO: stderr: ""
Feb 22 22:42:56.574: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 22:42:56.574: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 22:42:56.583: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 22:42:56.583: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 22:42:56.592: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 22 22:43:06.637: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998969s
Feb 22 22:43:07.641: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.991791712s
Feb 22 22:43:08.647: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987107051s
Feb 22 22:43:09.653: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.980988889s
Feb 22 22:43:10.813: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.97558379s
Feb 22 22:43:11.820: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.815300593s
Feb 22 22:43:12.828: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.807954949s
Feb 22 22:43:13.834: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.800387201s
Feb 22 22:43:14.841: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.794185251s
Feb 22 22:43:15.849: INFO: Verifying statefulset ss doesn't scale past 1 for another 787.13022ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-nfjpl
Feb 22 22:43:16.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:43:17.158: INFO: stderr: ""
Feb 22 22:43:17.158: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 22:43:17.158: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 22:43:17.165: INFO: Found 1 stateful pods, waiting for 3
Feb 22 22:43:27.181: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 22:43:27.181: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 22:43:27.181: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 22 22:43:27.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 22:43:27.599: INFO: stderr: ""
Feb 22 22:43:27.599: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 22:43:27.599: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 22:43:27.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 22:43:28.108: INFO: stderr: ""
Feb 22 22:43:28.108: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 22:43:28.108: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 22:43:28.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 22:43:28.434: INFO: stderr: ""
Feb 22 22:43:28.434: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 22:43:28.434: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 22:43:28.434: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 22:43:28.440: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 22 22:43:38.459: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 22:43:38.459: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 22:43:38.459: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 22:43:38.498: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999365s
Feb 22 22:43:39.503: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993044755s
Feb 22 22:43:40.509: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988153805s
Feb 22 22:43:41.514: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98218728s
Feb 22 22:43:42.520: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976918882s
Feb 22 22:43:43.527: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.970681187s
Feb 22 22:43:44.535: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963815559s
Feb 22 22:43:45.541: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.956105037s
Feb 22 22:43:46.549: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.949589923s
Feb 22 22:43:47.566: INFO: Verifying statefulset ss doesn't scale past 3 for another 941.615269ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-nfjpl
Feb 22 22:43:48.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:43:48.876: INFO: stderr: ""
Feb 22 22:43:48.876: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 22:43:48.876: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 22:43:48.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:43:49.419: INFO: stderr: ""
Feb 22 22:43:49.419: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 22:43:49.419: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 22:43:49.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:43:49.728: INFO: rc: 126
Feb 22 22:43:49.741: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil> cannot exec in a stopped state: unknown
 command terminated with exit code 126
 [] <nil> 0xc00224d9e0 exit status 126 <nil> <nil> true [0xc00449c3c8 0xc00449c410 0xc00449c490] [0xc00449c3c8 0xc00449c410 0xc00449c490] [0xc00449c3f8 0xc00449c438] [0x92f8e0 0x92f8e0] 0xc003e022a0 <nil>}:
Command stdout:
cannot exec in a stopped state: unknown

stderr:
command terminated with exit code 126

error:
exit status 126

Feb 22 22:43:59.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:43:59.824: INFO: rc: 1
Feb 22 22:43:59.824: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00224de90 exit status 1 <nil> <nil> true [0xc00449c4b8 0xc00449c570 0xc00449c5c0] [0xc00449c4b8 0xc00449c570 0xc00449c5c0] [0xc00449c508 0xc00449c5a8] [0x92f8e0 0x92f8e0] 0xc003e029c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:44:09.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:44:09.914: INFO: rc: 1
Feb 22 22:44:09.914: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021bc2d0 exit status 1 <nil> <nil> true [0xc00449c608 0xc00449c6a8 0xc00449c768] [0xc00449c608 0xc00449c6a8 0xc00449c768] [0xc00449c668 0xc00449c758] [0x92f8e0 0x92f8e0] 0xc003e03020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:44:19.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:44:20.016: INFO: rc: 1
Feb 22 22:44:20.017: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021bc6c0 exit status 1 <nil> <nil> true [0xc00449c7b0 0xc00449c7e8 0xc00449c888] [0xc00449c7b0 0xc00449c7e8 0xc00449c888] [0xc00449c7d0 0xc00449c830] [0x92f8e0 0x92f8e0] 0xc003e034a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:44:30.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:44:30.151: INFO: rc: 1
Feb 22 22:44:30.151: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021bcab0 exit status 1 <nil> <nil> true [0xc00449c8a0 0xc00449c948 0xc00449c9b0] [0xc00449c8a0 0xc00449c948 0xc00449c9b0] [0xc00449c908 0xc00449c9a8] [0x92f8e0 0x92f8e0] 0xc003e03860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:44:40.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:44:40.230: INFO: rc: 1
Feb 22 22:44:40.230: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021bcea0 exit status 1 <nil> <nil> true [0xc00449c9b8 0xc00449c9d0 0xc00449ca08] [0xc00449c9b8 0xc00449c9d0 0xc00449ca08] [0xc00449c9c8 0xc00449ca00] [0x92f8e0 0x92f8e0] 0xc003e03bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:44:50.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:44:50.343: INFO: rc: 1
Feb 22 22:44:50.343: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021bd4d0 exit status 1 <nil> <nil> true [0xc00449ca10 0xc00449ca28 0xc00449ca40] [0xc00449ca10 0xc00449ca28 0xc00449ca40] [0xc00449ca20 0xc00449ca38] [0x92f8e0 0x92f8e0] 0xc003e03f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:45:00.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:45:00.457: INFO: rc: 1
Feb 22 22:45:00.457: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021bd8c0 exit status 1 <nil> <nil> true [0xc00449ca48 0xc00449ca60 0xc00449ca78] [0xc00449ca48 0xc00449ca60 0xc00449ca78] [0xc00449ca58 0xc00449ca70] [0x92f8e0 0x92f8e0] 0xc001674480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:45:10.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:45:10.551: INFO: rc: 1
Feb 22 22:45:10.551: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021bde60 exit status 1 <nil> <nil> true [0xc00449ca80 0xc00449ca98 0xc00449cab0] [0xc00449ca80 0xc00449ca98 0xc00449cab0] [0xc00449ca90 0xc00449caa8] [0x92f8e0 0x92f8e0] 0xc001674a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:45:20.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:45:20.637: INFO: rc: 1
Feb 22 22:45:20.637: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00224c7e0 exit status 1 <nil> <nil> true [0xc0017cc0f8 0xc0017cc370 0xc0017cc4d0] [0xc0017cc0f8 0xc0017cc370 0xc0017cc4d0] [0xc0017cc270 0xc0017cc498] [0x92f8e0 0x92f8e0] 0xc003e025a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:45:30.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:45:30.710: INFO: rc: 1
Feb 22 22:45:30.710: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00224d0e0 exit status 1 <nil> <nil> true [0xc0017cc5e8 0xc0017cc768 0xc0017cc928] [0xc0017cc5e8 0xc0017cc768 0xc0017cc928] [0xc0017cc718 0xc0017cc878] [0x92f8e0 0x92f8e0] 0xc003e02c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:45:40.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:45:40.845: INFO: rc: 1
Feb 22 22:45:40.845: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00224d560 exit status 1 <nil> <nil> true [0xc0017cc9c8 0xc0017ccb80 0xc0017ccd08] [0xc0017cc9c8 0xc0017ccb80 0xc0017ccd08] [0xc0017ccb10 0xc0017ccc78] [0x92f8e0 0x92f8e0] 0xc003e031a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:45:50.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:45:50.994: INFO: rc: 1
Feb 22 22:45:50.994: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00224d980 exit status 1 <nil> <nil> true [0xc0017ccd38 0xc0017ccde8 0xc0017cced0] [0xc0017ccd38 0xc0017ccde8 0xc0017cced0] [0xc0017ccda8 0xc0017cce98] [0x92f8e0 0x92f8e0] 0xc003e035c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:46:00.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:46:01.168: INFO: rc: 1
Feb 22 22:46:01.168: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00224dda0 exit status 1 <nil> <nil> true [0xc0017ccf68 0xc0017ccff0 0xc0017cd140] [0xc0017ccf68 0xc0017ccff0 0xc0017cd140] [0xc0017ccfc8 0xc0017cd0d8] [0x92f8e0 0x92f8e0] 0xc003e03980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:46:11.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:46:11.303: INFO: rc: 1
Feb 22 22:46:11.303: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023d62d0 exit status 1 <nil> <nil> true [0xc0017cd1a0 0xc0017cd2c8 0xc0017cd360] [0xc0017cd1a0 0xc0017cd2c8 0xc0017cd360] [0xc0017cd208 0xc0017cd348] [0x92f8e0 0x92f8e0] 0xc003e03d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:46:21.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:46:21.420: INFO: rc: 1
Feb 22 22:46:21.420: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023d66c0 exit status 1 <nil> <nil> true [0xc0017cd390 0xc0017cd448 0xc0017cd4d8] [0xc0017cd390 0xc0017cd448 0xc0017cd4d8] [0xc0017cd410 0xc0017cd498] [0x92f8e0 0x92f8e0] 0xc003ed2060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:46:31.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:46:31.553: INFO: rc: 1
Feb 22 22:46:31.553: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023d6f90 exit status 1 <nil> <nil> true [0xc0017cd538 0xc0017cd5c8 0xc0017cd680] [0xc0017cd538 0xc0017cd5c8 0xc0017cd680] [0xc0017cd598 0xc0017cd628] [0x92f8e0 0x92f8e0] 0xc003ed2360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:46:41.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:46:41.688: INFO: rc: 1
Feb 22 22:46:41.688: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023d74a0 exit status 1 <nil> <nil> true [0xc0017cd6b8 0xc0017cd800 0xc0017cd880] [0xc0017cd6b8 0xc0017cd800 0xc0017cd880] [0xc0017cd7b8 0xc0017cd850] [0x92f8e0 0x92f8e0] 0xc003ed27e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:46:51.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:46:51.829: INFO: rc: 1
Feb 22 22:46:51.829: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023d7c20 exit status 1 <nil> <nil> true [0xc0017cd8f0 0xc0017cd990 0xc0017cda08] [0xc0017cd8f0 0xc0017cd990 0xc0017cda08] [0xc0017cd978 0xc0017cd9d8] [0x92f8e0 0x92f8e0] 0xc003ed2cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:47:01.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:47:01.976: INFO: rc: 1
Feb 22 22:47:01.976: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004250420 exit status 1 <nil> <nil> true [0xc0017cda20 0xc0017cda98 0xc0017cdb28] [0xc0017cda20 0xc0017cda98 0xc0017cdb28] [0xc0017cda80 0xc0017cdad0] [0x92f8e0 0x92f8e0] 0xc003ed3140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:47:11.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:47:12.151: INFO: rc: 1
Feb 22 22:47:12.151: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0042508d0 exit status 1 <nil> <nil> true [0xc0017cdb38 0xc0017cdb98 0xc0017cdc08] [0xc0017cdb38 0xc0017cdb98 0xc0017cdc08] [0xc0017cdb80 0xc0017cdbf0] [0x92f8e0 0x92f8e0] 0xc003ed37a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:47:22.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:47:22.279: INFO: rc: 1
Feb 22 22:47:22.279: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004250cc0 exit status 1 <nil> <nil> true [0xc0017cdc30 0xc0017cdc80 0xc0017cdce0] [0xc0017cdc30 0xc0017cdc80 0xc0017cdce0] [0xc0017cdc78 0xc0017cdcc8] [0x92f8e0 0x92f8e0] 0xc003ed3c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:47:32.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:47:32.407: INFO: rc: 1
Feb 22 22:47:32.408: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023d64e0 exit status 1 <nil> <nil> true [0xc0017cc0f8 0xc0017cc370 0xc0017cc4d0] [0xc0017cc0f8 0xc0017cc370 0xc0017cc4d0] [0xc0017cc270 0xc0017cc498] [0x92f8e0 0x92f8e0] 0xc003e025a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:47:42.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:47:42.503: INFO: rc: 1
Feb 22 22:47:42.504: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023d6db0 exit status 1 <nil> <nil> true [0xc0017cc5e8 0xc0017cc768 0xc0017cc928] [0xc0017cc5e8 0xc0017cc768 0xc0017cc928] [0xc0017cc718 0xc0017cc878] [0x92f8e0 0x92f8e0] 0xc003e02c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:47:52.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:47:52.584: INFO: rc: 1
Feb 22 22:47:52.585: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023d7200 exit status 1 <nil> <nil> true [0xc0017cc9c8 0xc0017ccb80 0xc0017ccd08] [0xc0017cc9c8 0xc0017ccb80 0xc0017ccd08] [0xc0017ccb10 0xc0017ccc78] [0x92f8e0 0x92f8e0] 0xc003e031a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:48:02.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:48:02.714: INFO: rc: 1
Feb 22 22:48:02.714: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023d7a70 exit status 1 <nil> <nil> true [0xc0017ccd38 0xc0017ccde8 0xc0017cced0] [0xc0017ccd38 0xc0017ccde8 0xc0017cced0] [0xc0017ccda8 0xc0017cce98] [0x92f8e0 0x92f8e0] 0xc003e035c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:48:12.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:48:12.817: INFO: rc: 1
Feb 22 22:48:12.817: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00224c150 exit status 1 <nil> <nil> true [0xc0017ccf68 0xc0017ccff0 0xc0017cd140] [0xc0017ccf68 0xc0017ccff0 0xc0017cd140] [0xc0017ccfc8 0xc0017cd0d8] [0x92f8e0 0x92f8e0] 0xc003e03980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:48:22.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:48:22.909: INFO: rc: 1
Feb 22 22:48:22.909: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00224cde0 exit status 1 <nil> <nil> true [0xc0017cd1a0 0xc0017cd2c8 0xc0017cd360] [0xc0017cd1a0 0xc0017cd2c8 0xc0017cd360] [0xc0017cd208 0xc0017cd348] [0x92f8e0 0x92f8e0] 0xc003e03d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:48:32.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:48:33.028: INFO: rc: 1
Feb 22 22:48:33.028: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00224d320 exit status 1 <nil> <nil> true [0xc0017cd390 0xc0017cd448 0xc0017cd4d8] [0xc0017cd390 0xc0017cd448 0xc0017cd4d8] [0xc0017cd410 0xc0017cd498] [0x92f8e0 0x92f8e0] 0xc003ed2060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:48:43.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:48:43.121: INFO: rc: 1
Feb 22 22:48:43.121: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00224d740 exit status 1 <nil> <nil> true [0xc0017cd538 0xc0017cd5c8 0xc0017cd680] [0xc0017cd538 0xc0017cd5c8 0xc0017cd680] [0xc0017cd598 0xc0017cd628] [0x92f8e0 0x92f8e0] 0xc003ed2360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 22 22:48:53.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 exec --namespace=e2e-tests-statefulset-nfjpl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:48:53.205: INFO: rc: 1
Feb 22 22:48:53.205: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb 22 22:48:53.205: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 22 22:48:53.229: INFO: Deleting all statefulset in ns e2e-tests-statefulset-nfjpl
Feb 22 22:48:53.233: INFO: Scaling statefulset ss to 0
Feb 22 22:48:53.243: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 22:48:53.247: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:48:53.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-nfjpl" for this suite.
Feb 22 22:48:59.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:48:59.422: INFO: namespace: e2e-tests-statefulset-nfjpl, resource: bindings, ignored listing per whitelist
Feb 22 22:48:59.493: INFO: namespace e2e-tests-statefulset-nfjpl deletion completed in 6.21200117s

• [SLOW TEST:373.669 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:48:59.494: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 22 22:48:59.624: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-hmh4g" to be "success or failure"
Feb 22 22:48:59.642: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 17.880806ms
Feb 22 22:49:01.649: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024946887s
Feb 22 22:49:03.666: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042122786s
STEP: Saw pod success
Feb 22 22:49:03.666: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 22 22:49:03.669: INFO: Trying to get logs from node conformance113-3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 22 22:49:03.711: INFO: Waiting for pod pod-host-path-test to disappear
Feb 22 22:49:03.756: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:49:03.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-hmh4g" for this suite.
Feb 22 22:49:09.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:49:09.827: INFO: namespace: e2e-tests-hostpath-hmh4g, resource: bindings, ignored listing per whitelist
Feb 22 22:49:09.960: INFO: namespace e2e-tests-hostpath-hmh4g deletion completed in 6.190162646s

• [SLOW TEST:10.466 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:49:09.960: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 22 22:49:16.145: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 22:49:16.149: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 22:49:18.149: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 22:49:18.155: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 22:49:20.149: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 22:49:20.154: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:49:20.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hd4x2" for this suite.
Feb 22 22:49:42.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:49:42.239: INFO: namespace: e2e-tests-container-lifecycle-hook-hd4x2, resource: bindings, ignored listing per whitelist
Feb 22 22:49:42.374: INFO: namespace e2e-tests-container-lifecycle-hook-hd4x2 deletion completed in 22.197437921s

• [SLOW TEST:32.414 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:49:42.374: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-24893908-36f4-11e9-b6f8-82efa66823a4
STEP: Creating a pod to test consume secrets
Feb 22 22:49:42.465: INFO: Waiting up to 5m0s for pod "pod-secrets-248aecd8-36f4-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-secrets-h5vlb" to be "success or failure"
Feb 22 22:49:42.479: INFO: Pod "pod-secrets-248aecd8-36f4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.48588ms
Feb 22 22:49:44.485: INFO: Pod "pod-secrets-248aecd8-36f4-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020030211s
STEP: Saw pod success
Feb 22 22:49:44.485: INFO: Pod "pod-secrets-248aecd8-36f4-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:49:44.491: INFO: Trying to get logs from node conformance113-2 pod pod-secrets-248aecd8-36f4-11e9-b6f8-82efa66823a4 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:49:44.531: INFO: Waiting for pod pod-secrets-248aecd8-36f4-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:49:44.561: INFO: Pod pod-secrets-248aecd8-36f4-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:49:44.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-h5vlb" for this suite.
Feb 22 22:49:50.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:49:50.712: INFO: namespace: e2e-tests-secrets-h5vlb, resource: bindings, ignored listing per whitelist
Feb 22 22:49:50.761: INFO: namespace e2e-tests-secrets-h5vlb deletion completed in 6.193851632s

• [SLOW TEST:8.386 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:49:50.761: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 22:49:50.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-zqz46'
Feb 22 22:49:50.973: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 22 22:49:50.973: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb 22 22:49:52.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-zqz46'
Feb 22 22:49:53.084: INFO: stderr: ""
Feb 22 22:49:53.085: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:49:53.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zqz46" for this suite.
Feb 22 22:51:15.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:51:15.169: INFO: namespace: e2e-tests-kubectl-zqz46, resource: bindings, ignored listing per whitelist
Feb 22 22:51:15.285: INFO: namespace e2e-tests-kubectl-zqz46 deletion completed in 1m22.194823737s

• [SLOW TEST:84.524 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:51:15.285: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 22 22:51:15.435: INFO: Waiting up to 5m0s for pod "var-expansion-5bf4db9e-36f4-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-var-expansion-jbdzg" to be "success or failure"
Feb 22 22:51:15.441: INFO: Pod "var-expansion-5bf4db9e-36f4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.196824ms
Feb 22 22:51:17.446: INFO: Pod "var-expansion-5bf4db9e-36f4-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010878433s
STEP: Saw pod success
Feb 22 22:51:17.446: INFO: Pod "var-expansion-5bf4db9e-36f4-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:51:17.449: INFO: Trying to get logs from node conformance113-1 pod var-expansion-5bf4db9e-36f4-11e9-b6f8-82efa66823a4 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:51:17.474: INFO: Waiting for pod var-expansion-5bf4db9e-36f4-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:51:17.478: INFO: Pod var-expansion-5bf4db9e-36f4-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:51:17.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-jbdzg" for this suite.
Feb 22 22:51:23.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:51:23.662: INFO: namespace: e2e-tests-var-expansion-jbdzg, resource: bindings, ignored listing per whitelist
Feb 22 22:51:23.713: INFO: namespace e2e-tests-var-expansion-jbdzg deletion completed in 6.222587905s

• [SLOW TEST:8.427 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:51:23.713: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0222 22:52:03.893805      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 22:52:03.893: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:52:03.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qhkw9" for this suite.
Feb 22 22:52:11.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:52:12.088: INFO: namespace: e2e-tests-gc-qhkw9, resource: bindings, ignored listing per whitelist
Feb 22 22:52:12.214: INFO: namespace e2e-tests-gc-qhkw9 deletion completed in 8.314803632s

• [SLOW TEST:48.501 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:52:12.215: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 22 22:52:12.307: INFO: Waiting up to 5m0s for pod "var-expansion-7dda5897-36f4-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-var-expansion-7rdqx" to be "success or failure"
Feb 22 22:52:12.321: INFO: Pod "var-expansion-7dda5897-36f4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.733967ms
Feb 22 22:52:14.396: INFO: Pod "var-expansion-7dda5897-36f4-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08843293s
STEP: Saw pod success
Feb 22 22:52:14.396: INFO: Pod "var-expansion-7dda5897-36f4-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:52:14.403: INFO: Trying to get logs from node conformance113-3 pod var-expansion-7dda5897-36f4-11e9-b6f8-82efa66823a4 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:52:14.444: INFO: Waiting for pod var-expansion-7dda5897-36f4-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:52:14.462: INFO: Pod var-expansion-7dda5897-36f4-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:52:14.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-7rdqx" for this suite.
Feb 22 22:52:20.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:52:20.632: INFO: namespace: e2e-tests-var-expansion-7rdqx, resource: bindings, ignored listing per whitelist
Feb 22 22:52:20.736: INFO: namespace e2e-tests-var-expansion-7rdqx deletion completed in 6.261715367s

• [SLOW TEST:8.521 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:52:20.737: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:52:20.835: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82eeba11-36f4-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-p8dcj" to be "success or failure"
Feb 22 22:52:20.849: INFO: Pod "downwardapi-volume-82eeba11-36f4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.666418ms
Feb 22 22:52:22.855: INFO: Pod "downwardapi-volume-82eeba11-36f4-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020376395s
STEP: Saw pod success
Feb 22 22:52:22.856: INFO: Pod "downwardapi-volume-82eeba11-36f4-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:52:22.860: INFO: Trying to get logs from node conformance113-1 pod downwardapi-volume-82eeba11-36f4-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 22:52:22.910: INFO: Waiting for pod downwardapi-volume-82eeba11-36f4-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:52:22.915: INFO: Pod downwardapi-volume-82eeba11-36f4-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:52:22.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p8dcj" for this suite.
Feb 22 22:52:30.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:52:30.967: INFO: namespace: e2e-tests-downward-api-p8dcj, resource: bindings, ignored listing per whitelist
Feb 22 22:52:31.187: INFO: namespace e2e-tests-downward-api-p8dcj deletion completed in 8.266544627s

• [SLOW TEST:10.451 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:52:31.191: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 22 22:52:31.332: INFO: Waiting up to 5m0s for pod "pod-892e3ea8-36f4-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-emptydir-rfkv8" to be "success or failure"
Feb 22 22:52:31.365: INFO: Pod "pod-892e3ea8-36f4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 32.643104ms
Feb 22 22:52:33.369: INFO: Pod "pod-892e3ea8-36f4-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037390762s
STEP: Saw pod success
Feb 22 22:52:33.369: INFO: Pod "pod-892e3ea8-36f4-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:52:33.373: INFO: Trying to get logs from node conformance113-2 pod pod-892e3ea8-36f4-11e9-b6f8-82efa66823a4 container test-container: <nil>
STEP: delete the pod
Feb 22 22:52:33.460: INFO: Waiting for pod pod-892e3ea8-36f4-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:52:33.464: INFO: Pod pod-892e3ea8-36f4-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:52:33.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rfkv8" for this suite.
Feb 22 22:52:39.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:52:39.704: INFO: namespace: e2e-tests-emptydir-rfkv8, resource: bindings, ignored listing per whitelist
Feb 22 22:52:39.712: INFO: namespace e2e-tests-emptydir-rfkv8 deletion completed in 6.242332315s

• [SLOW TEST:8.522 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:52:39.713: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:52:39.842: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e4376f2-36f4-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-pmmnv" to be "success or failure"
Feb 22 22:52:39.855: INFO: Pod "downwardapi-volume-8e4376f2-36f4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.143951ms
Feb 22 22:52:41.861: INFO: Pod "downwardapi-volume-8e4376f2-36f4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01920895s
Feb 22 22:52:43.868: INFO: Pod "downwardapi-volume-8e4376f2-36f4-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025991483s
STEP: Saw pod success
Feb 22 22:52:43.868: INFO: Pod "downwardapi-volume-8e4376f2-36f4-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:52:43.876: INFO: Trying to get logs from node conformance113-1 pod downwardapi-volume-8e4376f2-36f4-11e9-b6f8-82efa66823a4 container client-container: <nil>
STEP: delete the pod
Feb 22 22:52:43.925: INFO: Waiting for pod downwardapi-volume-8e4376f2-36f4-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:52:43.930: INFO: Pod downwardapi-volume-8e4376f2-36f4-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:52:43.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pmmnv" for this suite.
Feb 22 22:52:49.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:52:50.155: INFO: namespace: e2e-tests-downward-api-pmmnv, resource: bindings, ignored listing per whitelist
Feb 22 22:52:50.166: INFO: namespace e2e-tests-downward-api-pmmnv deletion completed in 6.227754502s

• [SLOW TEST:10.453 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:52:50.166: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-8mhp
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 22:52:50.311: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-8mhp" in namespace "e2e-tests-subpath-n4dxv" to be "success or failure"
Feb 22 22:52:50.338: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Pending", Reason="", readiness=false. Elapsed: 26.703148ms
Feb 22 22:52:52.344: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033316498s
Feb 22 22:52:54.352: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Running", Reason="", readiness=false. Elapsed: 4.040790372s
Feb 22 22:52:56.375: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Running", Reason="", readiness=false. Elapsed: 6.0639927s
Feb 22 22:52:58.381: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Running", Reason="", readiness=false. Elapsed: 8.070522825s
Feb 22 22:53:00.386: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Running", Reason="", readiness=false. Elapsed: 10.075545383s
Feb 22 22:53:02.391: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Running", Reason="", readiness=false. Elapsed: 12.079994665s
Feb 22 22:53:04.396: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Running", Reason="", readiness=false. Elapsed: 14.085298936s
Feb 22 22:53:06.411: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Running", Reason="", readiness=false. Elapsed: 16.100181969s
Feb 22 22:53:08.418: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Running", Reason="", readiness=false. Elapsed: 18.106607086s
Feb 22 22:53:10.425: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Running", Reason="", readiness=false. Elapsed: 20.11384124s
Feb 22 22:53:12.432: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Running", Reason="", readiness=false. Elapsed: 22.121482034s
Feb 22 22:53:14.437: INFO: Pod "pod-subpath-test-downwardapi-8mhp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.125977481s
STEP: Saw pod success
Feb 22 22:53:14.437: INFO: Pod "pod-subpath-test-downwardapi-8mhp" satisfied condition "success or failure"
Feb 22 22:53:14.441: INFO: Trying to get logs from node conformance113-3 pod pod-subpath-test-downwardapi-8mhp container test-container-subpath-downwardapi-8mhp: <nil>
STEP: delete the pod
Feb 22 22:53:14.495: INFO: Waiting for pod pod-subpath-test-downwardapi-8mhp to disappear
Feb 22 22:53:14.511: INFO: Pod pod-subpath-test-downwardapi-8mhp no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-8mhp
Feb 22 22:53:14.512: INFO: Deleting pod "pod-subpath-test-downwardapi-8mhp" in namespace "e2e-tests-subpath-n4dxv"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:53:14.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-n4dxv" for this suite.
Feb 22 22:53:20.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:53:20.762: INFO: namespace: e2e-tests-subpath-n4dxv, resource: bindings, ignored listing per whitelist
Feb 22 22:53:20.770: INFO: namespace e2e-tests-subpath-n4dxv deletion completed in 6.243342042s

• [SLOW TEST:30.604 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:53:20.770: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 22 22:53:20.915: INFO: Waiting up to 5m0s for pod "downward-api-a6bf044c-36f4-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-kskjz" to be "success or failure"
Feb 22 22:53:20.927: INFO: Pod "downward-api-a6bf044c-36f4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.730578ms
Feb 22 22:53:22.932: INFO: Pod "downward-api-a6bf044c-36f4-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016818963s
Feb 22 22:53:24.941: INFO: Pod "downward-api-a6bf044c-36f4-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02570007s
STEP: Saw pod success
Feb 22 22:53:24.941: INFO: Pod "downward-api-a6bf044c-36f4-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:53:24.947: INFO: Trying to get logs from node conformance113-1 pod downward-api-a6bf044c-36f4-11e9-b6f8-82efa66823a4 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:53:24.983: INFO: Waiting for pod downward-api-a6bf044c-36f4-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:53:24.988: INFO: Pod downward-api-a6bf044c-36f4-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:53:24.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kskjz" for this suite.
Feb 22 22:53:31.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:53:31.126: INFO: namespace: e2e-tests-downward-api-kskjz, resource: bindings, ignored listing per whitelist
Feb 22 22:53:31.263: INFO: namespace e2e-tests-downward-api-kskjz deletion completed in 6.268240465s

• [SLOW TEST:10.493 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:53:31.264: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-nt7kx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nt7kx to expose endpoints map[]
Feb 22 22:53:31.403: INFO: Get endpoints failed (12.188475ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 22 22:53:32.408: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nt7kx exposes endpoints map[] (1.01777722s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-nt7kx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nt7kx to expose endpoints map[pod1:[80]]
Feb 22 22:53:34.524: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nt7kx exposes endpoints map[pod1:[80]] (2.10317664s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-nt7kx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nt7kx to expose endpoints map[pod1:[80] pod2:[80]]
Feb 22 22:53:36.608: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nt7kx exposes endpoints map[pod1:[80] pod2:[80]] (2.073286958s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-nt7kx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nt7kx to expose endpoints map[pod2:[80]]
Feb 22 22:53:37.717: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nt7kx exposes endpoints map[pod2:[80]] (1.100566652s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-nt7kx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nt7kx to expose endpoints map[]
Feb 22 22:53:38.755: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nt7kx exposes endpoints map[] (1.01103101s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:53:38.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-nt7kx" for this suite.
Feb 22 22:53:44.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:53:45.038: INFO: namespace: e2e-tests-services-nt7kx, resource: bindings, ignored listing per whitelist
Feb 22 22:53:45.088: INFO: namespace e2e-tests-services-nt7kx deletion completed in 6.265985752s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.825 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:53:45.089: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 22:53:45.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-x4skq'
Feb 22 22:53:45.717: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 22 22:53:45.718: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 22 22:53:45.730: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 22 22:53:45.752: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 22 22:53:45.808: INFO: scanned /root for discovery docs: <nil>
Feb 22 22:53:45.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-x4skq'
Feb 22 22:54:01.740: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 22 22:54:01.740: INFO: stdout: "Created e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c\nScaling up e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 22 22:54:01.740: INFO: stdout: "Created e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c\nScaling up e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 22 22:54:01.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-x4skq'
Feb 22 22:54:01.933: INFO: stderr: ""
Feb 22 22:54:01.933: INFO: stdout: "e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c-rpztp "
Feb 22 22:54:01.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c-rpztp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x4skq'
Feb 22 22:54:02.113: INFO: stderr: ""
Feb 22 22:54:02.113: INFO: stdout: "true"
Feb 22 22:54:02.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 get pods e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c-rpztp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x4skq'
Feb 22 22:54:02.223: INFO: stderr: ""
Feb 22 22:54:02.223: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 22 22:54:02.223: INFO: e2e-test-nginx-rc-261ad179b33a8f4125cbe1ab329ffb4c-rpztp is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb 22 22:54:02.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-203049355 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-x4skq'
Feb 22 22:54:02.316: INFO: stderr: ""
Feb 22 22:54:02.316: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:54:02.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x4skq" for this suite.
Feb 22 22:54:24.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:54:24.422: INFO: namespace: e2e-tests-kubectl-x4skq, resource: bindings, ignored listing per whitelist
Feb 22 22:54:24.590: INFO: namespace e2e-tests-kubectl-x4skq deletion completed in 22.26630764s

• [SLOW TEST:39.501 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:54:24.590: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-l4lkw
Feb 22 22:54:28.702: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-l4lkw
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 22:54:28.709: INFO: Initial restart count of pod liveness-http is 0
Feb 22 22:54:46.785: INFO: Restart count of pod e2e-tests-container-probe-l4lkw/liveness-http is now 1 (18.076348996s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:54:46.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-l4lkw" for this suite.
Feb 22 22:54:52.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:54:52.855: INFO: namespace: e2e-tests-container-probe-l4lkw, resource: bindings, ignored listing per whitelist
Feb 22 22:54:53.002: INFO: namespace e2e-tests-container-probe-l4lkw deletion completed in 6.184076952s

• [SLOW TEST:28.412 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:54:53.003: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 22 22:54:53.098: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-lgcgs,SelfLink:/api/v1/namespaces/e2e-tests-watch-lgcgs/configmaps/e2e-watch-test-watch-closed,UID:ddb18a7d-36f4-11e9-a687-fac827d478c7,ResourceVersion:26675,Generation:0,CreationTimestamp:2019-02-22 22:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 22 22:54:53.098: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-lgcgs,SelfLink:/api/v1/namespaces/e2e-tests-watch-lgcgs/configmaps/e2e-watch-test-watch-closed,UID:ddb18a7d-36f4-11e9-a687-fac827d478c7,ResourceVersion:26676,Generation:0,CreationTimestamp:2019-02-22 22:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 22 22:54:53.125: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-lgcgs,SelfLink:/api/v1/namespaces/e2e-tests-watch-lgcgs/configmaps/e2e-watch-test-watch-closed,UID:ddb18a7d-36f4-11e9-a687-fac827d478c7,ResourceVersion:26677,Generation:0,CreationTimestamp:2019-02-22 22:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 22 22:54:53.125: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-lgcgs,SelfLink:/api/v1/namespaces/e2e-tests-watch-lgcgs/configmaps/e2e-watch-test-watch-closed,UID:ddb18a7d-36f4-11e9-a687-fac827d478c7,ResourceVersion:26679,Generation:0,CreationTimestamp:2019-02-22 22:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:54:53.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-lgcgs" for this suite.
Feb 22 22:54:59.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:54:59.230: INFO: namespace: e2e-tests-watch-lgcgs, resource: bindings, ignored listing per whitelist
Feb 22 22:54:59.323: INFO: namespace e2e-tests-watch-lgcgs deletion completed in 6.189439316s

• [SLOW TEST:6.320 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:54:59.326: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e1760d4d-36f4-11e9-b6f8-82efa66823a4
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e1760d4d-36f4-11e9-b6f8-82efa66823a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:55:03.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fm9vv" for this suite.
Feb 22 22:55:25.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:55:25.572: INFO: namespace: e2e-tests-projected-fm9vv, resource: bindings, ignored listing per whitelist
Feb 22 22:55:25.714: INFO: namespace e2e-tests-projected-fm9vv deletion completed in 22.176866572s

• [SLOW TEST:26.389 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:55:25.715: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 22 22:55:29.939: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:29.944: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:31.945: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:31.952: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:33.945: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:33.952: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:35.945: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:35.952: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:37.944: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:37.959: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:39.945: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:39.951: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:41.944: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:41.949: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:43.944: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:43.949: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:45.944: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:46.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:47.944: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:48.235: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:49.944: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:49.949: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:51.944: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:51.951: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:55:53.944: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:55:53.950: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:55:53.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6ffrf" for this suite.
Feb 22 22:56:15.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:56:16.161: INFO: namespace: e2e-tests-container-lifecycle-hook-6ffrf, resource: bindings, ignored listing per whitelist
Feb 22 22:56:16.204: INFO: namespace e2e-tests-container-lifecycle-hook-6ffrf deletion completed in 22.235844486s

• [SLOW TEST:50.490 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:56:16.206: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:56:16.339: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:56:20.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pgz96" for this suite.
Feb 22 22:57:00.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:57:00.573: INFO: namespace: e2e-tests-pods-pgz96, resource: bindings, ignored listing per whitelist
Feb 22 22:57:00.651: INFO: namespace e2e-tests-pods-pgz96 deletion completed in 40.217344771s

• [SLOW TEST:44.446 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 22 22:57:00.653: INFO: >>> kubeConfig: /tmp/kubeconfig-203049355
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 22 22:57:00.756: INFO: Waiting up to 5m0s for pod "downward-api-29c8d1a3-36f5-11e9-b6f8-82efa66823a4" in namespace "e2e-tests-downward-api-796lb" to be "success or failure"
Feb 22 22:57:00.775: INFO: Pod "downward-api-29c8d1a3-36f5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.755326ms
Feb 22 22:57:02.781: INFO: Pod "downward-api-29c8d1a3-36f5-11e9-b6f8-82efa66823a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024363007s
Feb 22 22:57:04.787: INFO: Pod "downward-api-29c8d1a3-36f5-11e9-b6f8-82efa66823a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031234368s
STEP: Saw pod success
Feb 22 22:57:04.788: INFO: Pod "downward-api-29c8d1a3-36f5-11e9-b6f8-82efa66823a4" satisfied condition "success or failure"
Feb 22 22:57:04.792: INFO: Trying to get logs from node conformance113-3 pod downward-api-29c8d1a3-36f5-11e9-b6f8-82efa66823a4 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:57:04.857: INFO: Waiting for pod downward-api-29c8d1a3-36f5-11e9-b6f8-82efa66823a4 to disappear
Feb 22 22:57:04.881: INFO: Pod downward-api-29c8d1a3-36f5-11e9-b6f8-82efa66823a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 22 22:57:04.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-796lb" for this suite.
Feb 22 22:57:10.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:57:11.007: INFO: namespace: e2e-tests-downward-api-796lb, resource: bindings, ignored listing per whitelist
Feb 22 22:57:11.135: INFO: namespace e2e-tests-downward-api-796lb deletion completed in 6.247289857s

• [SLOW TEST:10.483 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSFeb 22 22:57:11.136: INFO: Running AfterSuite actions on all nodes
Feb 22 22:57:11.137: INFO: Running AfterSuite actions on node 1
Feb 22 22:57:11.137: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 7107.621 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h58m30.748142934s
Test Suite Passed
