I0318 20:25:52.708855      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-818169620
I0318 20:25:52.708994      18 e2e.go:224] Starting e2e run "0660dcfc-49bc-11e9-9475-02f976e168bb" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1552940752 - Will randomize all specs
Will run 201 of 1946 specs

Mar 18 20:25:52.834: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:25:52.838: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 18 20:25:52.847: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 18 20:25:52.870: INFO: The status of Pod rke-ingress-controller-deploy-job-m9w44 is Succeeded, skipping waiting
Mar 18 20:25:52.870: INFO: The status of Pod rke-kube-dns-addon-deploy-job-xxq8d is Succeeded, skipping waiting
Mar 18 20:25:52.870: INFO: The status of Pod rke-metrics-addon-deploy-job-bk4gn is Succeeded, skipping waiting
Mar 18 20:25:52.870: INFO: The status of Pod rke-network-plugin-deploy-job-v9n5x is Succeeded, skipping waiting
Mar 18 20:25:52.871: INFO: 6 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 18 20:25:52.871: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Mar 18 20:25:52.871: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 18 20:25:52.877: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Mar 18 20:25:52.877: INFO: e2e test version: v1.13.0
Mar 18 20:25:52.878: INFO: kube-apiserver version: v1.13.4
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:25:52.878: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
Mar 18 20:25:52.949: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-06df902b-49bc-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 20:25:52.965: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-06e00d28-49bc-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-5cszw" to be "success or failure"
Mar 18 20:25:52.971: INFO: Pod "pod-projected-secrets-06e00d28-49bc-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.987385ms
Mar 18 20:25:54.974: INFO: Pod "pod-projected-secrets-06e00d28-49bc-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008706188s
Mar 18 20:25:56.977: INFO: Pod "pod-projected-secrets-06e00d28-49bc-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011765632s
STEP: Saw pod success
Mar 18 20:25:56.977: INFO: Pod "pod-projected-secrets-06e00d28-49bc-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:25:56.979: INFO: Trying to get logs from node node-1 pod pod-projected-secrets-06e00d28-49bc-11e9-9475-02f976e168bb container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 18 20:25:57.010: INFO: Waiting for pod pod-projected-secrets-06e00d28-49bc-11e9-9475-02f976e168bb to disappear
Mar 18 20:25:57.017: INFO: Pod pod-projected-secrets-06e00d28-49bc-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:25:57.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5cszw" for this suite.
Mar 18 20:26:03.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:26:03.117: INFO: namespace: e2e-tests-projected-5cszw, resource: bindings, ignored listing per whitelist
Mar 18 20:26:03.121: INFO: namespace e2e-tests-projected-5cszw deletion completed in 6.095891234s

• [SLOW TEST:10.242 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:26:03.121: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 20:26:03.182: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0cf83540-49bc-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-958xf" to be "success or failure"
Mar 18 20:26:03.189: INFO: Pod "downwardapi-volume-0cf83540-49bc-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.817995ms
Mar 18 20:26:05.192: INFO: Pod "downwardapi-volume-0cf83540-49bc-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009943313s
STEP: Saw pod success
Mar 18 20:26:05.192: INFO: Pod "downwardapi-volume-0cf83540-49bc-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:26:05.195: INFO: Trying to get logs from node node-1 pod downwardapi-volume-0cf83540-49bc-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 20:26:05.214: INFO: Waiting for pod downwardapi-volume-0cf83540-49bc-11e9-9475-02f976e168bb to disappear
Mar 18 20:26:05.218: INFO: Pod downwardapi-volume-0cf83540-49bc-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:26:05.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-958xf" for this suite.
Mar 18 20:26:11.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:26:11.295: INFO: namespace: e2e-tests-projected-958xf, resource: bindings, ignored listing per whitelist
Mar 18 20:26:11.311: INFO: namespace e2e-tests-projected-958xf deletion completed in 6.087094592s

• [SLOW TEST:8.190 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:26:11.311: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Mar 18 20:26:11.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-5z4tx'
Mar 18 20:26:11.789: INFO: stderr: ""
Mar 18 20:26:11.789: INFO: stdout: "pod/pause created\n"
Mar 18 20:26:11.789: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 18 20:26:11.789: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-5z4tx" to be "running and ready"
Mar 18 20:26:11.795: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.375883ms
Mar 18 20:26:13.798: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.008156703s
Mar 18 20:26:13.798: INFO: Pod "pause" satisfied condition "running and ready"
Mar 18 20:26:13.798: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 18 20:26:13.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-5z4tx'
Mar 18 20:26:13.864: INFO: stderr: ""
Mar 18 20:26:13.864: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 18 20:26:13.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pod pause -L testing-label --namespace=e2e-tests-kubectl-5z4tx'
Mar 18 20:26:13.929: INFO: stderr: ""
Mar 18 20:26:13.929: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 18 20:26:13.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 label pods pause testing-label- --namespace=e2e-tests-kubectl-5z4tx'
Mar 18 20:26:14.013: INFO: stderr: ""
Mar 18 20:26:14.013: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 18 20:26:14.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pod pause -L testing-label --namespace=e2e-tests-kubectl-5z4tx'
Mar 18 20:26:14.077: INFO: stderr: ""
Mar 18 20:26:14.077: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Mar 18 20:26:14.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5z4tx'
Mar 18 20:26:14.160: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 20:26:14.160: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 18 20:26:14.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-5z4tx'
Mar 18 20:26:14.236: INFO: stderr: "No resources found.\n"
Mar 18 20:26:14.236: INFO: stdout: ""
Mar 18 20:26:14.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -l name=pause --namespace=e2e-tests-kubectl-5z4tx -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 18 20:26:14.305: INFO: stderr: ""
Mar 18 20:26:14.305: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:26:14.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5z4tx" for this suite.
Mar 18 20:26:20.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:26:20.403: INFO: namespace: e2e-tests-kubectl-5z4tx, resource: bindings, ignored listing per whitelist
Mar 18 20:26:20.446: INFO: namespace e2e-tests-kubectl-5z4tx deletion completed in 6.137761596s

• [SLOW TEST:9.134 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:26:20.446: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 20:26:20.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-rf5tq'
Mar 18 20:26:20.595: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 18 20:26:20.595: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar 18 20:26:20.600: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Mar 18 20:26:20.608: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar 18 20:26:20.625: INFO: scanned /root for discovery docs: <nil>
Mar 18 20:26:20.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-rf5tq'
Mar 18 20:26:37.413: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 18 20:26:37.413: INFO: stdout: "Created e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e\nScaling up e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar 18 20:26:37.413: INFO: stdout: "Created e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e\nScaling up e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar 18 20:26:37.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rf5tq'
Mar 18 20:26:37.482: INFO: stderr: ""
Mar 18 20:26:37.482: INFO: stdout: "e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e-kw26q "
Mar 18 20:26:37.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e-kw26q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rf5tq'
Mar 18 20:26:37.547: INFO: stderr: ""
Mar 18 20:26:37.547: INFO: stdout: "true"
Mar 18 20:26:37.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e-kw26q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rf5tq'
Mar 18 20:26:37.612: INFO: stderr: ""
Mar 18 20:26:37.612: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Mar 18 20:26:37.612: INFO: e2e-test-nginx-rc-07c08e36106ba869d665c498bcbb444e-kw26q is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Mar 18 20:26:37.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rf5tq'
Mar 18 20:26:37.685: INFO: stderr: ""
Mar 18 20:26:37.685: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:26:37.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rf5tq" for this suite.
Mar 18 20:26:59.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:26:59.766: INFO: namespace: e2e-tests-kubectl-rf5tq, resource: bindings, ignored listing per whitelist
Mar 18 20:26:59.778: INFO: namespace e2e-tests-kubectl-rf5tq deletion completed in 22.089995883s

• [SLOW TEST:39.333 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:26:59.779: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 18 20:27:05.866: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 18 20:27:05.873: INFO: Pod pod-with-poststart-http-hook still exists
Mar 18 20:27:07.873: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 18 20:27:07.876: INFO: Pod pod-with-poststart-http-hook still exists
Mar 18 20:27:09.873: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 18 20:27:09.876: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:27:09.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-jcrlq" for this suite.
Mar 18 20:27:31.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:27:31.919: INFO: namespace: e2e-tests-container-lifecycle-hook-jcrlq, resource: bindings, ignored listing per whitelist
Mar 18 20:27:31.971: INFO: namespace e2e-tests-container-lifecycle-hook-jcrlq deletion completed in 22.092369258s

• [SLOW TEST:32.193 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:27:31.971: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 18 20:27:36.061: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 18 20:27:36.065: INFO: Pod pod-with-prestop-http-hook still exists
Mar 18 20:27:38.065: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 18 20:27:38.069: INFO: Pod pod-with-prestop-http-hook still exists
Mar 18 20:27:40.065: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 18 20:27:40.068: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:27:40.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dvhzs" for this suite.
Mar 18 20:28:02.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:28:02.150: INFO: namespace: e2e-tests-container-lifecycle-hook-dvhzs, resource: bindings, ignored listing per whitelist
Mar 18 20:28:02.168: INFO: namespace e2e-tests-container-lifecycle-hook-dvhzs deletion completed in 22.091137902s

• [SLOW TEST:30.197 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:28:02.168: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 18 20:28:02.232: INFO: Waiting up to 5m0s for pod "pod-53ed9e19-49bc-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-2lgfq" to be "success or failure"
Mar 18 20:28:02.235: INFO: Pod "pod-53ed9e19-49bc-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.080693ms
Mar 18 20:28:04.238: INFO: Pod "pod-53ed9e19-49bc-11e9-9475-02f976e168bb": Phase="Running", Reason="", readiness=true. Elapsed: 2.005984925s
Mar 18 20:28:06.241: INFO: Pod "pod-53ed9e19-49bc-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008978741s
STEP: Saw pod success
Mar 18 20:28:06.241: INFO: Pod "pod-53ed9e19-49bc-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:28:06.243: INFO: Trying to get logs from node node-1 pod pod-53ed9e19-49bc-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 20:28:06.260: INFO: Waiting for pod pod-53ed9e19-49bc-11e9-9475-02f976e168bb to disappear
Mar 18 20:28:06.267: INFO: Pod pod-53ed9e19-49bc-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:28:06.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2lgfq" for this suite.
Mar 18 20:28:12.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:28:12.322: INFO: namespace: e2e-tests-emptydir-2lgfq, resource: bindings, ignored listing per whitelist
Mar 18 20:28:12.379: INFO: namespace e2e-tests-emptydir-2lgfq deletion completed in 6.101705895s

• [SLOW TEST:10.211 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:28:12.379: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar 18 20:28:12.447: INFO: Waiting up to 5m0s for pod "client-containers-5a045c7d-49bc-11e9-9475-02f976e168bb" in namespace "e2e-tests-containers-kmpcn" to be "success or failure"
Mar 18 20:28:12.449: INFO: Pod "client-containers-5a045c7d-49bc-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.366444ms
Mar 18 20:28:14.453: INFO: Pod "client-containers-5a045c7d-49bc-11e9-9475-02f976e168bb": Phase="Running", Reason="", readiness=true. Elapsed: 2.005785767s
Mar 18 20:28:16.456: INFO: Pod "client-containers-5a045c7d-49bc-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008986072s
STEP: Saw pod success
Mar 18 20:28:16.456: INFO: Pod "client-containers-5a045c7d-49bc-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:28:16.458: INFO: Trying to get logs from node node-1 pod client-containers-5a045c7d-49bc-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 20:28:16.484: INFO: Waiting for pod client-containers-5a045c7d-49bc-11e9-9475-02f976e168bb to disappear
Mar 18 20:28:16.493: INFO: Pod client-containers-5a045c7d-49bc-11e9-9475-02f976e168bb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:28:16.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-kmpcn" for this suite.
Mar 18 20:28:22.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:28:22.581: INFO: namespace: e2e-tests-containers-kmpcn, resource: bindings, ignored listing per whitelist
Mar 18 20:28:22.599: INFO: namespace e2e-tests-containers-kmpcn deletion completed in 6.101903846s

• [SLOW TEST:10.220 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:28:22.599: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 18 20:28:22.663: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 18 20:28:22.668: INFO: Waiting for terminating namespaces to be deleted...
Mar 18 20:28:22.671: INFO: 
Logging pods the kubelet thinks is on node node-1 before test
Mar 18 20:28:22.676: INFO: rke-network-plugin-deploy-job-v9n5x from kube-system started at 2019-03-18 20:19:33 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.676: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 18 20:28:22.676: INFO: canal-k9vqq from kube-system started at 2019-03-18 20:19:37 +0000 UTC (2 container statuses recorded)
Mar 18 20:28:22.676: INFO: 	Container calico-node ready: true, restart count 0
Mar 18 20:28:22.676: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 18 20:28:22.676: INFO: rke-kube-dns-addon-deploy-job-xxq8d from kube-system started at 2019-03-18 20:19:42 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.676: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Mar 18 20:28:22.676: INFO: rke-ingress-controller-deploy-job-m9w44 from kube-system started at 2019-03-18 20:19:57 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.676: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 18 20:28:22.676: INFO: nginx-ingress-controller-x6mz2 from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.676: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 18 20:28:22.676: INFO: rke-metrics-addon-deploy-job-bk4gn from kube-system started at 2019-03-18 20:19:49 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.676: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 18 20:28:22.676: INFO: metrics-server-58bd5dd8d7-gzdst from kube-system started at 2019-03-18 20:19:50 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.676: INFO: 	Container metrics-server ready: true, restart count 0
Mar 18 20:28:22.676: INFO: sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-lhbmj from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 20:28:22.676: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 18 20:28:22.676: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 20:28:22.676: INFO: 
Logging pods the kubelet thinks is on node node-2 before test
Mar 18 20:28:22.696: INFO: canal-psvdr from kube-system started at 2019-03-18 20:19:37 +0000 UTC (2 container statuses recorded)
Mar 18 20:28:22.696: INFO: 	Container calico-node ready: true, restart count 0
Mar 18 20:28:22.696: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 18 20:28:22.696: INFO: kube-dns-58bd5b8dd7-l2glm from kube-system started at 2019-03-18 20:19:44 +0000 UTC (3 container statuses recorded)
Mar 18 20:28:22.696: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 18 20:28:22.696: INFO: 	Container kubedns ready: true, restart count 0
Mar 18 20:28:22.696: INFO: 	Container sidecar ready: true, restart count 0
Mar 18 20:28:22.696: INFO: kube-dns-autoscaler-77bc5fd84-lg7gr from kube-system started at 2019-03-18 20:19:44 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.696: INFO: 	Container autoscaler ready: true, restart count 0
Mar 18 20:28:22.696: INFO: nginx-ingress-controller-v87dt from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.696: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 18 20:28:22.696: INFO: sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-nnxbf from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 20:28:22.696: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 18 20:28:22.696: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 20:28:22.696: INFO: 
Logging pods the kubelet thinks is on node node-3 before test
Mar 18 20:28:22.712: INFO: sonobuoy-e2e-job-561a442ed17248ce from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 20:28:22.713: INFO: 	Container e2e ready: true, restart count 0
Mar 18 20:28:22.713: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 20:28:22.713: INFO: sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-w8nm8 from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 20:28:22.713: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 18 20:28:22.713: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 20:28:22.713: INFO: canal-fg6j2 from kube-system started at 2019-03-18 20:19:37 +0000 UTC (2 container statuses recorded)
Mar 18 20:28:22.713: INFO: 	Container calico-node ready: true, restart count 0
Mar 18 20:28:22.713: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 18 20:28:22.713: INFO: nginx-ingress-controller-q2xj8 from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.713: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 18 20:28:22.713: INFO: default-http-backend-78fccfc5d9-2lbst from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.713: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 18 20:28:22.713: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-18 20:25:25 +0000 UTC (1 container statuses recorded)
Mar 18 20:28:22.713: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node node-1
STEP: verifying the node has the label node node-2
STEP: verifying the node has the label node node-3
Mar 18 20:28:22.749: INFO: Pod sonobuoy requesting resource cpu=0m on Node node-3
Mar 18 20:28:22.749: INFO: Pod sonobuoy-e2e-job-561a442ed17248ce requesting resource cpu=0m on Node node-3
Mar 18 20:28:22.749: INFO: Pod sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-lhbmj requesting resource cpu=0m on Node node-1
Mar 18 20:28:22.749: INFO: Pod sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-nnxbf requesting resource cpu=0m on Node node-2
Mar 18 20:28:22.749: INFO: Pod sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-w8nm8 requesting resource cpu=0m on Node node-3
Mar 18 20:28:22.749: INFO: Pod default-http-backend-78fccfc5d9-2lbst requesting resource cpu=10m on Node node-3
Mar 18 20:28:22.749: INFO: Pod nginx-ingress-controller-q2xj8 requesting resource cpu=0m on Node node-3
Mar 18 20:28:22.749: INFO: Pod nginx-ingress-controller-v87dt requesting resource cpu=0m on Node node-2
Mar 18 20:28:22.749: INFO: Pod nginx-ingress-controller-x6mz2 requesting resource cpu=0m on Node node-1
Mar 18 20:28:22.749: INFO: Pod canal-fg6j2 requesting resource cpu=250m on Node node-3
Mar 18 20:28:22.749: INFO: Pod canal-k9vqq requesting resource cpu=250m on Node node-1
Mar 18 20:28:22.749: INFO: Pod canal-psvdr requesting resource cpu=250m on Node node-2
Mar 18 20:28:22.749: INFO: Pod kube-dns-58bd5b8dd7-l2glm requesting resource cpu=260m on Node node-2
Mar 18 20:28:22.749: INFO: Pod kube-dns-autoscaler-77bc5fd84-lg7gr requesting resource cpu=20m on Node node-2
Mar 18 20:28:22.749: INFO: Pod metrics-server-58bd5dd8d7-gzdst requesting resource cpu=0m on Node node-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-60291e8e-49bc-11e9-9475-02f976e168bb.158d2785f207fb1b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-2lrbx/filler-pod-60291e8e-49bc-11e9-9475-02f976e168bb to node-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-60291e8e-49bc-11e9-9475-02f976e168bb.158d278619e8c22a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-60291e8e-49bc-11e9-9475-02f976e168bb.158d27861d151348], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-60291e8e-49bc-11e9-9475-02f976e168bb.158d278621d0510e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6029eee5-49bc-11e9-9475-02f976e168bb.158d2785f2b5b4e0], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-2lrbx/filler-pod-6029eee5-49bc-11e9-9475-02f976e168bb to node-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6029eee5-49bc-11e9-9475-02f976e168bb.158d2786189a6682], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6029eee5-49bc-11e9-9475-02f976e168bb.158d278639bcdc9c], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6029eee5-49bc-11e9-9475-02f976e168bb.158d27863cf90647], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6029eee5-49bc-11e9-9475-02f976e168bb.158d2786419f626e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-602aa8d9-49bc-11e9-9475-02f976e168bb.158d2785f3598b0f], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-2lrbx/filler-pod-602aa8d9-49bc-11e9-9475-02f976e168bb to node-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-602aa8d9-49bc-11e9-9475-02f976e168bb.158d2786174359d4], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-602aa8d9-49bc-11e9-9475-02f976e168bb.158d2786389340c8], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-602aa8d9-49bc-11e9-9475-02f976e168bb.158d27863b53f484], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-602aa8d9-49bc-11e9-9475-02f976e168bb.158d2786436de8de], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158d2786e2c66b21], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node node-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:28:27.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-2lrbx" for this suite.
Mar 18 20:28:33.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:28:33.889: INFO: namespace: e2e-tests-sched-pred-2lrbx, resource: bindings, ignored listing per whitelist
Mar 18 20:28:33.958: INFO: namespace e2e-tests-sched-pred-2lrbx deletion completed in 6.088707619s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.359 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:28:33.958: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 18 20:28:34.024: INFO: Waiting up to 5m0s for pod "pod-66e0bb42-49bc-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-2x97s" to be "success or failure"
Mar 18 20:28:34.026: INFO: Pod "pod-66e0bb42-49bc-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.389313ms
Mar 18 20:28:36.029: INFO: Pod "pod-66e0bb42-49bc-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005382718s
STEP: Saw pod success
Mar 18 20:28:36.029: INFO: Pod "pod-66e0bb42-49bc-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:28:36.031: INFO: Trying to get logs from node node-1 pod pod-66e0bb42-49bc-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 20:28:36.064: INFO: Waiting for pod pod-66e0bb42-49bc-11e9-9475-02f976e168bb to disappear
Mar 18 20:28:36.067: INFO: Pod pod-66e0bb42-49bc-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:28:36.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2x97s" for this suite.
Mar 18 20:28:42.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:28:42.118: INFO: namespace: e2e-tests-emptydir-2x97s, resource: bindings, ignored listing per whitelist
Mar 18 20:28:42.154: INFO: namespace e2e-tests-emptydir-2x97s deletion completed in 6.08434541s

• [SLOW TEST:8.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:28:42.154: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-ckjgc/configmap-test-6bc25f1f-49bc-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 20:28:42.219: INFO: Waiting up to 5m0s for pod "pod-configmaps-6bc2da95-49bc-11e9-9475-02f976e168bb" in namespace "e2e-tests-configmap-ckjgc" to be "success or failure"
Mar 18 20:28:42.226: INFO: Pod "pod-configmaps-6bc2da95-49bc-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.452074ms
Mar 18 20:28:44.229: INFO: Pod "pod-configmaps-6bc2da95-49bc-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009483078s
Mar 18 20:28:46.232: INFO: Pod "pod-configmaps-6bc2da95-49bc-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01270337s
STEP: Saw pod success
Mar 18 20:28:46.232: INFO: Pod "pod-configmaps-6bc2da95-49bc-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:28:46.234: INFO: Trying to get logs from node node-1 pod pod-configmaps-6bc2da95-49bc-11e9-9475-02f976e168bb container env-test: <nil>
STEP: delete the pod
Mar 18 20:28:46.250: INFO: Waiting for pod pod-configmaps-6bc2da95-49bc-11e9-9475-02f976e168bb to disappear
Mar 18 20:28:46.255: INFO: Pod pod-configmaps-6bc2da95-49bc-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:28:46.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ckjgc" for this suite.
Mar 18 20:28:52.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:28:52.331: INFO: namespace: e2e-tests-configmap-ckjgc, resource: bindings, ignored listing per whitelist
Mar 18 20:28:52.352: INFO: namespace e2e-tests-configmap-ckjgc deletion completed in 6.093314044s

• [SLOW TEST:10.198 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:28:52.352: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0318 20:28:58.435288      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 20:28:58.435: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:28:58.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pvhnd" for this suite.
Mar 18 20:29:04.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:29:04.499: INFO: namespace: e2e-tests-gc-pvhnd, resource: bindings, ignored listing per whitelist
Mar 18 20:29:04.527: INFO: namespace e2e-tests-gc-pvhnd deletion completed in 6.089630994s

• [SLOW TEST:12.176 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:29:04.528: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 20:29:04.630: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"791b6552-49bc-11e9-a0d3-06934a8be3ba", Controller:(*bool)(0xc0016db9ae), BlockOwnerDeletion:(*bool)(0xc0016db9af)}}
Mar 18 20:29:04.642: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"79189d18-49bc-11e9-a0d3-06934a8be3ba", Controller:(*bool)(0xc0016dbbca), BlockOwnerDeletion:(*bool)(0xc0016dbbcb)}}
Mar 18 20:29:04.650: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"79193ae7-49bc-11e9-a0d3-06934a8be3ba", Controller:(*bool)(0xc0010c9d02), BlockOwnerDeletion:(*bool)(0xc0010c9d03)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:29:09.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6h2lk" for this suite.
Mar 18 20:29:15.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:29:15.712: INFO: namespace: e2e-tests-gc-6h2lk, resource: bindings, ignored listing per whitelist
Mar 18 20:29:15.747: INFO: namespace e2e-tests-gc-6h2lk deletion completed in 6.086888419s

• [SLOW TEST:11.219 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:29:15.747: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wzhsv
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar 18 20:29:15.819: INFO: Found 0 stateful pods, waiting for 3
Mar 18 20:29:25.823: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 20:29:25.823: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 20:29:25.823: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 18 20:29:25.847: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 18 20:29:35.875: INFO: Updating stateful set ss2
Mar 18 20:29:35.882: INFO: Waiting for Pod e2e-tests-statefulset-wzhsv/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar 18 20:29:45.956: INFO: Found 2 stateful pods, waiting for 3
Mar 18 20:29:55.959: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 20:29:55.959: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 20:29:55.959: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 18 20:29:55.982: INFO: Updating stateful set ss2
Mar 18 20:29:55.987: INFO: Waiting for Pod e2e-tests-statefulset-wzhsv/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 20:30:06.017: INFO: Updating stateful set ss2
Mar 18 20:30:06.025: INFO: Waiting for StatefulSet e2e-tests-statefulset-wzhsv/ss2 to complete update
Mar 18 20:30:06.025: INFO: Waiting for Pod e2e-tests-statefulset-wzhsv/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 20:30:16.032: INFO: Waiting for StatefulSet e2e-tests-statefulset-wzhsv/ss2 to complete update
Mar 18 20:30:16.032: INFO: Waiting for Pod e2e-tests-statefulset-wzhsv/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 18 20:30:26.031: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wzhsv
Mar 18 20:30:26.034: INFO: Scaling statefulset ss2 to 0
Mar 18 20:30:46.049: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 20:30:46.052: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:30:46.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wzhsv" for this suite.
Mar 18 20:30:52.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:30:52.122: INFO: namespace: e2e-tests-statefulset-wzhsv, resource: bindings, ignored listing per whitelist
Mar 18 20:30:52.158: INFO: namespace e2e-tests-statefulset-wzhsv deletion completed in 6.09129266s

• [SLOW TEST:96.411 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:30:52.158: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 18 20:30:52.218: INFO: Waiting up to 5m0s for pod "pod-b93f9446-49bc-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-pmbc6" to be "success or failure"
Mar 18 20:30:52.223: INFO: Pod "pod-b93f9446-49bc-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.99358ms
Mar 18 20:30:54.227: INFO: Pod "pod-b93f9446-49bc-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008415945s
STEP: Saw pod success
Mar 18 20:30:54.227: INFO: Pod "pod-b93f9446-49bc-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:30:54.229: INFO: Trying to get logs from node node-1 pod pod-b93f9446-49bc-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 20:30:54.250: INFO: Waiting for pod pod-b93f9446-49bc-11e9-9475-02f976e168bb to disappear
Mar 18 20:30:54.259: INFO: Pod pod-b93f9446-49bc-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:30:54.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pmbc6" for this suite.
Mar 18 20:31:00.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:31:00.300: INFO: namespace: e2e-tests-emptydir-pmbc6, resource: bindings, ignored listing per whitelist
Mar 18 20:31:00.356: INFO: namespace e2e-tests-emptydir-pmbc6 deletion completed in 6.093402453s

• [SLOW TEST:8.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:31:00.356: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 18 20:31:00.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-m82ff'
Mar 18 20:31:00.612: INFO: stderr: ""
Mar 18 20:31:00.612: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 20:31:00.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-m82ff'
Mar 18 20:31:00.681: INFO: stderr: ""
Mar 18 20:31:00.681: INFO: stdout: "update-demo-nautilus-lsrmv update-demo-nautilus-wdjcb "
Mar 18 20:31:00.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-lsrmv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m82ff'
Mar 18 20:31:00.747: INFO: stderr: ""
Mar 18 20:31:00.747: INFO: stdout: ""
Mar 18 20:31:00.747: INFO: update-demo-nautilus-lsrmv is created but not running
Mar 18 20:31:05.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-m82ff'
Mar 18 20:31:05.816: INFO: stderr: ""
Mar 18 20:31:05.817: INFO: stdout: "update-demo-nautilus-lsrmv update-demo-nautilus-wdjcb "
Mar 18 20:31:05.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-lsrmv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m82ff'
Mar 18 20:31:05.881: INFO: stderr: ""
Mar 18 20:31:05.881: INFO: stdout: "true"
Mar 18 20:31:05.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-lsrmv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m82ff'
Mar 18 20:31:05.945: INFO: stderr: ""
Mar 18 20:31:05.945: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 20:31:05.945: INFO: validating pod update-demo-nautilus-lsrmv
Mar 18 20:31:05.949: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 20:31:05.950: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 20:31:05.950: INFO: update-demo-nautilus-lsrmv is verified up and running
Mar 18 20:31:05.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-wdjcb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m82ff'
Mar 18 20:31:06.016: INFO: stderr: ""
Mar 18 20:31:06.016: INFO: stdout: "true"
Mar 18 20:31:06.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-wdjcb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m82ff'
Mar 18 20:31:06.083: INFO: stderr: ""
Mar 18 20:31:06.083: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 20:31:06.083: INFO: validating pod update-demo-nautilus-wdjcb
Mar 18 20:31:06.087: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 20:31:06.087: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 20:31:06.087: INFO: update-demo-nautilus-wdjcb is verified up and running
STEP: using delete to clean up resources
Mar 18 20:31:06.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-m82ff'
Mar 18 20:31:06.156: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 20:31:06.157: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 18 20:31:06.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-m82ff'
Mar 18 20:31:06.230: INFO: stderr: "No resources found.\n"
Mar 18 20:31:06.230: INFO: stdout: ""
Mar 18 20:31:06.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -l name=update-demo --namespace=e2e-tests-kubectl-m82ff -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 18 20:31:06.299: INFO: stderr: ""
Mar 18 20:31:06.299: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:31:06.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m82ff" for this suite.
Mar 18 20:31:28.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:31:28.326: INFO: namespace: e2e-tests-kubectl-m82ff, resource: bindings, ignored listing per whitelist
Mar 18 20:31:28.397: INFO: namespace e2e-tests-kubectl-m82ff deletion completed in 22.094291609s

• [SLOW TEST:28.041 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:31:28.397: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 18 20:31:28.456: INFO: Waiting up to 5m0s for pod "pod-ced90486-49bc-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-dxqtc" to be "success or failure"
Mar 18 20:31:28.459: INFO: Pod "pod-ced90486-49bc-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.652254ms
Mar 18 20:31:30.462: INFO: Pod "pod-ced90486-49bc-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005770613s
STEP: Saw pod success
Mar 18 20:31:30.462: INFO: Pod "pod-ced90486-49bc-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:31:30.464: INFO: Trying to get logs from node node-1 pod pod-ced90486-49bc-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 20:31:30.481: INFO: Waiting for pod pod-ced90486-49bc-11e9-9475-02f976e168bb to disappear
Mar 18 20:31:30.496: INFO: Pod pod-ced90486-49bc-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:31:30.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dxqtc" for this suite.
Mar 18 20:31:36.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:31:36.531: INFO: namespace: e2e-tests-emptydir-dxqtc, resource: bindings, ignored listing per whitelist
Mar 18 20:31:36.598: INFO: namespace e2e-tests-emptydir-dxqtc deletion completed in 6.09868927s

• [SLOW TEST:8.200 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:31:36.598: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 18 20:31:39.189: INFO: Successfully updated pod "labelsupdated3bcb9d5-49bc-11e9-9475-02f976e168bb"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:31:43.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qfdrr" for this suite.
Mar 18 20:32:05.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:32:05.281: INFO: namespace: e2e-tests-downward-api-qfdrr, resource: bindings, ignored listing per whitelist
Mar 18 20:32:05.310: INFO: namespace e2e-tests-downward-api-qfdrr deletion completed in 22.09483965s

• [SLOW TEST:28.712 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:32:05.310: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 18 20:32:05.387: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wb2jw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wb2jw/configmaps/e2e-watch-test-watch-closed,UID:e4db847d-49bc-11e9-a0d3-06934a8be3ba,ResourceVersion:3056,Generation:0,CreationTimestamp:2019-03-18 20:32:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 18 20:32:05.387: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wb2jw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wb2jw/configmaps/e2e-watch-test-watch-closed,UID:e4db847d-49bc-11e9-a0d3-06934a8be3ba,ResourceVersion:3057,Generation:0,CreationTimestamp:2019-03-18 20:32:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 18 20:32:05.399: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wb2jw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wb2jw/configmaps/e2e-watch-test-watch-closed,UID:e4db847d-49bc-11e9-a0d3-06934a8be3ba,ResourceVersion:3058,Generation:0,CreationTimestamp:2019-03-18 20:32:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 18 20:32:05.399: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wb2jw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wb2jw/configmaps/e2e-watch-test-watch-closed,UID:e4db847d-49bc-11e9-a0d3-06934a8be3ba,ResourceVersion:3059,Generation:0,CreationTimestamp:2019-03-18 20:32:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:32:05.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wb2jw" for this suite.
Mar 18 20:32:11.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:32:11.458: INFO: namespace: e2e-tests-watch-wb2jw, resource: bindings, ignored listing per whitelist
Mar 18 20:32:11.503: INFO: namespace e2e-tests-watch-wb2jw deletion completed in 6.097594184s

• [SLOW TEST:6.193 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:32:11.503: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 18 20:32:11.582: INFO: Number of nodes with available pods: 0
Mar 18 20:32:11.582: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:32:12.589: INFO: Number of nodes with available pods: 0
Mar 18 20:32:12.589: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:32:13.588: INFO: Number of nodes with available pods: 0
Mar 18 20:32:13.588: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:32:14.588: INFO: Number of nodes with available pods: 3
Mar 18 20:32:14.588: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 18 20:32:14.603: INFO: Number of nodes with available pods: 2
Mar 18 20:32:14.603: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:15.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:15.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:16.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:16.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:17.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:17.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:18.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:18.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:19.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:19.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:20.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:20.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:21.609: INFO: Number of nodes with available pods: 2
Mar 18 20:32:21.609: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:22.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:22.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:23.609: INFO: Number of nodes with available pods: 2
Mar 18 20:32:23.609: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:24.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:24.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:25.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:25.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:26.609: INFO: Number of nodes with available pods: 2
Mar 18 20:32:26.609: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:27.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:27.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:28.609: INFO: Number of nodes with available pods: 2
Mar 18 20:32:28.609: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:29.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:29.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:30.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:30.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:31.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:31.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:32.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:32.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:33.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:33.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:34.609: INFO: Number of nodes with available pods: 2
Mar 18 20:32:34.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:35.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:35.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:36.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:36.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:37.609: INFO: Number of nodes with available pods: 2
Mar 18 20:32:37.609: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:38.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:38.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:39.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:39.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:40.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:40.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:41.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:41.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:42.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:42.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:43.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:43.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:44.613: INFO: Number of nodes with available pods: 2
Mar 18 20:32:44.613: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:45.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:45.611: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:46.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:46.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:47.609: INFO: Number of nodes with available pods: 2
Mar 18 20:32:47.609: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:48.609: INFO: Number of nodes with available pods: 2
Mar 18 20:32:48.609: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:49.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:49.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:50.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:50.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:51.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:51.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:52.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:52.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:53.610: INFO: Number of nodes with available pods: 2
Mar 18 20:32:53.610: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:54.614: INFO: Number of nodes with available pods: 2
Mar 18 20:32:54.614: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:55.609: INFO: Number of nodes with available pods: 2
Mar 18 20:32:55.609: INFO: Node node-3 is running more than one daemon pod
Mar 18 20:32:56.610: INFO: Number of nodes with available pods: 3
Mar 18 20:32:56.610: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-w54zt, will wait for the garbage collector to delete the pods
Mar 18 20:32:56.670: INFO: Deleting DaemonSet.extensions daemon-set took: 5.706863ms
Mar 18 20:32:56.770: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.279978ms
Mar 18 20:33:36.573: INFO: Number of nodes with available pods: 0
Mar 18 20:33:36.573: INFO: Number of running nodes: 0, number of available pods: 0
Mar 18 20:33:36.577: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-w54zt/daemonsets","resourceVersion":"3286"},"items":null}

Mar 18 20:33:36.581: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-w54zt/pods","resourceVersion":"3286"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:33:36.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-w54zt" for this suite.
Mar 18 20:33:42.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:33:42.618: INFO: namespace: e2e-tests-daemonsets-w54zt, resource: bindings, ignored listing per whitelist
Mar 18 20:33:42.692: INFO: namespace e2e-tests-daemonsets-w54zt deletion completed in 6.097857074s

• [SLOW TEST:91.189 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:33:42.693: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-m5mzk/configmap-test-1ee55300-49bd-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 20:33:42.760: INFO: Waiting up to 5m0s for pod "pod-configmaps-1ee6229b-49bd-11e9-9475-02f976e168bb" in namespace "e2e-tests-configmap-m5mzk" to be "success or failure"
Mar 18 20:33:42.768: INFO: Pod "pod-configmaps-1ee6229b-49bd-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.064918ms
Mar 18 20:33:44.771: INFO: Pod "pod-configmaps-1ee6229b-49bd-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010847589s
STEP: Saw pod success
Mar 18 20:33:44.771: INFO: Pod "pod-configmaps-1ee6229b-49bd-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:33:44.774: INFO: Trying to get logs from node node-1 pod pod-configmaps-1ee6229b-49bd-11e9-9475-02f976e168bb container env-test: <nil>
STEP: delete the pod
Mar 18 20:33:44.792: INFO: Waiting for pod pod-configmaps-1ee6229b-49bd-11e9-9475-02f976e168bb to disappear
Mar 18 20:33:44.796: INFO: Pod pod-configmaps-1ee6229b-49bd-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:33:44.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m5mzk" for this suite.
Mar 18 20:33:50.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:33:50.862: INFO: namespace: e2e-tests-configmap-m5mzk, resource: bindings, ignored listing per whitelist
Mar 18 20:33:50.888: INFO: namespace e2e-tests-configmap-m5mzk deletion completed in 6.089102568s

• [SLOW TEST:8.195 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:33:50.889: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Mar 18 20:33:50.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-245ks'
Mar 18 20:33:51.091: INFO: stderr: ""
Mar 18 20:33:51.091: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar 18 20:33:52.095: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:33:52.095: INFO: Found 0 / 1
Mar 18 20:33:53.095: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:33:53.095: INFO: Found 0 / 1
Mar 18 20:33:54.095: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:33:54.095: INFO: Found 1 / 1
Mar 18 20:33:54.095: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 18 20:33:54.097: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:33:54.097: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar 18 20:33:54.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 logs redis-master-f8jh4 redis-master --namespace=e2e-tests-kubectl-245ks'
Mar 18 20:33:54.175: INFO: stderr: ""
Mar 18 20:33:54.175: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Mar 20:33:52.963 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Mar 20:33:52.963 # Server started, Redis version 3.2.12\n1:M 18 Mar 20:33:52.963 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Mar 20:33:52.963 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar 18 20:33:54.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 log redis-master-f8jh4 redis-master --namespace=e2e-tests-kubectl-245ks --tail=1'
Mar 18 20:33:54.255: INFO: stderr: ""
Mar 18 20:33:54.255: INFO: stdout: "1:M 18 Mar 20:33:52.963 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar 18 20:33:54.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 log redis-master-f8jh4 redis-master --namespace=e2e-tests-kubectl-245ks --limit-bytes=1'
Mar 18 20:33:54.334: INFO: stderr: ""
Mar 18 20:33:54.334: INFO: stdout: " "
STEP: exposing timestamps
Mar 18 20:33:54.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 log redis-master-f8jh4 redis-master --namespace=e2e-tests-kubectl-245ks --tail=1 --timestamps'
Mar 18 20:33:54.410: INFO: stderr: ""
Mar 18 20:33:54.410: INFO: stdout: "2019-03-18T20:33:52.964212725Z 1:M 18 Mar 20:33:52.963 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar 18 20:33:56.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 log redis-master-f8jh4 redis-master --namespace=e2e-tests-kubectl-245ks --since=1s'
Mar 18 20:33:56.987: INFO: stderr: ""
Mar 18 20:33:56.987: INFO: stdout: ""
Mar 18 20:33:56.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 log redis-master-f8jh4 redis-master --namespace=e2e-tests-kubectl-245ks --since=24h'
Mar 18 20:33:57.062: INFO: stderr: ""
Mar 18 20:33:57.062: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Mar 20:33:52.963 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Mar 20:33:52.963 # Server started, Redis version 3.2.12\n1:M 18 Mar 20:33:52.963 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Mar 20:33:52.963 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Mar 18 20:33:57.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-245ks'
Mar 18 20:33:57.129: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 20:33:57.129: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar 18 20:33:57.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-245ks'
Mar 18 20:33:57.204: INFO: stderr: "No resources found.\n"
Mar 18 20:33:57.204: INFO: stdout: ""
Mar 18 20:33:57.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -l name=nginx --namespace=e2e-tests-kubectl-245ks -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 18 20:33:57.275: INFO: stderr: ""
Mar 18 20:33:57.275: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:33:57.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-245ks" for this suite.
Mar 18 20:34:19.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:34:19.305: INFO: namespace: e2e-tests-kubectl-245ks, resource: bindings, ignored listing per whitelist
Mar 18 20:34:19.363: INFO: namespace e2e-tests-kubectl-245ks deletion completed in 22.084371776s

• [SLOW TEST:28.474 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:34:19.363: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-34c063be-49bd-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 20:34:19.427: INFO: Waiting up to 5m0s for pod "pod-secrets-34c117ef-49bd-11e9-9475-02f976e168bb" in namespace "e2e-tests-secrets-66ckw" to be "success or failure"
Mar 18 20:34:19.438: INFO: Pod "pod-secrets-34c117ef-49bd-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.858166ms
Mar 18 20:34:21.441: INFO: Pod "pod-secrets-34c117ef-49bd-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013789976s
STEP: Saw pod success
Mar 18 20:34:21.441: INFO: Pod "pod-secrets-34c117ef-49bd-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:34:21.443: INFO: Trying to get logs from node node-1 pod pod-secrets-34c117ef-49bd-11e9-9475-02f976e168bb container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 20:34:21.462: INFO: Waiting for pod pod-secrets-34c117ef-49bd-11e9-9475-02f976e168bb to disappear
Mar 18 20:34:21.472: INFO: Pod pod-secrets-34c117ef-49bd-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:34:21.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-66ckw" for this suite.
Mar 18 20:34:27.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:34:27.551: INFO: namespace: e2e-tests-secrets-66ckw, resource: bindings, ignored listing per whitelist
Mar 18 20:34:27.563: INFO: namespace e2e-tests-secrets-66ckw deletion completed in 6.087321876s

• [SLOW TEST:8.200 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:34:27.563: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-39aab5c9-49bd-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 20:34:27.673: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-39ab24a1-49bd-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-8t7l8" to be "success or failure"
Mar 18 20:34:27.678: INFO: Pod "pod-projected-secrets-39ab24a1-49bd-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.50234ms
Mar 18 20:34:29.680: INFO: Pod "pod-projected-secrets-39ab24a1-49bd-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007248196s
STEP: Saw pod success
Mar 18 20:34:29.680: INFO: Pod "pod-projected-secrets-39ab24a1-49bd-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:34:29.682: INFO: Trying to get logs from node node-1 pod pod-projected-secrets-39ab24a1-49bd-11e9-9475-02f976e168bb container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 18 20:34:29.705: INFO: Waiting for pod pod-projected-secrets-39ab24a1-49bd-11e9-9475-02f976e168bb to disappear
Mar 18 20:34:29.717: INFO: Pod pod-projected-secrets-39ab24a1-49bd-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:34:29.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8t7l8" for this suite.
Mar 18 20:34:35.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:34:35.765: INFO: namespace: e2e-tests-projected-8t7l8, resource: bindings, ignored listing per whitelist
Mar 18 20:34:35.828: INFO: namespace e2e-tests-projected-8t7l8 deletion completed in 6.107079409s

• [SLOW TEST:8.265 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:34:35.828: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 18 20:34:41.909: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dpppz PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:34:41.909: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:34:41.970: INFO: Exec stderr: ""
Mar 18 20:34:41.970: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dpppz PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:34:41.970: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:34:42.033: INFO: Exec stderr: ""
Mar 18 20:34:42.033: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dpppz PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:34:42.033: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:34:42.094: INFO: Exec stderr: ""
Mar 18 20:34:42.094: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dpppz PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:34:42.094: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:34:42.154: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 18 20:34:42.154: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dpppz PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:34:42.154: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:34:42.215: INFO: Exec stderr: ""
Mar 18 20:34:42.215: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dpppz PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:34:42.215: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:34:42.277: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 18 20:34:42.277: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dpppz PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:34:42.277: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:34:42.340: INFO: Exec stderr: ""
Mar 18 20:34:42.340: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dpppz PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:34:42.340: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:34:42.418: INFO: Exec stderr: ""
Mar 18 20:34:42.418: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dpppz PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:34:42.418: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:34:42.481: INFO: Exec stderr: ""
Mar 18 20:34:42.481: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dpppz PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:34:42.481: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:34:42.543: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:34:42.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-dpppz" for this suite.
Mar 18 20:35:24.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:35:24.607: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-dpppz, resource: bindings, ignored listing per whitelist
Mar 18 20:35:24.655: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-dpppz deletion completed in 42.1078143s

• [SLOW TEST:48.827 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:35:24.655: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 18 20:35:24.759: INFO: Waiting up to 5m0s for pod "downward-api-5bb1fbb7-49bd-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-h7xnj" to be "success or failure"
Mar 18 20:35:24.763: INFO: Pod "downward-api-5bb1fbb7-49bd-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.215672ms
Mar 18 20:35:26.766: INFO: Pod "downward-api-5bb1fbb7-49bd-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006215951s
STEP: Saw pod success
Mar 18 20:35:26.766: INFO: Pod "downward-api-5bb1fbb7-49bd-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:35:26.768: INFO: Trying to get logs from node node-1 pod downward-api-5bb1fbb7-49bd-11e9-9475-02f976e168bb container dapi-container: <nil>
STEP: delete the pod
Mar 18 20:35:26.788: INFO: Waiting for pod downward-api-5bb1fbb7-49bd-11e9-9475-02f976e168bb to disappear
Mar 18 20:35:26.795: INFO: Pod downward-api-5bb1fbb7-49bd-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:35:26.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-h7xnj" for this suite.
Mar 18 20:35:32.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:35:32.825: INFO: namespace: e2e-tests-downward-api-h7xnj, resource: bindings, ignored listing per whitelist
Mar 18 20:35:32.889: INFO: namespace e2e-tests-downward-api-h7xnj deletion completed in 6.089986593s

• [SLOW TEST:8.233 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:35:32.889: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nfnm2
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 18 20:35:32.946: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 18 20:35:55.081: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.0.35:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nfnm2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:35:55.081: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:35:55.154: INFO: Found all expected endpoints: [netserver-0]
Mar 18 20:35:55.156: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.2.13:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nfnm2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:35:55.156: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:35:55.225: INFO: Found all expected endpoints: [netserver-1]
Mar 18 20:35:55.227: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.13:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nfnm2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:35:55.227: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:35:55.287: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:35:55.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nfnm2" for this suite.
Mar 18 20:36:17.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:36:17.313: INFO: namespace: e2e-tests-pod-network-test-nfnm2, resource: bindings, ignored listing per whitelist
Mar 18 20:36:17.376: INFO: namespace e2e-tests-pod-network-test-nfnm2 deletion completed in 22.085523373s

• [SLOW TEST:44.487 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:36:17.376: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:36:17.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5q8j7" for this suite.
Mar 18 20:36:39.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:36:39.484: INFO: namespace: e2e-tests-pods-5q8j7, resource: bindings, ignored listing per whitelist
Mar 18 20:36:39.550: INFO: namespace e2e-tests-pods-5q8j7 deletion completed in 22.093963011s

• [SLOW TEST:22.174 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:36:39.550: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-884f7da1-49bd-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 20:36:39.613: INFO: Waiting up to 5m0s for pod "pod-configmaps-884fe369-49bd-11e9-9475-02f976e168bb" in namespace "e2e-tests-configmap-g246c" to be "success or failure"
Mar 18 20:36:39.619: INFO: Pod "pod-configmaps-884fe369-49bd-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.472245ms
Mar 18 20:36:41.622: INFO: Pod "pod-configmaps-884fe369-49bd-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008449015s
STEP: Saw pod success
Mar 18 20:36:41.622: INFO: Pod "pod-configmaps-884fe369-49bd-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:36:41.624: INFO: Trying to get logs from node node-1 pod pod-configmaps-884fe369-49bd-11e9-9475-02f976e168bb container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 20:36:41.653: INFO: Waiting for pod pod-configmaps-884fe369-49bd-11e9-9475-02f976e168bb to disappear
Mar 18 20:36:41.658: INFO: Pod pod-configmaps-884fe369-49bd-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:36:41.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g246c" for this suite.
Mar 18 20:36:47.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:36:47.699: INFO: namespace: e2e-tests-configmap-g246c, resource: bindings, ignored listing per whitelist
Mar 18 20:36:47.751: INFO: namespace e2e-tests-configmap-g246c deletion completed in 6.090398341s

• [SLOW TEST:8.201 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:36:47.752: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar 18 20:36:49.827: INFO: Pod pod-hostip-8d32760f-49bd-11e9-9475-02f976e168bb has hostIP: 172.31.35.20
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:36:49.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sjxsq" for this suite.
Mar 18 20:37:11.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:37:11.874: INFO: namespace: e2e-tests-pods-sjxsq, resource: bindings, ignored listing per whitelist
Mar 18 20:37:11.954: INFO: namespace e2e-tests-pods-sjxsq deletion completed in 22.124023595s

• [SLOW TEST:24.202 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:37:11.954: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9ba217f8-49bd-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 20:37:12.035: INFO: Waiting up to 5m0s for pod "pod-secrets-9ba29a15-49bd-11e9-9475-02f976e168bb" in namespace "e2e-tests-secrets-n2tfn" to be "success or failure"
Mar 18 20:37:12.037: INFO: Pod "pod-secrets-9ba29a15-49bd-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.555803ms
Mar 18 20:37:14.041: INFO: Pod "pod-secrets-9ba29a15-49bd-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005809922s
STEP: Saw pod success
Mar 18 20:37:14.041: INFO: Pod "pod-secrets-9ba29a15-49bd-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:37:14.043: INFO: Trying to get logs from node node-1 pod pod-secrets-9ba29a15-49bd-11e9-9475-02f976e168bb container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 20:37:14.060: INFO: Waiting for pod pod-secrets-9ba29a15-49bd-11e9-9475-02f976e168bb to disappear
Mar 18 20:37:14.076: INFO: Pod pod-secrets-9ba29a15-49bd-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:37:14.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n2tfn" for this suite.
Mar 18 20:37:20.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:37:20.113: INFO: namespace: e2e-tests-secrets-n2tfn, resource: bindings, ignored listing per whitelist
Mar 18 20:37:20.168: INFO: namespace e2e-tests-secrets-n2tfn deletion completed in 6.087643447s

• [SLOW TEST:8.215 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:37:20.169: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 18 20:37:24.267: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:24.269: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:26.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:26.273: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:28.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:28.273: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:30.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:30.273: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:32.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:32.273: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:34.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:34.273: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:36.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:36.273: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:38.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:38.272: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:40.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:40.273: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:42.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:42.273: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:44.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:44.274: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:46.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:46.273: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 20:37:48.270: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 20:37:48.273: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:37:48.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pw9dg" for this suite.
Mar 18 20:38:10.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:38:10.298: INFO: namespace: e2e-tests-container-lifecycle-hook-pw9dg, resource: bindings, ignored listing per whitelist
Mar 18 20:38:10.368: INFO: namespace e2e-tests-container-lifecycle-hook-pw9dg deletion completed in 22.089318066s

• [SLOW TEST:50.200 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:38:10.368: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-be70eb5b-49bd-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 20:38:10.430: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-be7156be-49bd-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-x7zdp" to be "success or failure"
Mar 18 20:38:10.435: INFO: Pod "pod-projected-configmaps-be7156be-49bd-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.849889ms
Mar 18 20:38:12.438: INFO: Pod "pod-projected-configmaps-be7156be-49bd-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008046353s
STEP: Saw pod success
Mar 18 20:38:12.438: INFO: Pod "pod-projected-configmaps-be7156be-49bd-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:38:12.440: INFO: Trying to get logs from node node-1 pod pod-projected-configmaps-be7156be-49bd-11e9-9475-02f976e168bb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 20:38:12.460: INFO: Waiting for pod pod-projected-configmaps-be7156be-49bd-11e9-9475-02f976e168bb to disappear
Mar 18 20:38:12.468: INFO: Pod pod-projected-configmaps-be7156be-49bd-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:38:12.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x7zdp" for this suite.
Mar 18 20:38:18.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:38:18.536: INFO: namespace: e2e-tests-projected-x7zdp, resource: bindings, ignored listing per whitelist
Mar 18 20:38:18.560: INFO: namespace e2e-tests-projected-x7zdp deletion completed in 6.087704333s

• [SLOW TEST:8.191 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:38:18.560: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 18 20:38:18.624: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-s2vhd,SelfLink:/api/v1/namespaces/e2e-tests-watch-s2vhd/configmaps/e2e-watch-test-label-changed,UID:c35269eb-49bd-11e9-a0d3-06934a8be3ba,ResourceVersion:4223,Generation:0,CreationTimestamp:2019-03-18 20:38:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 18 20:38:18.625: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-s2vhd,SelfLink:/api/v1/namespaces/e2e-tests-watch-s2vhd/configmaps/e2e-watch-test-label-changed,UID:c35269eb-49bd-11e9-a0d3-06934a8be3ba,ResourceVersion:4224,Generation:0,CreationTimestamp:2019-03-18 20:38:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 18 20:38:18.625: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-s2vhd,SelfLink:/api/v1/namespaces/e2e-tests-watch-s2vhd/configmaps/e2e-watch-test-label-changed,UID:c35269eb-49bd-11e9-a0d3-06934a8be3ba,ResourceVersion:4225,Generation:0,CreationTimestamp:2019-03-18 20:38:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 18 20:38:28.644: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-s2vhd,SelfLink:/api/v1/namespaces/e2e-tests-watch-s2vhd/configmaps/e2e-watch-test-label-changed,UID:c35269eb-49bd-11e9-a0d3-06934a8be3ba,ResourceVersion:4243,Generation:0,CreationTimestamp:2019-03-18 20:38:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 18 20:38:28.645: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-s2vhd,SelfLink:/api/v1/namespaces/e2e-tests-watch-s2vhd/configmaps/e2e-watch-test-label-changed,UID:c35269eb-49bd-11e9-a0d3-06934a8be3ba,ResourceVersion:4244,Generation:0,CreationTimestamp:2019-03-18 20:38:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 18 20:38:28.645: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-s2vhd,SelfLink:/api/v1/namespaces/e2e-tests-watch-s2vhd/configmaps/e2e-watch-test-label-changed,UID:c35269eb-49bd-11e9-a0d3-06934a8be3ba,ResourceVersion:4245,Generation:0,CreationTimestamp:2019-03-18 20:38:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:38:28.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-s2vhd" for this suite.
Mar 18 20:38:34.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:38:34.752: INFO: namespace: e2e-tests-watch-s2vhd, resource: bindings, ignored listing per whitelist
Mar 18 20:38:34.754: INFO: namespace e2e-tests-watch-s2vhd deletion completed in 6.106415812s

• [SLOW TEST:16.194 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:38:34.754: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 20:38:34.831: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 18 20:38:34.837: INFO: Number of nodes with available pods: 0
Mar 18 20:38:34.837: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 18 20:38:34.851: INFO: Number of nodes with available pods: 0
Mar 18 20:38:34.851: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:35.854: INFO: Number of nodes with available pods: 1
Mar 18 20:38:35.854: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 18 20:38:35.868: INFO: Number of nodes with available pods: 1
Mar 18 20:38:35.868: INFO: Number of running nodes: 0, number of available pods: 1
Mar 18 20:38:36.870: INFO: Number of nodes with available pods: 0
Mar 18 20:38:36.870: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 18 20:38:36.879: INFO: Number of nodes with available pods: 0
Mar 18 20:38:36.879: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:37.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:37.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:38.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:38.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:39.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:39.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:40.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:40.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:41.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:41.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:42.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:42.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:43.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:43.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:44.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:44.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:45.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:45.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:46.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:46.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:47.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:47.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:48.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:48.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:49.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:49.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:50.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:50.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:51.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:51.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:52.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:52.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:53.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:53.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:54.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:54.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:55.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:55.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:56.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:56.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:57.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:57.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:58.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:58.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:38:59.882: INFO: Number of nodes with available pods: 0
Mar 18 20:38:59.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:00.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:00.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:01.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:01.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:02.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:02.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:03.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:03.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:04.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:04.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:05.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:05.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:06.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:06.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:07.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:07.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:08.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:08.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:09.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:09.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:10.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:10.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:11.883: INFO: Number of nodes with available pods: 0
Mar 18 20:39:11.883: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:12.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:12.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:13.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:13.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:14.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:14.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:15.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:15.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:16.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:16.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:17.882: INFO: Number of nodes with available pods: 0
Mar 18 20:39:17.882: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:39:18.882: INFO: Number of nodes with available pods: 1
Mar 18 20:39:18.882: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-zqbmw, will wait for the garbage collector to delete the pods
Mar 18 20:39:18.947: INFO: Deleting DaemonSet.extensions daemon-set took: 5.775501ms
Mar 18 20:39:19.047: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.216846ms
Mar 18 20:39:56.651: INFO: Number of nodes with available pods: 0
Mar 18 20:39:56.651: INFO: Number of running nodes: 0, number of available pods: 0
Mar 18 20:39:56.654: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zqbmw/daemonsets","resourceVersion":"4438"},"items":null}

Mar 18 20:39:56.656: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zqbmw/pods","resourceVersion":"4438"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:39:56.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zqbmw" for this suite.
Mar 18 20:40:02.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:40:02.768: INFO: namespace: e2e-tests-daemonsets-zqbmw, resource: bindings, ignored listing per whitelist
Mar 18 20:40:02.792: INFO: namespace e2e-tests-daemonsets-zqbmw deletion completed in 6.111962199s

• [SLOW TEST:88.038 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:40:02.792: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-01756024-49be-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 20:40:02.868: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0175ede4-49be-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-gkzs7" to be "success or failure"
Mar 18 20:40:02.871: INFO: Pod "pod-projected-configmaps-0175ede4-49be-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.365205ms
Mar 18 20:40:04.874: INFO: Pod "pod-projected-configmaps-0175ede4-49be-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006463913s
STEP: Saw pod success
Mar 18 20:40:04.874: INFO: Pod "pod-projected-configmaps-0175ede4-49be-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:40:04.876: INFO: Trying to get logs from node node-1 pod pod-projected-configmaps-0175ede4-49be-11e9-9475-02f976e168bb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 20:40:04.893: INFO: Waiting for pod pod-projected-configmaps-0175ede4-49be-11e9-9475-02f976e168bb to disappear
Mar 18 20:40:04.902: INFO: Pod pod-projected-configmaps-0175ede4-49be-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:40:04.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gkzs7" for this suite.
Mar 18 20:40:10.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:40:10.973: INFO: namespace: e2e-tests-projected-gkzs7, resource: bindings, ignored listing per whitelist
Mar 18 20:40:10.999: INFO: namespace e2e-tests-projected-gkzs7 deletion completed in 6.091249029s

• [SLOW TEST:8.207 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:40:10.999: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 18 20:40:11.107: INFO: Waiting up to 5m0s for pod "downward-api-065f3cc8-49be-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-2rn6p" to be "success or failure"
Mar 18 20:40:11.110: INFO: Pod "downward-api-065f3cc8-49be-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.876735ms
Mar 18 20:40:13.114: INFO: Pod "downward-api-065f3cc8-49be-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006625403s
STEP: Saw pod success
Mar 18 20:40:13.114: INFO: Pod "downward-api-065f3cc8-49be-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:40:13.116: INFO: Trying to get logs from node node-1 pod downward-api-065f3cc8-49be-11e9-9475-02f976e168bb container dapi-container: <nil>
STEP: delete the pod
Mar 18 20:40:13.139: INFO: Waiting for pod downward-api-065f3cc8-49be-11e9-9475-02f976e168bb to disappear
Mar 18 20:40:13.149: INFO: Pod downward-api-065f3cc8-49be-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:40:13.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2rn6p" for this suite.
Mar 18 20:40:19.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:40:19.182: INFO: namespace: e2e-tests-downward-api-2rn6p, resource: bindings, ignored listing per whitelist
Mar 18 20:40:19.236: INFO: namespace e2e-tests-downward-api-2rn6p deletion completed in 6.08406323s

• [SLOW TEST:8.238 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:40:19.237: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-0b411d99-49be-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 20:40:19.303: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0b419461-49be-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-fjlx8" to be "success or failure"
Mar 18 20:40:19.313: INFO: Pod "pod-projected-secrets-0b419461-49be-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.510184ms
Mar 18 20:40:21.317: INFO: Pod "pod-projected-secrets-0b419461-49be-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013804487s
STEP: Saw pod success
Mar 18 20:40:21.317: INFO: Pod "pod-projected-secrets-0b419461-49be-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:40:21.319: INFO: Trying to get logs from node node-1 pod pod-projected-secrets-0b419461-49be-11e9-9475-02f976e168bb container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 18 20:40:21.342: INFO: Waiting for pod pod-projected-secrets-0b419461-49be-11e9-9475-02f976e168bb to disappear
Mar 18 20:40:21.344: INFO: Pod pod-projected-secrets-0b419461-49be-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:40:21.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fjlx8" for this suite.
Mar 18 20:40:27.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:40:27.386: INFO: namespace: e2e-tests-projected-fjlx8, resource: bindings, ignored listing per whitelist
Mar 18 20:40:27.444: INFO: namespace e2e-tests-projected-fjlx8 deletion completed in 6.092051149s

• [SLOW TEST:8.208 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:40:27.445: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar 18 20:40:27.511: INFO: Pod name pod-release: Found 0 pods out of 1
Mar 18 20:40:32.514: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:40:32.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8dqf6" for this suite.
Mar 18 20:40:38.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:40:38.655: INFO: namespace: e2e-tests-replication-controller-8dqf6, resource: bindings, ignored listing per whitelist
Mar 18 20:40:38.668: INFO: namespace e2e-tests-replication-controller-8dqf6 deletion completed in 6.126574094s

• [SLOW TEST:11.223 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:40:38.668: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 20:40:38.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 version --client'
Mar 18 20:40:38.782: INFO: stderr: ""
Mar 18 20:40:38.782: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar 18 20:40:38.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-47hdq'
Mar 18 20:40:39.174: INFO: stderr: ""
Mar 18 20:40:39.174: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar 18 20:40:39.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-47hdq'
Mar 18 20:40:39.327: INFO: stderr: ""
Mar 18 20:40:39.327: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 18 20:40:40.330: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:40:40.330: INFO: Found 0 / 1
Mar 18 20:40:41.330: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:40:41.330: INFO: Found 1 / 1
Mar 18 20:40:41.330: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 18 20:40:41.332: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:40:41.332: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 18 20:40:41.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 describe pod redis-master-245bn --namespace=e2e-tests-kubectl-47hdq'
Mar 18 20:40:41.422: INFO: stderr: ""
Mar 18 20:40:41.422: INFO: stdout: "Name:               redis-master-245bn\nNamespace:          e2e-tests-kubectl-47hdq\nPriority:           0\nPriorityClassName:  <none>\nNode:               node-1/172.31.35.20\nStart Time:         Mon, 18 Mar 2019 20:40:39 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.42.0.51/32\nStatus:             Running\nIP:                 10.42.0.51\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://5bc0d3adc73d104ff958c3267a3c88235b7a5f062109e174889274e5f7cbab0b\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 18 Mar 2019 20:40:39 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-mm7mr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-mm7mr:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-mm7mr\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned e2e-tests-kubectl-47hdq/redis-master-245bn to node-1\n  Normal  Pulled     2s    kubelet, node-1    Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, node-1    Created container\n  Normal  Started    2s    kubelet, node-1    Started container\n"
Mar 18 20:40:41.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 describe rc redis-master --namespace=e2e-tests-kubectl-47hdq'
Mar 18 20:40:41.510: INFO: stderr: ""
Mar 18 20:40:41.510: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-47hdq\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-245bn\n"
Mar 18 20:40:41.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 describe service redis-master --namespace=e2e-tests-kubectl-47hdq'
Mar 18 20:40:41.590: INFO: stderr: ""
Mar 18 20:40:41.590: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-47hdq\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.43.57.77\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.42.0.51:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 18 20:40:41.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 describe node node-1'
Mar 18 20:40:41.689: INFO: stderr: ""
Mar 18 20:40:41.689: INFO: stdout: "Name:               node-1\nRoles:              controlplane,etcd,worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=node-1\n                    node-role.kubernetes.io/controlplane=true\n                    node-role.kubernetes.io/etcd=true\n                    node-role.kubernetes.io/worker=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"e6:08:8c:91:fd:dc\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.31.35.20\n                    node.alpha.kubernetes.io/ttl: 0\n                    rke.cattle.io/external-ip: 34.208.215.193\n                    rke.cattle.io/internal-ip: 34.208.215.193\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 18 Mar 2019 20:19:06 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 18 Mar 2019 20:40:39 +0000   Mon, 18 Mar 2019 20:19:06 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 18 Mar 2019 20:40:39 +0000   Mon, 18 Mar 2019 20:19:06 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 18 Mar 2019 20:40:39 +0000   Mon, 18 Mar 2019 20:19:06 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 18 Mar 2019 20:40:39 +0000   Mon, 18 Mar 2019 20:19:46 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.31.35.20\n  Hostname:    node-1\nCapacity:\n cpu:                2\n ephemeral-storage:  8065444Ki\n hugepages-2Mi:      0\n memory:             4045052Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  7433113179\n hugepages-2Mi:      0\n memory:             3942652Ki\n pods:               110\nSystem Info:\n Machine ID:                 3d6ff2f75c7d3ae927580249a28e7e05\n System UUID:                EC2A56DE-FF88-DA76-4726-E4953C59AE01\n Boot ID:                    c99ee2b7-cf46-4070-a0d7-ed0ccd2b8495\n Kernel Version:             4.4.0-1067-aws\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.13.4\n Kube-Proxy Version:         v1.13.4\nPodCIDR:                     10.42.0.0/24\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-47hdq    redis-master-245bn                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-lhbmj    0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n  ingress-nginx              nginx-ingress-controller-x6mz2                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         20m\n  kube-system                canal-k9vqq                                                250m (12%)    0 (0%)      0 (0%)           0 (0%)         21m\n  kube-system                metrics-server-58bd5dd8d7-gzdst                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         20m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                Message\n  ----    ------                   ----               ----                -------\n  Normal  Starting                 21m                kubelet, node-1     Starting kubelet.\n  Normal  NodeHasSufficientMemory  21m (x2 over 21m)  kubelet, node-1     Node node-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    21m (x2 over 21m)  kubelet, node-1     Node node-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     21m (x2 over 21m)  kubelet, node-1     Node node-1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  21m                kubelet, node-1     Updated Node Allocatable limit across pods\n  Normal  Starting                 21m                kube-proxy, node-1  Starting kube-proxy.\n  Normal  NodeReady                20m                kubelet, node-1     Node node-1 status is now: NodeReady\n"
Mar 18 20:40:41.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 describe namespace e2e-tests-kubectl-47hdq'
Mar 18 20:40:41.765: INFO: stderr: ""
Mar 18 20:40:41.765: INFO: stdout: "Name:         e2e-tests-kubectl-47hdq\nLabels:       e2e-framework=kubectl\n              e2e-run=0660dcfc-49bc-11e9-9475-02f976e168bb\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:40:41.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-47hdq" for this suite.
Mar 18 20:41:03.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:41:03.854: INFO: namespace: e2e-tests-kubectl-47hdq, resource: bindings, ignored listing per whitelist
Mar 18 20:41:03.865: INFO: namespace e2e-tests-kubectl-47hdq deletion completed in 22.096376057s

• [SLOW TEST:25.198 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:41:03.866: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 20:41:03.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-p9p69'
Mar 18 20:41:04.010: INFO: stderr: ""
Mar 18 20:41:04.010: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar 18 20:41:09.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-p9p69 -o json'
Mar 18 20:41:09.125: INFO: stderr: ""
Mar 18 20:41:09.125: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.42.0.52/32\"\n        },\n        \"creationTimestamp\": \"2019-03-18T20:41:03Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-p9p69\",\n        \"resourceVersion\": \"4737\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-p9p69/pods/e2e-test-nginx-pod\",\n        \"uid\": \"25e69eee-49be-11e9-a0d3-06934a8be3ba\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-vmk2m\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"node-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-vmk2m\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-vmk2m\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-18T20:41:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-18T20:41:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-18T20:41:04Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-18T20:41:04Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://2f3a143373ba553a61c2e379c6f80c083d8846062d711e74c7d6a82ee7bce419\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-18T20:41:04Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.35.20\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.0.52\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-18T20:41:04Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 18 20:41:09.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 replace -f - --namespace=e2e-tests-kubectl-p9p69'
Mar 18 20:41:09.271: INFO: stderr: ""
Mar 18 20:41:09.271: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Mar 18 20:41:09.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-p9p69'
Mar 18 20:41:10.877: INFO: stderr: ""
Mar 18 20:41:10.877: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:41:10.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p9p69" for this suite.
Mar 18 20:41:16.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:41:16.968: INFO: namespace: e2e-tests-kubectl-p9p69, resource: bindings, ignored listing per whitelist
Mar 18 20:41:16.997: INFO: namespace e2e-tests-kubectl-p9p69 deletion completed in 6.103823903s

• [SLOW TEST:13.131 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:41:16.997: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bsv9m
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 18 20:41:17.062: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 18 20:41:41.135: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.1.14 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bsv9m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:41:41.135: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:41:42.190: INFO: Found all expected endpoints: [netserver-0]
Mar 18 20:41:42.192: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.2.14 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bsv9m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:41:42.192: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:41:43.250: INFO: Found all expected endpoints: [netserver-1]
Mar 18 20:41:43.254: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.0.53 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bsv9m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:41:43.254: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:41:44.318: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:41:44.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bsv9m" for this suite.
Mar 18 20:42:06.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:42:06.399: INFO: namespace: e2e-tests-pod-network-test-bsv9m, resource: bindings, ignored listing per whitelist
Mar 18 20:42:06.410: INFO: namespace e2e-tests-pod-network-test-bsv9m deletion completed in 22.087846614s

• [SLOW TEST:49.414 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:42:06.411: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 18 20:42:06.476: INFO: Waiting up to 5m0s for pod "pod-4b222c29-49be-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-6nz9p" to be "success or failure"
Mar 18 20:42:06.482: INFO: Pod "pod-4b222c29-49be-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.157716ms
Mar 18 20:42:08.485: INFO: Pod "pod-4b222c29-49be-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009067287s
STEP: Saw pod success
Mar 18 20:42:08.485: INFO: Pod "pod-4b222c29-49be-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:42:08.487: INFO: Trying to get logs from node node-1 pod pod-4b222c29-49be-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 20:42:08.505: INFO: Waiting for pod pod-4b222c29-49be-11e9-9475-02f976e168bb to disappear
Mar 18 20:42:08.517: INFO: Pod pod-4b222c29-49be-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:42:08.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6nz9p" for this suite.
Mar 18 20:42:14.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:42:14.571: INFO: namespace: e2e-tests-emptydir-6nz9p, resource: bindings, ignored listing per whitelist
Mar 18 20:42:14.608: INFO: namespace e2e-tests-emptydir-6nz9p deletion completed in 6.087009997s

• [SLOW TEST:8.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:42:14.608: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 20:42:14.669: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5005237e-49be-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-hd2c7" to be "success or failure"
Mar 18 20:42:14.671: INFO: Pod "downwardapi-volume-5005237e-49be-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.105991ms
Mar 18 20:42:16.674: INFO: Pod "downwardapi-volume-5005237e-49be-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005126034s
STEP: Saw pod success
Mar 18 20:42:16.674: INFO: Pod "downwardapi-volume-5005237e-49be-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:42:16.676: INFO: Trying to get logs from node node-1 pod downwardapi-volume-5005237e-49be-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 20:42:16.696: INFO: Waiting for pod downwardapi-volume-5005237e-49be-11e9-9475-02f976e168bb to disappear
Mar 18 20:42:16.701: INFO: Pod downwardapi-volume-5005237e-49be-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:42:16.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hd2c7" for this suite.
Mar 18 20:42:22.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:42:22.750: INFO: namespace: e2e-tests-downward-api-hd2c7, resource: bindings, ignored listing per whitelist
Mar 18 20:42:22.791: INFO: namespace e2e-tests-downward-api-hd2c7 deletion completed in 6.085094622s

• [SLOW TEST:8.183 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:42:22.791: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar 18 20:42:22.853: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-818169620 proxy --unix-socket=/tmp/kubectl-proxy-unix225050467/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:42:22.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zv5dg" for this suite.
Mar 18 20:42:28.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:42:28.940: INFO: namespace: e2e-tests-kubectl-zv5dg, resource: bindings, ignored listing per whitelist
Mar 18 20:42:29.000: INFO: namespace e2e-tests-kubectl-zv5dg deletion completed in 6.096276482s

• [SLOW TEST:6.209 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:42:29.001: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 18 20:42:29.066: INFO: Waiting up to 5m0s for pod "downward-api-5899deaa-49be-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-4s7cr" to be "success or failure"
Mar 18 20:42:29.071: INFO: Pod "downward-api-5899deaa-49be-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.169129ms
Mar 18 20:42:31.074: INFO: Pod "downward-api-5899deaa-49be-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00796132s
STEP: Saw pod success
Mar 18 20:42:31.074: INFO: Pod "downward-api-5899deaa-49be-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:42:31.076: INFO: Trying to get logs from node node-1 pod downward-api-5899deaa-49be-11e9-9475-02f976e168bb container dapi-container: <nil>
STEP: delete the pod
Mar 18 20:42:31.094: INFO: Waiting for pod downward-api-5899deaa-49be-11e9-9475-02f976e168bb to disappear
Mar 18 20:42:31.103: INFO: Pod downward-api-5899deaa-49be-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:42:31.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4s7cr" for this suite.
Mar 18 20:42:37.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:42:37.154: INFO: namespace: e2e-tests-downward-api-4s7cr, resource: bindings, ignored listing per whitelist
Mar 18 20:42:37.199: INFO: namespace e2e-tests-downward-api-4s7cr deletion completed in 6.085512403s

• [SLOW TEST:8.198 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:42:37.199: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 20:42:37.255: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:42:38.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-n42kh" for this suite.
Mar 18 20:42:44.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:42:44.315: INFO: namespace: e2e-tests-custom-resource-definition-n42kh, resource: bindings, ignored listing per whitelist
Mar 18 20:42:44.381: INFO: namespace e2e-tests-custom-resource-definition-n42kh deletion completed in 6.0846747s

• [SLOW TEST:7.183 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:42:44.381: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 20:42:44.439: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 18 20:42:49.443: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 18 20:42:49.443: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 18 20:42:51.446: INFO: Creating deployment "test-rollover-deployment"
Mar 18 20:42:51.452: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 18 20:42:53.458: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 18 20:42:53.462: INFO: Ensure that both replica sets have 1 created replica
Mar 18 20:42:53.466: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 18 20:42:53.472: INFO: Updating deployment test-rollover-deployment
Mar 18 20:42:53.472: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 18 20:42:55.480: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 18 20:42:55.484: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 18 20:42:55.489: INFO: all replica sets need to contain the pod-template-hash label
Mar 18 20:42:55.489: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538574, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 18 20:42:57.494: INFO: all replica sets need to contain the pod-template-hash label
Mar 18 20:42:57.495: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538574, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 18 20:42:59.494: INFO: all replica sets need to contain the pod-template-hash label
Mar 18 20:42:59.495: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538574, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 18 20:43:01.496: INFO: all replica sets need to contain the pod-template-hash label
Mar 18 20:43:01.496: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538574, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 18 20:43:03.494: INFO: all replica sets need to contain the pod-template-hash label
Mar 18 20:43:03.494: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538574, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688538571, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 18 20:43:05.495: INFO: 
Mar 18 20:43:05.495: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 18 20:43:05.501: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-rknlx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rknlx/deployments/test-rollover-deployment,UID:65f17397-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5213,Generation:2,CreationTimestamp:2019-03-18 20:42:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-18 20:42:51 +0000 UTC 2019-03-18 20:42:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-18 20:43:04 +0000 UTC 2019-03-18 20:42:51 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 18 20:43:05.504: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-rknlx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rknlx/replicasets/test-rollover-deployment-6b7f9d6597,UID:672685e6-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5204,Generation:2,CreationTimestamp:2019-03-18 20:42:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 65f17397-49be-11e9-a0d3-06934a8be3ba 0xc001ee8377 0xc001ee8378}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 18 20:43:05.504: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 18 20:43:05.504: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-rknlx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rknlx/replicasets/test-rollover-controller,UID:61c36410-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5212,Generation:2,CreationTimestamp:2019-03-18 20:42:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 65f17397-49be-11e9-a0d3-06934a8be3ba 0xc001ee81ef 0xc001ee8200}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 20:43:05.504: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-rknlx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rknlx/replicasets/test-rollover-deployment-6586df867b,UID:65f3c542-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5178,Generation:2,CreationTimestamp:2019-03-18 20:42:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 65f17397-49be-11e9-a0d3-06934a8be3ba 0xc001ee82b7 0xc001ee82b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 20:43:05.506: INFO: Pod "test-rollover-deployment-6b7f9d6597-qtchw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-qtchw,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-rknlx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rknlx/pods/test-rollover-deployment-6b7f9d6597-qtchw,UID:6729a5c2-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5185,Generation:0,CreationTimestamp:2019-03-18 20:42:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.60/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 672685e6-49be-11e9-a0d3-06934a8be3ba 0xc001ee9357 0xc001ee9358}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lv6jd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lv6jd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lv6jd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ee93d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ee93f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:42:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:42:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:42:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:42:53 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:10.42.0.60,StartTime:2019-03-18 20:42:53 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-18 20:42:54 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://f65fb7dd7712364302d4d91912163d3052c4103cd0836a7f822fd3d113092c25}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:43:05.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rknlx" for this suite.
Mar 18 20:43:11.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:43:11.594: INFO: namespace: e2e-tests-deployment-rknlx, resource: bindings, ignored listing per whitelist
Mar 18 20:43:11.604: INFO: namespace e2e-tests-deployment-rknlx deletion completed in 6.093707978s

• [SLOW TEST:27.222 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:43:11.604: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 20:43:11.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-s8lfr'
Mar 18 20:43:11.752: INFO: stderr: ""
Mar 18 20:43:11.752: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Mar 18 20:43:11.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s8lfr'
Mar 18 20:43:16.554: INFO: stderr: ""
Mar 18 20:43:16.554: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:43:16.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s8lfr" for this suite.
Mar 18 20:43:22.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:43:22.633: INFO: namespace: e2e-tests-kubectl-s8lfr, resource: bindings, ignored listing per whitelist
Mar 18 20:43:22.649: INFO: namespace e2e-tests-kubectl-s8lfr deletion completed in 6.090621854s

• [SLOW TEST:11.045 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:43:22.649: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nzx6q
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 18 20:43:22.706: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 18 20:43:42.784: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.62:8080/dial?request=hostName&protocol=http&host=10.42.0.61&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-nzx6q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:43:42.784: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:43:42.849: INFO: Waiting for endpoints: map[]
Mar 18 20:43:42.852: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.62:8080/dial?request=hostName&protocol=http&host=10.42.1.15&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-nzx6q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:43:42.852: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:43:42.917: INFO: Waiting for endpoints: map[]
Mar 18 20:43:42.920: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.62:8080/dial?request=hostName&protocol=http&host=10.42.2.15&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-nzx6q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 20:43:42.920: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 20:43:42.986: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:43:42.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nzx6q" for this suite.
Mar 18 20:44:03.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:44:03.053: INFO: namespace: e2e-tests-pod-network-test-nzx6q, resource: bindings, ignored listing per whitelist
Mar 18 20:44:03.087: INFO: namespace e2e-tests-pod-network-test-nzx6q deletion completed in 20.097200409s

• [SLOW TEST:40.439 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:44:03.088: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 20:44:03.153: INFO: Waiting up to 5m0s for pod "downwardapi-volume-90ae927b-49be-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-qt5q7" to be "success or failure"
Mar 18 20:44:03.158: INFO: Pod "downwardapi-volume-90ae927b-49be-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.411422ms
Mar 18 20:44:05.161: INFO: Pod "downwardapi-volume-90ae927b-49be-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007430735s
STEP: Saw pod success
Mar 18 20:44:05.161: INFO: Pod "downwardapi-volume-90ae927b-49be-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:44:05.164: INFO: Trying to get logs from node node-1 pod downwardapi-volume-90ae927b-49be-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 20:44:05.180: INFO: Waiting for pod downwardapi-volume-90ae927b-49be-11e9-9475-02f976e168bb to disappear
Mar 18 20:44:05.187: INFO: Pod downwardapi-volume-90ae927b-49be-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:44:05.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qt5q7" for this suite.
Mar 18 20:44:11.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:44:11.249: INFO: namespace: e2e-tests-projected-qt5q7, resource: bindings, ignored listing per whitelist
Mar 18 20:44:11.290: INFO: namespace e2e-tests-projected-qt5q7 deletion completed in 6.095985888s

• [SLOW TEST:8.203 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:44:11.290: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 20:44:11.363: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9593240a-49be-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-xj9mp" to be "success or failure"
Mar 18 20:44:11.377: INFO: Pod "downwardapi-volume-9593240a-49be-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 13.437836ms
Mar 18 20:44:13.380: INFO: Pod "downwardapi-volume-9593240a-49be-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016575081s
STEP: Saw pod success
Mar 18 20:44:13.380: INFO: Pod "downwardapi-volume-9593240a-49be-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:44:13.382: INFO: Trying to get logs from node node-1 pod downwardapi-volume-9593240a-49be-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 20:44:13.402: INFO: Waiting for pod downwardapi-volume-9593240a-49be-11e9-9475-02f976e168bb to disappear
Mar 18 20:44:13.405: INFO: Pod downwardapi-volume-9593240a-49be-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:44:13.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xj9mp" for this suite.
Mar 18 20:44:19.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:44:19.431: INFO: namespace: e2e-tests-projected-xj9mp, resource: bindings, ignored listing per whitelist
Mar 18 20:44:19.499: INFO: namespace e2e-tests-projected-xj9mp deletion completed in 6.087831184s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:44:19.500: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 20:44:19.557: INFO: Creating deployment "test-recreate-deployment"
Mar 18 20:44:19.560: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 18 20:44:19.565: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Mar 18 20:44:21.571: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 18 20:44:21.573: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 18 20:44:21.579: INFO: Updating deployment test-recreate-deployment
Mar 18 20:44:21.579: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 18 20:44:21.689: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-kv67f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kv67f/deployments/test-recreate-deployment,UID:9a7610f0-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5570,Generation:2,CreationTimestamp:2019-03-18 20:44:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-18 20:44:21 +0000 UTC 2019-03-18 20:44:21 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-18 20:44:21 +0000 UTC 2019-03-18 20:44:19 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 18 20:44:21.693: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-kv67f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kv67f/replicasets/test-recreate-deployment-697fbf54bf,UID:9bb0e4fe-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5566,Generation:1,CreationTimestamp:2019-03-18 20:44:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9a7610f0-49be-11e9-a0d3-06934a8be3ba 0xc0019b7457 0xc0019b7458}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 20:44:21.693: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 18 20:44:21.693: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-kv67f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kv67f/replicasets/test-recreate-deployment-5dfdcc846d,UID:9a76fb3e-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5558,Generation:2,CreationTimestamp:2019-03-18 20:44:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9a7610f0-49be-11e9-a0d3-06934a8be3ba 0xc0019b73a7 0xc0019b73a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 20:44:21.698: INFO: Pod "test-recreate-deployment-697fbf54bf-lx6sm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-lx6sm,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-kv67f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kv67f/pods/test-recreate-deployment-697fbf54bf-lx6sm,UID:9bb15817-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5571,Generation:0,CreationTimestamp:2019-03-18 20:44:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 9bb0e4fe-49be-11e9-a0d3-06934a8be3ba 0xc0019b7f57 0xc0019b7f58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cwt56 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cwt56,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cwt56 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019b7fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a7c000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:44:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:44:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:44:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:44:21 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:,StartTime:2019-03-18 20:44:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:44:21.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-kv67f" for this suite.
Mar 18 20:44:27.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:44:27.788: INFO: namespace: e2e-tests-deployment-kv67f, resource: bindings, ignored listing per whitelist
Mar 18 20:44:27.793: INFO: namespace e2e-tests-deployment-kv67f deletion completed in 6.090540019s

• [SLOW TEST:8.293 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:44:27.793: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-6s4b2
Mar 18 20:44:31.860: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-6s4b2
STEP: checking the pod's current state and verifying that restartCount is present
Mar 18 20:44:31.862: INFO: Initial restart count of pod liveness-http is 0
Mar 18 20:44:45.884: INFO: Restart count of pod e2e-tests-container-probe-6s4b2/liveness-http is now 1 (14.02221072s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:44:45.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6s4b2" for this suite.
Mar 18 20:44:51.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:44:51.970: INFO: namespace: e2e-tests-container-probe-6s4b2, resource: bindings, ignored listing per whitelist
Mar 18 20:44:52.009: INFO: namespace e2e-tests-container-probe-6s4b2 deletion completed in 6.089810965s

• [SLOW TEST:24.217 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:44:52.010: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 18 20:44:52.071: INFO: Waiting up to 5m0s for pod "pod-add6f1be-49be-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-bgrss" to be "success or failure"
Mar 18 20:44:52.073: INFO: Pod "pod-add6f1be-49be-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.99778ms
Mar 18 20:44:54.076: INFO: Pod "pod-add6f1be-49be-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005194175s
STEP: Saw pod success
Mar 18 20:44:54.076: INFO: Pod "pod-add6f1be-49be-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:44:54.078: INFO: Trying to get logs from node node-1 pod pod-add6f1be-49be-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 20:44:54.113: INFO: Waiting for pod pod-add6f1be-49be-11e9-9475-02f976e168bb to disappear
Mar 18 20:44:54.127: INFO: Pod pod-add6f1be-49be-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:44:54.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bgrss" for this suite.
Mar 18 20:45:00.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:45:00.183: INFO: namespace: e2e-tests-emptydir-bgrss, resource: bindings, ignored listing per whitelist
Mar 18 20:45:00.217: INFO: namespace e2e-tests-emptydir-bgrss deletion completed in 6.086155737s

• [SLOW TEST:8.207 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:45:00.217: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 20:45:00.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ddj65'
Mar 18 20:45:00.394: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 18 20:45:00.394: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Mar 18 20:45:00.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-ddj65'
Mar 18 20:45:00.481: INFO: stderr: ""
Mar 18 20:45:00.481: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:45:00.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ddj65" for this suite.
Mar 18 20:45:22.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:45:22.546: INFO: namespace: e2e-tests-kubectl-ddj65, resource: bindings, ignored listing per whitelist
Mar 18 20:45:22.580: INFO: namespace e2e-tests-kubectl-ddj65 deletion completed in 22.095294336s

• [SLOW TEST:22.363 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:45:22.580: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 18 20:45:22.656: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-g2zmr,SelfLink:/api/v1/namespaces/e2e-tests-watch-g2zmr/configmaps/e2e-watch-test-resource-version,UID:c00f5b38-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5779,Generation:0,CreationTimestamp:2019-03-18 20:45:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 18 20:45:22.656: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-g2zmr,SelfLink:/api/v1/namespaces/e2e-tests-watch-g2zmr/configmaps/e2e-watch-test-resource-version,UID:c00f5b38-49be-11e9-a0d3-06934a8be3ba,ResourceVersion:5780,Generation:0,CreationTimestamp:2019-03-18 20:45:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:45:22.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-g2zmr" for this suite.
Mar 18 20:45:28.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:45:28.692: INFO: namespace: e2e-tests-watch-g2zmr, resource: bindings, ignored listing per whitelist
Mar 18 20:45:28.757: INFO: namespace e2e-tests-watch-g2zmr deletion completed in 6.097115567s

• [SLOW TEST:6.177 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:45:28.757: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 20:45:28.819: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3be394b-49be-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-rsx6l" to be "success or failure"
Mar 18 20:45:28.823: INFO: Pod "downwardapi-volume-c3be394b-49be-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.056037ms
Mar 18 20:45:30.827: INFO: Pod "downwardapi-volume-c3be394b-49be-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007845058s
STEP: Saw pod success
Mar 18 20:45:30.827: INFO: Pod "downwardapi-volume-c3be394b-49be-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:45:30.831: INFO: Trying to get logs from node node-1 pod downwardapi-volume-c3be394b-49be-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 20:45:30.861: INFO: Waiting for pod downwardapi-volume-c3be394b-49be-11e9-9475-02f976e168bb to disappear
Mar 18 20:45:30.866: INFO: Pod downwardapi-volume-c3be394b-49be-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:45:30.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rsx6l" for this suite.
Mar 18 20:45:36.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:45:36.933: INFO: namespace: e2e-tests-projected-rsx6l, resource: bindings, ignored listing per whitelist
Mar 18 20:45:36.988: INFO: namespace e2e-tests-projected-rsx6l deletion completed in 6.118764949s

• [SLOW TEST:8.232 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:45:36.989: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 20:45:37.103: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 18 20:45:37.118: INFO: Number of nodes with available pods: 0
Mar 18 20:45:37.118: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:45:38.171: INFO: Number of nodes with available pods: 1
Mar 18 20:45:38.171: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:45:39.207: INFO: Number of nodes with available pods: 3
Mar 18 20:45:39.207: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 18 20:45:39.245: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:39.245: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:39.245: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:40.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:40.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:40.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:41.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:41.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:41.272: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:42.294: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:42.294: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:42.294: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:43.276: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:43.276: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:43.276: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:44.276: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:44.276: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:44.276: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:45.274: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:45.274: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:45.274: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:46.273: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:46.273: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:46.273: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:47.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:47.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:47.272: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:48.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:48.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:48.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:49.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:49.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:49.272: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:50.275: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:50.275: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:50.275: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:51.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:51.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:51.272: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:52.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:52.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:52.272: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:53.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:53.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:53.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:54.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:54.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:54.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:55.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:55.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:55.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:56.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:56.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:56.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:57.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:57.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:57.272: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:58.273: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:58.273: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:58.273: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:59.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:59.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:45:59.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:00.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:00.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:00.272: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:01.274: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:01.274: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:01.274: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:02.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:02.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:02.272: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:03.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:03.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:03.272: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:04.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:04.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:04.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:05.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:05.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:05.272: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:06.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:06.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:06.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:07.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:07.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:07.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:08.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:08.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:08.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:09.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:09.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:09.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:10.274: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:10.274: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:10.274: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:11.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:11.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:11.271: INFO: Wrong image for pod: daemon-set-z5hp8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:11.271: INFO: Pod daemon-set-z5hp8 is not available
Mar 18 20:46:12.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:12.271: INFO: Pod daemon-set-kgk5h is not available
Mar 18 20:46:12.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:13.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:13.272: INFO: Pod daemon-set-kgk5h is not available
Mar 18 20:46:13.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:14.273: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:14.273: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:15.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:15.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:16.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:16.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:17.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:17.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:18.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:18.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:19.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:19.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:20.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:20.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:21.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:21.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:22.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:22.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:23.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:23.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:24.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:24.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:25.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:25.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:26.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:26.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:27.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:27.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:28.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:28.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:29.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:29.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:30.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:30.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:31.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:31.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:32.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:32.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:33.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:33.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:34.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:34.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:35.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:35.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:36.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:36.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:37.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:37.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:38.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:38.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:39.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:39.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:40.272: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:40.272: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:41.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:41.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:42.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:42.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:43.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:43.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:44.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:44.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:45.271: INFO: Wrong image for pod: daemon-set-6kthr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:45.271: INFO: Pod daemon-set-6kthr is not available
Mar 18 20:46:45.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:46.275: INFO: Pod daemon-set-nzc8r is not available
Mar 18 20:46:46.275: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:47.271: INFO: Pod daemon-set-nzc8r is not available
Mar 18 20:46:47.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:48.271: INFO: Pod daemon-set-nzc8r is not available
Mar 18 20:46:48.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:49.271: INFO: Pod daemon-set-nzc8r is not available
Mar 18 20:46:49.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:50.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:51.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:52.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:53.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:54.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:55.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:56.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:57.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:58.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:46:59.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:00.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:01.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:02.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:03.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:04.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:05.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:06.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:07.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:08.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:09.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:10.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:11.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:12.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:13.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:14.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:15.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:16.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:17.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:18.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:19.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:20.271: INFO: Wrong image for pod: daemon-set-qh6vz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 20:47:20.271: INFO: Pod daemon-set-qh6vz is not available
Mar 18 20:47:21.271: INFO: Pod daemon-set-8b7k5 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 18 20:47:21.280: INFO: Number of nodes with available pods: 2
Mar 18 20:47:21.280: INFO: Node node-1 is running more than one daemon pod
Mar 18 20:47:22.294: INFO: Number of nodes with available pods: 3
Mar 18 20:47:22.294: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-tlxnb, will wait for the garbage collector to delete the pods
Mar 18 20:47:22.368: INFO: Deleting DaemonSet.extensions daemon-set took: 9.923411ms
Mar 18 20:47:22.468: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.223335ms
Mar 18 20:47:36.571: INFO: Number of nodes with available pods: 0
Mar 18 20:47:36.571: INFO: Number of running nodes: 0, number of available pods: 0
Mar 18 20:47:36.573: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-tlxnb/daemonsets","resourceVersion":"6140"},"items":null}

Mar 18 20:47:36.575: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-tlxnb/pods","resourceVersion":"6140"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:47:36.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-tlxnb" for this suite.
Mar 18 20:47:42.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:47:42.662: INFO: namespace: e2e-tests-daemonsets-tlxnb, resource: bindings, ignored listing per whitelist
Mar 18 20:47:42.673: INFO: namespace e2e-tests-daemonsets-tlxnb deletion completed in 6.084095388s

• [SLOW TEST:125.685 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:47:42.674: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 20:47:42.731: INFO: Waiting up to 5m0s for pod "downwardapi-volume-138f92e2-49bf-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-dcdcf" to be "success or failure"
Mar 18 20:47:42.734: INFO: Pod "downwardapi-volume-138f92e2-49bf-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.781213ms
Mar 18 20:47:44.737: INFO: Pod "downwardapi-volume-138f92e2-49bf-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0056645s
STEP: Saw pod success
Mar 18 20:47:44.737: INFO: Pod "downwardapi-volume-138f92e2-49bf-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:47:44.739: INFO: Trying to get logs from node node-1 pod downwardapi-volume-138f92e2-49bf-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 20:47:44.761: INFO: Waiting for pod downwardapi-volume-138f92e2-49bf-11e9-9475-02f976e168bb to disappear
Mar 18 20:47:44.766: INFO: Pod downwardapi-volume-138f92e2-49bf-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:47:44.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dcdcf" for this suite.
Mar 18 20:47:50.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:47:50.799: INFO: namespace: e2e-tests-downward-api-dcdcf, resource: bindings, ignored listing per whitelist
Mar 18 20:47:50.864: INFO: namespace e2e-tests-downward-api-dcdcf deletion completed in 6.092357181s

• [SLOW TEST:8.190 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:47:50.864: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar 18 20:47:50.915: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar 18 20:47:50.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:47:51.102: INFO: stderr: ""
Mar 18 20:47:51.102: INFO: stdout: "service/redis-slave created\n"
Mar 18 20:47:51.102: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar 18 20:47:51.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:47:51.261: INFO: stderr: ""
Mar 18 20:47:51.261: INFO: stdout: "service/redis-master created\n"
Mar 18 20:47:51.261: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 18 20:47:51.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:47:51.429: INFO: stderr: ""
Mar 18 20:47:51.429: INFO: stdout: "service/frontend created\n"
Mar 18 20:47:51.429: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar 18 20:47:51.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:47:51.584: INFO: stderr: ""
Mar 18 20:47:51.584: INFO: stdout: "deployment.extensions/frontend created\n"
Mar 18 20:47:51.584: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 18 20:47:51.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:47:51.733: INFO: stderr: ""
Mar 18 20:47:51.733: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar 18 20:47:51.734: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar 18 20:47:51.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:47:51.870: INFO: stderr: ""
Mar 18 20:47:51.870: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar 18 20:47:51.871: INFO: Waiting for all frontend pods to be Running.
Mar 18 20:48:06.921: INFO: Waiting for frontend to serve content.
Mar 18 20:48:11.938: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Mar 18 20:48:16.951: INFO: Trying to add a new entry to the guestbook.
Mar 18 20:48:16.963: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar 18 20:48:16.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:48:17.069: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 20:48:17.070: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 18 20:48:17.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:48:17.167: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 20:48:17.167: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 18 20:48:17.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:48:17.256: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 20:48:17.256: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 18 20:48:17.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:48:17.337: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 20:48:17.337: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 18 20:48:17.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:48:17.439: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 20:48:17.439: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 18 20:48:17.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bfjhn'
Mar 18 20:48:17.559: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 20:48:17.559: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:48:17.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bfjhn" for this suite.
Mar 18 20:48:55.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:48:55.637: INFO: namespace: e2e-tests-kubectl-bfjhn, resource: bindings, ignored listing per whitelist
Mar 18 20:48:55.652: INFO: namespace e2e-tests-kubectl-bfjhn deletion completed in 38.089912024s

• [SLOW TEST:64.788 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:48:55.653: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 18 20:48:55.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-a,UID:3f112efb-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6549,Generation:0,CreationTimestamp:2019-03-18 20:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 18 20:48:55.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-a,UID:3f112efb-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6549,Generation:0,CreationTimestamp:2019-03-18 20:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 18 20:49:05.730: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-a,UID:3f112efb-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6566,Generation:0,CreationTimestamp:2019-03-18 20:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 18 20:49:05.730: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-a,UID:3f112efb-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6566,Generation:0,CreationTimestamp:2019-03-18 20:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 18 20:49:15.737: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-a,UID:3f112efb-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6582,Generation:0,CreationTimestamp:2019-03-18 20:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 18 20:49:15.737: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-a,UID:3f112efb-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6582,Generation:0,CreationTimestamp:2019-03-18 20:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 18 20:49:25.742: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-a,UID:3f112efb-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6598,Generation:0,CreationTimestamp:2019-03-18 20:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 18 20:49:25.742: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-a,UID:3f112efb-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6598,Generation:0,CreationTimestamp:2019-03-18 20:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 18 20:49:35.747: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-b,UID:56ec204a-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6615,Generation:0,CreationTimestamp:2019-03-18 20:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 18 20:49:35.747: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-b,UID:56ec204a-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6615,Generation:0,CreationTimestamp:2019-03-18 20:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 18 20:49:45.753: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-b,UID:56ec204a-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6631,Generation:0,CreationTimestamp:2019-03-18 20:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 18 20:49:45.753: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-rz4c4,SelfLink:/api/v1/namespaces/e2e-tests-watch-rz4c4/configmaps/e2e-watch-test-configmap-b,UID:56ec204a-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:6631,Generation:0,CreationTimestamp:2019-03-18 20:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:49:55.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-rz4c4" for this suite.
Mar 18 20:50:01.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:50:01.810: INFO: namespace: e2e-tests-watch-rz4c4, resource: bindings, ignored listing per whitelist
Mar 18 20:50:01.871: INFO: namespace e2e-tests-watch-rz4c4 deletion completed in 6.11400252s

• [SLOW TEST:66.218 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:50:01.873: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-6690f5e4-49bf-11e9-9475-02f976e168bb
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-6690f5e4-49bf-11e9-9475-02f976e168bb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:50:06.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4lq9r" for this suite.
Mar 18 20:50:28.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:50:28.122: INFO: namespace: e2e-tests-projected-4lq9r, resource: bindings, ignored listing per whitelist
Mar 18 20:50:28.138: INFO: namespace e2e-tests-projected-4lq9r deletion completed in 22.089009415s

• [SLOW TEST:26.266 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:50:28.139: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6tkr9
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-6tkr9
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-6tkr9
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-6tkr9
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-6tkr9
Mar 18 20:50:30.236: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6tkr9, name: ss-0, uid: 76ecb05b-49bf-11e9-a0d3-06934a8be3ba, status phase: Pending. Waiting for statefulset controller to delete.
Mar 18 20:50:30.414: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6tkr9, name: ss-0, uid: 76ecb05b-49bf-11e9-a0d3-06934a8be3ba, status phase: Failed. Waiting for statefulset controller to delete.
Mar 18 20:50:30.420: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6tkr9, name: ss-0, uid: 76ecb05b-49bf-11e9-a0d3-06934a8be3ba, status phase: Failed. Waiting for statefulset controller to delete.
Mar 18 20:50:30.425: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-6tkr9
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-6tkr9
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-6tkr9 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 18 20:50:32.456: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6tkr9
Mar 18 20:50:32.458: INFO: Scaling statefulset ss to 0
Mar 18 20:50:52.472: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 20:50:52.474: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:50:52.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6tkr9" for this suite.
Mar 18 20:50:58.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:50:58.566: INFO: namespace: e2e-tests-statefulset-6tkr9, resource: bindings, ignored listing per whitelist
Mar 18 20:50:58.582: INFO: namespace e2e-tests-statefulset-6tkr9 deletion completed in 6.095362775s

• [SLOW TEST:30.444 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:50:58.582: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-852mp
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-852mp to expose endpoints map[]
Mar 18 20:50:58.649: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-852mp exposes endpoints map[] (3.240296ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-852mp
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-852mp to expose endpoints map[pod1:[80]]
Mar 18 20:50:59.673: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-852mp exposes endpoints map[pod1:[80]] (1.015143891s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-852mp
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-852mp to expose endpoints map[pod1:[80] pod2:[80]]
Mar 18 20:51:01.700: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-852mp exposes endpoints map[pod2:[80] pod1:[80]] (2.023347782s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-852mp
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-852mp to expose endpoints map[pod2:[80]]
Mar 18 20:51:01.722: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-852mp exposes endpoints map[pod2:[80]] (14.155424ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-852mp
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-852mp to expose endpoints map[]
Mar 18 20:51:02.741: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-852mp exposes endpoints map[] (1.007019688s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:51:02.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-852mp" for this suite.
Mar 18 20:51:24.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:51:24.813: INFO: namespace: e2e-tests-services-852mp, resource: bindings, ignored listing per whitelist
Mar 18 20:51:24.869: INFO: namespace e2e-tests-services-852mp deletion completed in 22.100076196s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:26.286 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:51:24.869: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 20:51:24.933: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9800a1a9-49bf-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-f5fp5" to be "success or failure"
Mar 18 20:51:24.936: INFO: Pod "downwardapi-volume-9800a1a9-49bf-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.952112ms
Mar 18 20:51:26.939: INFO: Pod "downwardapi-volume-9800a1a9-49bf-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005958129s
STEP: Saw pod success
Mar 18 20:51:26.939: INFO: Pod "downwardapi-volume-9800a1a9-49bf-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:51:26.943: INFO: Trying to get logs from node node-1 pod downwardapi-volume-9800a1a9-49bf-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 20:51:26.956: INFO: Waiting for pod downwardapi-volume-9800a1a9-49bf-11e9-9475-02f976e168bb to disappear
Mar 18 20:51:26.968: INFO: Pod downwardapi-volume-9800a1a9-49bf-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:51:26.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f5fp5" for this suite.
Mar 18 20:51:32.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:51:33.046: INFO: namespace: e2e-tests-downward-api-f5fp5, resource: bindings, ignored listing per whitelist
Mar 18 20:51:33.062: INFO: namespace e2e-tests-downward-api-f5fp5 deletion completed in 6.088569441s

• [SLOW TEST:8.194 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:51:33.062: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 18 20:51:33.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-swr99'
Mar 18 20:51:33.575: INFO: stderr: ""
Mar 18 20:51:33.575: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 18 20:51:34.579: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:51:34.579: INFO: Found 0 / 1
Mar 18 20:51:35.579: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:51:35.579: INFO: Found 1 / 1
Mar 18 20:51:35.579: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 18 20:51:35.581: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:51:35.581: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 18 20:51:35.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 patch pod redis-master-g29ck --namespace=e2e-tests-kubectl-swr99 -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 18 20:51:35.652: INFO: stderr: ""
Mar 18 20:51:35.652: INFO: stdout: "pod/redis-master-g29ck patched\n"
STEP: checking annotations
Mar 18 20:51:35.659: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 20:51:35.659: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:51:35.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-swr99" for this suite.
Mar 18 20:51:57.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:51:57.745: INFO: namespace: e2e-tests-kubectl-swr99, resource: bindings, ignored listing per whitelist
Mar 18 20:51:57.757: INFO: namespace e2e-tests-kubectl-swr99 deletion completed in 22.093828123s

• [SLOW TEST:24.694 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:51:57.757: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ab9b5dd5-49bf-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 20:51:57.824: INFO: Waiting up to 5m0s for pod "pod-secrets-ab9bc8d8-49bf-11e9-9475-02f976e168bb" in namespace "e2e-tests-secrets-shtv8" to be "success or failure"
Mar 18 20:51:57.828: INFO: Pod "pod-secrets-ab9bc8d8-49bf-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.186874ms
Mar 18 20:51:59.830: INFO: Pod "pod-secrets-ab9bc8d8-49bf-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00603241s
STEP: Saw pod success
Mar 18 20:51:59.830: INFO: Pod "pod-secrets-ab9bc8d8-49bf-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:51:59.833: INFO: Trying to get logs from node node-1 pod pod-secrets-ab9bc8d8-49bf-11e9-9475-02f976e168bb container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 20:51:59.850: INFO: Waiting for pod pod-secrets-ab9bc8d8-49bf-11e9-9475-02f976e168bb to disappear
Mar 18 20:51:59.859: INFO: Pod pod-secrets-ab9bc8d8-49bf-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:51:59.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-shtv8" for this suite.
Mar 18 20:52:05.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:52:05.933: INFO: namespace: e2e-tests-secrets-shtv8, resource: bindings, ignored listing per whitelist
Mar 18 20:52:05.954: INFO: namespace e2e-tests-secrets-shtv8 deletion completed in 6.091745785s

• [SLOW TEST:8.198 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:52:05.955: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qtbzd
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-qtbzd
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-qtbzd
Mar 18 20:52:06.072: INFO: Found 0 stateful pods, waiting for 1
Mar 18 20:52:16.076: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 18 20:52:16.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-qtbzd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 20:52:16.216: INFO: stderr: ""
Mar 18 20:52:16.216: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 20:52:16.216: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 20:52:16.219: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 18 20:52:26.226: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 20:52:26.226: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 20:52:26.237: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999037s
Mar 18 20:52:27.240: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996826546s
Mar 18 20:52:28.243: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993585246s
Mar 18 20:52:29.246: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990409402s
Mar 18 20:52:30.250: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.987292578s
Mar 18 20:52:31.253: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.983850197s
Mar 18 20:52:32.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.980591579s
Mar 18 20:52:33.260: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.977359625s
Mar 18 20:52:34.263: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.974085636s
Mar 18 20:52:35.266: INFO: Verifying statefulset ss doesn't scale past 1 for another 970.784873ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-qtbzd
Mar 18 20:52:36.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-qtbzd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 20:52:36.400: INFO: stderr: ""
Mar 18 20:52:36.400: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 20:52:36.400: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 20:52:36.403: INFO: Found 1 stateful pods, waiting for 3
Mar 18 20:52:46.408: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 20:52:46.408: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 20:52:46.408: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 18 20:52:46.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-qtbzd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 20:52:46.540: INFO: stderr: ""
Mar 18 20:52:46.540: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 20:52:46.540: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 20:52:46.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-qtbzd ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 20:52:46.681: INFO: stderr: ""
Mar 18 20:52:46.681: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 20:52:46.681: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 20:52:46.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-qtbzd ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 20:52:46.810: INFO: stderr: ""
Mar 18 20:52:46.810: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 20:52:46.810: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 20:52:46.810: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 20:52:46.813: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 18 20:52:56.819: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 20:52:56.819: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 20:52:56.819: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 20:52:56.827: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999908s
Mar 18 20:52:57.831: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997351672s
Mar 18 20:52:58.834: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993773022s
Mar 18 20:52:59.837: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990790769s
Mar 18 20:53:00.841: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987788084s
Mar 18 20:53:01.856: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983572463s
Mar 18 20:53:02.859: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.968798766s
Mar 18 20:53:03.864: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964947101s
Mar 18 20:53:04.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.960767282s
Mar 18 20:53:05.871: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.620296ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-qtbzd
Mar 18 20:53:06.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-qtbzd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 20:53:06.999: INFO: stderr: ""
Mar 18 20:53:06.999: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 20:53:06.999: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 20:53:06.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-qtbzd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 20:53:07.125: INFO: stderr: ""
Mar 18 20:53:07.125: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 20:53:07.125: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 20:53:07.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-qtbzd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 20:53:07.250: INFO: stderr: ""
Mar 18 20:53:07.250: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 20:53:07.250: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 20:53:07.250: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 18 20:53:27.266: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qtbzd
Mar 18 20:53:27.268: INFO: Scaling statefulset ss to 0
Mar 18 20:53:27.275: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 20:53:27.277: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:53:27.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qtbzd" for this suite.
Mar 18 20:53:33.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:53:33.352: INFO: namespace: e2e-tests-statefulset-qtbzd, resource: bindings, ignored listing per whitelist
Mar 18 20:53:33.390: INFO: namespace e2e-tests-statefulset-qtbzd deletion completed in 6.094266897s

• [SLOW TEST:87.435 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:53:33.390: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 18 20:53:35.973: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e49ba09c-49bf-11e9-9475-02f976e168bb"
Mar 18 20:53:35.973: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e49ba09c-49bf-11e9-9475-02f976e168bb" in namespace "e2e-tests-pods-xrpfj" to be "terminated due to deadline exceeded"
Mar 18 20:53:35.977: INFO: Pod "pod-update-activedeadlineseconds-e49ba09c-49bf-11e9-9475-02f976e168bb": Phase="Running", Reason="", readiness=true. Elapsed: 3.617418ms
Mar 18 20:53:37.980: INFO: Pod "pod-update-activedeadlineseconds-e49ba09c-49bf-11e9-9475-02f976e168bb": Phase="Running", Reason="", readiness=true. Elapsed: 2.006551529s
Mar 18 20:53:39.983: INFO: Pod "pod-update-activedeadlineseconds-e49ba09c-49bf-11e9-9475-02f976e168bb": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009515254s
Mar 18 20:53:39.983: INFO: Pod "pod-update-activedeadlineseconds-e49ba09c-49bf-11e9-9475-02f976e168bb" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:53:39.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xrpfj" for this suite.
Mar 18 20:53:45.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:53:46.014: INFO: namespace: e2e-tests-pods-xrpfj, resource: bindings, ignored listing per whitelist
Mar 18 20:53:46.076: INFO: namespace e2e-tests-pods-xrpfj deletion completed in 6.089390707s

• [SLOW TEST:12.686 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:53:46.076: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-ec2b34a0-49bf-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 20:53:46.146: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ec2baa08-49bf-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-8fs8p" to be "success or failure"
Mar 18 20:53:46.149: INFO: Pod "pod-projected-secrets-ec2baa08-49bf-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.784283ms
Mar 18 20:53:48.152: INFO: Pod "pod-projected-secrets-ec2baa08-49bf-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005810095s
STEP: Saw pod success
Mar 18 20:53:48.152: INFO: Pod "pod-projected-secrets-ec2baa08-49bf-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:53:48.154: INFO: Trying to get logs from node node-1 pod pod-projected-secrets-ec2baa08-49bf-11e9-9475-02f976e168bb container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 18 20:53:48.169: INFO: Waiting for pod pod-projected-secrets-ec2baa08-49bf-11e9-9475-02f976e168bb to disappear
Mar 18 20:53:48.184: INFO: Pod pod-projected-secrets-ec2baa08-49bf-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:53:48.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8fs8p" for this suite.
Mar 18 20:53:54.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:53:54.230: INFO: namespace: e2e-tests-projected-8fs8p, resource: bindings, ignored listing per whitelist
Mar 18 20:53:54.276: INFO: namespace e2e-tests-projected-8fs8p deletion completed in 6.088346022s

• [SLOW TEST:8.200 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:53:54.277: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 20:53:54.335: INFO: (0) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.708647ms)
Mar 18 20:53:54.338: INFO: (1) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.672371ms)
Mar 18 20:53:54.341: INFO: (2) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.538983ms)
Mar 18 20:53:54.343: INFO: (3) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.719018ms)
Mar 18 20:53:54.346: INFO: (4) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.858258ms)
Mar 18 20:53:54.349: INFO: (5) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.536835ms)
Mar 18 20:53:54.351: INFO: (6) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.543531ms)
Mar 18 20:53:54.354: INFO: (7) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.682116ms)
Mar 18 20:53:54.357: INFO: (8) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.208891ms)
Mar 18 20:53:54.360: INFO: (9) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.578812ms)
Mar 18 20:53:54.363: INFO: (10) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.207813ms)
Mar 18 20:53:54.366: INFO: (11) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.485232ms)
Mar 18 20:53:54.368: INFO: (12) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.575239ms)
Mar 18 20:53:54.371: INFO: (13) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.651594ms)
Mar 18 20:53:54.374: INFO: (14) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.782664ms)
Mar 18 20:53:54.377: INFO: (15) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.778624ms)
Mar 18 20:53:54.380: INFO: (16) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.12489ms)
Mar 18 20:53:54.383: INFO: (17) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.130852ms)
Mar 18 20:53:54.386: INFO: (18) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.692815ms)
Mar 18 20:53:54.388: INFO: (19) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.623755ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:53:54.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-j48q2" for this suite.
Mar 18 20:54:00.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:54:00.433: INFO: namespace: e2e-tests-proxy-j48q2, resource: bindings, ignored listing per whitelist
Mar 18 20:54:00.522: INFO: namespace e2e-tests-proxy-j48q2 deletion completed in 6.129956897s

• [SLOW TEST:6.245 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:54:00.522: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 20:54:00.592: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 18 20:54:00.599: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 18 20:54:05.602: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 18 20:54:05.602: INFO: Creating deployment "test-rolling-update-deployment"
Mar 18 20:54:05.606: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 18 20:54:05.611: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 18 20:54:07.616: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 18 20:54:07.618: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 18 20:54:07.625: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-275v4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-275v4/deployments/test-rolling-update-deployment,UID:f7c55e9b-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:7638,Generation:1,CreationTimestamp:2019-03-18 20:54:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-18 20:54:05 +0000 UTC 2019-03-18 20:54:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-18 20:54:06 +0000 UTC 2019-03-18 20:54:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 18 20:54:07.628: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-275v4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-275v4/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:f7c7563f-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:7629,Generation:1,CreationTimestamp:2019-03-18 20:54:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f7c55e9b-49bf-11e9-a0d3-06934a8be3ba 0xc001f0ef27 0xc001f0ef28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 18 20:54:07.628: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 18 20:54:07.628: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-275v4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-275v4/replicasets/test-rolling-update-controller,UID:f4c8ef25-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:7637,Generation:2,CreationTimestamp:2019-03-18 20:54:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f7c55e9b-49bf-11e9-a0d3-06934a8be3ba 0xc001f0ee5f 0xc001f0ee70}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 20:54:07.630: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-mwgns" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-mwgns,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-275v4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-275v4/pods/test-rolling-update-deployment-68b55d7bc6-mwgns,UID:f7c7d2b8-49bf-11e9-a0d3-06934a8be3ba,ResourceVersion:7628,Generation:0,CreationTimestamp:2019-03-18 20:54:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.87/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 f7c7563f-49bf-11e9-a0d3-06934a8be3ba 0xc001f0f7c7 0xc001f0f7c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ld6md {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ld6md,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-ld6md true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f0f840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f0f860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:54:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:54:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:54:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 20:54:05 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:10.42.0.87,StartTime:2019-03-18 20:54:05 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-18 20:54:06 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://61cd276b35b9cb63c65cd032acce1860af78b292a381d17e9749435bddeaf43a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:54:07.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-275v4" for this suite.
Mar 18 20:54:13.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:54:13.722: INFO: namespace: e2e-tests-deployment-275v4, resource: bindings, ignored listing per whitelist
Mar 18 20:54:13.733: INFO: namespace e2e-tests-deployment-275v4 deletion completed in 6.098702785s

• [SLOW TEST:13.211 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:54:13.733: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:54:15.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qft9l" for this suite.
Mar 18 20:54:53.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:54:53.858: INFO: namespace: e2e-tests-kubelet-test-qft9l, resource: bindings, ignored listing per whitelist
Mar 18 20:54:53.902: INFO: namespace e2e-tests-kubelet-test-qft9l deletion completed in 38.085523193s

• [SLOW TEST:40.169 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:54:53.902: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar 18 20:54:54.481: INFO: created pod pod-service-account-defaultsa
Mar 18 20:54:54.481: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 18 20:54:54.485: INFO: created pod pod-service-account-mountsa
Mar 18 20:54:54.485: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 18 20:54:54.492: INFO: created pod pod-service-account-nomountsa
Mar 18 20:54:54.492: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 18 20:54:54.499: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 18 20:54:54.499: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 18 20:54:54.515: INFO: created pod pod-service-account-mountsa-mountspec
Mar 18 20:54:54.515: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 18 20:54:54.525: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 18 20:54:54.525: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 18 20:54:54.533: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 18 20:54:54.533: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 18 20:54:54.539: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 18 20:54:54.539: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 18 20:54:54.543: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 18 20:54:54.543: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:54:54.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-bdv8n" for this suite.
Mar 18 20:55:00.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:55:00.634: INFO: namespace: e2e-tests-svcaccounts-bdv8n, resource: bindings, ignored listing per whitelist
Mar 18 20:55:00.679: INFO: namespace e2e-tests-svcaccounts-bdv8n deletion completed in 6.125478241s

• [SLOW TEST:6.777 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:55:00.680: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 20:55:00.748: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18a36ce3-49c0-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-wfmkb" to be "success or failure"
Mar 18 20:55:00.758: INFO: Pod "downwardapi-volume-18a36ce3-49c0-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.119676ms
Mar 18 20:55:02.762: INFO: Pod "downwardapi-volume-18a36ce3-49c0-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013685824s
STEP: Saw pod success
Mar 18 20:55:02.762: INFO: Pod "downwardapi-volume-18a36ce3-49c0-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:55:02.764: INFO: Trying to get logs from node node-1 pod downwardapi-volume-18a36ce3-49c0-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 20:55:02.789: INFO: Waiting for pod downwardapi-volume-18a36ce3-49c0-11e9-9475-02f976e168bb to disappear
Mar 18 20:55:02.799: INFO: Pod downwardapi-volume-18a36ce3-49c0-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:55:02.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wfmkb" for this suite.
Mar 18 20:55:08.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:55:08.839: INFO: namespace: e2e-tests-downward-api-wfmkb, resource: bindings, ignored listing per whitelist
Mar 18 20:55:08.911: INFO: namespace e2e-tests-downward-api-wfmkb deletion completed in 6.107813751s

• [SLOW TEST:8.231 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:55:08.911: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:55:11.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-crt4c" for this suite.
Mar 18 20:55:49.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:55:49.032: INFO: namespace: e2e-tests-kubelet-test-crt4c, resource: bindings, ignored listing per whitelist
Mar 18 20:55:49.102: INFO: namespace e2e-tests-kubelet-test-crt4c deletion completed in 38.093001912s

• [SLOW TEST:40.191 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:55:49.102: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 20:55:49.166: INFO: Waiting up to 5m0s for pod "downwardapi-volume-357f9a2e-49c0-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-xrt6t" to be "success or failure"
Mar 18 20:55:49.173: INFO: Pod "downwardapi-volume-357f9a2e-49c0-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.438803ms
Mar 18 20:55:51.176: INFO: Pod "downwardapi-volume-357f9a2e-49c0-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010434971s
STEP: Saw pod success
Mar 18 20:55:51.176: INFO: Pod "downwardapi-volume-357f9a2e-49c0-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:55:51.178: INFO: Trying to get logs from node node-1 pod downwardapi-volume-357f9a2e-49c0-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 20:55:51.197: INFO: Waiting for pod downwardapi-volume-357f9a2e-49c0-11e9-9475-02f976e168bb to disappear
Mar 18 20:55:51.203: INFO: Pod downwardapi-volume-357f9a2e-49c0-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:55:51.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xrt6t" for this suite.
Mar 18 20:55:57.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:55:57.249: INFO: namespace: e2e-tests-projected-xrt6t, resource: bindings, ignored listing per whitelist
Mar 18 20:55:57.311: INFO: namespace e2e-tests-projected-xrt6t deletion completed in 6.096203177s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:55:57.311: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3a637fb7-49c0-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 20:55:57.374: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3a63fbf5-49c0-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-zrtp7" to be "success or failure"
Mar 18 20:55:57.380: INFO: Pod "pod-projected-configmaps-3a63fbf5-49c0-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.466078ms
Mar 18 20:55:59.383: INFO: Pod "pod-projected-configmaps-3a63fbf5-49c0-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008592463s
STEP: Saw pod success
Mar 18 20:55:59.383: INFO: Pod "pod-projected-configmaps-3a63fbf5-49c0-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:55:59.385: INFO: Trying to get logs from node node-1 pod pod-projected-configmaps-3a63fbf5-49c0-11e9-9475-02f976e168bb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 20:55:59.409: INFO: Waiting for pod pod-projected-configmaps-3a63fbf5-49c0-11e9-9475-02f976e168bb to disappear
Mar 18 20:55:59.418: INFO: Pod pod-projected-configmaps-3a63fbf5-49c0-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:55:59.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zrtp7" for this suite.
Mar 18 20:56:05.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:56:05.502: INFO: namespace: e2e-tests-projected-zrtp7, resource: bindings, ignored listing per whitelist
Mar 18 20:56:05.512: INFO: namespace e2e-tests-projected-zrtp7 deletion completed in 6.090497041s

• [SLOW TEST:8.201 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:56:05.513: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 20:56:05.585: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Mar 18 20:56:05.590: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vg2lv/daemonsets","resourceVersion":"8076"},"items":null}

Mar 18 20:56:05.592: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vg2lv/pods","resourceVersion":"8076"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:56:05.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vg2lv" for this suite.
Mar 18 20:56:11.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:56:11.691: INFO: namespace: e2e-tests-daemonsets-vg2lv, resource: bindings, ignored listing per whitelist
Mar 18 20:56:11.706: INFO: namespace e2e-tests-daemonsets-vg2lv deletion completed in 6.098722075s

S [SKIPPING] [6.193 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar 18 20:56:05.585: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:56:11.706: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 18 20:56:11.769: INFO: Waiting up to 5m0s for pod "pod-42f88e6d-49c0-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-b2wcz" to be "success or failure"
Mar 18 20:56:11.775: INFO: Pod "pod-42f88e6d-49c0-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.061606ms
Mar 18 20:56:13.778: INFO: Pod "pod-42f88e6d-49c0-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008988159s
STEP: Saw pod success
Mar 18 20:56:13.778: INFO: Pod "pod-42f88e6d-49c0-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:56:13.780: INFO: Trying to get logs from node node-1 pod pod-42f88e6d-49c0-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 20:56:13.795: INFO: Waiting for pod pod-42f88e6d-49c0-11e9-9475-02f976e168bb to disappear
Mar 18 20:56:13.805: INFO: Pod pod-42f88e6d-49c0-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:56:13.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b2wcz" for this suite.
Mar 18 20:56:19.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:56:19.836: INFO: namespace: e2e-tests-emptydir-b2wcz, resource: bindings, ignored listing per whitelist
Mar 18 20:56:19.898: INFO: namespace e2e-tests-emptydir-b2wcz deletion completed in 6.088969294s

• [SLOW TEST:8.192 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:56:19.898: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-lrqc9
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar 18 20:56:19.970: INFO: Found 0 stateful pods, waiting for 3
Mar 18 20:56:29.973: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 20:56:29.973: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 20:56:29.973: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 20:56:29.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-lrqc9 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 20:56:30.109: INFO: stderr: ""
Mar 18 20:56:30.109: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 20:56:30.109: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 18 20:56:40.138: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 18 20:56:50.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-lrqc9 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 20:56:50.280: INFO: stderr: ""
Mar 18 20:56:50.280: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 20:56:50.280: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 20:57:00.297: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqc9/ss2 to complete update
Mar 18 20:57:00.297: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 20:57:00.297: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 20:57:00.297: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 20:57:10.306: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqc9/ss2 to complete update
Mar 18 20:57:10.306: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 20:57:10.306: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 20:57:20.303: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqc9/ss2 to complete update
Mar 18 20:57:20.303: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar 18 20:57:30.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-lrqc9 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 20:57:30.429: INFO: stderr: ""
Mar 18 20:57:30.429: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 20:57:30.429: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 20:57:40.456: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 18 20:57:50.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-lrqc9 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 20:57:50.617: INFO: stderr: ""
Mar 18 20:57:50.617: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 20:57:50.617: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 20:58:00.635: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqc9/ss2 to complete update
Mar 18 20:58:00.635: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 18 20:58:00.635: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 18 20:58:00.635: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 18 20:58:10.640: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqc9/ss2 to complete update
Mar 18 20:58:10.640: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 18 20:58:10.640: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 18 20:58:20.640: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqc9/ss2 to complete update
Mar 18 20:58:20.640: INFO: Waiting for Pod e2e-tests-statefulset-lrqc9/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 18 20:58:30.640: INFO: Deleting all statefulset in ns e2e-tests-statefulset-lrqc9
Mar 18 20:58:30.643: INFO: Scaling statefulset ss2 to 0
Mar 18 20:58:50.655: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 20:58:50.657: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:58:50.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-lrqc9" for this suite.
Mar 18 20:58:56.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:58:56.805: INFO: namespace: e2e-tests-statefulset-lrqc9, resource: bindings, ignored listing per whitelist
Mar 18 20:58:56.808: INFO: namespace e2e-tests-statefulset-lrqc9 deletion completed in 6.133118628s

• [SLOW TEST:156.910 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:58:56.808: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a5644750-49c0-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 20:58:56.898: INFO: Waiting up to 5m0s for pod "pod-secrets-a564cab1-49c0-11e9-9475-02f976e168bb" in namespace "e2e-tests-secrets-xp6xz" to be "success or failure"
Mar 18 20:58:56.906: INFO: Pod "pod-secrets-a564cab1-49c0-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.119349ms
Mar 18 20:58:58.909: INFO: Pod "pod-secrets-a564cab1-49c0-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011460474s
STEP: Saw pod success
Mar 18 20:58:58.910: INFO: Pod "pod-secrets-a564cab1-49c0-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:58:58.912: INFO: Trying to get logs from node node-1 pod pod-secrets-a564cab1-49c0-11e9-9475-02f976e168bb container secret-env-test: <nil>
STEP: delete the pod
Mar 18 20:58:58.934: INFO: Waiting for pod pod-secrets-a564cab1-49c0-11e9-9475-02f976e168bb to disappear
Mar 18 20:58:58.942: INFO: Pod pod-secrets-a564cab1-49c0-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:58:58.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xp6xz" for this suite.
Mar 18 20:59:04.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:59:05.013: INFO: namespace: e2e-tests-secrets-xp6xz, resource: bindings, ignored listing per whitelist
Mar 18 20:59:05.052: INFO: namespace e2e-tests-secrets-xp6xz deletion completed in 6.104929082s

• [SLOW TEST:8.243 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:59:05.052: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 18 20:59:05.118: INFO: Waiting up to 5m0s for pod "pod-aa4b82de-49c0-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-fcfvb" to be "success or failure"
Mar 18 20:59:05.125: INFO: Pod "pod-aa4b82de-49c0-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.493385ms
Mar 18 20:59:07.130: INFO: Pod "pod-aa4b82de-49c0-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011686679s
STEP: Saw pod success
Mar 18 20:59:07.130: INFO: Pod "pod-aa4b82de-49c0-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:59:07.132: INFO: Trying to get logs from node node-1 pod pod-aa4b82de-49c0-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 20:59:07.150: INFO: Waiting for pod pod-aa4b82de-49c0-11e9-9475-02f976e168bb to disappear
Mar 18 20:59:07.166: INFO: Pod pod-aa4b82de-49c0-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:59:07.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fcfvb" for this suite.
Mar 18 20:59:13.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:59:13.230: INFO: namespace: e2e-tests-emptydir-fcfvb, resource: bindings, ignored listing per whitelist
Mar 18 20:59:13.274: INFO: namespace e2e-tests-emptydir-fcfvb deletion completed in 6.104529158s

• [SLOW TEST:8.223 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:59:13.275: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-6xtrv.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-6xtrv.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-6xtrv.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-6xtrv.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-6xtrv.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-6xtrv.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 18 20:59:23.410: INFO: DNS probes using e2e-tests-dns-6xtrv/dns-test-af33bfa9-49c0-11e9-9475-02f976e168bb succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:59:23.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-6xtrv" for this suite.
Mar 18 20:59:31.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:59:31.491: INFO: namespace: e2e-tests-dns-6xtrv, resource: bindings, ignored listing per whitelist
Mar 18 20:59:31.533: INFO: namespace e2e-tests-dns-6xtrv deletion completed in 8.088049917s

• [SLOW TEST:18.258 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:59:31.533: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 18 20:59:31.594: INFO: Waiting up to 5m0s for pod "pod-ba135510-49c0-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-vl9l8" to be "success or failure"
Mar 18 20:59:31.599: INFO: Pod "pod-ba135510-49c0-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.134819ms
Mar 18 20:59:33.602: INFO: Pod "pod-ba135510-49c0-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008009528s
STEP: Saw pod success
Mar 18 20:59:33.602: INFO: Pod "pod-ba135510-49c0-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 20:59:33.604: INFO: Trying to get logs from node node-1 pod pod-ba135510-49c0-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 20:59:33.622: INFO: Waiting for pod pod-ba135510-49c0-11e9-9475-02f976e168bb to disappear
Mar 18 20:59:33.637: INFO: Pod pod-ba135510-49c0-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 20:59:33.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vl9l8" for this suite.
Mar 18 20:59:39.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 20:59:39.662: INFO: namespace: e2e-tests-emptydir-vl9l8, resource: bindings, ignored listing per whitelist
Mar 18 20:59:39.724: INFO: namespace e2e-tests-emptydir-vl9l8 deletion completed in 6.083632927s

• [SLOW TEST:8.191 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 20:59:39.724: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 18 20:59:43.809: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 20:59:43.814: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 20:59:45.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 20:59:45.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 20:59:47.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 20:59:47.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 20:59:49.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 20:59:49.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 20:59:51.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 20:59:51.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 20:59:53.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 20:59:53.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 20:59:55.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 20:59:55.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 20:59:57.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 20:59:57.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 20:59:59.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 20:59:59.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 21:00:01.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 21:00:01.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 21:00:03.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 21:00:03.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 21:00:05.814: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 21:00:05.817: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 21:00:07.815: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 21:00:07.823: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:00:07.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-h22m7" for this suite.
Mar 18 21:00:29.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:00:29.859: INFO: namespace: e2e-tests-container-lifecycle-hook-h22m7, resource: bindings, ignored listing per whitelist
Mar 18 21:00:29.933: INFO: namespace e2e-tests-container-lifecycle-hook-h22m7 deletion completed in 22.100385068s

• [SLOW TEST:50.209 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:00:29.933: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 18 21:00:30.003: INFO: Waiting up to 5m0s for pod "pod-dce3be36-49c0-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-brzjl" to be "success or failure"
Mar 18 21:00:30.010: INFO: Pod "pod-dce3be36-49c0-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.025962ms
Mar 18 21:00:32.013: INFO: Pod "pod-dce3be36-49c0-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010304959s
STEP: Saw pod success
Mar 18 21:00:32.013: INFO: Pod "pod-dce3be36-49c0-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:00:32.015: INFO: Trying to get logs from node node-1 pod pod-dce3be36-49c0-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 21:00:32.036: INFO: Waiting for pod pod-dce3be36-49c0-11e9-9475-02f976e168bb to disappear
Mar 18 21:00:32.049: INFO: Pod pod-dce3be36-49c0-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:00:32.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-brzjl" for this suite.
Mar 18 21:00:38.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:00:38.132: INFO: namespace: e2e-tests-emptydir-brzjl, resource: bindings, ignored listing per whitelist
Mar 18 21:00:38.147: INFO: namespace e2e-tests-emptydir-brzjl deletion completed in 6.094504703s

• [SLOW TEST:8.214 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:00:38.147: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-v6wml
Mar 18 21:00:40.214: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-v6wml
STEP: checking the pod's current state and verifying that restartCount is present
Mar 18 21:00:40.216: INFO: Initial restart count of pod liveness-http is 0
Mar 18 21:01:00.249: INFO: Restart count of pod e2e-tests-container-probe-v6wml/liveness-http is now 1 (20.033078375s elapsed)
Mar 18 21:01:20.280: INFO: Restart count of pod e2e-tests-container-probe-v6wml/liveness-http is now 2 (40.064045975s elapsed)
Mar 18 21:01:40.315: INFO: Restart count of pod e2e-tests-container-probe-v6wml/liveness-http is now 3 (1m0.099094542s elapsed)
Mar 18 21:02:00.345: INFO: Restart count of pod e2e-tests-container-probe-v6wml/liveness-http is now 4 (1m20.129141565s elapsed)
Mar 18 21:03:06.458: INFO: Restart count of pod e2e-tests-container-probe-v6wml/liveness-http is now 5 (2m26.241332297s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:03:06.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-v6wml" for this suite.
Mar 18 21:03:12.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:03:12.526: INFO: namespace: e2e-tests-container-probe-v6wml, resource: bindings, ignored listing per whitelist
Mar 18 21:03:12.581: INFO: namespace e2e-tests-container-probe-v6wml deletion completed in 6.100259108s

• [SLOW TEST:154.434 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:03:12.581: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 18 21:03:15.167: INFO: Successfully updated pod "pod-update-3dd57e06-49c1-11e9-9475-02f976e168bb"
STEP: verifying the updated pod is in kubernetes
Mar 18 21:03:15.185: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:03:15.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ztxgx" for this suite.
Mar 18 21:03:37.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:03:37.217: INFO: namespace: e2e-tests-pods-ztxgx, resource: bindings, ignored listing per whitelist
Mar 18 21:03:37.274: INFO: namespace e2e-tests-pods-ztxgx deletion completed in 22.085286418s

• [SLOW TEST:24.693 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:03:37.274: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4c8cc4c7-49c1-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 21:03:37.339: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4c8d2ec6-49c1-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-g4tzp" to be "success or failure"
Mar 18 21:03:37.341: INFO: Pod "pod-projected-configmaps-4c8d2ec6-49c1-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.309765ms
Mar 18 21:03:39.344: INFO: Pod "pod-projected-configmaps-4c8d2ec6-49c1-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005208357s
STEP: Saw pod success
Mar 18 21:03:39.344: INFO: Pod "pod-projected-configmaps-4c8d2ec6-49c1-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:03:39.346: INFO: Trying to get logs from node node-1 pod pod-projected-configmaps-4c8d2ec6-49c1-11e9-9475-02f976e168bb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 21:03:39.366: INFO: Waiting for pod pod-projected-configmaps-4c8d2ec6-49c1-11e9-9475-02f976e168bb to disappear
Mar 18 21:03:39.374: INFO: Pod pod-projected-configmaps-4c8d2ec6-49c1-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:03:39.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g4tzp" for this suite.
Mar 18 21:03:45.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:03:45.431: INFO: namespace: e2e-tests-projected-g4tzp, resource: bindings, ignored listing per whitelist
Mar 18 21:03:45.473: INFO: namespace e2e-tests-projected-g4tzp deletion completed in 6.095191032s

• [SLOW TEST:8.198 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:03:45.473: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 21:03:45.532: INFO: Creating deployment "nginx-deployment"
Mar 18 21:03:45.536: INFO: Waiting for observed generation 1
Mar 18 21:03:47.542: INFO: Waiting for all required pods to come up
Mar 18 21:03:47.545: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 18 21:03:49.551: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 18 21:03:49.555: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 18 21:03:49.561: INFO: Updating deployment nginx-deployment
Mar 18 21:03:49.561: INFO: Waiting for observed generation 2
Mar 18 21:03:51.568: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 18 21:03:51.570: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 18 21:03:51.572: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 18 21:03:51.579: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 18 21:03:51.579: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 18 21:03:51.581: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 18 21:03:51.584: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 18 21:03:51.585: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 18 21:03:51.591: INFO: Updating deployment nginx-deployment
Mar 18 21:03:51.591: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 18 21:03:51.608: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 18 21:03:53.638: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 18 21:03:53.643: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6q9w6/deployments/nginx-deployment,UID:516fae8b-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9870,Generation:3,CreationTimestamp:2019-03-18 21:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:12,UnavailableReplicas:21,Conditions:[{Available False 2019-03-18 21:03:51 +0000 UTC 2019-03-18 21:03:51 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-18 21:03:53 +0000 UTC 2019-03-18 21:03:45 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:12,CollisionCount:nil,},}

Mar 18 21:03:53.646: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6q9w6/replicasets/nginx-deployment-65bbdb5f8,UID:53d63e98-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9750,Generation:3,CreationTimestamp:2019-03-18 21:03:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 516fae8b-49c1-11e9-a0d3-06934a8be3ba 0xc000995117 0xc000995118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 21:03:53.646: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 18 21:03:53.646: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6q9w6/replicasets/nginx-deployment-555b55d965,UID:5170b527-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9865,Generation:3,CreationTimestamp:2019-03-18 21:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 516fae8b-49c1-11e9-a0d3-06934a8be3ba 0xc000995057 0xc000995058}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:12,AvailableReplicas:12,Conditions:[],},}
Mar 18 21:03:53.652: INFO: Pod "nginx-deployment-555b55d965-4gngw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4gngw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-4gngw,UID:5510a77d-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9832,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.119/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc0020af660 0xc0020af661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020afa10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020afa30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.652: INFO: Pod "nginx-deployment-555b55d965-5hd7d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5hd7d,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-5hd7d,UID:55193291-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9828,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.35/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc0020afaf7 0xc0020afaf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020afba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020afbc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.32.70,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.652: INFO: Pod "nginx-deployment-555b55d965-68rwd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-68rwd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-68rwd,UID:5179e6d5-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9564,Generation:0,CreationTimestamp:2019-03-18 21:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.27/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc0020afdd7 0xc0020afdd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020afe50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020afe70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:10.42.2.27,StartTime:2019-03-18 21:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://18f8145b16dcb93e4a17bacc0df86137265e9f4858721f207ff1e5fc04836b4d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.652: INFO: Pod "nginx-deployment-555b55d965-8hwcz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8hwcz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-8hwcz,UID:551919a9-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9875,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.123/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc0019940d0 0xc0019940d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019941f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001994210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.652: INFO: Pod "nginx-deployment-555b55d965-bfmww" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bfmww,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-bfmww,UID:5175e513-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9593,Generation:0,CreationTimestamp:2019-03-18 21:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.114/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc0019942d7 0xc0019942d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001994350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019943e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:10.42.0.114,StartTime:2019-03-18 21:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://39e02b70c4289e01edef64c59b1419166d85aedf32fd343d0289dd0ecc7bf30d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.653: INFO: Pod "nginx-deployment-555b55d965-ds5ld" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ds5ld,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-ds5ld,UID:5175a555-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9585,Generation:0,CreationTimestamp:2019-03-18 21:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.26/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001994680 0xc001994681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019949c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019949e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  }],Message:,Reason:,HostIP:172.31.32.70,PodIP:10.42.1.26,StartTime:2019-03-18 21:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://19e11b48bf79f25ede7a7e382dbd61149727fdada3f1712ad01156e755b68247}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.653: INFO: Pod "nginx-deployment-555b55d965-fhn2p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fhn2p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-fhn2p,UID:55187bf2-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9844,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.36/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001994b90 0xc001994b91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001994c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001994c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.653: INFO: Pod "nginx-deployment-555b55d965-lftlp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lftlp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-lftlp,UID:517283f8-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9553,Generation:0,CreationTimestamp:2019-03-18 21:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.112/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001994ce7 0xc001994ce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001994df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001994e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:10.42.0.112,StartTime:2019-03-18 21:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://3c394b9b6b36fb7fb160a742daea4950e8923dbd54cb905f3b340182ea905b58}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.653: INFO: Pod "nginx-deployment-555b55d965-lgpr9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lgpr9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-lgpr9,UID:550c8457-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9819,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.31/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001994ee0 0xc001994ee1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001994fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001994fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.32.70,PodIP:10.42.1.31,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://6ae5baa9c56d2916f6506b3ab033da7eef69238aaf342732789f6793645b730b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.653: INFO: Pod "nginx-deployment-555b55d965-p9dkn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-p9dkn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-p9dkn,UID:550d6066-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9862,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.30/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001995120 0xc001995121}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001995450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001995470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:10.42.2.30,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://108be9bcd30323615554365d00b8b637e4849f398dfd1768b71765be5bf2a731}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.653: INFO: Pod "nginx-deployment-555b55d965-pqmmq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pqmmq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-pqmmq,UID:55108636-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9827,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.33/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001995570 0xc001995571}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019955e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001995600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.653: INFO: Pod "nginx-deployment-555b55d965-pvpfc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pvpfc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-pvpfc,UID:51735eb2-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9560,Generation:0,CreationTimestamp:2019-03-18 21:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.26/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001995737 0xc001995738}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019957b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019957d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:10.42.2.26,StartTime:2019-03-18 21:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://cb983375ca44c04ae46a4d2f759c141bcdab1e4cd8ab250742a5461f74380550}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.653: INFO: Pod "nginx-deployment-555b55d965-q5hmf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q5hmf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-q5hmf,UID:5175f22a-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9568,Generation:0,CreationTimestamp:2019-03-18 21:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.28/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001995930 0xc001995931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019959a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019959c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:10.42.2.28,StartTime:2019-03-18 21:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://cbeadc1301b4a06d3bbf9fb6c792cf08c18682fd85acea05450b5948f8b9df77}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.653: INFO: Pod "nginx-deployment-555b55d965-rcz7g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rcz7g,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-rcz7g,UID:517348f5-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9582,Generation:0,CreationTimestamp:2019-03-18 21:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.28/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001995aa0 0xc001995aa1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001995b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001995bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  }],Message:,Reason:,HostIP:172.31.32.70,PodIP:10.42.1.28,StartTime:2019-03-18 21:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://bb9a81aaa8439b4720801a0c0fd066187a037b479384dd355db2d352a31f2913}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.653: INFO: Pod "nginx-deployment-555b55d965-rfjpd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rfjpd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-rfjpd,UID:550d7023-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9860,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.118/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001995c80 0xc001995c81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001995da0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001995dc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:10.42.0.118,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://c5bb2cd686b3827e9badebd874c3a854e8f60b7232f481790f75f3fbab82d552}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.654: INFO: Pod "nginx-deployment-555b55d965-wwmm5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wwmm5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-wwmm5,UID:5517eaf7-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9847,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.120/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc001995e90 0xc001995e91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001995f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bae010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.654: INFO: Pod "nginx-deployment-555b55d965-xf4r6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xf4r6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-xf4r6,UID:55109fa0-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9839,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.32/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc002bae0d7 0xc002bae0d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bae160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bae180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.32.70,PodIP:10.42.1.32,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://42c85bd4bc1e8f65164081abb61f0f427b06b34599604b2f26ce6d04924d927e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.654: INFO: Pod "nginx-deployment-555b55d965-xk5rh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xk5rh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-xk5rh,UID:5179f091-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9591,Generation:0,CreationTimestamp:2019-03-18 21:03:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.115/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc002bae250 0xc002bae251}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bae2d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bae2f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:45 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:10.42.0.115,StartTime:2019-03-18 21:03:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:03:46 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://5e185c7f748580243473596f71c1704e2a340bc0792aee39e51813b4d828c551}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.654: INFO: Pod "nginx-deployment-555b55d965-xxj5w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xxj5w,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-xxj5w,UID:55106dd2-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9826,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.34/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc002bae400 0xc002bae401}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bae470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bae490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.32.70,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.654: INFO: Pod "nginx-deployment-555b55d965-zlk29" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zlk29,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-555b55d965-zlk29,UID:55193edd-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9852,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.121/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5170b527-49c1-11e9-a0d3-06934a8be3ba 0xc002bae577 0xc002bae578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bae5f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bae610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.654: INFO: Pod "nginx-deployment-65bbdb5f8-4mtxq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4mtxq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-4mtxq,UID:55182236-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9814,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.33/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc002bae6d0 0xc002bae6d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002baef20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002baef40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.32.70,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.654: INFO: Pod "nginx-deployment-65bbdb5f8-667ql" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-667ql,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-667ql,UID:5510453f-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9817,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.32/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc002baf190 0xc002baf191}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002baf380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002baf3a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.654: INFO: Pod "nginx-deployment-65bbdb5f8-86psn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-86psn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-86psn,UID:550e0cd5-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9808,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.31/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc002baf470 0xc002baf471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002baf4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002baf510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.654: INFO: Pod "nginx-deployment-65bbdb5f8-9l29s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-9l29s,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-9l29s,UID:53e0b01d-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9867,Generation:0,CreationTimestamp:2019-03-18 21:03:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.30/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc002baf5e0 0xc002baf5e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002baf840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002baf860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.32.70,PodIP:10.42.1.30,StartTime:2019-03-18 21:03:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.654: INFO: Pod "nginx-deployment-65bbdb5f8-cvnb4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cvnb4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-cvnb4,UID:551f4475-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9835,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.35/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc002baf950 0xc002baf951}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002baf9d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002baf9f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.655: INFO: Pod "nginx-deployment-65bbdb5f8-frd2k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-frd2k,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-frd2k,UID:53d7c6f1-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9673,Generation:0,CreationTimestamp:2019-03-18 21:03:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.29/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc002bafc70 0xc002bafc71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bafea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bafec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.32.70,PodIP:10.42.1.29,StartTime:2019-03-18 21:03:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.655: INFO: Pod "nginx-deployment-65bbdb5f8-fsxm8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fsxm8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-fsxm8,UID:551924e9-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9831,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.34/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc00192c0e0 0xc00192c0e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00192c160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00192c180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.655: INFO: Pod "nginx-deployment-65bbdb5f8-jg7vd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jg7vd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-jg7vd,UID:5510323b-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9857,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.122/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc00192c250 0xc00192c251}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00192c2d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00192c2f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.655: INFO: Pod "nginx-deployment-65bbdb5f8-jvzhg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jvzhg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-jvzhg,UID:53df9950-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9664,Generation:0,CreationTimestamp:2019-03-18 21:03:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.117/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc00192c3d0 0xc00192c3d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00192c450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00192c470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:,StartTime:2019-03-18 21:03:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.655: INFO: Pod "nginx-deployment-65bbdb5f8-nhxr5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nhxr5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-nhxr5,UID:55188956-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9829,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.36/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc00192c540 0xc00192c541}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00192c5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00192c5e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.32.70,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.655: INFO: Pod "nginx-deployment-65bbdb5f8-q5g6g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-q5g6g,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-q5g6g,UID:53d7a4dc-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9744,Generation:0,CreationTimestamp:2019-03-18 21:03:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.116/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc00192c6b0 0xc00192c6b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00192c730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00192c750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:10.42.0.116,StartTime:2019-03-18 21:03:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.655: INFO: Pod "nginx-deployment-65bbdb5f8-qhptg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qhptg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-qhptg,UID:5518521e-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9874,Generation:0,CreationTimestamp:2019-03-18 21:03:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.124/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc00192c840 0xc00192c841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00192c8c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00192c8e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:,StartTime:2019-03-18 21:03:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 21:03:53.655: INFO: Pod "nginx-deployment-65bbdb5f8-strgj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-strgj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6q9w6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6q9w6/pods/nginx-deployment-65bbdb5f8-strgj,UID:53d6c0ae-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:9725,Generation:0,CreationTimestamp:2019-03-18 21:03:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.29/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 53d63e98-49c1-11e9-a0d3-06934a8be3ba 0xc00192c9b0 0xc00192c9b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l92b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l92b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l92b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00192ca30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00192ca50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:03:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.212,PodIP:10.42.2.29,StartTime:2019-03-18 21:03:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:03:53.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-6q9w6" for this suite.
Mar 18 21:04:01.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:04:01.729: INFO: namespace: e2e-tests-deployment-6q9w6, resource: bindings, ignored listing per whitelist
Mar 18 21:04:01.770: INFO: namespace e2e-tests-deployment-6q9w6 deletion completed in 8.108765139s

• [SLOW TEST:16.297 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:04:01.770: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-5b27e326-49c1-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 21:04:01.845: INFO: Waiting up to 5m0s for pod "pod-configmaps-5b286556-49c1-11e9-9475-02f976e168bb" in namespace "e2e-tests-configmap-9bkqb" to be "success or failure"
Mar 18 21:04:01.847: INFO: Pod "pod-configmaps-5b286556-49c1-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.741776ms
Mar 18 21:04:03.851: INFO: Pod "pod-configmaps-5b286556-49c1-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005971374s
STEP: Saw pod success
Mar 18 21:04:03.851: INFO: Pod "pod-configmaps-5b286556-49c1-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:04:03.854: INFO: Trying to get logs from node node-1 pod pod-configmaps-5b286556-49c1-11e9-9475-02f976e168bb container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 21:04:03.878: INFO: Waiting for pod pod-configmaps-5b286556-49c1-11e9-9475-02f976e168bb to disappear
Mar 18 21:04:03.898: INFO: Pod pod-configmaps-5b286556-49c1-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:04:03.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9bkqb" for this suite.
Mar 18 21:04:09.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:04:09.996: INFO: namespace: e2e-tests-configmap-9bkqb, resource: bindings, ignored listing per whitelist
Mar 18 21:04:09.999: INFO: namespace e2e-tests-configmap-9bkqb deletion completed in 6.097422432s

• [SLOW TEST:8.229 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:04:09.999: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 21:04:10.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-kgjj9'
Mar 18 21:04:10.332: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 18 21:04:10.332: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Mar 18 21:04:12.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-kgjj9'
Mar 18 21:04:12.414: INFO: stderr: ""
Mar 18 21:04:12.414: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:04:12.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kgjj9" for this suite.
Mar 18 21:04:34.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:04:34.464: INFO: namespace: e2e-tests-kubectl-kgjj9, resource: bindings, ignored listing per whitelist
Mar 18 21:04:34.511: INFO: namespace e2e-tests-kubectl-kgjj9 deletion completed in 22.092455767s

• [SLOW TEST:24.511 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:04:34.511: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 21:04:34.570: INFO: Creating ReplicaSet my-hostname-basic-6eaaa881-49c1-11e9-9475-02f976e168bb
Mar 18 21:04:34.580: INFO: Pod name my-hostname-basic-6eaaa881-49c1-11e9-9475-02f976e168bb: Found 0 pods out of 1
Mar 18 21:04:39.583: INFO: Pod name my-hostname-basic-6eaaa881-49c1-11e9-9475-02f976e168bb: Found 1 pods out of 1
Mar 18 21:04:39.583: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-6eaaa881-49c1-11e9-9475-02f976e168bb" is running
Mar 18 21:04:39.585: INFO: Pod "my-hostname-basic-6eaaa881-49c1-11e9-9475-02f976e168bb-zslcr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 21:04:34 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 21:04:36 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 21:04:36 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 21:04:34 +0000 UTC Reason: Message:}])
Mar 18 21:04:39.585: INFO: Trying to dial the pod
Mar 18 21:04:44.593: INFO: Controller my-hostname-basic-6eaaa881-49c1-11e9-9475-02f976e168bb: Got expected result from replica 1 [my-hostname-basic-6eaaa881-49c1-11e9-9475-02f976e168bb-zslcr]: "my-hostname-basic-6eaaa881-49c1-11e9-9475-02f976e168bb-zslcr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:04:44.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-dl9sq" for this suite.
Mar 18 21:04:50.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:04:50.662: INFO: namespace: e2e-tests-replicaset-dl9sq, resource: bindings, ignored listing per whitelist
Mar 18 21:04:50.687: INFO: namespace e2e-tests-replicaset-dl9sq deletion completed in 6.08997877s

• [SLOW TEST:16.175 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:04:50.687: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 21:04:50.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 version'
Mar 18 21:04:50.811: INFO: stderr: ""
Mar 18 21:04:50.811: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.4\", GitCommit:\"c27b913fddd1a6c480c229191a087698aa92f0b1\", GitTreeState:\"clean\", BuildDate:\"2019-02-28T13:30:26Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:04:50.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ggqgs" for this suite.
Mar 18 21:04:56.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:04:56.835: INFO: namespace: e2e-tests-kubectl-ggqgs, resource: bindings, ignored listing per whitelist
Mar 18 21:04:56.901: INFO: namespace e2e-tests-kubectl-ggqgs deletion completed in 6.08671543s

• [SLOW TEST:6.215 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:04:56.902: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 18 21:04:57.016: INFO: Waiting up to 5m0s for pod "pod-7c0af921-49c1-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-ddc9x" to be "success or failure"
Mar 18 21:04:57.019: INFO: Pod "pod-7c0af921-49c1-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.785395ms
Mar 18 21:04:59.022: INFO: Pod "pod-7c0af921-49c1-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005836937s
STEP: Saw pod success
Mar 18 21:04:59.022: INFO: Pod "pod-7c0af921-49c1-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:04:59.025: INFO: Trying to get logs from node node-1 pod pod-7c0af921-49c1-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 21:04:59.044: INFO: Waiting for pod pod-7c0af921-49c1-11e9-9475-02f976e168bb to disappear
Mar 18 21:04:59.055: INFO: Pod pod-7c0af921-49c1-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:04:59.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ddc9x" for this suite.
Mar 18 21:05:05.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:05:05.084: INFO: namespace: e2e-tests-emptydir-ddc9x, resource: bindings, ignored listing per whitelist
Mar 18 21:05:05.161: INFO: namespace e2e-tests-emptydir-ddc9x deletion completed in 6.097742595s

• [SLOW TEST:8.259 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:05:05.161: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-22v4k/secret-test-80efced7-49c1-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 21:05:05.230: INFO: Waiting up to 5m0s for pod "pod-configmaps-80f047ec-49c1-11e9-9475-02f976e168bb" in namespace "e2e-tests-secrets-22v4k" to be "success or failure"
Mar 18 21:05:05.233: INFO: Pod "pod-configmaps-80f047ec-49c1-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.727084ms
Mar 18 21:05:07.236: INFO: Pod "pod-configmaps-80f047ec-49c1-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006160014s
STEP: Saw pod success
Mar 18 21:05:07.236: INFO: Pod "pod-configmaps-80f047ec-49c1-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:05:07.240: INFO: Trying to get logs from node node-1 pod pod-configmaps-80f047ec-49c1-11e9-9475-02f976e168bb container env-test: <nil>
STEP: delete the pod
Mar 18 21:05:07.260: INFO: Waiting for pod pod-configmaps-80f047ec-49c1-11e9-9475-02f976e168bb to disappear
Mar 18 21:05:07.264: INFO: Pod pod-configmaps-80f047ec-49c1-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:05:07.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-22v4k" for this suite.
Mar 18 21:05:13.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:05:13.351: INFO: namespace: e2e-tests-secrets-22v4k, resource: bindings, ignored listing per whitelist
Mar 18 21:05:13.371: INFO: namespace e2e-tests-secrets-22v4k deletion completed in 6.098868097s

• [SLOW TEST:8.210 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:05:13.371: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 21:05:13.435: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 18 21:05:18.438: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 18 21:05:18.438: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 18 21:05:18.453: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-sxrhj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sxrhj/deployments/test-cleanup-deployment,UID:88d07991-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:10452,Generation:1,CreationTimestamp:2019-03-18 21:05:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar 18 21:05:18.456: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Mar 18 21:05:18.456: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar 18 21:05:18.456: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-sxrhj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sxrhj/replicasets/test-cleanup-controller,UID:85d39b0a-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:10453,Generation:1,CreationTimestamp:2019-03-18 21:05:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 88d07991-49c1-11e9-a0d3-06934a8be3ba 0xc0022653e7 0xc0022653e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 18 21:05:18.460: INFO: Pod "test-cleanup-controller-7bdk6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-7bdk6,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-sxrhj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-sxrhj/pods/test-cleanup-controller-7bdk6,UID:85d53321-49c1-11e9-a0d3-06934a8be3ba,ResourceVersion:10446,Generation:0,CreationTimestamp:2019-03-18 21:05:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.132/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 85d39b0a-49c1-11e9-a0d3-06934a8be3ba 0xc002265997 0xc002265998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-47vwn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-47vwn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-47vwn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002265a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002265a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:05:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:05:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:05:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:05:13 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:10.42.0.132,StartTime:2019-03-18 21:05:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 21:05:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://9a98206db7f8725f80d7d2337802f52e97fb5eec7d39ca0fa80d877ead7b0417}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:05:18.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-sxrhj" for this suite.
Mar 18 21:05:24.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:05:24.525: INFO: namespace: e2e-tests-deployment-sxrhj, resource: bindings, ignored listing per whitelist
Mar 18 21:05:24.573: INFO: namespace e2e-tests-deployment-sxrhj deletion completed in 6.104746617s

• [SLOW TEST:11.202 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:05:24.573: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 18 21:05:24.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:24.823: INFO: stderr: ""
Mar 18 21:05:24.823: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 21:05:24.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:24.893: INFO: stderr: ""
Mar 18 21:05:24.893: INFO: stdout: "update-demo-nautilus-mkldl update-demo-nautilus-z65vl "
Mar 18 21:05:24.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-mkldl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:24.957: INFO: stderr: ""
Mar 18 21:05:24.957: INFO: stdout: ""
Mar 18 21:05:24.957: INFO: update-demo-nautilus-mkldl is created but not running
Mar 18 21:05:29.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:30.025: INFO: stderr: ""
Mar 18 21:05:30.026: INFO: stdout: "update-demo-nautilus-mkldl update-demo-nautilus-z65vl "
Mar 18 21:05:30.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-mkldl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:30.090: INFO: stderr: ""
Mar 18 21:05:30.090: INFO: stdout: "true"
Mar 18 21:05:30.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-mkldl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:30.157: INFO: stderr: ""
Mar 18 21:05:30.157: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 21:05:30.157: INFO: validating pod update-demo-nautilus-mkldl
Mar 18 21:05:30.161: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 21:05:30.161: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 21:05:30.161: INFO: update-demo-nautilus-mkldl is verified up and running
Mar 18 21:05:30.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-z65vl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:30.232: INFO: stderr: ""
Mar 18 21:05:30.232: INFO: stdout: "true"
Mar 18 21:05:30.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-z65vl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:30.298: INFO: stderr: ""
Mar 18 21:05:30.298: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 21:05:30.298: INFO: validating pod update-demo-nautilus-z65vl
Mar 18 21:05:30.301: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 21:05:30.301: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 21:05:30.301: INFO: update-demo-nautilus-z65vl is verified up and running
STEP: scaling down the replication controller
Mar 18 21:05:30.303: INFO: scanned /root for discovery docs: <nil>
Mar 18 21:05:30.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:31.394: INFO: stderr: ""
Mar 18 21:05:31.394: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 21:05:31.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:31.462: INFO: stderr: ""
Mar 18 21:05:31.462: INFO: stdout: "update-demo-nautilus-mkldl update-demo-nautilus-z65vl "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 18 21:05:36.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:36.532: INFO: stderr: ""
Mar 18 21:05:36.532: INFO: stdout: "update-demo-nautilus-z65vl "
Mar 18 21:05:36.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-z65vl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:36.596: INFO: stderr: ""
Mar 18 21:05:36.596: INFO: stdout: "true"
Mar 18 21:05:36.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-z65vl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:36.662: INFO: stderr: ""
Mar 18 21:05:36.662: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 21:05:36.662: INFO: validating pod update-demo-nautilus-z65vl
Mar 18 21:05:36.665: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 21:05:36.665: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 21:05:36.665: INFO: update-demo-nautilus-z65vl is verified up and running
STEP: scaling up the replication controller
Mar 18 21:05:36.667: INFO: scanned /root for discovery docs: <nil>
Mar 18 21:05:36.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:37.759: INFO: stderr: ""
Mar 18 21:05:37.759: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 21:05:37.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:37.831: INFO: stderr: ""
Mar 18 21:05:37.831: INFO: stdout: "update-demo-nautilus-vgbwz update-demo-nautilus-z65vl "
Mar 18 21:05:37.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-vgbwz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:37.897: INFO: stderr: ""
Mar 18 21:05:37.897: INFO: stdout: ""
Mar 18 21:05:37.897: INFO: update-demo-nautilus-vgbwz is created but not running
Mar 18 21:05:42.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:42.965: INFO: stderr: ""
Mar 18 21:05:42.965: INFO: stdout: "update-demo-nautilus-vgbwz update-demo-nautilus-z65vl "
Mar 18 21:05:42.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-vgbwz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:43.033: INFO: stderr: ""
Mar 18 21:05:43.033: INFO: stdout: "true"
Mar 18 21:05:43.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-vgbwz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:43.097: INFO: stderr: ""
Mar 18 21:05:43.097: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 21:05:43.097: INFO: validating pod update-demo-nautilus-vgbwz
Mar 18 21:05:43.101: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 21:05:43.101: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 21:05:43.101: INFO: update-demo-nautilus-vgbwz is verified up and running
Mar 18 21:05:43.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-z65vl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:43.167: INFO: stderr: ""
Mar 18 21:05:43.167: INFO: stdout: "true"
Mar 18 21:05:43.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-z65vl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:43.235: INFO: stderr: ""
Mar 18 21:05:43.235: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 21:05:43.235: INFO: validating pod update-demo-nautilus-z65vl
Mar 18 21:05:43.237: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 21:05:43.237: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 21:05:43.237: INFO: update-demo-nautilus-z65vl is verified up and running
STEP: using delete to clean up resources
Mar 18 21:05:43.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:43.305: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 21:05:43.305: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 18 21:05:43.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-wbzfm'
Mar 18 21:05:43.409: INFO: stderr: "No resources found.\n"
Mar 18 21:05:43.409: INFO: stdout: ""
Mar 18 21:05:43.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -l name=update-demo --namespace=e2e-tests-kubectl-wbzfm -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 18 21:05:43.501: INFO: stderr: ""
Mar 18 21:05:43.503: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:05:43.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wbzfm" for this suite.
Mar 18 21:05:49.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:05:49.572: INFO: namespace: e2e-tests-kubectl-wbzfm, resource: bindings, ignored listing per whitelist
Mar 18 21:05:49.597: INFO: namespace e2e-tests-kubectl-wbzfm deletion completed in 6.090059916s

• [SLOW TEST:25.024 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:05:49.598: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-pq42b
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 18 21:05:49.655: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 18 21:06:11.730: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.136:8080/dial?request=hostName&protocol=udp&host=10.42.0.135&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-pq42b PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 21:06:11.730: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 21:06:11.795: INFO: Waiting for endpoints: map[]
Mar 18 21:06:11.798: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.136:8080/dial?request=hostName&protocol=udp&host=10.42.1.38&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-pq42b PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 21:06:11.798: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 21:06:11.863: INFO: Waiting for endpoints: map[]
Mar 18 21:06:11.866: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.136:8080/dial?request=hostName&protocol=udp&host=10.42.2.40&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-pq42b PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 21:06:11.866: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
Mar 18 21:06:11.928: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:06:11.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-pq42b" for this suite.
Mar 18 21:06:33.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:06:33.966: INFO: namespace: e2e-tests-pod-network-test-pq42b, resource: bindings, ignored listing per whitelist
Mar 18 21:06:34.061: INFO: namespace e2e-tests-pod-network-test-pq42b deletion completed in 22.128675603s

• [SLOW TEST:44.463 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:06:34.061: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:06:36.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-8kfzd" for this suite.
Mar 18 21:06:42.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:06:42.249: INFO: namespace: e2e-tests-emptydir-wrapper-8kfzd, resource: bindings, ignored listing per whitelist
Mar 18 21:06:42.258: INFO: namespace e2e-tests-emptydir-wrapper-8kfzd deletion completed in 6.094956335s

• [SLOW TEST:8.197 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:06:42.258: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar 18 21:06:44.332: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-bace441e-49c1-11e9-9475-02f976e168bb", GenerateName:"", Namespace:"e2e-tests-pods-29w7q", SelfLink:"/api/v1/namespaces/e2e-tests-pods-29w7q/pods/pod-submit-remove-bace441e-49c1-11e9-9475-02f976e168bb", UID:"baceb466-49c1-11e9-a0d3-06934a8be3ba", ResourceVersion:"10849", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688540002, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"310665156"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.0.138/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-s2pp6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00124eac0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s2pp6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001bd3358), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001a225a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001bd33a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001bd33c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001bd33c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001bd33cc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688540002, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688540003, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688540003, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688540002, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.35.20", PodIP:"10.42.0.138", StartTime:(*v1.Time)(0xc001753140), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001753160), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d", ContainerID:"docker://058f8df7394bee70b0ebaac77acab56ddfc61b7cb078210100a09bd2e7c53576"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:06:56.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-29w7q" for this suite.
Mar 18 21:07:02.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:07:02.631: INFO: namespace: e2e-tests-pods-29w7q, resource: bindings, ignored listing per whitelist
Mar 18 21:07:02.672: INFO: namespace e2e-tests-pods-29w7q deletion completed in 6.100343604s

• [SLOW TEST:20.414 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:07:02.672: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:08:02.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-sgt2r" for this suite.
Mar 18 21:08:24.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:08:24.775: INFO: namespace: e2e-tests-container-probe-sgt2r, resource: bindings, ignored listing per whitelist
Mar 18 21:08:24.835: INFO: namespace e2e-tests-container-probe-sgt2r deletion completed in 22.082649333s

• [SLOW TEST:82.163 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:08:24.835: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar 18 21:08:29.918: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:08:29.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-7v2qx" for this suite.
Mar 18 21:08:51.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:08:51.987: INFO: namespace: e2e-tests-replicaset-7v2qx, resource: bindings, ignored listing per whitelist
Mar 18 21:08:52.048: INFO: namespace e2e-tests-replicaset-7v2qx deletion completed in 22.102125218s

• [SLOW TEST:27.213 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:08:52.048: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:08:56.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-gbjxq" for this suite.
Mar 18 21:09:02.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:09:02.180: INFO: namespace: e2e-tests-kubelet-test-gbjxq, resource: bindings, ignored listing per whitelist
Mar 18 21:09:02.226: INFO: namespace e2e-tests-kubelet-test-gbjxq deletion completed in 6.103791163s

• [SLOW TEST:10.178 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:09:02.226: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 21:09:02.283: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:09:04.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tcgrg" for this suite.
Mar 18 21:09:48.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:09:48.422: INFO: namespace: e2e-tests-pods-tcgrg, resource: bindings, ignored listing per whitelist
Mar 18 21:09:48.450: INFO: namespace e2e-tests-pods-tcgrg deletion completed in 44.090966518s

• [SLOW TEST:46.224 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:09:48.450: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-29c9c49e-49c2-11e9-9475-02f976e168bb
STEP: Creating secret with name s-test-opt-upd-29c9c4e4-49c2-11e9-9475-02f976e168bb
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-29c9c49e-49c2-11e9-9475-02f976e168bb
STEP: Updating secret s-test-opt-upd-29c9c4e4-49c2-11e9-9475-02f976e168bb
STEP: Creating secret with name s-test-opt-create-29c9c505-49c2-11e9-9475-02f976e168bb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:09:52.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lhxgx" for this suite.
Mar 18 21:10:14.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:10:14.669: INFO: namespace: e2e-tests-projected-lhxgx, resource: bindings, ignored listing per whitelist
Mar 18 21:10:14.674: INFO: namespace e2e-tests-projected-lhxgx deletion completed in 22.087597642s

• [SLOW TEST:26.224 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:10:14.674: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar 18 21:10:14.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 --namespace=e2e-tests-kubectl-mjp5x run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 18 21:10:16.258: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 18 21:10:16.258: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:10:18.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mjp5x" for this suite.
Mar 18 21:10:28.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:10:28.302: INFO: namespace: e2e-tests-kubectl-mjp5x, resource: bindings, ignored listing per whitelist
Mar 18 21:10:28.355: INFO: namespace e2e-tests-kubectl-mjp5x deletion completed in 10.088412071s

• [SLOW TEST:13.681 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:10:28.355: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 21:10:28.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-d9gl7'
Mar 18 21:10:28.482: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 18 21:10:28.482: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Mar 18 21:10:32.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-d9gl7'
Mar 18 21:10:32.565: INFO: stderr: ""
Mar 18 21:10:32.565: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:10:32.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d9gl7" for this suite.
Mar 18 21:10:38.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:10:38.607: INFO: namespace: e2e-tests-kubectl-d9gl7, resource: bindings, ignored listing per whitelist
Mar 18 21:10:38.682: INFO: namespace e2e-tests-kubectl-d9gl7 deletion completed in 6.112200819s

• [SLOW TEST:10.326 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:10:38.682: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-r6dd
STEP: Creating a pod to test atomic-volume-subpath
Mar 18 21:10:38.764: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-r6dd" in namespace "e2e-tests-subpath-r2m6b" to be "success or failure"
Mar 18 21:10:38.767: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.135879ms
Mar 18 21:10:40.770: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005248043s
Mar 18 21:10:42.774: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Running", Reason="", readiness=false. Elapsed: 4.009547438s
Mar 18 21:10:44.778: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Running", Reason="", readiness=false. Elapsed: 6.01318274s
Mar 18 21:10:46.781: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Running", Reason="", readiness=false. Elapsed: 8.016120112s
Mar 18 21:10:48.784: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Running", Reason="", readiness=false. Elapsed: 10.018985203s
Mar 18 21:10:50.788: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Running", Reason="", readiness=false. Elapsed: 12.023365553s
Mar 18 21:10:52.793: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Running", Reason="", readiness=false. Elapsed: 14.028783275s
Mar 18 21:10:54.797: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Running", Reason="", readiness=false. Elapsed: 16.032033103s
Mar 18 21:10:56.800: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Running", Reason="", readiness=false. Elapsed: 18.035137642s
Mar 18 21:10:58.803: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Running", Reason="", readiness=false. Elapsed: 20.038471371s
Mar 18 21:11:00.806: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Running", Reason="", readiness=false. Elapsed: 22.041512298s
Mar 18 21:11:02.810: INFO: Pod "pod-subpath-test-configmap-r6dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.045272935s
STEP: Saw pod success
Mar 18 21:11:02.810: INFO: Pod "pod-subpath-test-configmap-r6dd" satisfied condition "success or failure"
Mar 18 21:11:02.816: INFO: Trying to get logs from node node-1 pod pod-subpath-test-configmap-r6dd container test-container-subpath-configmap-r6dd: <nil>
STEP: delete the pod
Mar 18 21:11:02.835: INFO: Waiting for pod pod-subpath-test-configmap-r6dd to disappear
Mar 18 21:11:02.851: INFO: Pod pod-subpath-test-configmap-r6dd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-r6dd
Mar 18 21:11:02.851: INFO: Deleting pod "pod-subpath-test-configmap-r6dd" in namespace "e2e-tests-subpath-r2m6b"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:11:02.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-r2m6b" for this suite.
Mar 18 21:11:08.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:11:08.914: INFO: namespace: e2e-tests-subpath-r2m6b, resource: bindings, ignored listing per whitelist
Mar 18 21:11:08.951: INFO: namespace e2e-tests-subpath-r2m6b deletion completed in 6.093813812s

• [SLOW TEST:30.269 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:11:08.951: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 18 21:11:09.011: INFO: namespace e2e-tests-kubectl-2ssns
Mar 18 21:11:09.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-2ssns'
Mar 18 21:11:09.188: INFO: stderr: ""
Mar 18 21:11:09.188: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 18 21:11:10.191: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 21:11:10.191: INFO: Found 0 / 1
Mar 18 21:11:11.191: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 21:11:11.191: INFO: Found 1 / 1
Mar 18 21:11:11.191: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 18 21:11:11.193: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 21:11:11.193: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 18 21:11:11.193: INFO: wait on redis-master startup in e2e-tests-kubectl-2ssns 
Mar 18 21:11:11.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 logs redis-master-lbqfl redis-master --namespace=e2e-tests-kubectl-2ssns'
Mar 18 21:11:11.268: INFO: stderr: ""
Mar 18 21:11:11.268: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Mar 21:11:09.926 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Mar 21:11:09.926 # Server started, Redis version 3.2.12\n1:M 18 Mar 21:11:09.926 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Mar 21:11:09.926 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar 18 21:11:11.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-2ssns'
Mar 18 21:11:11.349: INFO: stderr: ""
Mar 18 21:11:11.349: INFO: stdout: "service/rm2 exposed\n"
Mar 18 21:11:11.354: INFO: Service rm2 in namespace e2e-tests-kubectl-2ssns found.
STEP: exposing service
Mar 18 21:11:13.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-2ssns'
Mar 18 21:11:13.435: INFO: stderr: ""
Mar 18 21:11:13.435: INFO: stdout: "service/rm3 exposed\n"
Mar 18 21:11:13.440: INFO: Service rm3 in namespace e2e-tests-kubectl-2ssns found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:11:15.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2ssns" for this suite.
Mar 18 21:11:37.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:11:37.519: INFO: namespace: e2e-tests-kubectl-2ssns, resource: bindings, ignored listing per whitelist
Mar 18 21:11:37.537: INFO: namespace e2e-tests-kubectl-2ssns deletion completed in 22.088669502s

• [SLOW TEST:28.586 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:11:37.537: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar 18 21:11:38.104: INFO: Waiting up to 5m0s for pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-jnjmw" in namespace "e2e-tests-svcaccounts-c4n4l" to be "success or failure"
Mar 18 21:11:38.107: INFO: Pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-jnjmw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.603441ms
Mar 18 21:11:40.110: INFO: Pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-jnjmw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005465966s
STEP: Saw pod success
Mar 18 21:11:40.110: INFO: Pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-jnjmw" satisfied condition "success or failure"
Mar 18 21:11:40.112: INFO: Trying to get logs from node node-1 pod pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-jnjmw container token-test: <nil>
STEP: delete the pod
Mar 18 21:11:40.137: INFO: Waiting for pod pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-jnjmw to disappear
Mar 18 21:11:40.148: INFO: Pod pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-jnjmw no longer exists
STEP: Creating a pod to test consume service account root CA
Mar 18 21:11:40.152: INFO: Waiting up to 5m0s for pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-tl27f" in namespace "e2e-tests-svcaccounts-c4n4l" to be "success or failure"
Mar 18 21:11:40.155: INFO: Pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-tl27f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.863934ms
Mar 18 21:11:42.158: INFO: Pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-tl27f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005830923s
STEP: Saw pod success
Mar 18 21:11:42.158: INFO: Pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-tl27f" satisfied condition "success or failure"
Mar 18 21:11:42.160: INFO: Trying to get logs from node node-1 pod pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-tl27f container root-ca-test: <nil>
STEP: delete the pod
Mar 18 21:11:42.184: INFO: Waiting for pod pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-tl27f to disappear
Mar 18 21:11:42.193: INFO: Pod pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-tl27f no longer exists
STEP: Creating a pod to test consume service account namespace
Mar 18 21:11:42.198: INFO: Waiting up to 5m0s for pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-v8zjq" in namespace "e2e-tests-svcaccounts-c4n4l" to be "success or failure"
Mar 18 21:11:42.201: INFO: Pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-v8zjq": Phase="Pending", Reason="", readiness=false. Elapsed: 3.030085ms
Mar 18 21:11:44.204: INFO: Pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-v8zjq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006023228s
STEP: Saw pod success
Mar 18 21:11:44.204: INFO: Pod "pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-v8zjq" satisfied condition "success or failure"
Mar 18 21:11:44.206: INFO: Trying to get logs from node node-1 pod pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-v8zjq container namespace-test: <nil>
STEP: delete the pod
Mar 18 21:11:44.233: INFO: Waiting for pod pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-v8zjq to disappear
Mar 18 21:11:44.236: INFO: Pod pod-service-account-6b1c2284-49c2-11e9-9475-02f976e168bb-v8zjq no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:11:44.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-c4n4l" for this suite.
Mar 18 21:11:50.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:11:50.296: INFO: namespace: e2e-tests-svcaccounts-c4n4l, resource: bindings, ignored listing per whitelist
Mar 18 21:11:50.335: INFO: namespace e2e-tests-svcaccounts-c4n4l deletion completed in 6.095580428s

• [SLOW TEST:12.798 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:11:50.335: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-726f6945-49c2-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 21:11:50.397: INFO: Waiting up to 5m0s for pod "pod-configmaps-726fd318-49c2-11e9-9475-02f976e168bb" in namespace "e2e-tests-configmap-m5wd6" to be "success or failure"
Mar 18 21:11:50.400: INFO: Pod "pod-configmaps-726fd318-49c2-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.581129ms
Mar 18 21:11:52.403: INFO: Pod "pod-configmaps-726fd318-49c2-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005576908s
STEP: Saw pod success
Mar 18 21:11:52.403: INFO: Pod "pod-configmaps-726fd318-49c2-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:11:52.405: INFO: Trying to get logs from node node-1 pod pod-configmaps-726fd318-49c2-11e9-9475-02f976e168bb container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 21:11:52.424: INFO: Waiting for pod pod-configmaps-726fd318-49c2-11e9-9475-02f976e168bb to disappear
Mar 18 21:11:52.429: INFO: Pod pod-configmaps-726fd318-49c2-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:11:52.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m5wd6" for this suite.
Mar 18 21:11:58.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:11:58.503: INFO: namespace: e2e-tests-configmap-m5wd6, resource: bindings, ignored listing per whitelist
Mar 18 21:11:58.516: INFO: namespace e2e-tests-configmap-m5wd6 deletion completed in 6.082113589s

• [SLOW TEST:8.181 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:11:58.516: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-7752a163-49c2-11e9-9475-02f976e168bb
STEP: Creating secret with name s-test-opt-upd-7752a1a5-49c2-11e9-9475-02f976e168bb
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7752a163-49c2-11e9-9475-02f976e168bb
STEP: Updating secret s-test-opt-upd-7752a1a5-49c2-11e9-9475-02f976e168bb
STEP: Creating secret with name s-test-opt-create-7752a1c0-49c2-11e9-9475-02f976e168bb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:12:02.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-p6hch" for this suite.
Mar 18 21:12:24.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:12:24.690: INFO: namespace: e2e-tests-secrets-p6hch, resource: bindings, ignored listing per whitelist
Mar 18 21:12:24.752: INFO: namespace e2e-tests-secrets-p6hch deletion completed in 22.085881464s

• [SLOW TEST:26.236 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:12:24.752: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 21:12:24.812: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86f2e33d-49c2-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-8hcbb" to be "success or failure"
Mar 18 21:12:24.817: INFO: Pod "downwardapi-volume-86f2e33d-49c2-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.473556ms
Mar 18 21:12:26.820: INFO: Pod "downwardapi-volume-86f2e33d-49c2-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007747174s
STEP: Saw pod success
Mar 18 21:12:26.820: INFO: Pod "downwardapi-volume-86f2e33d-49c2-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:12:26.822: INFO: Trying to get logs from node node-1 pod downwardapi-volume-86f2e33d-49c2-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 21:12:26.843: INFO: Waiting for pod downwardapi-volume-86f2e33d-49c2-11e9-9475-02f976e168bb to disappear
Mar 18 21:12:26.850: INFO: Pod downwardapi-volume-86f2e33d-49c2-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:12:26.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8hcbb" for this suite.
Mar 18 21:12:32.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:12:32.876: INFO: namespace: e2e-tests-downward-api-8hcbb, resource: bindings, ignored listing per whitelist
Mar 18 21:12:32.942: INFO: namespace e2e-tests-downward-api-8hcbb deletion completed in 6.088433632s

• [SLOW TEST:8.190 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:12:32.942: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 21:12:33.008: INFO: (0) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.814758ms)
Mar 18 21:12:33.011: INFO: (1) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.765104ms)
Mar 18 21:12:33.014: INFO: (2) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.802539ms)
Mar 18 21:12:33.016: INFO: (3) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.555341ms)
Mar 18 21:12:33.019: INFO: (4) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.613872ms)
Mar 18 21:12:33.021: INFO: (5) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.7118ms)
Mar 18 21:12:33.024: INFO: (6) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.547314ms)
Mar 18 21:12:33.027: INFO: (7) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.642688ms)
Mar 18 21:12:33.029: INFO: (8) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.672846ms)
Mar 18 21:12:33.034: INFO: (9) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.04416ms)
Mar 18 21:12:33.036: INFO: (10) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.743774ms)
Mar 18 21:12:33.039: INFO: (11) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.554912ms)
Mar 18 21:12:33.042: INFO: (12) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.903902ms)
Mar 18 21:12:33.044: INFO: (13) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.595466ms)
Mar 18 21:12:33.047: INFO: (14) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.705664ms)
Mar 18 21:12:33.050: INFO: (15) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.870463ms)
Mar 18 21:12:33.053: INFO: (16) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.811811ms)
Mar 18 21:12:33.055: INFO: (17) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.548109ms)
Mar 18 21:12:33.058: INFO: (18) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.840612ms)
Mar 18 21:12:33.061: INFO: (19) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.670796ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:12:33.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-t9zhp" for this suite.
Mar 18 21:12:39.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:12:39.085: INFO: namespace: e2e-tests-proxy-t9zhp, resource: bindings, ignored listing per whitelist
Mar 18 21:12:39.147: INFO: namespace e2e-tests-proxy-t9zhp deletion completed in 6.083168485s

• [SLOW TEST:6.205 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:12:39.148: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:12:41.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-5l9ml" for this suite.
Mar 18 21:13:31.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:13:31.254: INFO: namespace: e2e-tests-kubelet-test-5l9ml, resource: bindings, ignored listing per whitelist
Mar 18 21:13:31.309: INFO: namespace e2e-tests-kubelet-test-5l9ml deletion completed in 50.086241777s

• [SLOW TEST:52.161 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:13:31.309: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar 18 21:13:31.370: INFO: Waiting up to 5m0s for pod "var-expansion-ae9f1d99-49c2-11e9-9475-02f976e168bb" in namespace "e2e-tests-var-expansion-rvbhm" to be "success or failure"
Mar 18 21:13:31.372: INFO: Pod "var-expansion-ae9f1d99-49c2-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.475008ms
Mar 18 21:13:33.375: INFO: Pod "var-expansion-ae9f1d99-49c2-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005384747s
STEP: Saw pod success
Mar 18 21:13:33.375: INFO: Pod "var-expansion-ae9f1d99-49c2-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:13:33.377: INFO: Trying to get logs from node node-1 pod var-expansion-ae9f1d99-49c2-11e9-9475-02f976e168bb container dapi-container: <nil>
STEP: delete the pod
Mar 18 21:13:33.401: INFO: Waiting for pod var-expansion-ae9f1d99-49c2-11e9-9475-02f976e168bb to disappear
Mar 18 21:13:33.409: INFO: Pod var-expansion-ae9f1d99-49c2-11e9-9475-02f976e168bb no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:13:33.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-rvbhm" for this suite.
Mar 18 21:13:39.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:13:39.469: INFO: namespace: e2e-tests-var-expansion-rvbhm, resource: bindings, ignored listing per whitelist
Mar 18 21:13:39.504: INFO: namespace e2e-tests-var-expansion-rvbhm deletion completed in 6.091747158s

• [SLOW TEST:8.195 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:13:39.504: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar 18 21:13:39.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 create -f - --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:13:39.724: INFO: stderr: ""
Mar 18 21:13:39.724: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 21:13:39.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:13:39.801: INFO: stderr: ""
Mar 18 21:13:39.801: INFO: stdout: "update-demo-nautilus-5l5rf update-demo-nautilus-vv47s "
Mar 18 21:13:39.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-5l5rf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:13:39.866: INFO: stderr: ""
Mar 18 21:13:39.866: INFO: stdout: ""
Mar 18 21:13:39.866: INFO: update-demo-nautilus-5l5rf is created but not running
Mar 18 21:13:44.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:13:44.932: INFO: stderr: ""
Mar 18 21:13:44.932: INFO: stdout: "update-demo-nautilus-5l5rf update-demo-nautilus-vv47s "
Mar 18 21:13:44.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-5l5rf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:13:44.996: INFO: stderr: ""
Mar 18 21:13:44.996: INFO: stdout: "true"
Mar 18 21:13:44.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-5l5rf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:13:45.060: INFO: stderr: ""
Mar 18 21:13:45.060: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 21:13:45.060: INFO: validating pod update-demo-nautilus-5l5rf
Mar 18 21:13:45.064: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 21:13:45.064: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 21:13:45.064: INFO: update-demo-nautilus-5l5rf is verified up and running
Mar 18 21:13:45.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-vv47s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:13:45.127: INFO: stderr: ""
Mar 18 21:13:45.127: INFO: stdout: "true"
Mar 18 21:13:45.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-nautilus-vv47s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:13:45.191: INFO: stderr: ""
Mar 18 21:13:45.191: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 21:13:45.191: INFO: validating pod update-demo-nautilus-vv47s
Mar 18 21:13:45.195: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 21:13:45.195: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 21:13:45.195: INFO: update-demo-nautilus-vv47s is verified up and running
STEP: rolling-update to new replication controller
Mar 18 21:13:45.197: INFO: scanned /root for discovery docs: <nil>
Mar 18 21:13:45.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:14:07.491: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 18 21:14:07.491: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 21:14:07.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:14:07.561: INFO: stderr: ""
Mar 18 21:14:07.561: INFO: stdout: "update-demo-kitten-fpgsv update-demo-kitten-pplcj "
Mar 18 21:14:07.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-kitten-fpgsv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:14:07.630: INFO: stderr: ""
Mar 18 21:14:07.631: INFO: stdout: "true"
Mar 18 21:14:07.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-kitten-fpgsv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:14:07.696: INFO: stderr: ""
Mar 18 21:14:07.696: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 18 21:14:07.696: INFO: validating pod update-demo-kitten-fpgsv
Mar 18 21:14:07.700: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 18 21:14:07.700: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 18 21:14:07.700: INFO: update-demo-kitten-fpgsv is verified up and running
Mar 18 21:14:07.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-kitten-pplcj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:14:07.768: INFO: stderr: ""
Mar 18 21:14:07.768: INFO: stdout: "true"
Mar 18 21:14:07.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 get pods update-demo-kitten-pplcj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb58n'
Mar 18 21:14:07.832: INFO: stderr: ""
Mar 18 21:14:07.832: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 18 21:14:07.833: INFO: validating pod update-demo-kitten-pplcj
Mar 18 21:14:07.836: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 18 21:14:07.836: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 18 21:14:07.836: INFO: update-demo-kitten-pplcj is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:14:07.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pb58n" for this suite.
Mar 18 21:14:29.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:14:29.878: INFO: namespace: e2e-tests-kubectl-pb58n, resource: bindings, ignored listing per whitelist
Mar 18 21:14:29.923: INFO: namespace e2e-tests-kubectl-pb58n deletion completed in 22.083768874s

• [SLOW TEST:50.419 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:14:29.924: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0318 21:15:10.010235      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 21:15:10.010: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:15:10.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-r78v4" for this suite.
Mar 18 21:15:16.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:15:16.048: INFO: namespace: e2e-tests-gc-r78v4, resource: bindings, ignored listing per whitelist
Mar 18 21:15:16.104: INFO: namespace e2e-tests-gc-r78v4 deletion completed in 6.090487533s

• [SLOW TEST:46.180 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:15:16.104: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar 18 21:15:16.167: INFO: Waiting up to 5m0s for pod "var-expansion-ed15ca95-49c2-11e9-9475-02f976e168bb" in namespace "e2e-tests-var-expansion-45hpc" to be "success or failure"
Mar 18 21:15:16.173: INFO: Pod "var-expansion-ed15ca95-49c2-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.300667ms
Mar 18 21:15:18.176: INFO: Pod "var-expansion-ed15ca95-49c2-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009248714s
STEP: Saw pod success
Mar 18 21:15:18.176: INFO: Pod "var-expansion-ed15ca95-49c2-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:15:18.178: INFO: Trying to get logs from node node-1 pod var-expansion-ed15ca95-49c2-11e9-9475-02f976e168bb container dapi-container: <nil>
STEP: delete the pod
Mar 18 21:15:18.201: INFO: Waiting for pod var-expansion-ed15ca95-49c2-11e9-9475-02f976e168bb to disappear
Mar 18 21:15:18.209: INFO: Pod var-expansion-ed15ca95-49c2-11e9-9475-02f976e168bb no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:15:18.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-45hpc" for this suite.
Mar 18 21:15:24.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:15:24.299: INFO: namespace: e2e-tests-var-expansion-45hpc, resource: bindings, ignored listing per whitelist
Mar 18 21:15:24.304: INFO: namespace e2e-tests-var-expansion-45hpc deletion completed in 6.092037732s

• [SLOW TEST:8.199 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:15:24.304: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 18 21:15:24.361: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 18 21:15:24.367: INFO: Waiting for terminating namespaces to be deleted...
Mar 18 21:15:24.369: INFO: 
Logging pods the kubelet thinks is on node node-1 before test
Mar 18 21:15:24.374: INFO: rke-network-plugin-deploy-job-v9n5x from kube-system started at 2019-03-18 20:19:33 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.374: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 18 21:15:24.374: INFO: nginx-ingress-controller-x6mz2 from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.374: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 18 21:15:24.374: INFO: canal-k9vqq from kube-system started at 2019-03-18 20:19:37 +0000 UTC (2 container statuses recorded)
Mar 18 21:15:24.374: INFO: 	Container calico-node ready: true, restart count 0
Mar 18 21:15:24.374: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 18 21:15:24.374: INFO: rke-kube-dns-addon-deploy-job-xxq8d from kube-system started at 2019-03-18 20:19:42 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.374: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Mar 18 21:15:24.374: INFO: rke-ingress-controller-deploy-job-m9w44 from kube-system started at 2019-03-18 20:19:57 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.374: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 18 21:15:24.374: INFO: rke-metrics-addon-deploy-job-bk4gn from kube-system started at 2019-03-18 20:19:49 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.374: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 18 21:15:24.374: INFO: metrics-server-58bd5dd8d7-gzdst from kube-system started at 2019-03-18 20:19:50 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.374: INFO: 	Container metrics-server ready: true, restart count 0
Mar 18 21:15:24.374: INFO: sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-lhbmj from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 21:15:24.374: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 18 21:15:24.374: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 21:15:24.374: INFO: 
Logging pods the kubelet thinks is on node node-2 before test
Mar 18 21:15:24.379: INFO: nginx-ingress-controller-v87dt from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.379: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 18 21:15:24.379: INFO: sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-nnxbf from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 21:15:24.379: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 18 21:15:24.379: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 21:15:24.379: INFO: kube-dns-58bd5b8dd7-l2glm from kube-system started at 2019-03-18 20:19:44 +0000 UTC (3 container statuses recorded)
Mar 18 21:15:24.379: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 18 21:15:24.379: INFO: 	Container kubedns ready: true, restart count 0
Mar 18 21:15:24.379: INFO: 	Container sidecar ready: true, restart count 0
Mar 18 21:15:24.379: INFO: canal-psvdr from kube-system started at 2019-03-18 20:19:37 +0000 UTC (2 container statuses recorded)
Mar 18 21:15:24.379: INFO: 	Container calico-node ready: true, restart count 0
Mar 18 21:15:24.379: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 18 21:15:24.379: INFO: kube-dns-autoscaler-77bc5fd84-lg7gr from kube-system started at 2019-03-18 20:19:44 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.379: INFO: 	Container autoscaler ready: true, restart count 0
Mar 18 21:15:24.379: INFO: 
Logging pods the kubelet thinks is on node node-3 before test
Mar 18 21:15:24.384: INFO: nginx-ingress-controller-q2xj8 from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.384: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 18 21:15:24.384: INFO: default-http-backend-78fccfc5d9-2lbst from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.384: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 18 21:15:24.384: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-18 20:25:25 +0000 UTC (1 container statuses recorded)
Mar 18 21:15:24.384: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 18 21:15:24.384: INFO: sonobuoy-e2e-job-561a442ed17248ce from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 21:15:24.384: INFO: 	Container e2e ready: true, restart count 0
Mar 18 21:15:24.384: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 21:15:24.384: INFO: sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-w8nm8 from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 21:15:24.384: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 18 21:15:24.384: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 21:15:24.384: INFO: canal-fg6j2 from kube-system started at 2019-03-18 20:19:37 +0000 UTC (2 container statuses recorded)
Mar 18 21:15:24.384: INFO: 	Container calico-node ready: true, restart count 0
Mar 18 21:15:24.384: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f331cc83-49c2-11e9-9475-02f976e168bb 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f331cc83-49c2-11e9-9475-02f976e168bb off the node node-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f331cc83-49c2-11e9-9475-02f976e168bb
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:15:28.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-q5hgh" for this suite.
Mar 18 21:15:56.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:15:56.506: INFO: namespace: e2e-tests-sched-pred-q5hgh, resource: bindings, ignored listing per whitelist
Mar 18 21:15:56.554: INFO: namespace e2e-tests-sched-pred-q5hgh deletion completed in 28.094896209s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:32.251 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:15:56.555: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar 18 21:15:56.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 api-versions'
Mar 18 21:15:56.724: INFO: stderr: ""
Mar 18 21:15:56.724: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:15:56.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n29vd" for this suite.
Mar 18 21:16:02.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:16:02.822: INFO: namespace: e2e-tests-kubectl-n29vd, resource: bindings, ignored listing per whitelist
Mar 18 21:16:02.843: INFO: namespace e2e-tests-kubectl-n29vd deletion completed in 6.106862065s

• [SLOW TEST:6.289 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:16:02.844: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-08f13709-49c3-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 21:16:02.906: INFO: Waiting up to 5m0s for pod "pod-configmaps-08f1a793-49c3-11e9-9475-02f976e168bb" in namespace "e2e-tests-configmap-x6xct" to be "success or failure"
Mar 18 21:16:02.914: INFO: Pod "pod-configmaps-08f1a793-49c3-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.358162ms
Mar 18 21:16:04.917: INFO: Pod "pod-configmaps-08f1a793-49c3-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011544446s
STEP: Saw pod success
Mar 18 21:16:04.917: INFO: Pod "pod-configmaps-08f1a793-49c3-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:16:04.920: INFO: Trying to get logs from node node-1 pod pod-configmaps-08f1a793-49c3-11e9-9475-02f976e168bb container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 21:16:04.947: INFO: Waiting for pod pod-configmaps-08f1a793-49c3-11e9-9475-02f976e168bb to disappear
Mar 18 21:16:04.954: INFO: Pod pod-configmaps-08f1a793-49c3-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:16:04.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x6xct" for this suite.
Mar 18 21:16:10.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:16:10.991: INFO: namespace: e2e-tests-configmap-x6xct, resource: bindings, ignored listing per whitelist
Mar 18 21:16:11.059: INFO: namespace e2e-tests-configmap-x6xct deletion completed in 6.099004885s

• [SLOW TEST:8.215 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:16:11.059: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-0dd7758d-49c3-11e9-9475-02f976e168bb
Mar 18 21:16:11.124: INFO: Pod name my-hostname-basic-0dd7758d-49c3-11e9-9475-02f976e168bb: Found 0 pods out of 1
Mar 18 21:16:16.127: INFO: Pod name my-hostname-basic-0dd7758d-49c3-11e9-9475-02f976e168bb: Found 1 pods out of 1
Mar 18 21:16:16.127: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-0dd7758d-49c3-11e9-9475-02f976e168bb" are running
Mar 18 21:16:16.130: INFO: Pod "my-hostname-basic-0dd7758d-49c3-11e9-9475-02f976e168bb-6hb58" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 21:16:11 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 21:16:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 21:16:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 21:16:11 +0000 UTC Reason: Message:}])
Mar 18 21:16:16.130: INFO: Trying to dial the pod
Mar 18 21:16:21.138: INFO: Controller my-hostname-basic-0dd7758d-49c3-11e9-9475-02f976e168bb: Got expected result from replica 1 [my-hostname-basic-0dd7758d-49c3-11e9-9475-02f976e168bb-6hb58]: "my-hostname-basic-0dd7758d-49c3-11e9-9475-02f976e168bb-6hb58", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:16:21.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-hks44" for this suite.
Mar 18 21:16:27.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:16:27.168: INFO: namespace: e2e-tests-replication-controller-hks44, resource: bindings, ignored listing per whitelist
Mar 18 21:16:27.235: INFO: namespace e2e-tests-replication-controller-hks44 deletion completed in 6.093372533s

• [SLOW TEST:16.176 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:16:27.236: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar 18 21:16:27.529: INFO: Pod name wrapped-volume-race-17905f25-49c3-11e9-9475-02f976e168bb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-17905f25-49c3-11e9-9475-02f976e168bb in namespace e2e-tests-emptydir-wrapper-6tv28, will wait for the garbage collector to delete the pods
Mar 18 21:16:43.629: INFO: Deleting ReplicationController wrapped-volume-race-17905f25-49c3-11e9-9475-02f976e168bb took: 6.464146ms
Mar 18 21:16:43.729: INFO: Terminating ReplicationController wrapped-volume-race-17905f25-49c3-11e9-9475-02f976e168bb pods took: 100.236118ms
STEP: Creating RC which spawns configmap-volume pods
Mar 18 21:17:18.742: INFO: Pod name wrapped-volume-race-36242905-49c3-11e9-9475-02f976e168bb: Found 0 pods out of 5
Mar 18 21:17:23.748: INFO: Pod name wrapped-volume-race-36242905-49c3-11e9-9475-02f976e168bb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-36242905-49c3-11e9-9475-02f976e168bb in namespace e2e-tests-emptydir-wrapper-6tv28, will wait for the garbage collector to delete the pods
Mar 18 21:17:35.823: INFO: Deleting ReplicationController wrapped-volume-race-36242905-49c3-11e9-9475-02f976e168bb took: 5.680938ms
Mar 18 21:17:35.923: INFO: Terminating ReplicationController wrapped-volume-race-36242905-49c3-11e9-9475-02f976e168bb pods took: 100.234442ms
STEP: Creating RC which spawns configmap-volume pods
Mar 18 21:18:17.638: INFO: Pod name wrapped-volume-race-593eaf90-49c3-11e9-9475-02f976e168bb: Found 0 pods out of 5
Mar 18 21:18:22.643: INFO: Pod name wrapped-volume-race-593eaf90-49c3-11e9-9475-02f976e168bb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-593eaf90-49c3-11e9-9475-02f976e168bb in namespace e2e-tests-emptydir-wrapper-6tv28, will wait for the garbage collector to delete the pods
Mar 18 21:18:34.721: INFO: Deleting ReplicationController wrapped-volume-race-593eaf90-49c3-11e9-9475-02f976e168bb took: 6.029128ms
Mar 18 21:18:34.921: INFO: Terminating ReplicationController wrapped-volume-race-593eaf90-49c3-11e9-9475-02f976e168bb pods took: 200.271169ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:19:17.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-6tv28" for this suite.
Mar 18 21:19:23.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:19:23.865: INFO: namespace: e2e-tests-emptydir-wrapper-6tv28, resource: bindings, ignored listing per whitelist
Mar 18 21:19:23.934: INFO: namespace e2e-tests-emptydir-wrapper-6tv28 deletion completed in 6.087497493s

• [SLOW TEST:176.698 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:19:23.934: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 21:19:24.002: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80ce33c5-49c3-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-rjr87" to be "success or failure"
Mar 18 21:19:24.007: INFO: Pod "downwardapi-volume-80ce33c5-49c3-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.612815ms
Mar 18 21:19:26.011: INFO: Pod "downwardapi-volume-80ce33c5-49c3-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008815768s
STEP: Saw pod success
Mar 18 21:19:26.011: INFO: Pod "downwardapi-volume-80ce33c5-49c3-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:19:26.013: INFO: Trying to get logs from node node-1 pod downwardapi-volume-80ce33c5-49c3-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 21:19:26.034: INFO: Waiting for pod downwardapi-volume-80ce33c5-49c3-11e9-9475-02f976e168bb to disappear
Mar 18 21:19:26.041: INFO: Pod downwardapi-volume-80ce33c5-49c3-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:19:26.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rjr87" for this suite.
Mar 18 21:19:32.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:19:32.086: INFO: namespace: e2e-tests-projected-rjr87, resource: bindings, ignored listing per whitelist
Mar 18 21:19:32.129: INFO: namespace e2e-tests-projected-rjr87 deletion completed in 6.084362027s

• [SLOW TEST:8.195 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:19:32.129: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-85af2da1-49c3-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 21:19:32.189: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-85afabfc-49c3-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-qpxx4" to be "success or failure"
Mar 18 21:19:32.191: INFO: Pod "pod-projected-secrets-85afabfc-49c3-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.942133ms
Mar 18 21:19:34.194: INFO: Pod "pod-projected-secrets-85afabfc-49c3-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00512572s
STEP: Saw pod success
Mar 18 21:19:34.194: INFO: Pod "pod-projected-secrets-85afabfc-49c3-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:19:34.196: INFO: Trying to get logs from node node-1 pod pod-projected-secrets-85afabfc-49c3-11e9-9475-02f976e168bb container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 18 21:19:34.210: INFO: Waiting for pod pod-projected-secrets-85afabfc-49c3-11e9-9475-02f976e168bb to disappear
Mar 18 21:19:34.220: INFO: Pod pod-projected-secrets-85afabfc-49c3-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:19:34.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qpxx4" for this suite.
Mar 18 21:19:40.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:19:40.254: INFO: namespace: e2e-tests-projected-qpxx4, resource: bindings, ignored listing per whitelist
Mar 18 21:19:40.311: INFO: namespace e2e-tests-projected-qpxx4 deletion completed in 6.085556019s

• [SLOW TEST:8.181 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:19:40.311: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 18 21:19:40.365: INFO: PodSpec: initContainers in spec.initContainers
Mar 18 21:20:21.968: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-8a8ff9e2-49c3-11e9-9475-02f976e168bb", GenerateName:"", Namespace:"e2e-tests-init-container-l2jxw", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-l2jxw/pods/pod-init-8a8ff9e2-49c3-11e9-9475-02f976e168bb", UID:"8a900dc2-49c3-11e9-a0d3-06934a8be3ba", ResourceVersion:"14141", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688540780, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"365262638"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.0.185/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-npxng", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002199300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-npxng", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-npxng", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-npxng", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001e45a58), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00211e4e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001e45ae0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001e45b10)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001e45b18), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001e45b1c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688540780, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688540780, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688540780, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688540780, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.35.20", PodIP:"10.42.0.185", StartTime:(*v1.Time)(0xc0009a0040), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0003d6fc0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0003d7030)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://181918ae98074968ef05791f036d2062d7df585b8002c1083a4dd51386ebdb0e"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0009a0080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0009a0060), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:20:21.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-l2jxw" for this suite.
Mar 18 21:20:43.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:20:44.042: INFO: namespace: e2e-tests-init-container-l2jxw, resource: bindings, ignored listing per whitelist
Mar 18 21:20:44.064: INFO: namespace e2e-tests-init-container-l2jxw deletion completed in 22.090436116s

• [SLOW TEST:63.753 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:20:44.065: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-b0906288-49c3-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 21:20:44.130: INFO: Waiting up to 5m0s for pod "pod-secrets-b090d5f9-49c3-11e9-9475-02f976e168bb" in namespace "e2e-tests-secrets-r56d6" to be "success or failure"
Mar 18 21:20:44.136: INFO: Pod "pod-secrets-b090d5f9-49c3-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.567489ms
Mar 18 21:20:46.139: INFO: Pod "pod-secrets-b090d5f9-49c3-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00938108s
STEP: Saw pod success
Mar 18 21:20:46.139: INFO: Pod "pod-secrets-b090d5f9-49c3-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:20:46.141: INFO: Trying to get logs from node node-1 pod pod-secrets-b090d5f9-49c3-11e9-9475-02f976e168bb container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 21:20:46.160: INFO: Waiting for pod pod-secrets-b090d5f9-49c3-11e9-9475-02f976e168bb to disappear
Mar 18 21:20:46.168: INFO: Pod pod-secrets-b090d5f9-49c3-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:20:46.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-r56d6" for this suite.
Mar 18 21:20:52.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:20:52.189: INFO: namespace: e2e-tests-secrets-r56d6, resource: bindings, ignored listing per whitelist
Mar 18 21:20:52.259: INFO: namespace e2e-tests-secrets-r56d6 deletion completed in 6.087239956s

• [SLOW TEST:8.194 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:20:52.259: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-b5728a1f-49c3-11e9-9475-02f976e168bb
STEP: Creating configMap with name cm-test-opt-upd-b5728a5d-49c3-11e9-9475-02f976e168bb
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b5728a1f-49c3-11e9-9475-02f976e168bb
STEP: Updating configmap cm-test-opt-upd-b5728a5d-49c3-11e9-9475-02f976e168bb
STEP: Creating configMap with name cm-test-opt-create-b5728b19-49c3-11e9-9475-02f976e168bb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:20:56.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6lw5x" for this suite.
Mar 18 21:21:18.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:21:18.680: INFO: namespace: e2e-tests-projected-6lw5x, resource: bindings, ignored listing per whitelist
Mar 18 21:21:18.691: INFO: namespace e2e-tests-projected-6lw5x deletion completed in 22.090581214s

• [SLOW TEST:26.433 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:21:18.692: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 21:21:18.753: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:21:20.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tkfcx" for this suite.
Mar 18 21:22:10.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:22:10.834: INFO: namespace: e2e-tests-pods-tkfcx, resource: bindings, ignored listing per whitelist
Mar 18 21:22:10.870: INFO: namespace e2e-tests-pods-tkfcx deletion completed in 50.086379143s

• [SLOW TEST:52.179 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:22:10.870: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 18 21:22:10.938: INFO: Waiting up to 5m0s for pod "pod-e44e701b-49c3-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-prq62" to be "success or failure"
Mar 18 21:22:10.941: INFO: Pod "pod-e44e701b-49c3-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.744599ms
Mar 18 21:22:12.943: INFO: Pod "pod-e44e701b-49c3-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005214421s
STEP: Saw pod success
Mar 18 21:22:12.943: INFO: Pod "pod-e44e701b-49c3-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:22:12.945: INFO: Trying to get logs from node node-1 pod pod-e44e701b-49c3-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 21:22:12.964: INFO: Waiting for pod pod-e44e701b-49c3-11e9-9475-02f976e168bb to disappear
Mar 18 21:22:12.974: INFO: Pod pod-e44e701b-49c3-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:22:12.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-prq62" for this suite.
Mar 18 21:22:18.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:22:19.002: INFO: namespace: e2e-tests-emptydir-prq62, resource: bindings, ignored listing per whitelist
Mar 18 21:22:19.073: INFO: namespace e2e-tests-emptydir-prq62 deletion completed in 6.095549395s

• [SLOW TEST:8.203 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:22:19.073: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 18 21:22:19.133: INFO: Waiting up to 5m0s for pod "downward-api-e931213b-49c3-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-fksnd" to be "success or failure"
Mar 18 21:22:19.138: INFO: Pod "downward-api-e931213b-49c3-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.442551ms
Mar 18 21:22:21.141: INFO: Pod "downward-api-e931213b-49c3-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008406331s
STEP: Saw pod success
Mar 18 21:22:21.141: INFO: Pod "downward-api-e931213b-49c3-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:22:21.145: INFO: Trying to get logs from node node-1 pod downward-api-e931213b-49c3-11e9-9475-02f976e168bb container dapi-container: <nil>
STEP: delete the pod
Mar 18 21:22:21.173: INFO: Waiting for pod downward-api-e931213b-49c3-11e9-9475-02f976e168bb to disappear
Mar 18 21:22:21.180: INFO: Pod downward-api-e931213b-49c3-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:22:21.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fksnd" for this suite.
Mar 18 21:22:27.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:22:27.208: INFO: namespace: e2e-tests-downward-api-fksnd, resource: bindings, ignored listing per whitelist
Mar 18 21:22:27.284: INFO: namespace e2e-tests-downward-api-fksnd deletion completed in 6.09648275s

• [SLOW TEST:8.211 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:22:27.284: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0318 21:22:37.409223      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 21:22:37.409: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:22:37.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lrrpt" for this suite.
Mar 18 21:22:43.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:22:43.492: INFO: namespace: e2e-tests-gc-lrrpt, resource: bindings, ignored listing per whitelist
Mar 18 21:22:43.503: INFO: namespace e2e-tests-gc-lrrpt deletion completed in 6.090980042s

• [SLOW TEST:16.219 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:22:43.503: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-khkx6
Mar 18 21:22:45.570: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-khkx6
STEP: checking the pod's current state and verifying that restartCount is present
Mar 18 21:22:45.573: INFO: Initial restart count of pod liveness-exec is 0
Mar 18 21:23:33.650: INFO: Restart count of pod e2e-tests-container-probe-khkx6/liveness-exec is now 1 (48.077134998s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:23:33.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-khkx6" for this suite.
Mar 18 21:23:39.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:23:39.691: INFO: namespace: e2e-tests-container-probe-khkx6, resource: bindings, ignored listing per whitelist
Mar 18 21:23:39.755: INFO: namespace e2e-tests-container-probe-khkx6 deletion completed in 6.085574029s

• [SLOW TEST:56.252 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:23:39.755: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 21:24:05.823: INFO: Container started at 2019-03-18 21:23:40 +0000 UTC, pod became ready at 2019-03-18 21:24:04 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:24:05.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mqvgk" for this suite.
Mar 18 21:24:27.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:24:27.864: INFO: namespace: e2e-tests-container-probe-mqvgk, resource: bindings, ignored listing per whitelist
Mar 18 21:24:27.915: INFO: namespace e2e-tests-container-probe-mqvgk deletion completed in 22.087695194s

• [SLOW TEST:48.159 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:24:27.915: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-35fd639d-49c4-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 21:24:27.980: INFO: Waiting up to 5m0s for pod "pod-configmaps-35fdd2eb-49c4-11e9-9475-02f976e168bb" in namespace "e2e-tests-configmap-zpvzk" to be "success or failure"
Mar 18 21:24:27.985: INFO: Pod "pod-configmaps-35fdd2eb-49c4-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.035929ms
Mar 18 21:24:29.988: INFO: Pod "pod-configmaps-35fdd2eb-49c4-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007946211s
STEP: Saw pod success
Mar 18 21:24:29.988: INFO: Pod "pod-configmaps-35fdd2eb-49c4-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:24:29.990: INFO: Trying to get logs from node node-1 pod pod-configmaps-35fdd2eb-49c4-11e9-9475-02f976e168bb container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 21:24:30.017: INFO: Waiting for pod pod-configmaps-35fdd2eb-49c4-11e9-9475-02f976e168bb to disappear
Mar 18 21:24:30.021: INFO: Pod pod-configmaps-35fdd2eb-49c4-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:24:30.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zpvzk" for this suite.
Mar 18 21:24:36.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:24:36.044: INFO: namespace: e2e-tests-configmap-zpvzk, resource: bindings, ignored listing per whitelist
Mar 18 21:24:36.115: INFO: namespace e2e-tests-configmap-zpvzk deletion completed in 6.090121507s

• [SLOW TEST:8.200 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:24:36.115: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar 18 21:24:36.171: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-w5ltl" to be "success or failure"
Mar 18 21:24:36.174: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.158897ms
Mar 18 21:24:38.177: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006097645s
STEP: Saw pod success
Mar 18 21:24:38.177: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 18 21:24:38.179: INFO: Trying to get logs from node node-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 18 21:24:38.203: INFO: Waiting for pod pod-host-path-test to disappear
Mar 18 21:24:38.210: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:24:38.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-w5ltl" for this suite.
Mar 18 21:24:44.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:24:44.256: INFO: namespace: e2e-tests-hostpath-w5ltl, resource: bindings, ignored listing per whitelist
Mar 18 21:24:44.303: INFO: namespace e2e-tests-hostpath-w5ltl deletion completed in 6.088920984s

• [SLOW TEST:8.188 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:24:44.303: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-3fc1a528-49c4-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 21:24:44.368: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3fc20e3a-49c4-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-d6x95" to be "success or failure"
Mar 18 21:24:44.373: INFO: Pod "pod-projected-secrets-3fc20e3a-49c4-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.887654ms
Mar 18 21:24:46.376: INFO: Pod "pod-projected-secrets-3fc20e3a-49c4-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007757529s
STEP: Saw pod success
Mar 18 21:24:46.376: INFO: Pod "pod-projected-secrets-3fc20e3a-49c4-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:24:46.378: INFO: Trying to get logs from node node-1 pod pod-projected-secrets-3fc20e3a-49c4-11e9-9475-02f976e168bb container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 21:24:46.392: INFO: Waiting for pod pod-projected-secrets-3fc20e3a-49c4-11e9-9475-02f976e168bb to disappear
Mar 18 21:24:46.396: INFO: Pod pod-projected-secrets-3fc20e3a-49c4-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:24:46.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d6x95" for this suite.
Mar 18 21:24:52.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:24:52.484: INFO: namespace: e2e-tests-projected-d6x95, resource: bindings, ignored listing per whitelist
Mar 18 21:24:52.495: INFO: namespace e2e-tests-projected-d6x95 deletion completed in 6.08977564s

• [SLOW TEST:8.192 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:24:52.495: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar 18 21:24:52.549: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-818169620 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:24:52.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zrprb" for this suite.
Mar 18 21:24:58.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:24:58.633: INFO: namespace: e2e-tests-kubectl-zrprb, resource: bindings, ignored listing per whitelist
Mar 18 21:24:58.692: INFO: namespace e2e-tests-kubectl-zrprb deletion completed in 6.084106181s

• [SLOW TEST:6.197 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:24:58.692: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 18 21:24:58.750: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:25:02.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-q9hzg" for this suite.
Mar 18 21:25:08.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:25:08.350: INFO: namespace: e2e-tests-init-container-q9hzg, resource: bindings, ignored listing per whitelist
Mar 18 21:25:08.406: INFO: namespace e2e-tests-init-container-q9hzg deletion completed in 6.082286997s

• [SLOW TEST:9.713 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:25:08.406: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:25:13.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-546sb" for this suite.
Mar 18 21:25:35.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:25:35.514: INFO: namespace: e2e-tests-replication-controller-546sb, resource: bindings, ignored listing per whitelist
Mar 18 21:25:35.570: INFO: namespace e2e-tests-replication-controller-546sb deletion completed in 22.085608539s

• [SLOW TEST:27.164 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:25:35.570: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 18 21:25:35.631: INFO: Waiting up to 5m0s for pod "downward-api-5e50aa4e-49c4-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-dtjsw" to be "success or failure"
Mar 18 21:25:35.634: INFO: Pod "downward-api-5e50aa4e-49c4-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.445193ms
Mar 18 21:25:37.637: INFO: Pod "downward-api-5e50aa4e-49c4-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005425719s
STEP: Saw pod success
Mar 18 21:25:37.637: INFO: Pod "downward-api-5e50aa4e-49c4-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:25:37.639: INFO: Trying to get logs from node node-1 pod downward-api-5e50aa4e-49c4-11e9-9475-02f976e168bb container dapi-container: <nil>
STEP: delete the pod
Mar 18 21:25:37.667: INFO: Waiting for pod downward-api-5e50aa4e-49c4-11e9-9475-02f976e168bb to disappear
Mar 18 21:25:37.674: INFO: Pod downward-api-5e50aa4e-49c4-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:25:37.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dtjsw" for this suite.
Mar 18 21:25:43.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:25:43.759: INFO: namespace: e2e-tests-downward-api-dtjsw, resource: bindings, ignored listing per whitelist
Mar 18 21:25:43.769: INFO: namespace e2e-tests-downward-api-dtjsw deletion completed in 6.091673289s

• [SLOW TEST:8.199 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:25:43.769: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 18 21:25:46.355: INFO: Successfully updated pod "annotationupdate6333e7a7-49c4-11e9-9475-02f976e168bb"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:25:50.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k5vbf" for this suite.
Mar 18 21:26:12.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:26:12.411: INFO: namespace: e2e-tests-downward-api-k5vbf, resource: bindings, ignored listing per whitelist
Mar 18 21:26:12.477: INFO: namespace e2e-tests-downward-api-k5vbf deletion completed in 22.094067037s

• [SLOW TEST:28.708 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:26:12.477: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:26:18.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-flk6l" for this suite.
Mar 18 21:26:24.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:26:24.637: INFO: namespace: e2e-tests-namespaces-flk6l, resource: bindings, ignored listing per whitelist
Mar 18 21:26:24.688: INFO: namespace e2e-tests-namespaces-flk6l deletion completed in 6.087143965s
STEP: Destroying namespace "e2e-tests-nsdeletetest-gjzxp" for this suite.
Mar 18 21:26:24.690: INFO: Namespace e2e-tests-nsdeletetest-gjzxp was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-9j4f4" for this suite.
Mar 18 21:26:30.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:26:30.753: INFO: namespace: e2e-tests-nsdeletetest-9j4f4, resource: bindings, ignored listing per whitelist
Mar 18 21:26:30.782: INFO: namespace e2e-tests-nsdeletetest-9j4f4 deletion completed in 6.091447483s

• [SLOW TEST:18.305 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:26:30.782: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 18 21:26:32.852: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-7f392199-49c4-11e9-9475-02f976e168bb,GenerateName:,Namespace:e2e-tests-events-5lk7f,SelfLink:/api/v1/namespaces/e2e-tests-events-5lk7f/pods/send-events-7f392199-49c4-11e9-9475-02f976e168bb,UID:7f394c87-49c4-11e9-a0d3-06934a8be3ba,ResourceVersion:15475,Generation:0,CreationTimestamp:2019-03-18 21:26:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 837908478,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.204/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tpj9k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tpj9k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-tpj9k true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010b6f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010b6fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:26:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:26:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:26:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:26:30 +0000 UTC  }],Message:,Reason:,HostIP:172.31.35.20,PodIP:10.42.0.204,StartTime:2019-03-18 21:26:30 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-18 21:26:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ab6188fec6fbd467457a2172b9799a2600d7c632b1534616302276b9e778c237}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar 18 21:26:34.856: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 18 21:26:36.859: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:26:36.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-5lk7f" for this suite.
Mar 18 21:27:14.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:27:14.948: INFO: namespace: e2e-tests-events-5lk7f, resource: bindings, ignored listing per whitelist
Mar 18 21:27:14.956: INFO: namespace e2e-tests-events-5lk7f deletion completed in 38.084918151s

• [SLOW TEST:44.174 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:27:14.957: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-dsrtk
I0318 21:27:15.016688      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-dsrtk, replica count: 1
I0318 21:27:16.067068      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0318 21:27:17.067283      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 18 21:27:17.174: INFO: Created: latency-svc-trv5x
Mar 18 21:27:17.191: INFO: Got endpoints: latency-svc-trv5x [23.526395ms]
Mar 18 21:27:17.206: INFO: Created: latency-svc-jck4t
Mar 18 21:27:17.213: INFO: Created: latency-svc-bfvz8
Mar 18 21:27:17.214: INFO: Got endpoints: latency-svc-jck4t [23.125761ms]
Mar 18 21:27:17.220: INFO: Got endpoints: latency-svc-bfvz8 [28.310877ms]
Mar 18 21:27:17.222: INFO: Created: latency-svc-9tzhf
Mar 18 21:27:17.227: INFO: Created: latency-svc-8fdll
Mar 18 21:27:17.231: INFO: Got endpoints: latency-svc-9tzhf [39.349776ms]
Mar 18 21:27:17.234: INFO: Got endpoints: latency-svc-8fdll [43.185208ms]
Mar 18 21:27:17.238: INFO: Created: latency-svc-8t24s
Mar 18 21:27:17.242: INFO: Created: latency-svc-kjfwv
Mar 18 21:27:17.249: INFO: Created: latency-svc-sp29d
Mar 18 21:27:17.254: INFO: Got endpoints: latency-svc-kjfwv [62.024976ms]
Mar 18 21:27:17.254: INFO: Got endpoints: latency-svc-8t24s [62.720944ms]
Mar 18 21:27:17.255: INFO: Got endpoints: latency-svc-sp29d [64.260754ms]
Mar 18 21:27:17.258: INFO: Created: latency-svc-bck68
Mar 18 21:27:17.266: INFO: Created: latency-svc-z6l7v
Mar 18 21:27:17.271: INFO: Got endpoints: latency-svc-z6l7v [79.572871ms]
Mar 18 21:27:17.274: INFO: Created: latency-svc-dzx7m
Mar 18 21:27:17.280: INFO: Got endpoints: latency-svc-dzx7m [87.455555ms]
Mar 18 21:27:17.282: INFO: Created: latency-svc-5dnnd
Mar 18 21:27:17.284: INFO: Got endpoints: latency-svc-bck68 [92.466373ms]
Mar 18 21:27:17.288: INFO: Created: latency-svc-zgckv
Mar 18 21:27:17.291: INFO: Got endpoints: latency-svc-5dnnd [98.574154ms]
Mar 18 21:27:17.294: INFO: Got endpoints: latency-svc-zgckv [101.428793ms]
Mar 18 21:27:17.297: INFO: Created: latency-svc-6mw88
Mar 18 21:27:17.302: INFO: Got endpoints: latency-svc-6mw88 [109.906652ms]
Mar 18 21:27:17.304: INFO: Created: latency-svc-lk7bz
Mar 18 21:27:17.313: INFO: Created: latency-svc-gksb4
Mar 18 21:27:17.315: INFO: Got endpoints: latency-svc-lk7bz [24.342699ms]
Mar 18 21:27:17.323: INFO: Got endpoints: latency-svc-gksb4 [129.931655ms]
Mar 18 21:27:17.323: INFO: Created: latency-svc-k22s7
Mar 18 21:27:17.324: INFO: Created: latency-svc-fb2zh
Mar 18 21:27:17.327: INFO: Got endpoints: latency-svc-k22s7 [135.513728ms]
Mar 18 21:27:17.331: INFO: Got endpoints: latency-svc-fb2zh [117.468596ms]
Mar 18 21:27:17.336: INFO: Created: latency-svc-zthmv
Mar 18 21:27:17.374: INFO: Got endpoints: latency-svc-zthmv [154.756902ms]
Mar 18 21:27:17.375: INFO: Created: latency-svc-4wc5c
Mar 18 21:27:17.375: INFO: Created: latency-svc-j9kkj
Mar 18 21:27:17.375: INFO: Created: latency-svc-xmssw
Mar 18 21:27:17.375: INFO: Created: latency-svc-pr6wz
Mar 18 21:27:17.375: INFO: Created: latency-svc-hjqv2
Mar 18 21:27:17.375: INFO: Got endpoints: latency-svc-hjqv2 [119.489359ms]
Mar 18 21:27:17.375: INFO: Got endpoints: latency-svc-4wc5c [140.857571ms]
Mar 18 21:27:17.375: INFO: Got endpoints: latency-svc-xmssw [144.450571ms]
Mar 18 21:27:17.375: INFO: Got endpoints: latency-svc-j9kkj [121.738425ms]
Mar 18 21:27:17.402: INFO: Got endpoints: latency-svc-pr6wz [148.383311ms]
Mar 18 21:27:17.403: INFO: Created: latency-svc-dnc8c
Mar 18 21:27:17.403: INFO: Created: latency-svc-tsnzp
Mar 18 21:27:17.403: INFO: Created: latency-svc-r28h9
Mar 18 21:27:17.403: INFO: Created: latency-svc-bsgf7
Mar 18 21:27:17.403: INFO: Got endpoints: latency-svc-bsgf7 [131.158161ms]
Mar 18 21:27:17.408: INFO: Got endpoints: latency-svc-r28h9 [124.000649ms]
Mar 18 21:27:17.409: INFO: Got endpoints: latency-svc-tsnzp [128.939108ms]
Mar 18 21:27:17.409: INFO: Created: latency-svc-lwddl
Mar 18 21:27:17.413: INFO: Got endpoints: latency-svc-dnc8c [118.771217ms]
Mar 18 21:27:17.417: INFO: Created: latency-svc-sgpvj
Mar 18 21:27:17.427: INFO: Got endpoints: latency-svc-lwddl [124.099579ms]
Mar 18 21:27:17.427: INFO: Got endpoints: latency-svc-sgpvj [111.481135ms]
Mar 18 21:27:17.428: INFO: Created: latency-svc-7st8c
Mar 18 21:27:17.431: INFO: Created: latency-svc-ktnds
Mar 18 21:27:17.434: INFO: Got endpoints: latency-svc-7st8c [106.467404ms]
Mar 18 21:27:17.439: INFO: Got endpoints: latency-svc-ktnds [116.455156ms]
Mar 18 21:27:17.440: INFO: Created: latency-svc-hbfc7
Mar 18 21:27:17.447: INFO: Got endpoints: latency-svc-hbfc7 [115.186582ms]
Mar 18 21:27:17.447: INFO: Created: latency-svc-r46vz
Mar 18 21:27:17.453: INFO: Created: latency-svc-n8qmh
Mar 18 21:27:17.455: INFO: Got endpoints: latency-svc-r46vz [80.232464ms]
Mar 18 21:27:17.460: INFO: Got endpoints: latency-svc-n8qmh [84.845721ms]
Mar 18 21:27:17.464: INFO: Created: latency-svc-75hv6
Mar 18 21:27:17.467: INFO: Created: latency-svc-9q8ls
Mar 18 21:27:17.479: INFO: Created: latency-svc-64g5x
Mar 18 21:27:17.479: INFO: Got endpoints: latency-svc-75hv6 [104.878573ms]
Mar 18 21:27:17.484: INFO: Created: latency-svc-9bdmr
Mar 18 21:27:17.490: INFO: Created: latency-svc-snbfc
Mar 18 21:27:17.497: INFO: Created: latency-svc-7hcxq
Mar 18 21:27:17.504: INFO: Created: latency-svc-r6jmj
Mar 18 21:27:17.509: INFO: Created: latency-svc-bbjmj
Mar 18 21:27:17.515: INFO: Created: latency-svc-k67hv
Mar 18 21:27:17.520: INFO: Created: latency-svc-gq4dw
Mar 18 21:27:17.527: INFO: Created: latency-svc-xfww6
Mar 18 21:27:17.544: INFO: Got endpoints: latency-svc-9q8ls [168.714434ms]
Mar 18 21:27:17.544: INFO: Created: latency-svc-2dztx
Mar 18 21:27:17.559: INFO: Created: latency-svc-r6t4m
Mar 18 21:27:17.571: INFO: Created: latency-svc-srb99
Mar 18 21:27:17.578: INFO: Created: latency-svc-f8wdd
Mar 18 21:27:17.580: INFO: Got endpoints: latency-svc-64g5x [204.625555ms]
Mar 18 21:27:17.588: INFO: Created: latency-svc-9grvb
Mar 18 21:27:17.594: INFO: Created: latency-svc-tb5z7
Mar 18 21:27:17.600: INFO: Created: latency-svc-qwxd2
Mar 18 21:27:17.627: INFO: Got endpoints: latency-svc-9bdmr [224.90948ms]
Mar 18 21:27:17.635: INFO: Created: latency-svc-bqm5j
Mar 18 21:27:17.677: INFO: Got endpoints: latency-svc-snbfc [274.373942ms]
Mar 18 21:27:17.684: INFO: Created: latency-svc-9hwvz
Mar 18 21:27:17.729: INFO: Got endpoints: latency-svc-7hcxq [320.887235ms]
Mar 18 21:27:17.737: INFO: Created: latency-svc-22slf
Mar 18 21:27:17.777: INFO: Got endpoints: latency-svc-r6jmj [364.760965ms]
Mar 18 21:27:17.784: INFO: Created: latency-svc-m9m5r
Mar 18 21:27:17.827: INFO: Got endpoints: latency-svc-bbjmj [418.556558ms]
Mar 18 21:27:17.833: INFO: Created: latency-svc-ggchc
Mar 18 21:27:17.877: INFO: Got endpoints: latency-svc-k67hv [450.859328ms]
Mar 18 21:27:17.884: INFO: Created: latency-svc-zgv9h
Mar 18 21:27:17.928: INFO: Got endpoints: latency-svc-gq4dw [501.025783ms]
Mar 18 21:27:17.934: INFO: Created: latency-svc-fpqf8
Mar 18 21:27:17.978: INFO: Got endpoints: latency-svc-xfww6 [544.020089ms]
Mar 18 21:27:17.984: INFO: Created: latency-svc-vxzx4
Mar 18 21:27:18.027: INFO: Got endpoints: latency-svc-2dztx [588.405222ms]
Mar 18 21:27:18.034: INFO: Created: latency-svc-7s6rg
Mar 18 21:27:18.078: INFO: Got endpoints: latency-svc-r6t4m [631.622928ms]
Mar 18 21:27:18.084: INFO: Created: latency-svc-jbsqr
Mar 18 21:27:18.127: INFO: Got endpoints: latency-svc-srb99 [671.455345ms]
Mar 18 21:27:18.133: INFO: Created: latency-svc-rbf8s
Mar 18 21:27:18.177: INFO: Got endpoints: latency-svc-f8wdd [717.120291ms]
Mar 18 21:27:18.183: INFO: Created: latency-svc-rnnzq
Mar 18 21:27:18.227: INFO: Got endpoints: latency-svc-9grvb [748.084832ms]
Mar 18 21:27:18.233: INFO: Created: latency-svc-5bcz8
Mar 18 21:27:18.277: INFO: Got endpoints: latency-svc-tb5z7 [732.983014ms]
Mar 18 21:27:18.283: INFO: Created: latency-svc-nv2bj
Mar 18 21:27:18.327: INFO: Got endpoints: latency-svc-qwxd2 [747.404153ms]
Mar 18 21:27:18.334: INFO: Created: latency-svc-72n4d
Mar 18 21:27:18.377: INFO: Got endpoints: latency-svc-bqm5j [749.711063ms]
Mar 18 21:27:18.383: INFO: Created: latency-svc-zpqwt
Mar 18 21:27:18.427: INFO: Got endpoints: latency-svc-9hwvz [749.673458ms]
Mar 18 21:27:18.434: INFO: Created: latency-svc-qsmj5
Mar 18 21:27:18.477: INFO: Got endpoints: latency-svc-22slf [747.956276ms]
Mar 18 21:27:18.485: INFO: Created: latency-svc-xr9r6
Mar 18 21:27:18.527: INFO: Got endpoints: latency-svc-m9m5r [749.672125ms]
Mar 18 21:27:18.533: INFO: Created: latency-svc-x7q7n
Mar 18 21:27:18.577: INFO: Got endpoints: latency-svc-ggchc [750.467119ms]
Mar 18 21:27:18.584: INFO: Created: latency-svc-5cksz
Mar 18 21:27:18.628: INFO: Got endpoints: latency-svc-zgv9h [751.01247ms]
Mar 18 21:27:18.635: INFO: Created: latency-svc-hqtzl
Mar 18 21:27:18.677: INFO: Got endpoints: latency-svc-fpqf8 [749.375141ms]
Mar 18 21:27:18.684: INFO: Created: latency-svc-d2cbp
Mar 18 21:27:18.727: INFO: Got endpoints: latency-svc-vxzx4 [749.714359ms]
Mar 18 21:27:18.734: INFO: Created: latency-svc-9v5xw
Mar 18 21:27:18.777: INFO: Got endpoints: latency-svc-7s6rg [749.799243ms]
Mar 18 21:27:18.783: INFO: Created: latency-svc-d78h8
Mar 18 21:27:18.827: INFO: Got endpoints: latency-svc-jbsqr [748.655234ms]
Mar 18 21:27:18.834: INFO: Created: latency-svc-h29mp
Mar 18 21:27:18.878: INFO: Got endpoints: latency-svc-rbf8s [750.845637ms]
Mar 18 21:27:18.885: INFO: Created: latency-svc-44xzj
Mar 18 21:27:18.927: INFO: Got endpoints: latency-svc-rnnzq [750.238247ms]
Mar 18 21:27:18.933: INFO: Created: latency-svc-rswkn
Mar 18 21:27:18.977: INFO: Got endpoints: latency-svc-5bcz8 [749.74679ms]
Mar 18 21:27:18.984: INFO: Created: latency-svc-xfnwm
Mar 18 21:27:19.027: INFO: Got endpoints: latency-svc-nv2bj [749.985239ms]
Mar 18 21:27:19.034: INFO: Created: latency-svc-jsx4b
Mar 18 21:27:19.077: INFO: Got endpoints: latency-svc-72n4d [749.611146ms]
Mar 18 21:27:19.083: INFO: Created: latency-svc-tmz7n
Mar 18 21:27:19.127: INFO: Got endpoints: latency-svc-zpqwt [749.844723ms]
Mar 18 21:27:19.133: INFO: Created: latency-svc-dq44m
Mar 18 21:27:19.178: INFO: Got endpoints: latency-svc-qsmj5 [750.963035ms]
Mar 18 21:27:19.185: INFO: Created: latency-svc-nkv9l
Mar 18 21:27:19.228: INFO: Got endpoints: latency-svc-xr9r6 [750.509568ms]
Mar 18 21:27:19.234: INFO: Created: latency-svc-l7f55
Mar 18 21:27:19.277: INFO: Got endpoints: latency-svc-x7q7n [750.184794ms]
Mar 18 21:27:19.284: INFO: Created: latency-svc-77r6t
Mar 18 21:27:19.327: INFO: Got endpoints: latency-svc-5cksz [749.981824ms]
Mar 18 21:27:19.334: INFO: Created: latency-svc-s2pbp
Mar 18 21:27:19.377: INFO: Got endpoints: latency-svc-hqtzl [748.499656ms]
Mar 18 21:27:19.385: INFO: Created: latency-svc-w42hf
Mar 18 21:27:19.427: INFO: Got endpoints: latency-svc-d2cbp [749.813948ms]
Mar 18 21:27:19.433: INFO: Created: latency-svc-6xp64
Mar 18 21:27:19.478: INFO: Got endpoints: latency-svc-9v5xw [750.03503ms]
Mar 18 21:27:19.484: INFO: Created: latency-svc-m7t4w
Mar 18 21:27:19.528: INFO: Got endpoints: latency-svc-d78h8 [750.162448ms]
Mar 18 21:27:19.534: INFO: Created: latency-svc-v2t2p
Mar 18 21:27:19.577: INFO: Got endpoints: latency-svc-h29mp [750.476418ms]
Mar 18 21:27:19.585: INFO: Created: latency-svc-zbfgf
Mar 18 21:27:19.628: INFO: Got endpoints: latency-svc-44xzj [749.736031ms]
Mar 18 21:27:19.635: INFO: Created: latency-svc-q2zvt
Mar 18 21:27:19.677: INFO: Got endpoints: latency-svc-rswkn [749.902756ms]
Mar 18 21:27:19.684: INFO: Created: latency-svc-ctptt
Mar 18 21:27:19.727: INFO: Got endpoints: latency-svc-xfnwm [749.823491ms]
Mar 18 21:27:19.734: INFO: Created: latency-svc-w4q6j
Mar 18 21:27:19.778: INFO: Got endpoints: latency-svc-jsx4b [750.652302ms]
Mar 18 21:27:19.785: INFO: Created: latency-svc-dvdh7
Mar 18 21:27:19.827: INFO: Got endpoints: latency-svc-tmz7n [749.570872ms]
Mar 18 21:27:19.836: INFO: Created: latency-svc-4nww8
Mar 18 21:27:19.877: INFO: Got endpoints: latency-svc-dq44m [750.335232ms]
Mar 18 21:27:19.884: INFO: Created: latency-svc-xlpgz
Mar 18 21:27:19.928: INFO: Got endpoints: latency-svc-nkv9l [749.892295ms]
Mar 18 21:27:19.934: INFO: Created: latency-svc-s58tk
Mar 18 21:27:19.978: INFO: Got endpoints: latency-svc-l7f55 [749.900915ms]
Mar 18 21:27:19.985: INFO: Created: latency-svc-l5q5x
Mar 18 21:27:20.028: INFO: Got endpoints: latency-svc-77r6t [750.128412ms]
Mar 18 21:27:20.036: INFO: Created: latency-svc-glw22
Mar 18 21:27:20.078: INFO: Got endpoints: latency-svc-s2pbp [750.446985ms]
Mar 18 21:27:20.084: INFO: Created: latency-svc-swlk9
Mar 18 21:27:20.127: INFO: Got endpoints: latency-svc-w42hf [750.043066ms]
Mar 18 21:27:20.134: INFO: Created: latency-svc-nstlc
Mar 18 21:27:20.178: INFO: Got endpoints: latency-svc-6xp64 [750.538419ms]
Mar 18 21:27:20.187: INFO: Created: latency-svc-4v4nf
Mar 18 21:27:20.228: INFO: Got endpoints: latency-svc-m7t4w [750.199098ms]
Mar 18 21:27:20.236: INFO: Created: latency-svc-wbkqf
Mar 18 21:27:20.278: INFO: Got endpoints: latency-svc-v2t2p [750.67883ms]
Mar 18 21:27:20.285: INFO: Created: latency-svc-2plpc
Mar 18 21:27:20.327: INFO: Got endpoints: latency-svc-zbfgf [749.9404ms]
Mar 18 21:27:20.334: INFO: Created: latency-svc-h4bn2
Mar 18 21:27:20.377: INFO: Got endpoints: latency-svc-q2zvt [749.52356ms]
Mar 18 21:27:20.384: INFO: Created: latency-svc-dc7bv
Mar 18 21:27:20.428: INFO: Got endpoints: latency-svc-ctptt [750.385484ms]
Mar 18 21:27:20.434: INFO: Created: latency-svc-bpd27
Mar 18 21:27:20.477: INFO: Got endpoints: latency-svc-w4q6j [750.338096ms]
Mar 18 21:27:20.484: INFO: Created: latency-svc-62mmk
Mar 18 21:27:20.527: INFO: Got endpoints: latency-svc-dvdh7 [749.344267ms]
Mar 18 21:27:20.535: INFO: Created: latency-svc-mdgvj
Mar 18 21:27:20.577: INFO: Got endpoints: latency-svc-4nww8 [750.39497ms]
Mar 18 21:27:20.583: INFO: Created: latency-svc-f5stz
Mar 18 21:27:20.627: INFO: Got endpoints: latency-svc-xlpgz [749.698529ms]
Mar 18 21:27:20.634: INFO: Created: latency-svc-2f8b6
Mar 18 21:27:20.677: INFO: Got endpoints: latency-svc-s58tk [749.450912ms]
Mar 18 21:27:20.684: INFO: Created: latency-svc-9brkx
Mar 18 21:27:20.727: INFO: Got endpoints: latency-svc-l5q5x [749.416533ms]
Mar 18 21:27:20.734: INFO: Created: latency-svc-smh7q
Mar 18 21:27:20.777: INFO: Got endpoints: latency-svc-glw22 [749.479642ms]
Mar 18 21:27:20.785: INFO: Created: latency-svc-q6m2p
Mar 18 21:27:20.828: INFO: Got endpoints: latency-svc-swlk9 [749.745607ms]
Mar 18 21:27:20.834: INFO: Created: latency-svc-qcdk4
Mar 18 21:27:20.877: INFO: Got endpoints: latency-svc-nstlc [749.904203ms]
Mar 18 21:27:20.884: INFO: Created: latency-svc-xrgfv
Mar 18 21:27:20.927: INFO: Got endpoints: latency-svc-4v4nf [749.503999ms]
Mar 18 21:27:20.934: INFO: Created: latency-svc-nxnrb
Mar 18 21:27:20.977: INFO: Got endpoints: latency-svc-wbkqf [749.672408ms]
Mar 18 21:27:20.987: INFO: Created: latency-svc-6nfwb
Mar 18 21:27:21.028: INFO: Got endpoints: latency-svc-2plpc [749.560438ms]
Mar 18 21:27:21.034: INFO: Created: latency-svc-w4mcf
Mar 18 21:27:21.077: INFO: Got endpoints: latency-svc-h4bn2 [750.053627ms]
Mar 18 21:27:21.084: INFO: Created: latency-svc-4srnr
Mar 18 21:27:21.128: INFO: Got endpoints: latency-svc-dc7bv [750.978112ms]
Mar 18 21:27:21.136: INFO: Created: latency-svc-kzwd8
Mar 18 21:27:21.177: INFO: Got endpoints: latency-svc-bpd27 [749.699478ms]
Mar 18 21:27:21.185: INFO: Created: latency-svc-mpcqw
Mar 18 21:27:21.229: INFO: Got endpoints: latency-svc-62mmk [751.354725ms]
Mar 18 21:27:21.235: INFO: Created: latency-svc-66w58
Mar 18 21:27:21.278: INFO: Got endpoints: latency-svc-mdgvj [750.730857ms]
Mar 18 21:27:21.285: INFO: Created: latency-svc-hqjv7
Mar 18 21:27:21.328: INFO: Got endpoints: latency-svc-f5stz [750.241436ms]
Mar 18 21:27:21.334: INFO: Created: latency-svc-5hspf
Mar 18 21:27:21.378: INFO: Got endpoints: latency-svc-2f8b6 [751.007672ms]
Mar 18 21:27:21.385: INFO: Created: latency-svc-86wp9
Mar 18 21:27:21.427: INFO: Got endpoints: latency-svc-9brkx [749.669117ms]
Mar 18 21:27:21.434: INFO: Created: latency-svc-v4fq2
Mar 18 21:27:21.477: INFO: Got endpoints: latency-svc-smh7q [749.440605ms]
Mar 18 21:27:21.482: INFO: Created: latency-svc-ljbxg
Mar 18 21:27:21.527: INFO: Got endpoints: latency-svc-q6m2p [749.928347ms]
Mar 18 21:27:21.534: INFO: Created: latency-svc-vjl2r
Mar 18 21:27:21.578: INFO: Got endpoints: latency-svc-qcdk4 [749.807961ms]
Mar 18 21:27:21.584: INFO: Created: latency-svc-fvq2b
Mar 18 21:27:21.628: INFO: Got endpoints: latency-svc-xrgfv [750.453385ms]
Mar 18 21:27:21.635: INFO: Created: latency-svc-kwmdm
Mar 18 21:27:21.677: INFO: Got endpoints: latency-svc-nxnrb [749.602263ms]
Mar 18 21:27:21.684: INFO: Created: latency-svc-qv6k6
Mar 18 21:27:21.728: INFO: Got endpoints: latency-svc-6nfwb [750.236455ms]
Mar 18 21:27:21.735: INFO: Created: latency-svc-wstpl
Mar 18 21:27:21.778: INFO: Got endpoints: latency-svc-w4mcf [749.673261ms]
Mar 18 21:27:21.784: INFO: Created: latency-svc-5pb8d
Mar 18 21:27:21.828: INFO: Got endpoints: latency-svc-4srnr [750.078446ms]
Mar 18 21:27:21.835: INFO: Created: latency-svc-gjr22
Mar 18 21:27:21.878: INFO: Got endpoints: latency-svc-kzwd8 [749.776446ms]
Mar 18 21:27:21.886: INFO: Created: latency-svc-ps86s
Mar 18 21:27:21.928: INFO: Got endpoints: latency-svc-mpcqw [750.782855ms]
Mar 18 21:27:21.936: INFO: Created: latency-svc-hn445
Mar 18 21:27:21.978: INFO: Got endpoints: latency-svc-66w58 [749.194531ms]
Mar 18 21:27:21.987: INFO: Created: latency-svc-nlwhs
Mar 18 21:27:22.029: INFO: Got endpoints: latency-svc-hqjv7 [751.153512ms]
Mar 18 21:27:22.036: INFO: Created: latency-svc-bz8hn
Mar 18 21:27:22.078: INFO: Got endpoints: latency-svc-5hspf [750.549816ms]
Mar 18 21:27:22.085: INFO: Created: latency-svc-s2j7v
Mar 18 21:27:22.128: INFO: Got endpoints: latency-svc-86wp9 [750.152877ms]
Mar 18 21:27:22.137: INFO: Created: latency-svc-4vk8g
Mar 18 21:27:22.177: INFO: Got endpoints: latency-svc-v4fq2 [750.162928ms]
Mar 18 21:27:22.184: INFO: Created: latency-svc-pdnhj
Mar 18 21:27:22.228: INFO: Got endpoints: latency-svc-ljbxg [751.056679ms]
Mar 18 21:27:22.234: INFO: Created: latency-svc-kjbsh
Mar 18 21:27:22.278: INFO: Got endpoints: latency-svc-vjl2r [750.426907ms]
Mar 18 21:27:22.285: INFO: Created: latency-svc-wpjjg
Mar 18 21:27:22.327: INFO: Got endpoints: latency-svc-fvq2b [749.822403ms]
Mar 18 21:27:22.334: INFO: Created: latency-svc-pzxq7
Mar 18 21:27:22.378: INFO: Got endpoints: latency-svc-kwmdm [750.146185ms]
Mar 18 21:27:22.385: INFO: Created: latency-svc-qkksz
Mar 18 21:27:22.427: INFO: Got endpoints: latency-svc-qv6k6 [750.536676ms]
Mar 18 21:27:22.433: INFO: Created: latency-svc-2dz72
Mar 18 21:27:22.477: INFO: Got endpoints: latency-svc-wstpl [749.522211ms]
Mar 18 21:27:22.484: INFO: Created: latency-svc-l2whz
Mar 18 21:27:22.530: INFO: Got endpoints: latency-svc-5pb8d [752.536724ms]
Mar 18 21:27:22.538: INFO: Created: latency-svc-8h5jp
Mar 18 21:27:22.577: INFO: Got endpoints: latency-svc-gjr22 [749.682396ms]
Mar 18 21:27:22.584: INFO: Created: latency-svc-7zp4z
Mar 18 21:27:22.627: INFO: Got endpoints: latency-svc-ps86s [748.73998ms]
Mar 18 21:27:22.635: INFO: Created: latency-svc-xgf8w
Mar 18 21:27:22.677: INFO: Got endpoints: latency-svc-hn445 [749.286019ms]
Mar 18 21:27:22.684: INFO: Created: latency-svc-t4kcl
Mar 18 21:27:22.728: INFO: Got endpoints: latency-svc-nlwhs [749.470117ms]
Mar 18 21:27:22.740: INFO: Created: latency-svc-gz87c
Mar 18 21:27:22.778: INFO: Got endpoints: latency-svc-bz8hn [748.788454ms]
Mar 18 21:27:22.784: INFO: Created: latency-svc-fwv92
Mar 18 21:27:22.828: INFO: Got endpoints: latency-svc-s2j7v [749.944881ms]
Mar 18 21:27:22.835: INFO: Created: latency-svc-4klpm
Mar 18 21:27:22.878: INFO: Got endpoints: latency-svc-4vk8g [749.273221ms]
Mar 18 21:27:22.886: INFO: Created: latency-svc-p9rqg
Mar 18 21:27:22.927: INFO: Got endpoints: latency-svc-pdnhj [749.881749ms]
Mar 18 21:27:22.933: INFO: Created: latency-svc-gx996
Mar 18 21:27:22.978: INFO: Got endpoints: latency-svc-kjbsh [749.827826ms]
Mar 18 21:27:22.985: INFO: Created: latency-svc-smrj8
Mar 18 21:27:23.028: INFO: Got endpoints: latency-svc-wpjjg [750.052206ms]
Mar 18 21:27:23.035: INFO: Created: latency-svc-d9ln8
Mar 18 21:27:23.077: INFO: Got endpoints: latency-svc-pzxq7 [749.614391ms]
Mar 18 21:27:23.085: INFO: Created: latency-svc-4rrvw
Mar 18 21:27:23.127: INFO: Got endpoints: latency-svc-qkksz [749.61491ms]
Mar 18 21:27:23.138: INFO: Created: latency-svc-whhmb
Mar 18 21:27:23.178: INFO: Got endpoints: latency-svc-2dz72 [749.987852ms]
Mar 18 21:27:23.184: INFO: Created: latency-svc-z8gbf
Mar 18 21:27:23.227: INFO: Got endpoints: latency-svc-l2whz [749.828205ms]
Mar 18 21:27:23.234: INFO: Created: latency-svc-kj46h
Mar 18 21:27:23.277: INFO: Got endpoints: latency-svc-8h5jp [747.223789ms]
Mar 18 21:27:23.284: INFO: Created: latency-svc-8vpsd
Mar 18 21:27:23.328: INFO: Got endpoints: latency-svc-7zp4z [750.225525ms]
Mar 18 21:27:23.335: INFO: Created: latency-svc-jtm9v
Mar 18 21:27:23.378: INFO: Got endpoints: latency-svc-xgf8w [750.837977ms]
Mar 18 21:27:23.387: INFO: Created: latency-svc-mpbcq
Mar 18 21:27:23.428: INFO: Got endpoints: latency-svc-t4kcl [750.051188ms]
Mar 18 21:27:23.434: INFO: Created: latency-svc-f4xs4
Mar 18 21:27:23.477: INFO: Got endpoints: latency-svc-gz87c [749.765332ms]
Mar 18 21:27:23.485: INFO: Created: latency-svc-lqtnn
Mar 18 21:27:23.527: INFO: Got endpoints: latency-svc-fwv92 [749.465176ms]
Mar 18 21:27:23.534: INFO: Created: latency-svc-2wljv
Mar 18 21:27:23.577: INFO: Got endpoints: latency-svc-4klpm [749.166609ms]
Mar 18 21:27:23.584: INFO: Created: latency-svc-7j8cm
Mar 18 21:27:23.628: INFO: Got endpoints: latency-svc-p9rqg [750.005838ms]
Mar 18 21:27:23.635: INFO: Created: latency-svc-t9d9m
Mar 18 21:27:23.677: INFO: Got endpoints: latency-svc-gx996 [749.58582ms]
Mar 18 21:27:23.684: INFO: Created: latency-svc-qlz9s
Mar 18 21:27:23.727: INFO: Got endpoints: latency-svc-smrj8 [749.064657ms]
Mar 18 21:27:23.733: INFO: Created: latency-svc-mc24p
Mar 18 21:27:23.778: INFO: Got endpoints: latency-svc-d9ln8 [750.001217ms]
Mar 18 21:27:23.785: INFO: Created: latency-svc-28jtk
Mar 18 21:27:23.827: INFO: Got endpoints: latency-svc-4rrvw [750.184134ms]
Mar 18 21:27:23.833: INFO: Created: latency-svc-b6p5s
Mar 18 21:27:23.877: INFO: Got endpoints: latency-svc-whhmb [749.774681ms]
Mar 18 21:27:23.884: INFO: Created: latency-svc-v52rt
Mar 18 21:27:23.928: INFO: Got endpoints: latency-svc-z8gbf [749.994281ms]
Mar 18 21:27:23.935: INFO: Created: latency-svc-zmf2h
Mar 18 21:27:23.977: INFO: Got endpoints: latency-svc-kj46h [749.614714ms]
Mar 18 21:27:23.984: INFO: Created: latency-svc-64zbb
Mar 18 21:27:24.028: INFO: Got endpoints: latency-svc-8vpsd [750.245889ms]
Mar 18 21:27:24.034: INFO: Created: latency-svc-xs5sr
Mar 18 21:27:24.078: INFO: Got endpoints: latency-svc-jtm9v [750.018582ms]
Mar 18 21:27:24.085: INFO: Created: latency-svc-c8gjz
Mar 18 21:27:24.128: INFO: Got endpoints: latency-svc-mpbcq [749.876545ms]
Mar 18 21:27:24.135: INFO: Created: latency-svc-8r4gs
Mar 18 21:27:24.178: INFO: Got endpoints: latency-svc-f4xs4 [750.317628ms]
Mar 18 21:27:24.185: INFO: Created: latency-svc-tcvt9
Mar 18 21:27:24.227: INFO: Got endpoints: latency-svc-lqtnn [749.925444ms]
Mar 18 21:27:24.233: INFO: Created: latency-svc-bzggr
Mar 18 21:27:24.277: INFO: Got endpoints: latency-svc-2wljv [749.861651ms]
Mar 18 21:27:24.285: INFO: Created: latency-svc-c9f8p
Mar 18 21:27:24.328: INFO: Got endpoints: latency-svc-7j8cm [750.470892ms]
Mar 18 21:27:24.334: INFO: Created: latency-svc-n7b6l
Mar 18 21:27:24.378: INFO: Got endpoints: latency-svc-t9d9m [750.131057ms]
Mar 18 21:27:24.384: INFO: Created: latency-svc-wgt2q
Mar 18 21:27:24.427: INFO: Got endpoints: latency-svc-qlz9s [750.101689ms]
Mar 18 21:27:24.434: INFO: Created: latency-svc-ks6ls
Mar 18 21:27:24.478: INFO: Got endpoints: latency-svc-mc24p [750.668445ms]
Mar 18 21:27:24.485: INFO: Created: latency-svc-wlh65
Mar 18 21:27:24.527: INFO: Got endpoints: latency-svc-28jtk [749.554173ms]
Mar 18 21:27:24.535: INFO: Created: latency-svc-gfbvr
Mar 18 21:27:24.579: INFO: Got endpoints: latency-svc-b6p5s [751.615066ms]
Mar 18 21:27:24.591: INFO: Created: latency-svc-22crw
Mar 18 21:27:24.627: INFO: Got endpoints: latency-svc-v52rt [749.633804ms]
Mar 18 21:27:24.636: INFO: Created: latency-svc-bjltw
Mar 18 21:27:24.677: INFO: Got endpoints: latency-svc-zmf2h [749.82842ms]
Mar 18 21:27:24.685: INFO: Created: latency-svc-5dkb4
Mar 18 21:27:24.727: INFO: Got endpoints: latency-svc-64zbb [749.992023ms]
Mar 18 21:27:24.735: INFO: Created: latency-svc-h8zmw
Mar 18 21:27:24.777: INFO: Got endpoints: latency-svc-xs5sr [749.389519ms]
Mar 18 21:27:24.785: INFO: Created: latency-svc-5v9zj
Mar 18 21:27:24.827: INFO: Got endpoints: latency-svc-c8gjz [749.496542ms]
Mar 18 21:27:24.835: INFO: Created: latency-svc-qfzlf
Mar 18 21:27:24.878: INFO: Got endpoints: latency-svc-8r4gs [750.256046ms]
Mar 18 21:27:24.885: INFO: Created: latency-svc-4fmng
Mar 18 21:27:24.928: INFO: Got endpoints: latency-svc-tcvt9 [749.677294ms]
Mar 18 21:27:24.934: INFO: Created: latency-svc-6wf2m
Mar 18 21:27:24.978: INFO: Got endpoints: latency-svc-bzggr [750.190464ms]
Mar 18 21:27:24.985: INFO: Created: latency-svc-v77nv
Mar 18 21:27:25.028: INFO: Got endpoints: latency-svc-c9f8p [750.512225ms]
Mar 18 21:27:25.078: INFO: Got endpoints: latency-svc-n7b6l [749.756095ms]
Mar 18 21:27:25.128: INFO: Got endpoints: latency-svc-wgt2q [749.924724ms]
Mar 18 21:27:25.177: INFO: Got endpoints: latency-svc-ks6ls [750.209853ms]
Mar 18 21:27:25.227: INFO: Got endpoints: latency-svc-wlh65 [749.310235ms]
Mar 18 21:27:25.277: INFO: Got endpoints: latency-svc-gfbvr [749.915976ms]
Mar 18 21:27:25.329: INFO: Got endpoints: latency-svc-22crw [750.00923ms]
Mar 18 21:27:25.378: INFO: Got endpoints: latency-svc-bjltw [750.970251ms]
Mar 18 21:27:25.429: INFO: Got endpoints: latency-svc-5dkb4 [751.537827ms]
Mar 18 21:27:25.477: INFO: Got endpoints: latency-svc-h8zmw [750.126631ms]
Mar 18 21:27:25.529: INFO: Got endpoints: latency-svc-5v9zj [751.318287ms]
Mar 18 21:27:25.577: INFO: Got endpoints: latency-svc-qfzlf [749.983964ms]
Mar 18 21:27:25.627: INFO: Got endpoints: latency-svc-4fmng [748.878562ms]
Mar 18 21:27:25.678: INFO: Got endpoints: latency-svc-6wf2m [749.688189ms]
Mar 18 21:27:25.728: INFO: Got endpoints: latency-svc-v77nv [750.368801ms]
Mar 18 21:27:25.728: INFO: Latencies: [23.125761ms 24.342699ms 28.310877ms 39.349776ms 43.185208ms 62.024976ms 62.720944ms 64.260754ms 79.572871ms 80.232464ms 84.845721ms 87.455555ms 92.466373ms 98.574154ms 101.428793ms 104.878573ms 106.467404ms 109.906652ms 111.481135ms 115.186582ms 116.455156ms 117.468596ms 118.771217ms 119.489359ms 121.738425ms 124.000649ms 124.099579ms 128.939108ms 129.931655ms 131.158161ms 135.513728ms 140.857571ms 144.450571ms 148.383311ms 154.756902ms 168.714434ms 204.625555ms 224.90948ms 274.373942ms 320.887235ms 364.760965ms 418.556558ms 450.859328ms 501.025783ms 544.020089ms 588.405222ms 631.622928ms 671.455345ms 717.120291ms 732.983014ms 747.223789ms 747.404153ms 747.956276ms 748.084832ms 748.499656ms 748.655234ms 748.73998ms 748.788454ms 748.878562ms 749.064657ms 749.166609ms 749.194531ms 749.273221ms 749.286019ms 749.310235ms 749.344267ms 749.375141ms 749.389519ms 749.416533ms 749.440605ms 749.450912ms 749.465176ms 749.470117ms 749.479642ms 749.496542ms 749.503999ms 749.522211ms 749.52356ms 749.554173ms 749.560438ms 749.570872ms 749.58582ms 749.602263ms 749.611146ms 749.614391ms 749.614714ms 749.61491ms 749.633804ms 749.669117ms 749.672125ms 749.672408ms 749.673261ms 749.673458ms 749.677294ms 749.682396ms 749.688189ms 749.698529ms 749.699478ms 749.711063ms 749.714359ms 749.736031ms 749.745607ms 749.74679ms 749.756095ms 749.765332ms 749.774681ms 749.776446ms 749.799243ms 749.807961ms 749.813948ms 749.822403ms 749.823491ms 749.827826ms 749.828205ms 749.82842ms 749.844723ms 749.861651ms 749.876545ms 749.881749ms 749.892295ms 749.900915ms 749.902756ms 749.904203ms 749.915976ms 749.924724ms 749.925444ms 749.928347ms 749.9404ms 749.944881ms 749.981824ms 749.983964ms 749.985239ms 749.987852ms 749.992023ms 749.994281ms 750.001217ms 750.005838ms 750.00923ms 750.018582ms 750.03503ms 750.043066ms 750.051188ms 750.052206ms 750.053627ms 750.078446ms 750.101689ms 750.126631ms 750.128412ms 750.131057ms 750.146185ms 750.152877ms 750.162448ms 750.162928ms 750.184134ms 750.184794ms 750.190464ms 750.199098ms 750.209853ms 750.225525ms 750.236455ms 750.238247ms 750.241436ms 750.245889ms 750.256046ms 750.317628ms 750.335232ms 750.338096ms 750.368801ms 750.385484ms 750.39497ms 750.426907ms 750.446985ms 750.453385ms 750.467119ms 750.470892ms 750.476418ms 750.509568ms 750.512225ms 750.536676ms 750.538419ms 750.549816ms 750.652302ms 750.668445ms 750.67883ms 750.730857ms 750.782855ms 750.837977ms 750.845637ms 750.963035ms 750.970251ms 750.978112ms 751.007672ms 751.01247ms 751.056679ms 751.153512ms 751.318287ms 751.354725ms 751.537827ms 751.615066ms 752.536724ms]
Mar 18 21:27:25.728: INFO: 50 %ile: 749.736031ms
Mar 18 21:27:25.728: INFO: 90 %ile: 750.549816ms
Mar 18 21:27:25.728: INFO: 99 %ile: 751.615066ms
Mar 18 21:27:25.728: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:27:25.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-dsrtk" for this suite.
Mar 18 21:27:37.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:27:37.812: INFO: namespace: e2e-tests-svc-latency-dsrtk, resource: bindings, ignored listing per whitelist
Mar 18 21:27:37.833: INFO: namespace e2e-tests-svc-latency-dsrtk deletion completed in 12.101478799s

• [SLOW TEST:22.876 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:27:37.833: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a7316400-49c4-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 21:27:37.902: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a731c3d0-49c4-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-h6cq2" to be "success or failure"
Mar 18 21:27:37.906: INFO: Pod "pod-projected-configmaps-a731c3d0-49c4-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.061452ms
Mar 18 21:27:39.908: INFO: Pod "pod-projected-configmaps-a731c3d0-49c4-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005694586s
STEP: Saw pod success
Mar 18 21:27:39.908: INFO: Pod "pod-projected-configmaps-a731c3d0-49c4-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:27:39.910: INFO: Trying to get logs from node node-1 pod pod-projected-configmaps-a731c3d0-49c4-11e9-9475-02f976e168bb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 21:27:39.930: INFO: Waiting for pod pod-projected-configmaps-a731c3d0-49c4-11e9-9475-02f976e168bb to disappear
Mar 18 21:27:39.941: INFO: Pod pod-projected-configmaps-a731c3d0-49c4-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:27:39.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h6cq2" for this suite.
Mar 18 21:27:45.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:27:46.021: INFO: namespace: e2e-tests-projected-h6cq2, resource: bindings, ignored listing per whitelist
Mar 18 21:27:46.031: INFO: namespace e2e-tests-projected-h6cq2 deletion completed in 6.086532013s

• [SLOW TEST:8.198 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:27:46.031: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-ac138212-49c4-11e9-9475-02f976e168bb
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-ac138212-49c4-11e9-9475-02f976e168bb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:27:50.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7kzl7" for this suite.
Mar 18 21:28:12.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:28:12.186: INFO: namespace: e2e-tests-configmap-7kzl7, resource: bindings, ignored listing per whitelist
Mar 18 21:28:12.224: INFO: namespace e2e-tests-configmap-7kzl7 deletion completed in 22.089032919s

• [SLOW TEST:26.193 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:28:12.224: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-bbb1020d-49c4-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 21:28:12.294: INFO: Waiting up to 5m0s for pod "pod-secrets-bbb1752e-49c4-11e9-9475-02f976e168bb" in namespace "e2e-tests-secrets-mwlqt" to be "success or failure"
Mar 18 21:28:12.296: INFO: Pod "pod-secrets-bbb1752e-49c4-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121834ms
Mar 18 21:28:14.299: INFO: Pod "pod-secrets-bbb1752e-49c4-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005002519s
STEP: Saw pod success
Mar 18 21:28:14.299: INFO: Pod "pod-secrets-bbb1752e-49c4-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:28:14.301: INFO: Trying to get logs from node node-1 pod pod-secrets-bbb1752e-49c4-11e9-9475-02f976e168bb container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 21:28:14.327: INFO: Waiting for pod pod-secrets-bbb1752e-49c4-11e9-9475-02f976e168bb to disappear
Mar 18 21:28:14.331: INFO: Pod pod-secrets-bbb1752e-49c4-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:28:14.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mwlqt" for this suite.
Mar 18 21:28:20.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:28:20.381: INFO: namespace: e2e-tests-secrets-mwlqt, resource: bindings, ignored listing per whitelist
Mar 18 21:28:20.429: INFO: namespace e2e-tests-secrets-mwlqt deletion completed in 6.094667608s

• [SLOW TEST:8.204 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:28:20.429: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-5pdgg
Mar 18 21:28:22.555: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-5pdgg
STEP: checking the pod's current state and verifying that restartCount is present
Mar 18 21:28:22.557: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:32:22.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5pdgg" for this suite.
Mar 18 21:32:28.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:32:29.004: INFO: namespace: e2e-tests-container-probe-5pdgg, resource: bindings, ignored listing per whitelist
Mar 18 21:32:29.036: INFO: namespace e2e-tests-container-probe-5pdgg deletion completed in 6.08732485s

• [SLOW TEST:248.608 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:32:29.037: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-54c268dc-49c5-11e9-9475-02f976e168bb
STEP: Creating secret with name secret-projected-all-test-volume-54c268bf-49c5-11e9-9475-02f976e168bb
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 18 21:32:29.101: INFO: Waiting up to 5m0s for pod "projected-volume-54c26884-49c5-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-nf5ng" to be "success or failure"
Mar 18 21:32:29.108: INFO: Pod "projected-volume-54c26884-49c5-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.60648ms
Mar 18 21:32:31.111: INFO: Pod "projected-volume-54c26884-49c5-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0096154s
STEP: Saw pod success
Mar 18 21:32:31.111: INFO: Pod "projected-volume-54c26884-49c5-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:32:31.114: INFO: Trying to get logs from node node-1 pod projected-volume-54c26884-49c5-11e9-9475-02f976e168bb container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 18 21:32:31.134: INFO: Waiting for pod projected-volume-54c26884-49c5-11e9-9475-02f976e168bb to disappear
Mar 18 21:32:31.141: INFO: Pod projected-volume-54c26884-49c5-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:32:31.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nf5ng" for this suite.
Mar 18 21:32:37.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:32:37.161: INFO: namespace: e2e-tests-projected-nf5ng, resource: bindings, ignored listing per whitelist
Mar 18 21:32:37.233: INFO: namespace e2e-tests-projected-nf5ng deletion completed in 6.087942364s

• [SLOW TEST:8.196 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:32:37.233: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar 18 21:32:37.288: INFO: Waiting up to 5m0s for pod "var-expansion-59a463de-49c5-11e9-9475-02f976e168bb" in namespace "e2e-tests-var-expansion-q6d9n" to be "success or failure"
Mar 18 21:32:37.291: INFO: Pod "var-expansion-59a463de-49c5-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.879137ms
Mar 18 21:32:39.294: INFO: Pod "var-expansion-59a463de-49c5-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005758846s
STEP: Saw pod success
Mar 18 21:32:39.294: INFO: Pod "var-expansion-59a463de-49c5-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:32:39.296: INFO: Trying to get logs from node node-1 pod var-expansion-59a463de-49c5-11e9-9475-02f976e168bb container dapi-container: <nil>
STEP: delete the pod
Mar 18 21:32:39.316: INFO: Waiting for pod var-expansion-59a463de-49c5-11e9-9475-02f976e168bb to disappear
Mar 18 21:32:39.328: INFO: Pod var-expansion-59a463de-49c5-11e9-9475-02f976e168bb no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:32:39.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-q6d9n" for this suite.
Mar 18 21:32:45.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:32:45.402: INFO: namespace: e2e-tests-var-expansion-q6d9n, resource: bindings, ignored listing per whitelist
Mar 18 21:32:45.417: INFO: namespace e2e-tests-var-expansion-q6d9n deletion completed in 6.085843127s

• [SLOW TEST:8.184 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:32:45.417: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 21:32:45.479: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e863d3c-49c5-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-j4njc" to be "success or failure"
Mar 18 21:32:45.482: INFO: Pod "downwardapi-volume-5e863d3c-49c5-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.200295ms
Mar 18 21:32:47.484: INFO: Pod "downwardapi-volume-5e863d3c-49c5-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005019718s
STEP: Saw pod success
Mar 18 21:32:47.484: INFO: Pod "downwardapi-volume-5e863d3c-49c5-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:32:47.486: INFO: Trying to get logs from node node-1 pod downwardapi-volume-5e863d3c-49c5-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 21:32:47.512: INFO: Waiting for pod downwardapi-volume-5e863d3c-49c5-11e9-9475-02f976e168bb to disappear
Mar 18 21:32:47.519: INFO: Pod downwardapi-volume-5e863d3c-49c5-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:32:47.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j4njc" for this suite.
Mar 18 21:32:53.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:32:53.559: INFO: namespace: e2e-tests-downward-api-j4njc, resource: bindings, ignored listing per whitelist
Mar 18 21:32:53.612: INFO: namespace e2e-tests-downward-api-j4njc deletion completed in 6.089369201s

• [SLOW TEST:8.195 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:32:53.612: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6367b7b1-49c5-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 21:32:53.670: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-63681f8a-49c5-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-nzvbp" to be "success or failure"
Mar 18 21:32:53.673: INFO: Pod "pod-projected-configmaps-63681f8a-49c5-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.154381ms
Mar 18 21:32:55.676: INFO: Pod "pod-projected-configmaps-63681f8a-49c5-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005430264s
STEP: Saw pod success
Mar 18 21:32:55.676: INFO: Pod "pod-projected-configmaps-63681f8a-49c5-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:32:55.678: INFO: Trying to get logs from node node-1 pod pod-projected-configmaps-63681f8a-49c5-11e9-9475-02f976e168bb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 21:32:55.700: INFO: Waiting for pod pod-projected-configmaps-63681f8a-49c5-11e9-9475-02f976e168bb to disappear
Mar 18 21:32:55.708: INFO: Pod pod-projected-configmaps-63681f8a-49c5-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:32:55.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nzvbp" for this suite.
Mar 18 21:33:01.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:33:01.751: INFO: namespace: e2e-tests-projected-nzvbp, resource: bindings, ignored listing per whitelist
Mar 18 21:33:01.804: INFO: namespace e2e-tests-projected-nzvbp deletion completed in 6.092031008s

• [SLOW TEST:8.192 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:33:01.805: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-684af60c-49c5-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 21:33:01.873: INFO: Waiting up to 5m0s for pod "pod-configmaps-684b8e4e-49c5-11e9-9475-02f976e168bb" in namespace "e2e-tests-configmap-vtbjp" to be "success or failure"
Mar 18 21:33:01.876: INFO: Pod "pod-configmaps-684b8e4e-49c5-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.196014ms
Mar 18 21:33:03.879: INFO: Pod "pod-configmaps-684b8e4e-49c5-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006523216s
STEP: Saw pod success
Mar 18 21:33:03.879: INFO: Pod "pod-configmaps-684b8e4e-49c5-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:33:03.882: INFO: Trying to get logs from node node-1 pod pod-configmaps-684b8e4e-49c5-11e9-9475-02f976e168bb container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 21:33:03.898: INFO: Waiting for pod pod-configmaps-684b8e4e-49c5-11e9-9475-02f976e168bb to disappear
Mar 18 21:33:03.905: INFO: Pod pod-configmaps-684b8e4e-49c5-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:33:03.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vtbjp" for this suite.
Mar 18 21:33:09.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:33:09.956: INFO: namespace: e2e-tests-configmap-vtbjp, resource: bindings, ignored listing per whitelist
Mar 18 21:33:10.012: INFO: namespace e2e-tests-configmap-vtbjp deletion completed in 6.099452304s

• [SLOW TEST:8.207 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:33:10.012: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 18 21:33:12.596: INFO: Successfully updated pod "annotationupdate6d2e5e15-49c5-11e9-9475-02f976e168bb"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:33:16.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7rmb8" for this suite.
Mar 18 21:33:38.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:33:38.683: INFO: namespace: e2e-tests-projected-7rmb8, resource: bindings, ignored listing per whitelist
Mar 18 21:33:38.719: INFO: namespace e2e-tests-projected-7rmb8 deletion completed in 22.092066245s

• [SLOW TEST:28.707 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:33:38.719: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 21:33:40.802: INFO: Waiting up to 5m0s for pod "client-envvars-7f7fa7db-49c5-11e9-9475-02f976e168bb" in namespace "e2e-tests-pods-wj45l" to be "success or failure"
Mar 18 21:33:40.807: INFO: Pod "client-envvars-7f7fa7db-49c5-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.550944ms
Mar 18 21:33:42.810: INFO: Pod "client-envvars-7f7fa7db-49c5-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007654049s
STEP: Saw pod success
Mar 18 21:33:42.810: INFO: Pod "client-envvars-7f7fa7db-49c5-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:33:42.812: INFO: Trying to get logs from node node-1 pod client-envvars-7f7fa7db-49c5-11e9-9475-02f976e168bb container env3cont: <nil>
STEP: delete the pod
Mar 18 21:33:42.833: INFO: Waiting for pod client-envvars-7f7fa7db-49c5-11e9-9475-02f976e168bb to disappear
Mar 18 21:33:42.842: INFO: Pod client-envvars-7f7fa7db-49c5-11e9-9475-02f976e168bb no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:33:42.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wj45l" for this suite.
Mar 18 21:34:20.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:34:20.902: INFO: namespace: e2e-tests-pods-wj45l, resource: bindings, ignored listing per whitelist
Mar 18 21:34:20.931: INFO: namespace e2e-tests-pods-wj45l deletion completed in 38.084599241s

• [SLOW TEST:42.212 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:34:20.931: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 21:34:21.003: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9775ba24-49c5-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-fr7kl" to be "success or failure"
Mar 18 21:34:21.006: INFO: Pod "downwardapi-volume-9775ba24-49c5-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.762336ms
Mar 18 21:34:23.009: INFO: Pod "downwardapi-volume-9775ba24-49c5-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006824338s
STEP: Saw pod success
Mar 18 21:34:23.009: INFO: Pod "downwardapi-volume-9775ba24-49c5-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:34:23.012: INFO: Trying to get logs from node node-1 pod downwardapi-volume-9775ba24-49c5-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 21:34:23.029: INFO: Waiting for pod downwardapi-volume-9775ba24-49c5-11e9-9475-02f976e168bb to disappear
Mar 18 21:34:23.040: INFO: Pod downwardapi-volume-9775ba24-49c5-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:34:23.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fr7kl" for this suite.
Mar 18 21:34:29.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:34:29.122: INFO: namespace: e2e-tests-downward-api-fr7kl, resource: bindings, ignored listing per whitelist
Mar 18 21:34:29.132: INFO: namespace e2e-tests-downward-api-fr7kl deletion completed in 6.087796015s

• [SLOW TEST:8.201 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:34:29.132: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9c572038-49c5-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 21:34:29.212: INFO: Waiting up to 5m0s for pod "pod-secrets-9c5aa3dd-49c5-11e9-9475-02f976e168bb" in namespace "e2e-tests-secrets-khn7t" to be "success or failure"
Mar 18 21:34:29.215: INFO: Pod "pod-secrets-9c5aa3dd-49c5-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.406437ms
Mar 18 21:34:31.217: INFO: Pod "pod-secrets-9c5aa3dd-49c5-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005141853s
STEP: Saw pod success
Mar 18 21:34:31.217: INFO: Pod "pod-secrets-9c5aa3dd-49c5-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:34:31.220: INFO: Trying to get logs from node node-1 pod pod-secrets-9c5aa3dd-49c5-11e9-9475-02f976e168bb container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 21:34:31.240: INFO: Waiting for pod pod-secrets-9c5aa3dd-49c5-11e9-9475-02f976e168bb to disappear
Mar 18 21:34:31.244: INFO: Pod pod-secrets-9c5aa3dd-49c5-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:34:31.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-khn7t" for this suite.
Mar 18 21:34:37.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:34:37.307: INFO: namespace: e2e-tests-secrets-khn7t, resource: bindings, ignored listing per whitelist
Mar 18 21:34:37.341: INFO: namespace e2e-tests-secrets-khn7t deletion completed in 6.091510485s
STEP: Destroying namespace "e2e-tests-secret-namespace-4g2mp" for this suite.
Mar 18 21:34:43.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:34:43.398: INFO: namespace: e2e-tests-secret-namespace-4g2mp, resource: bindings, ignored listing per whitelist
Mar 18 21:34:43.430: INFO: namespace e2e-tests-secret-namespace-4g2mp deletion completed in 6.088539233s

• [SLOW TEST:14.298 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:34:43.430: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-95xs
STEP: Creating a pod to test atomic-volume-subpath
Mar 18 21:34:43.516: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-95xs" in namespace "e2e-tests-subpath-4z8j5" to be "success or failure"
Mar 18 21:34:43.523: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Pending", Reason="", readiness=false. Elapsed: 7.651997ms
Mar 18 21:34:45.526: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 2.010543543s
Mar 18 21:34:47.529: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 4.013648576s
Mar 18 21:34:49.532: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 6.01663042s
Mar 18 21:34:51.537: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 8.021303528s
Mar 18 21:34:53.540: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 10.024427712s
Mar 18 21:34:55.544: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 12.028537389s
Mar 18 21:34:57.547: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 14.031527348s
Mar 18 21:34:59.552: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 16.036459091s
Mar 18 21:35:01.556: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 18.040287231s
Mar 18 21:35:03.559: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 20.043613812s
Mar 18 21:35:05.563: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Running", Reason="", readiness=false. Elapsed: 22.046823293s
Mar 18 21:35:07.566: INFO: Pod "pod-subpath-test-projected-95xs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.049781671s
STEP: Saw pod success
Mar 18 21:35:07.566: INFO: Pod "pod-subpath-test-projected-95xs" satisfied condition "success or failure"
Mar 18 21:35:07.568: INFO: Trying to get logs from node node-1 pod pod-subpath-test-projected-95xs container test-container-subpath-projected-95xs: <nil>
STEP: delete the pod
Mar 18 21:35:07.599: INFO: Waiting for pod pod-subpath-test-projected-95xs to disappear
Mar 18 21:35:07.611: INFO: Pod pod-subpath-test-projected-95xs no longer exists
STEP: Deleting pod pod-subpath-test-projected-95xs
Mar 18 21:35:07.611: INFO: Deleting pod "pod-subpath-test-projected-95xs" in namespace "e2e-tests-subpath-4z8j5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:35:07.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4z8j5" for this suite.
Mar 18 21:35:13.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:35:13.681: INFO: namespace: e2e-tests-subpath-4z8j5, resource: bindings, ignored listing per whitelist
Mar 18 21:35:13.721: INFO: namespace e2e-tests-subpath-4z8j5 deletion completed in 6.103454044s

• [SLOW TEST:30.291 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:35:13.721: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 18 21:35:13.816: INFO: Number of nodes with available pods: 0
Mar 18 21:35:13.816: INFO: Node node-1 is running more than one daemon pod
Mar 18 21:35:14.823: INFO: Number of nodes with available pods: 2
Mar 18 21:35:14.823: INFO: Node node-2 is running more than one daemon pod
Mar 18 21:35:15.823: INFO: Number of nodes with available pods: 3
Mar 18 21:35:15.823: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 18 21:35:15.850: INFO: Number of nodes with available pods: 2
Mar 18 21:35:15.852: INFO: Node node-3 is running more than one daemon pod
Mar 18 21:35:16.860: INFO: Number of nodes with available pods: 3
Mar 18 21:35:16.860: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2kbrt, will wait for the garbage collector to delete the pods
Mar 18 21:35:16.923: INFO: Deleting DaemonSet.extensions daemon-set took: 5.938848ms
Mar 18 21:35:17.023: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.229616ms
Mar 18 21:35:54.326: INFO: Number of nodes with available pods: 0
Mar 18 21:35:54.326: INFO: Number of running nodes: 0, number of available pods: 0
Mar 18 21:35:54.328: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2kbrt/daemonsets","resourceVersion":"18167"},"items":null}

Mar 18 21:35:54.330: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2kbrt/pods","resourceVersion":"18167"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:35:54.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2kbrt" for this suite.
Mar 18 21:36:00.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:36:00.363: INFO: namespace: e2e-tests-daemonsets-2kbrt, resource: bindings, ignored listing per whitelist
Mar 18 21:36:00.431: INFO: namespace e2e-tests-daemonsets-2kbrt deletion completed in 6.089050769s

• [SLOW TEST:46.710 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:36:00.432: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 18 21:36:00.486: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:36:03.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wzrxs" for this suite.
Mar 18 21:36:09.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:36:09.156: INFO: namespace: e2e-tests-init-container-wzrxs, resource: bindings, ignored listing per whitelist
Mar 18 21:36:09.161: INFO: namespace e2e-tests-init-container-wzrxs deletion completed in 6.096762193s

• [SLOW TEST:8.729 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:36:09.161: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 18 21:36:09.216: INFO: Waiting up to 5m0s for pod "pod-d7f60528-49c5-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-qbqqg" to be "success or failure"
Mar 18 21:36:09.218: INFO: Pod "pod-d7f60528-49c5-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.216889ms
Mar 18 21:36:11.221: INFO: Pod "pod-d7f60528-49c5-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005038769s
STEP: Saw pod success
Mar 18 21:36:11.221: INFO: Pod "pod-d7f60528-49c5-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:36:11.223: INFO: Trying to get logs from node node-1 pod pod-d7f60528-49c5-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 21:36:11.247: INFO: Waiting for pod pod-d7f60528-49c5-11e9-9475-02f976e168bb to disappear
Mar 18 21:36:11.249: INFO: Pod pod-d7f60528-49c5-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:36:11.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qbqqg" for this suite.
Mar 18 21:36:17.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:36:17.283: INFO: namespace: e2e-tests-emptydir-qbqqg, resource: bindings, ignored listing per whitelist
Mar 18 21:36:17.339: INFO: namespace e2e-tests-emptydir-qbqqg deletion completed in 6.086002231s

• [SLOW TEST:8.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:36:17.339: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 18 21:36:17.397: INFO: Waiting up to 5m0s for pod "pod-dcd652c0-49c5-11e9-9475-02f976e168bb" in namespace "e2e-tests-emptydir-gk9mm" to be "success or failure"
Mar 18 21:36:17.399: INFO: Pod "pod-dcd652c0-49c5-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.171124ms
Mar 18 21:36:19.402: INFO: Pod "pod-dcd652c0-49c5-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005193525s
STEP: Saw pod success
Mar 18 21:36:19.402: INFO: Pod "pod-dcd652c0-49c5-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:36:19.404: INFO: Trying to get logs from node node-1 pod pod-dcd652c0-49c5-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 21:36:19.425: INFO: Waiting for pod pod-dcd652c0-49c5-11e9-9475-02f976e168bb to disappear
Mar 18 21:36:19.437: INFO: Pod pod-dcd652c0-49c5-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:36:19.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gk9mm" for this suite.
Mar 18 21:36:25.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:36:25.508: INFO: namespace: e2e-tests-emptydir-gk9mm, resource: bindings, ignored listing per whitelist
Mar 18 21:36:25.539: INFO: namespace e2e-tests-emptydir-gk9mm deletion completed in 6.097286993s

• [SLOW TEST:8.200 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:36:25.540: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 21:36:25.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-b6b26'
Mar 18 21:36:25.853: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 18 21:36:25.853: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar 18 21:36:25.864: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-gjntd]
Mar 18 21:36:25.864: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-gjntd" in namespace "e2e-tests-kubectl-b6b26" to be "running and ready"
Mar 18 21:36:25.874: INFO: Pod "e2e-test-nginx-rc-gjntd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.396486ms
Mar 18 21:36:27.877: INFO: Pod "e2e-test-nginx-rc-gjntd": Phase="Running", Reason="", readiness=true. Elapsed: 2.012418539s
Mar 18 21:36:27.877: INFO: Pod "e2e-test-nginx-rc-gjntd" satisfied condition "running and ready"
Mar 18 21:36:27.877: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-gjntd]
Mar 18 21:36:27.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-b6b26'
Mar 18 21:36:27.957: INFO: stderr: ""
Mar 18 21:36:27.957: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Mar 18 21:36:27.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-b6b26'
Mar 18 21:36:28.027: INFO: stderr: ""
Mar 18 21:36:28.027: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:36:28.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b6b26" for this suite.
Mar 18 21:36:34.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:36:34.051: INFO: namespace: e2e-tests-kubectl-b6b26, resource: bindings, ignored listing per whitelist
Mar 18 21:36:34.117: INFO: namespace e2e-tests-kubectl-b6b26 deletion completed in 6.085951599s

• [SLOW TEST:8.578 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:36:34.118: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Mar 18 21:36:36.225: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:37:00.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-z2nt6" for this suite.
Mar 18 21:37:06.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:37:06.358: INFO: namespace: e2e-tests-namespaces-z2nt6, resource: bindings, ignored listing per whitelist
Mar 18 21:37:06.360: INFO: namespace e2e-tests-namespaces-z2nt6 deletion completed in 6.095100541s
STEP: Destroying namespace "e2e-tests-nsdeletetest-hqm99" for this suite.
Mar 18 21:37:06.362: INFO: Namespace e2e-tests-nsdeletetest-hqm99 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-rshth" for this suite.
Mar 18 21:37:12.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:37:12.408: INFO: namespace: e2e-tests-nsdeletetest-rshth, resource: bindings, ignored listing per whitelist
Mar 18 21:37:12.455: INFO: namespace e2e-tests-nsdeletetest-rshth deletion completed in 6.092582505s

• [SLOW TEST:38.337 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:37:12.455: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-fdb27bf0-49c5-11e9-9475-02f976e168bb
STEP: Creating configMap with name cm-test-opt-upd-fdb27c2d-49c5-11e9-9475-02f976e168bb
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fdb27bf0-49c5-11e9-9475-02f976e168bb
STEP: Updating configmap cm-test-opt-upd-fdb27c2d-49c5-11e9-9475-02f976e168bb
STEP: Creating configMap with name cm-test-opt-create-fdb27c49-49c5-11e9-9475-02f976e168bb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:37:16.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jqght" for this suite.
Mar 18 21:37:38.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:37:38.635: INFO: namespace: e2e-tests-configmap-jqght, resource: bindings, ignored listing per whitelist
Mar 18 21:37:38.695: INFO: namespace e2e-tests-configmap-jqght deletion completed in 22.088048654s

• [SLOW TEST:26.240 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:37:38.695: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-8s5xk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8s5xk to expose endpoints map[]
Mar 18 21:37:38.763: INFO: Get endpoints failed (4.871481ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar 18 21:37:39.766: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8s5xk exposes endpoints map[] (1.007713269s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-8s5xk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8s5xk to expose endpoints map[pod1:[100]]
Mar 18 21:37:41.789: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8s5xk exposes endpoints map[pod1:[100]] (2.018658755s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-8s5xk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8s5xk to expose endpoints map[pod1:[100] pod2:[101]]
Mar 18 21:37:43.820: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8s5xk exposes endpoints map[pod1:[100] pod2:[101]] (2.027821411s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-8s5xk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8s5xk to expose endpoints map[pod2:[101]]
Mar 18 21:37:44.843: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8s5xk exposes endpoints map[pod2:[101]] (1.018993978s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-8s5xk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8s5xk to expose endpoints map[]
Mar 18 21:37:45.857: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8s5xk exposes endpoints map[] (1.005652262s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:37:45.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-8s5xk" for this suite.
Mar 18 21:38:07.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:38:07.936: INFO: namespace: e2e-tests-services-8s5xk, resource: bindings, ignored listing per whitelist
Mar 18 21:38:07.970: INFO: namespace e2e-tests-services-8s5xk deletion completed in 22.089281758s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.275 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:38:07.970: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 18 21:38:10.555: INFO: Successfully updated pod "labelsupdate1ec7cc37-49c6-11e9-9475-02f976e168bb"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:38:14.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wftkx" for this suite.
Mar 18 21:38:36.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:38:36.654: INFO: namespace: e2e-tests-projected-wftkx, resource: bindings, ignored listing per whitelist
Mar 18 21:38:36.666: INFO: namespace e2e-tests-projected-wftkx deletion completed in 22.087075309s

• [SLOW TEST:28.696 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:38:36.666: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-2fe2d7a5-49c6-11e9-9475-02f976e168bb
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:38:38.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-klhf6" for this suite.
Mar 18 21:39:00.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:39:00.792: INFO: namespace: e2e-tests-configmap-klhf6, resource: bindings, ignored listing per whitelist
Mar 18 21:39:00.845: INFO: namespace e2e-tests-configmap-klhf6 deletion completed in 22.088883s

• [SLOW TEST:24.179 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:39:00.846: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4thhg A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-4thhg;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4thhg A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-4thhg;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4thhg.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-4thhg.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4thhg.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-4thhg.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4thhg.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-4thhg.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4thhg.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-4thhg.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-4thhg.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 253.230.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.230.253_udp@PTR;check="$$(dig +tcp +noall +answer +search 253.230.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.230.253_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4thhg A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-4thhg;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4thhg A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-4thhg;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-4thhg.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-4thhg.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-4thhg.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-4thhg.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4thhg.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-4thhg.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-4thhg.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-4thhg.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-4thhg.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 253.230.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.230.253_udp@PTR;check="$$(dig +tcp +noall +answer +search 253.230.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.230.253_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 18 21:39:02.938: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.941: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.943: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-4thhg from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.946: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-4thhg from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.948: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-4thhg.svc from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.951: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-4thhg.svc from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.953: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.955: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.975: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.978: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.980: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-4thhg from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.983: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-4thhg from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.985: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-4thhg.svc from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.988: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-4thhg.svc from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.990: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:02.992: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc from pod e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb: the server could not find the requested resource (get pods dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb)
Mar 18 21:39:03.009: INFO: Lookups using e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-4thhg wheezy_tcp@dns-test-service.e2e-tests-dns-4thhg wheezy_udp@dns-test-service.e2e-tests-dns-4thhg.svc wheezy_tcp@dns-test-service.e2e-tests-dns-4thhg.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-4thhg jessie_tcp@dns-test-service.e2e-tests-dns-4thhg jessie_udp@dns-test-service.e2e-tests-dns-4thhg.svc jessie_tcp@dns-test-service.e2e-tests-dns-4thhg.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-4thhg.svc]

Mar 18 21:39:08.088: INFO: DNS probes using e2e-tests-dns-4thhg/dns-test-3e4dc380-49c6-11e9-9475-02f976e168bb succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:39:08.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-4thhg" for this suite.
Mar 18 21:39:14.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:39:14.244: INFO: namespace: e2e-tests-dns-4thhg, resource: bindings, ignored listing per whitelist
Mar 18 21:39:14.280: INFO: namespace e2e-tests-dns-4thhg deletion completed in 6.092888417s

• [SLOW TEST:13.435 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:39:14.280: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-bzvg
STEP: Creating a pod to test atomic-volume-subpath
Mar 18 21:39:14.351: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bzvg" in namespace "e2e-tests-subpath-fbtx5" to be "success or failure"
Mar 18 21:39:14.355: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Pending", Reason="", readiness=false. Elapsed: 3.399275ms
Mar 18 21:39:16.358: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006524568s
Mar 18 21:39:18.361: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Running", Reason="", readiness=false. Elapsed: 4.009512692s
Mar 18 21:39:20.364: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Running", Reason="", readiness=false. Elapsed: 6.012410558s
Mar 18 21:39:22.366: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Running", Reason="", readiness=false. Elapsed: 8.015281971s
Mar 18 21:39:24.369: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Running", Reason="", readiness=false. Elapsed: 10.018085908s
Mar 18 21:39:26.372: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Running", Reason="", readiness=false. Elapsed: 12.021084127s
Mar 18 21:39:28.375: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Running", Reason="", readiness=false. Elapsed: 14.02399164s
Mar 18 21:39:30.378: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Running", Reason="", readiness=false. Elapsed: 16.026999447s
Mar 18 21:39:32.381: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Running", Reason="", readiness=false. Elapsed: 18.030221777s
Mar 18 21:39:34.384: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Running", Reason="", readiness=false. Elapsed: 20.033211844s
Mar 18 21:39:36.387: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Running", Reason="", readiness=false. Elapsed: 22.035736934s
Mar 18 21:39:38.390: INFO: Pod "pod-subpath-test-configmap-bzvg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.038959278s
STEP: Saw pod success
Mar 18 21:39:38.390: INFO: Pod "pod-subpath-test-configmap-bzvg" satisfied condition "success or failure"
Mar 18 21:39:38.392: INFO: Trying to get logs from node node-1 pod pod-subpath-test-configmap-bzvg container test-container-subpath-configmap-bzvg: <nil>
STEP: delete the pod
Mar 18 21:39:38.410: INFO: Waiting for pod pod-subpath-test-configmap-bzvg to disappear
Mar 18 21:39:38.420: INFO: Pod pod-subpath-test-configmap-bzvg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-bzvg
Mar 18 21:39:38.421: INFO: Deleting pod "pod-subpath-test-configmap-bzvg" in namespace "e2e-tests-subpath-fbtx5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:39:38.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-fbtx5" for this suite.
Mar 18 21:39:44.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:39:44.470: INFO: namespace: e2e-tests-subpath-fbtx5, resource: bindings, ignored listing per whitelist
Mar 18 21:39:44.510: INFO: namespace e2e-tests-subpath-fbtx5 deletion completed in 6.083730383s

• [SLOW TEST:30.229 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:39:44.510: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-b7j54
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-b7j54
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-b7j54
Mar 18 21:39:44.595: INFO: Found 0 stateful pods, waiting for 1
Mar 18 21:39:54.598: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 18 21:39:54.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-b7j54 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 21:39:54.744: INFO: stderr: ""
Mar 18 21:39:54.744: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 21:39:54.744: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 21:39:54.747: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 18 21:40:04.751: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 21:40:04.751: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 21:40:04.763: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 18 21:40:04.763: INFO: ss-0  node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:39:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:39:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:39:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:39:44 +0000 UTC  }]
Mar 18 21:40:04.763: INFO: 
Mar 18 21:40:04.763: INFO: StatefulSet ss has not reached scale 3, at 1
Mar 18 21:40:05.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997167236s
Mar 18 21:40:06.771: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993683197s
Mar 18 21:40:07.774: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989632743s
Mar 18 21:40:08.777: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986071722s
Mar 18 21:40:09.781: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982715419s
Mar 18 21:40:10.784: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97935074s
Mar 18 21:40:11.788: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.976058926s
Mar 18 21:40:12.791: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.972610047s
Mar 18 21:40:13.795: INFO: Verifying statefulset ss doesn't scale past 3 for another 968.845913ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-b7j54
Mar 18 21:40:14.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-b7j54 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 21:40:14.928: INFO: stderr: ""
Mar 18 21:40:14.928: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 21:40:14.928: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 21:40:14.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-b7j54 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 21:40:15.056: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 18 21:40:15.056: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 21:40:15.056: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 21:40:15.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-b7j54 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 21:40:15.185: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 18 21:40:15.185: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 21:40:15.185: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 21:40:15.188: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Mar 18 21:40:25.192: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 21:40:25.192: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 21:40:25.192: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 18 21:40:25.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-b7j54 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 21:40:25.317: INFO: stderr: ""
Mar 18 21:40:25.317: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 21:40:25.317: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 21:40:25.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-b7j54 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 21:40:25.442: INFO: stderr: ""
Mar 18 21:40:25.442: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 21:40:25.442: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 21:40:25.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 exec --namespace=e2e-tests-statefulset-b7j54 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 21:40:25.574: INFO: stderr: ""
Mar 18 21:40:25.574: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 21:40:25.574: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 21:40:25.574: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 21:40:25.577: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 18 21:40:35.583: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 21:40:35.583: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 21:40:35.583: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 21:40:35.591: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 18 21:40:35.591: INFO: ss-0  node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:39:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:39:44 +0000 UTC  }]
Mar 18 21:40:35.591: INFO: ss-1  node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:35.591: INFO: ss-2  node-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:35.591: INFO: 
Mar 18 21:40:35.591: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 18 21:40:36.595: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 18 21:40:36.595: INFO: ss-0  node-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:39:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:39:44 +0000 UTC  }]
Mar 18 21:40:36.595: INFO: ss-1  node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:36.595: INFO: ss-2  node-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:36.595: INFO: 
Mar 18 21:40:36.595: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 18 21:40:37.599: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 18 21:40:37.599: INFO: ss-1  node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:37.599: INFO: 
Mar 18 21:40:37.599: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 18 21:40:38.602: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 18 21:40:38.602: INFO: ss-1  node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:38.602: INFO: 
Mar 18 21:40:38.602: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 18 21:40:39.605: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 18 21:40:39.605: INFO: ss-1  node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:39.605: INFO: 
Mar 18 21:40:39.605: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 18 21:40:40.609: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 18 21:40:40.609: INFO: ss-1  node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:40.609: INFO: 
Mar 18 21:40:40.609: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 18 21:40:41.612: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 18 21:40:41.612: INFO: ss-1  node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:41.612: INFO: 
Mar 18 21:40:41.612: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 18 21:40:42.615: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 18 21:40:42.615: INFO: ss-1  node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:42.616: INFO: 
Mar 18 21:40:42.616: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 18 21:40:43.619: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 18 21:40:43.619: INFO: ss-1  node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 21:40:04 +0000 UTC  }]
Mar 18 21:40:43.619: INFO: 
Mar 18 21:40:43.619: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 18 21:40:44.622: INFO: Verifying statefulset ss doesn't scale past 0 for another 969.14131ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-b7j54
Mar 18 21:40:45.625: INFO: Scaling statefulset ss to 0
Mar 18 21:40:45.632: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 18 21:40:45.634: INFO: Deleting all statefulset in ns e2e-tests-statefulset-b7j54
Mar 18 21:40:45.636: INFO: Scaling statefulset ss to 0
Mar 18 21:40:45.643: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 21:40:45.645: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:40:45.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-b7j54" for this suite.
Mar 18 21:40:51.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:40:51.734: INFO: namespace: e2e-tests-statefulset-b7j54, resource: bindings, ignored listing per whitelist
Mar 18 21:40:51.749: INFO: namespace e2e-tests-statefulset-b7j54 deletion completed in 6.087334595s

• [SLOW TEST:67.239 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:40:51.749: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 21:40:51.814: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8066aa32-49c6-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-cg7rq" to be "success or failure"
Mar 18 21:40:51.828: INFO: Pod "downwardapi-volume-8066aa32-49c6-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 13.999058ms
Mar 18 21:40:53.831: INFO: Pod "downwardapi-volume-8066aa32-49c6-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017404195s
STEP: Saw pod success
Mar 18 21:40:53.831: INFO: Pod "downwardapi-volume-8066aa32-49c6-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:40:53.833: INFO: Trying to get logs from node node-1 pod downwardapi-volume-8066aa32-49c6-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 21:40:53.861: INFO: Waiting for pod downwardapi-volume-8066aa32-49c6-11e9-9475-02f976e168bb to disappear
Mar 18 21:40:53.870: INFO: Pod downwardapi-volume-8066aa32-49c6-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:40:53.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cg7rq" for this suite.
Mar 18 21:40:59.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:40:59.924: INFO: namespace: e2e-tests-downward-api-cg7rq, resource: bindings, ignored listing per whitelist
Mar 18 21:40:59.969: INFO: namespace e2e-tests-downward-api-cg7rq deletion completed in 6.09459636s

• [SLOW TEST:8.220 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:40:59.970: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 21:41:00.041: INFO: Waiting up to 5m0s for pod "downwardapi-volume-854dfca6-49c6-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-96gdn" to be "success or failure"
Mar 18 21:41:00.046: INFO: Pod "downwardapi-volume-854dfca6-49c6-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.966381ms
Mar 18 21:41:02.049: INFO: Pod "downwardapi-volume-854dfca6-49c6-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008128029s
STEP: Saw pod success
Mar 18 21:41:02.049: INFO: Pod "downwardapi-volume-854dfca6-49c6-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:41:02.052: INFO: Trying to get logs from node node-1 pod downwardapi-volume-854dfca6-49c6-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 21:41:02.073: INFO: Waiting for pod downwardapi-volume-854dfca6-49c6-11e9-9475-02f976e168bb to disappear
Mar 18 21:41:02.076: INFO: Pod downwardapi-volume-854dfca6-49c6-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:41:02.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-96gdn" for this suite.
Mar 18 21:41:08.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:41:08.145: INFO: namespace: e2e-tests-projected-96gdn, resource: bindings, ignored listing per whitelist
Mar 18 21:41:08.180: INFO: namespace e2e-tests-projected-96gdn deletion completed in 6.093416946s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:41:08.180: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0318 21:41:38.765915      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 21:41:38.765: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:41:38.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-n6wjp" for this suite.
Mar 18 21:41:44.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:41:44.793: INFO: namespace: e2e-tests-gc-n6wjp, resource: bindings, ignored listing per whitelist
Mar 18 21:41:44.856: INFO: namespace e2e-tests-gc-n6wjp deletion completed in 6.087293708s

• [SLOW TEST:36.675 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:41:44.856: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar 18 21:41:44.917: INFO: Waiting up to 5m0s for pod "client-containers-a00ddd4b-49c6-11e9-9475-02f976e168bb" in namespace "e2e-tests-containers-2jbhq" to be "success or failure"
Mar 18 21:41:44.920: INFO: Pod "client-containers-a00ddd4b-49c6-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.901934ms
Mar 18 21:41:46.923: INFO: Pod "client-containers-a00ddd4b-49c6-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005904788s
STEP: Saw pod success
Mar 18 21:41:46.923: INFO: Pod "client-containers-a00ddd4b-49c6-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:41:46.925: INFO: Trying to get logs from node node-1 pod client-containers-a00ddd4b-49c6-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 21:41:46.941: INFO: Waiting for pod client-containers-a00ddd4b-49c6-11e9-9475-02f976e168bb to disappear
Mar 18 21:41:46.950: INFO: Pod client-containers-a00ddd4b-49c6-11e9-9475-02f976e168bb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:41:46.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2jbhq" for this suite.
Mar 18 21:41:52.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:41:53.027: INFO: namespace: e2e-tests-containers-2jbhq, resource: bindings, ignored listing per whitelist
Mar 18 21:41:53.041: INFO: namespace e2e-tests-containers-2jbhq deletion completed in 6.087026614s

• [SLOW TEST:8.185 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:41:53.041: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-a4ee2abd-49c6-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 21:41:53.100: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a4ee9998-49c6-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-8b2q2" to be "success or failure"
Mar 18 21:41:53.104: INFO: Pod "pod-projected-configmaps-a4ee9998-49c6-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.15898ms
Mar 18 21:41:55.107: INFO: Pod "pod-projected-configmaps-a4ee9998-49c6-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006125209s
STEP: Saw pod success
Mar 18 21:41:55.107: INFO: Pod "pod-projected-configmaps-a4ee9998-49c6-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:41:55.108: INFO: Trying to get logs from node node-1 pod pod-projected-configmaps-a4ee9998-49c6-11e9-9475-02f976e168bb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 21:41:55.133: INFO: Waiting for pod pod-projected-configmaps-a4ee9998-49c6-11e9-9475-02f976e168bb to disappear
Mar 18 21:41:55.138: INFO: Pod pod-projected-configmaps-a4ee9998-49c6-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:41:55.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8b2q2" for this suite.
Mar 18 21:42:01.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:42:01.177: INFO: namespace: e2e-tests-projected-8b2q2, resource: bindings, ignored listing per whitelist
Mar 18 21:42:01.228: INFO: namespace e2e-tests-projected-8b2q2 deletion completed in 6.08505298s

• [SLOW TEST:8.187 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:42:01.228: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-shc8
STEP: Creating a pod to test atomic-volume-subpath
Mar 18 21:42:01.299: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-shc8" in namespace "e2e-tests-subpath-xb5tl" to be "success or failure"
Mar 18 21:42:01.304: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.976809ms
Mar 18 21:42:03.308: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008215471s
Mar 18 21:42:05.311: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Running", Reason="", readiness=false. Elapsed: 4.011995136s
Mar 18 21:42:07.315: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Running", Reason="", readiness=false. Elapsed: 6.015546825s
Mar 18 21:42:09.318: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Running", Reason="", readiness=false. Elapsed: 8.018908714s
Mar 18 21:42:11.321: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Running", Reason="", readiness=false. Elapsed: 10.022009902s
Mar 18 21:42:13.326: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Running", Reason="", readiness=false. Elapsed: 12.026467097s
Mar 18 21:42:15.329: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Running", Reason="", readiness=false. Elapsed: 14.029528136s
Mar 18 21:42:17.332: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Running", Reason="", readiness=false. Elapsed: 16.032526913s
Mar 18 21:42:19.335: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Running", Reason="", readiness=false. Elapsed: 18.03554159s
Mar 18 21:42:21.338: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Running", Reason="", readiness=false. Elapsed: 20.038346011s
Mar 18 21:42:23.341: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Running", Reason="", readiness=false. Elapsed: 22.041631876s
Mar 18 21:42:25.344: INFO: Pod "pod-subpath-test-downwardapi-shc8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.044657165s
STEP: Saw pod success
Mar 18 21:42:25.344: INFO: Pod "pod-subpath-test-downwardapi-shc8" satisfied condition "success or failure"
Mar 18 21:42:25.346: INFO: Trying to get logs from node node-1 pod pod-subpath-test-downwardapi-shc8 container test-container-subpath-downwardapi-shc8: <nil>
STEP: delete the pod
Mar 18 21:42:25.374: INFO: Waiting for pod pod-subpath-test-downwardapi-shc8 to disappear
Mar 18 21:42:25.377: INFO: Pod pod-subpath-test-downwardapi-shc8 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-shc8
Mar 18 21:42:25.377: INFO: Deleting pod "pod-subpath-test-downwardapi-shc8" in namespace "e2e-tests-subpath-xb5tl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:42:25.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xb5tl" for this suite.
Mar 18 21:42:31.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:42:31.437: INFO: namespace: e2e-tests-subpath-xb5tl, resource: bindings, ignored listing per whitelist
Mar 18 21:42:31.468: INFO: namespace e2e-tests-subpath-xb5tl deletion completed in 6.085814376s

• [SLOW TEST:30.240 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:42:31.468: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 21:42:31.529: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bbd634d3-49c6-11e9-9475-02f976e168bb" in namespace "e2e-tests-downward-api-4sh6z" to be "success or failure"
Mar 18 21:42:31.531: INFO: Pod "downwardapi-volume-bbd634d3-49c6-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.550732ms
Mar 18 21:42:33.534: INFO: Pod "downwardapi-volume-bbd634d3-49c6-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005492345s
STEP: Saw pod success
Mar 18 21:42:33.534: INFO: Pod "downwardapi-volume-bbd634d3-49c6-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:42:33.536: INFO: Trying to get logs from node node-1 pod downwardapi-volume-bbd634d3-49c6-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 21:42:33.555: INFO: Waiting for pod downwardapi-volume-bbd634d3-49c6-11e9-9475-02f976e168bb to disappear
Mar 18 21:42:33.564: INFO: Pod downwardapi-volume-bbd634d3-49c6-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:42:33.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4sh6z" for this suite.
Mar 18 21:42:39.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:42:39.611: INFO: namespace: e2e-tests-downward-api-4sh6z, resource: bindings, ignored listing per whitelist
Mar 18 21:42:39.660: INFO: namespace e2e-tests-downward-api-4sh6z deletion completed in 6.092118552s

• [SLOW TEST:8.192 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:42:39.661: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:43:03.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-sm56b" for this suite.
Mar 18 21:43:09.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:43:09.995: INFO: namespace: e2e-tests-container-runtime-sm56b, resource: bindings, ignored listing per whitelist
Mar 18 21:43:10.023: INFO: namespace e2e-tests-container-runtime-sm56b deletion completed in 6.09137111s

• [SLOW TEST:30.362 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:43:10.023: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:43:10.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-lk85z" for this suite.
Mar 18 21:43:32.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:43:32.154: INFO: namespace: e2e-tests-kubelet-test-lk85z, resource: bindings, ignored listing per whitelist
Mar 18 21:43:32.196: INFO: namespace e2e-tests-kubelet-test-lk85z deletion completed in 22.092483866s

• [SLOW TEST:22.173 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:43:32.196: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar 18 21:43:32.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-818169620 cluster-info'
Mar 18 21:43:32.319: INFO: stderr: ""
Mar 18 21:43:32.319: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:43:32.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vjhdq" for this suite.
Mar 18 21:43:38.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:43:38.347: INFO: namespace: e2e-tests-kubectl-vjhdq, resource: bindings, ignored listing per whitelist
Mar 18 21:43:38.407: INFO: namespace e2e-tests-kubectl-vjhdq deletion completed in 6.084434773s

• [SLOW TEST:6.210 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:43:38.407: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-v68mf
Mar 18 21:43:40.470: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-v68mf
STEP: checking the pod's current state and verifying that restartCount is present
Mar 18 21:43:40.472: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:47:40.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-v68mf" for this suite.
Mar 18 21:47:46.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:47:46.924: INFO: namespace: e2e-tests-container-probe-v68mf, resource: bindings, ignored listing per whitelist
Mar 18 21:47:46.943: INFO: namespace e2e-tests-container-probe-v68mf deletion completed in 6.09391919s

• [SLOW TEST:248.536 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:47:46.944: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar 18 21:47:47.009: INFO: Waiting up to 5m0s for pod "client-containers-77e03ad8-49c7-11e9-9475-02f976e168bb" in namespace "e2e-tests-containers-2spdq" to be "success or failure"
Mar 18 21:47:47.011: INFO: Pod "client-containers-77e03ad8-49c7-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036688ms
Mar 18 21:47:49.015: INFO: Pod "client-containers-77e03ad8-49c7-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005136833s
STEP: Saw pod success
Mar 18 21:47:49.015: INFO: Pod "client-containers-77e03ad8-49c7-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:47:49.017: INFO: Trying to get logs from node node-1 pod client-containers-77e03ad8-49c7-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 21:47:49.035: INFO: Waiting for pod client-containers-77e03ad8-49c7-11e9-9475-02f976e168bb to disappear
Mar 18 21:47:49.042: INFO: Pod client-containers-77e03ad8-49c7-11e9-9475-02f976e168bb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:47:49.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2spdq" for this suite.
Mar 18 21:47:55.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:47:55.126: INFO: namespace: e2e-tests-containers-2spdq, resource: bindings, ignored listing per whitelist
Mar 18 21:47:55.134: INFO: namespace e2e-tests-containers-2spdq deletion completed in 6.08790546s

• [SLOW TEST:8.191 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:47:55.134: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0318 21:48:05.204317      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 21:48:05.204: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:48:05.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ddjb2" for this suite.
Mar 18 21:48:11.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:48:11.264: INFO: namespace: e2e-tests-gc-ddjb2, resource: bindings, ignored listing per whitelist
Mar 18 21:48:11.301: INFO: namespace e2e-tests-gc-ddjb2 deletion completed in 6.094050362s

• [SLOW TEST:16.166 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:48:11.301: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 21:48:11.368: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8665ab08-49c7-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-75ccb" to be "success or failure"
Mar 18 21:48:11.370: INFO: Pod "downwardapi-volume-8665ab08-49c7-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.980577ms
Mar 18 21:48:13.373: INFO: Pod "downwardapi-volume-8665ab08-49c7-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004946788s
STEP: Saw pod success
Mar 18 21:48:13.373: INFO: Pod "downwardapi-volume-8665ab08-49c7-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:48:13.375: INFO: Trying to get logs from node node-1 pod downwardapi-volume-8665ab08-49c7-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 21:48:13.394: INFO: Waiting for pod downwardapi-volume-8665ab08-49c7-11e9-9475-02f976e168bb to disappear
Mar 18 21:48:13.406: INFO: Pod downwardapi-volume-8665ab08-49c7-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:48:13.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-75ccb" for this suite.
Mar 18 21:48:19.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:48:19.494: INFO: namespace: e2e-tests-projected-75ccb, resource: bindings, ignored listing per whitelist
Mar 18 21:48:19.494: INFO: namespace e2e-tests-projected-75ccb deletion completed in 6.084360298s

• [SLOW TEST:8.193 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:48:19.495: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 18 21:48:19.598: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:48:25.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hxcsr" for this suite.
Mar 18 21:48:47.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:48:47.345: INFO: namespace: e2e-tests-init-container-hxcsr, resource: bindings, ignored listing per whitelist
Mar 18 21:48:47.371: INFO: namespace e2e-tests-init-container-hxcsr deletion completed in 22.089924135s

• [SLOW TEST:27.877 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:48:47.371: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 18 21:48:47.425: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 18 21:48:47.432: INFO: Waiting for terminating namespaces to be deleted...
Mar 18 21:48:47.435: INFO: 
Logging pods the kubelet thinks is on node node-1 before test
Mar 18 21:48:47.440: INFO: canal-k9vqq from kube-system started at 2019-03-18 20:19:37 +0000 UTC (2 container statuses recorded)
Mar 18 21:48:47.440: INFO: 	Container calico-node ready: true, restart count 0
Mar 18 21:48:47.440: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 18 21:48:47.440: INFO: rke-kube-dns-addon-deploy-job-xxq8d from kube-system started at 2019-03-18 20:19:42 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.440: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Mar 18 21:48:47.440: INFO: rke-ingress-controller-deploy-job-m9w44 from kube-system started at 2019-03-18 20:19:57 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.440: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 18 21:48:47.440: INFO: rke-metrics-addon-deploy-job-bk4gn from kube-system started at 2019-03-18 20:19:49 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.440: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 18 21:48:47.440: INFO: metrics-server-58bd5dd8d7-gzdst from kube-system started at 2019-03-18 20:19:50 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.440: INFO: 	Container metrics-server ready: true, restart count 0
Mar 18 21:48:47.440: INFO: sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-lhbmj from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 21:48:47.440: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 18 21:48:47.440: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 18 21:48:47.440: INFO: rke-network-plugin-deploy-job-v9n5x from kube-system started at 2019-03-18 20:19:33 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.440: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 18 21:48:47.440: INFO: nginx-ingress-controller-x6mz2 from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.440: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 18 21:48:47.440: INFO: 
Logging pods the kubelet thinks is on node node-2 before test
Mar 18 21:48:47.446: INFO: nginx-ingress-controller-v87dt from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.446: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 18 21:48:47.446: INFO: sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-nnxbf from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 21:48:47.446: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 18 21:48:47.446: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 18 21:48:47.446: INFO: kube-dns-58bd5b8dd7-l2glm from kube-system started at 2019-03-18 20:19:44 +0000 UTC (3 container statuses recorded)
Mar 18 21:48:47.446: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 18 21:48:47.446: INFO: 	Container kubedns ready: true, restart count 0
Mar 18 21:48:47.446: INFO: 	Container sidecar ready: true, restart count 0
Mar 18 21:48:47.446: INFO: canal-psvdr from kube-system started at 2019-03-18 20:19:37 +0000 UTC (2 container statuses recorded)
Mar 18 21:48:47.446: INFO: 	Container calico-node ready: true, restart count 0
Mar 18 21:48:47.446: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 18 21:48:47.446: INFO: kube-dns-autoscaler-77bc5fd84-lg7gr from kube-system started at 2019-03-18 20:19:44 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.446: INFO: 	Container autoscaler ready: true, restart count 0
Mar 18 21:48:47.446: INFO: 
Logging pods the kubelet thinks is on node node-3 before test
Mar 18 21:48:47.451: INFO: canal-fg6j2 from kube-system started at 2019-03-18 20:19:37 +0000 UTC (2 container statuses recorded)
Mar 18 21:48:47.451: INFO: 	Container calico-node ready: true, restart count 0
Mar 18 21:48:47.451: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 18 21:48:47.451: INFO: nginx-ingress-controller-q2xj8 from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.451: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 18 21:48:47.451: INFO: default-http-backend-78fccfc5d9-2lbst from ingress-nginx started at 2019-03-18 20:19:59 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.451: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 18 21:48:47.451: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-18 20:25:25 +0000 UTC (1 container statuses recorded)
Mar 18 21:48:47.451: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 18 21:48:47.451: INFO: sonobuoy-e2e-job-561a442ed17248ce from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 21:48:47.451: INFO: 	Container e2e ready: true, restart count 0
Mar 18 21:48:47.451: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 21:48:47.451: INFO: sonobuoy-systemd-logs-daemon-set-a076d914539e43d2-w8nm8 from heptio-sonobuoy started at 2019-03-18 20:25:28 +0000 UTC (2 container statuses recorded)
Mar 18 21:48:47.451: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 18 21:48:47.451: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158d2be948f8606d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:48:48.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-hhpxj" for this suite.
Mar 18 21:48:54.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:48:54.572: INFO: namespace: e2e-tests-sched-pred-hhpxj, resource: bindings, ignored listing per whitelist
Mar 18 21:48:54.583: INFO: namespace e2e-tests-sched-pred-hhpxj deletion completed in 6.110299096s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.212 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:48:54.583: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a0321d89-49c7-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume configMaps
Mar 18 21:48:54.655: INFO: Waiting up to 5m0s for pod "pod-configmaps-a0328a5a-49c7-11e9-9475-02f976e168bb" in namespace "e2e-tests-configmap-7vtrj" to be "success or failure"
Mar 18 21:48:54.660: INFO: Pod "pod-configmaps-a0328a5a-49c7-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.648357ms
Mar 18 21:48:56.663: INFO: Pod "pod-configmaps-a0328a5a-49c7-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007967853s
STEP: Saw pod success
Mar 18 21:48:56.663: INFO: Pod "pod-configmaps-a0328a5a-49c7-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:48:56.677: INFO: Trying to get logs from node node-1 pod pod-configmaps-a0328a5a-49c7-11e9-9475-02f976e168bb container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 21:48:56.695: INFO: Waiting for pod pod-configmaps-a0328a5a-49c7-11e9-9475-02f976e168bb to disappear
Mar 18 21:48:56.708: INFO: Pod pod-configmaps-a0328a5a-49c7-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:48:56.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7vtrj" for this suite.
Mar 18 21:49:02.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:49:02.756: INFO: namespace: e2e-tests-configmap-7vtrj, resource: bindings, ignored listing per whitelist
Mar 18 21:49:02.808: INFO: namespace e2e-tests-configmap-7vtrj deletion completed in 6.096072749s

• [SLOW TEST:8.225 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:49:02.808: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:49:02.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-vqhjg" for this suite.
Mar 18 21:49:08.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:49:08.913: INFO: namespace: e2e-tests-services-vqhjg, resource: bindings, ignored listing per whitelist
Mar 18 21:49:08.969: INFO: namespace e2e-tests-services-vqhjg deletion completed in 6.092418171s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.161 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:49:08.969: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-a8c651f2-49c7-11e9-9475-02f976e168bb
STEP: Creating a pod to test consume secrets
Mar 18 21:49:09.047: INFO: Waiting up to 5m0s for pod "pod-secrets-a8c6b5c0-49c7-11e9-9475-02f976e168bb" in namespace "e2e-tests-secrets-pz42v" to be "success or failure"
Mar 18 21:49:09.051: INFO: Pod "pod-secrets-a8c6b5c0-49c7-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.522496ms
Mar 18 21:49:11.054: INFO: Pod "pod-secrets-a8c6b5c0-49c7-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007456749s
STEP: Saw pod success
Mar 18 21:49:11.054: INFO: Pod "pod-secrets-a8c6b5c0-49c7-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:49:11.056: INFO: Trying to get logs from node node-1 pod pod-secrets-a8c6b5c0-49c7-11e9-9475-02f976e168bb container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 21:49:11.074: INFO: Waiting for pod pod-secrets-a8c6b5c0-49c7-11e9-9475-02f976e168bb to disappear
Mar 18 21:49:11.083: INFO: Pod pod-secrets-a8c6b5c0-49c7-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:49:11.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pz42v" for this suite.
Mar 18 21:49:17.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:49:17.156: INFO: namespace: e2e-tests-secrets-pz42v, resource: bindings, ignored listing per whitelist
Mar 18 21:49:17.181: INFO: namespace e2e-tests-secrets-pz42v deletion completed in 6.090620271s

• [SLOW TEST:8.212 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:49:17.181: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar 18 21:49:17.243: INFO: Waiting up to 5m0s for pod "client-containers-ada94025-49c7-11e9-9475-02f976e168bb" in namespace "e2e-tests-containers-x6sz8" to be "success or failure"
Mar 18 21:49:17.246: INFO: Pod "client-containers-ada94025-49c7-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.310788ms
Mar 18 21:49:19.249: INFO: Pod "client-containers-ada94025-49c7-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006114156s
STEP: Saw pod success
Mar 18 21:49:19.249: INFO: Pod "client-containers-ada94025-49c7-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:49:19.252: INFO: Trying to get logs from node node-1 pod client-containers-ada94025-49c7-11e9-9475-02f976e168bb container test-container: <nil>
STEP: delete the pod
Mar 18 21:49:19.272: INFO: Waiting for pod client-containers-ada94025-49c7-11e9-9475-02f976e168bb to disappear
Mar 18 21:49:19.277: INFO: Pod client-containers-ada94025-49c7-11e9-9475-02f976e168bb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:49:19.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-x6sz8" for this suite.
Mar 18 21:49:25.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:49:25.324: INFO: namespace: e2e-tests-containers-x6sz8, resource: bindings, ignored listing per whitelist
Mar 18 21:49:25.370: INFO: namespace e2e-tests-containers-x6sz8 deletion completed in 6.088603184s

• [SLOW TEST:8.189 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:49:25.370: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-c8vn5 in namespace e2e-tests-proxy-4qhgg
I0318 21:49:25.436451      18 runners.go:184] Created replication controller with name: proxy-service-c8vn5, namespace: e2e-tests-proxy-4qhgg, replica count: 1
I0318 21:49:26.486825      18 runners.go:184] proxy-service-c8vn5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0318 21:49:27.487052      18 runners.go:184] proxy-service-c8vn5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0318 21:49:28.487244      18 runners.go:184] proxy-service-c8vn5 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 18 21:49:28.489: INFO: setup took 3.066242236s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 18 21:49:28.495: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 5.052828ms)
Mar 18 21:49:28.495: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 5.421941ms)
Mar 18 21:49:28.499: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 9.517896ms)
Mar 18 21:49:28.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 11.094489ms)
Mar 18 21:49:28.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 11.331828ms)
Mar 18 21:49:28.506: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 15.845456ms)
Mar 18 21:49:28.506: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 16.204379ms)
Mar 18 21:49:28.506: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 15.790141ms)
Mar 18 21:49:28.506: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 15.486932ms)
Mar 18 21:49:28.506: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 15.540258ms)
Mar 18 21:49:28.516: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 26.024673ms)
Mar 18 21:49:28.517: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 26.82115ms)
Mar 18 21:49:28.518: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 27.571681ms)
Mar 18 21:49:28.518: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 28.601862ms)
Mar 18 21:49:28.519: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 28.559617ms)
Mar 18 21:49:28.519: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 28.447875ms)
Mar 18 21:49:28.531: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 11.526017ms)
Mar 18 21:49:28.531: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 11.857662ms)
Mar 18 21:49:28.531: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 12.059095ms)
Mar 18 21:49:28.531: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 12.185276ms)
Mar 18 21:49:28.531: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 12.215629ms)
Mar 18 21:49:28.531: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 12.170714ms)
Mar 18 21:49:28.531: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 12.214634ms)
Mar 18 21:49:28.532: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 13.135075ms)
Mar 18 21:49:28.532: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 13.16766ms)
Mar 18 21:49:28.532: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 13.43876ms)
Mar 18 21:49:28.533: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 13.505927ms)
Mar 18 21:49:28.533: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 13.601824ms)
Mar 18 21:49:28.533: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 13.961052ms)
Mar 18 21:49:28.533: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 13.861071ms)
Mar 18 21:49:28.533: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 14.00866ms)
Mar 18 21:49:28.533: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 14.102651ms)
Mar 18 21:49:28.540: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 7.179323ms)
Mar 18 21:49:28.546: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 12.733488ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 16.516014ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 16.695198ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 16.92364ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 16.599074ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 16.863937ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 17.149632ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 16.795767ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 17.121085ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 16.42476ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 16.592169ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 16.678933ms)
Mar 18 21:49:28.550: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 16.423368ms)
Mar 18 21:49:28.554: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 19.940063ms)
Mar 18 21:49:28.554: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 19.952259ms)
Mar 18 21:49:28.558: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 4.290626ms)
Mar 18 21:49:28.564: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 10.234106ms)
Mar 18 21:49:28.565: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 10.340332ms)
Mar 18 21:49:28.565: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 9.968601ms)
Mar 18 21:49:28.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 11.273237ms)
Mar 18 21:49:28.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 11.111167ms)
Mar 18 21:49:28.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 10.983494ms)
Mar 18 21:49:28.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 10.983325ms)
Mar 18 21:49:28.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 11.109624ms)
Mar 18 21:49:28.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 11.204404ms)
Mar 18 21:49:28.568: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 14.244247ms)
Mar 18 21:49:28.569: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 14.957922ms)
Mar 18 21:49:28.569: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 14.65828ms)
Mar 18 21:49:28.569: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 14.921671ms)
Mar 18 21:49:28.569: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 14.983987ms)
Mar 18 21:49:28.570: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 15.134405ms)
Mar 18 21:49:28.575: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 4.904245ms)
Mar 18 21:49:28.575: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 5.051428ms)
Mar 18 21:49:28.575: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 5.25396ms)
Mar 18 21:49:28.575: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 5.614136ms)
Mar 18 21:49:28.576: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 5.612808ms)
Mar 18 21:49:28.581: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 11.009085ms)
Mar 18 21:49:28.581: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 10.961305ms)
Mar 18 21:49:28.581: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 11.050726ms)
Mar 18 21:49:28.582: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 12.003159ms)
Mar 18 21:49:28.582: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 12.369554ms)
Mar 18 21:49:28.582: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 12.202109ms)
Mar 18 21:49:28.582: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 12.082243ms)
Mar 18 21:49:28.583: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 12.53637ms)
Mar 18 21:49:28.583: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 12.348497ms)
Mar 18 21:49:28.583: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 12.726401ms)
Mar 18 21:49:28.583: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 12.701355ms)
Mar 18 21:49:28.588: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 4.91244ms)
Mar 18 21:49:28.590: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 7.186269ms)
Mar 18 21:49:28.590: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 7.183814ms)
Mar 18 21:49:28.590: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 7.181707ms)
Mar 18 21:49:28.591: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 7.524415ms)
Mar 18 21:49:28.592: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 9.370104ms)
Mar 18 21:49:28.592: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 9.232786ms)
Mar 18 21:49:28.595: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 11.237298ms)
Mar 18 21:49:28.595: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 11.529325ms)
Mar 18 21:49:28.595: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 11.256165ms)
Mar 18 21:49:28.595: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 11.359941ms)
Mar 18 21:49:28.595: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 11.36187ms)
Mar 18 21:49:28.595: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 11.241829ms)
Mar 18 21:49:28.596: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 12.624669ms)
Mar 18 21:49:28.597: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 13.36182ms)
Mar 18 21:49:28.597: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 13.678652ms)
Mar 18 21:49:28.601: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 4.220013ms)
Mar 18 21:49:28.606: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 8.641861ms)
Mar 18 21:49:28.607: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 9.612044ms)
Mar 18 21:49:28.607: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 9.589ms)
Mar 18 21:49:28.607: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 10.331768ms)
Mar 18 21:49:28.608: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 11.344267ms)
Mar 18 21:49:28.608: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 11.167263ms)
Mar 18 21:49:28.609: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 11.436111ms)
Mar 18 21:49:28.609: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 11.824302ms)
Mar 18 21:49:28.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 12.496679ms)
Mar 18 21:49:28.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 12.511889ms)
Mar 18 21:49:28.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 12.671944ms)
Mar 18 21:49:28.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 12.556177ms)
Mar 18 21:49:28.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 12.581586ms)
Mar 18 21:49:28.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 12.942104ms)
Mar 18 21:49:28.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 13.157767ms)
Mar 18 21:49:28.619: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 7.662548ms)
Mar 18 21:49:28.619: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 8.619929ms)
Mar 18 21:49:28.619: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 8.548429ms)
Mar 18 21:49:28.619: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 8.506047ms)
Mar 18 21:49:28.620: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 9.39511ms)
Mar 18 21:49:28.621: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 9.799634ms)
Mar 18 21:49:28.621: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 9.904574ms)
Mar 18 21:49:28.621: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 9.89035ms)
Mar 18 21:49:28.622: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 11.906091ms)
Mar 18 21:49:28.623: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 12.119584ms)
Mar 18 21:49:28.623: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 12.44418ms)
Mar 18 21:49:28.623: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 12.490667ms)
Mar 18 21:49:28.624: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 13.01609ms)
Mar 18 21:49:28.624: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 13.094484ms)
Mar 18 21:49:28.624: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 13.224366ms)
Mar 18 21:49:28.625: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 14.162405ms)
Mar 18 21:49:28.629: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 3.714294ms)
Mar 18 21:49:28.631: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 5.933848ms)
Mar 18 21:49:28.632: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 6.802252ms)
Mar 18 21:49:28.634: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 7.770833ms)
Mar 18 21:49:28.634: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 8.508516ms)
Mar 18 21:49:28.634: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 8.536248ms)
Mar 18 21:49:28.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 10.581486ms)
Mar 18 21:49:28.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 10.423449ms)
Mar 18 21:49:28.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 10.908505ms)
Mar 18 21:49:28.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 11.54086ms)
Mar 18 21:49:28.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 11.811498ms)
Mar 18 21:49:28.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 12.025646ms)
Mar 18 21:49:28.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 12.880392ms)
Mar 18 21:49:28.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 12.468413ms)
Mar 18 21:49:28.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 12.010976ms)
Mar 18 21:49:28.640: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 13.851259ms)
Mar 18 21:49:28.650: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 9.033898ms)
Mar 18 21:49:28.650: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 9.415793ms)
Mar 18 21:49:28.650: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 10.120435ms)
Mar 18 21:49:28.650: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 9.653814ms)
Mar 18 21:49:28.651: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 11.15144ms)
Mar 18 21:49:28.652: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 11.204168ms)
Mar 18 21:49:28.652: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 12.048665ms)
Mar 18 21:49:28.652: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 11.947771ms)
Mar 18 21:49:28.653: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 12.087527ms)
Mar 18 21:49:28.653: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 13.235571ms)
Mar 18 21:49:28.653: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 12.624871ms)
Mar 18 21:49:28.654: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 13.29593ms)
Mar 18 21:49:28.654: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 13.537795ms)
Mar 18 21:49:28.654: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 14.243957ms)
Mar 18 21:49:28.654: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 13.536929ms)
Mar 18 21:49:28.655: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 14.634747ms)
Mar 18 21:49:28.658: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 2.995363ms)
Mar 18 21:49:28.661: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 5.941704ms)
Mar 18 21:49:28.662: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 7.422405ms)
Mar 18 21:49:28.663: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 7.903141ms)
Mar 18 21:49:28.663: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 7.748908ms)
Mar 18 21:49:28.663: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 7.750952ms)
Mar 18 21:49:28.663: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 7.93063ms)
Mar 18 21:49:28.663: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 8.062486ms)
Mar 18 21:49:28.663: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 8.003025ms)
Mar 18 21:49:28.664: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 9.33139ms)
Mar 18 21:49:28.666: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 10.698594ms)
Mar 18 21:49:28.666: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 10.886378ms)
Mar 18 21:49:28.666: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 11.149215ms)
Mar 18 21:49:28.666: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 11.013191ms)
Mar 18 21:49:28.666: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 11.536358ms)
Mar 18 21:49:28.666: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 11.701042ms)
Mar 18 21:49:28.673: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 6.406153ms)
Mar 18 21:49:28.674: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 7.08479ms)
Mar 18 21:49:28.674: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 7.570847ms)
Mar 18 21:49:28.675: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 7.971339ms)
Mar 18 21:49:28.675: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 8.59799ms)
Mar 18 21:49:28.675: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 8.580109ms)
Mar 18 21:49:28.675: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 8.813484ms)
Mar 18 21:49:28.675: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 8.738408ms)
Mar 18 21:49:28.682: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 15.084555ms)
Mar 18 21:49:28.682: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 15.081904ms)
Mar 18 21:49:28.682: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 15.479322ms)
Mar 18 21:49:28.682: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 15.217661ms)
Mar 18 21:49:28.682: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 15.36799ms)
Mar 18 21:49:28.682: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 15.665102ms)
Mar 18 21:49:28.682: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 15.534564ms)
Mar 18 21:49:28.683: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 15.644653ms)
Mar 18 21:49:28.691: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 7.576505ms)
Mar 18 21:49:28.691: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 8.041505ms)
Mar 18 21:49:28.691: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 8.372102ms)
Mar 18 21:49:28.691: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 8.382305ms)
Mar 18 21:49:28.691: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 8.76558ms)
Mar 18 21:49:28.692: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 8.80009ms)
Mar 18 21:49:28.692: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 9.247182ms)
Mar 18 21:49:28.692: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 9.23611ms)
Mar 18 21:49:28.692: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 9.11483ms)
Mar 18 21:49:28.692: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 9.488132ms)
Mar 18 21:49:28.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 12.495182ms)
Mar 18 21:49:28.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 13.061841ms)
Mar 18 21:49:28.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 13.268759ms)
Mar 18 21:49:28.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 13.113821ms)
Mar 18 21:49:28.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 13.201166ms)
Mar 18 21:49:28.696: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 13.477515ms)
Mar 18 21:49:28.704: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 7.327045ms)
Mar 18 21:49:28.705: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 7.41038ms)
Mar 18 21:49:28.705: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 7.690942ms)
Mar 18 21:49:28.705: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 7.546088ms)
Mar 18 21:49:28.705: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 7.325902ms)
Mar 18 21:49:28.705: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 8.376764ms)
Mar 18 21:49:28.706: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 8.793041ms)
Mar 18 21:49:28.706: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 9.805517ms)
Mar 18 21:49:28.707: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 9.908874ms)
Mar 18 21:49:28.707: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 9.270535ms)
Mar 18 21:49:28.707: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 9.309924ms)
Mar 18 21:49:28.707: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 9.376427ms)
Mar 18 21:49:28.707: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 10.413877ms)
Mar 18 21:49:28.707: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 10.696072ms)
Mar 18 21:49:28.707: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 10.100838ms)
Mar 18 21:49:28.708: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 10.795991ms)
Mar 18 21:49:28.716: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 7.415593ms)
Mar 18 21:49:28.716: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 7.843885ms)
Mar 18 21:49:28.720: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 11.876992ms)
Mar 18 21:49:28.720: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 11.407604ms)
Mar 18 21:49:28.721: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 12.811611ms)
Mar 18 21:49:28.721: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 12.955356ms)
Mar 18 21:49:28.721: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 13.343768ms)
Mar 18 21:49:28.721: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 12.564554ms)
Mar 18 21:49:28.721: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 12.832491ms)
Mar 18 21:49:28.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 13.303706ms)
Mar 18 21:49:28.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 14.109818ms)
Mar 18 21:49:28.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 13.828875ms)
Mar 18 21:49:28.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 13.935102ms)
Mar 18 21:49:28.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 14.281575ms)
Mar 18 21:49:28.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 13.536156ms)
Mar 18 21:49:28.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 13.572314ms)
Mar 18 21:49:28.729: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 6.294555ms)
Mar 18 21:49:28.729: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 6.468063ms)
Mar 18 21:49:28.729: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 6.840882ms)
Mar 18 21:49:28.729: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 6.667153ms)
Mar 18 21:49:28.731: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 8.211212ms)
Mar 18 21:49:28.731: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 8.246261ms)
Mar 18 21:49:28.731: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 8.310826ms)
Mar 18 21:49:28.731: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 8.320083ms)
Mar 18 21:49:28.731: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 8.492078ms)
Mar 18 21:49:28.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 10.32681ms)
Mar 18 21:49:28.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 10.448943ms)
Mar 18 21:49:28.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 10.724228ms)
Mar 18 21:49:28.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 10.70436ms)
Mar 18 21:49:28.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 10.687623ms)
Mar 18 21:49:28.734: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 10.945556ms)
Mar 18 21:49:28.734: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 10.904936ms)
Mar 18 21:49:28.739: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 5.322735ms)
Mar 18 21:49:28.741: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 7.016296ms)
Mar 18 21:49:28.741: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 7.495642ms)
Mar 18 21:49:28.741: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 7.689025ms)
Mar 18 21:49:28.744: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 9.411023ms)
Mar 18 21:49:28.744: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 10.241337ms)
Mar 18 21:49:28.745: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 11.109641ms)
Mar 18 21:49:28.745: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 11.12119ms)
Mar 18 21:49:28.745: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 11.250355ms)
Mar 18 21:49:28.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 11.803938ms)
Mar 18 21:49:28.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 11.490785ms)
Mar 18 21:49:28.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 11.962322ms)
Mar 18 21:49:28.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 11.827407ms)
Mar 18 21:49:28.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 12.132914ms)
Mar 18 21:49:28.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 12.176287ms)
Mar 18 21:49:28.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 12.52659ms)
Mar 18 21:49:28.752: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 5.504509ms)
Mar 18 21:49:28.755: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 8.561718ms)
Mar 18 21:49:28.756: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 9.285971ms)
Mar 18 21:49:28.757: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 9.823105ms)
Mar 18 21:49:28.757: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 9.788123ms)
Mar 18 21:49:28.757: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 9.936417ms)
Mar 18 21:49:28.757: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 9.972692ms)
Mar 18 21:49:28.757: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 10.713585ms)
Mar 18 21:49:28.758: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 10.972731ms)
Mar 18 21:49:28.758: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 11.052167ms)
Mar 18 21:49:28.758: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 10.952081ms)
Mar 18 21:49:28.758: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 11.14308ms)
Mar 18 21:49:28.758: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 11.469481ms)
Mar 18 21:49:28.758: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 11.110112ms)
Mar 18 21:49:28.759: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 11.661717ms)
Mar 18 21:49:28.759: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 11.950816ms)
Mar 18 21:49:28.766: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 6.66607ms)
Mar 18 21:49:28.766: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 7.143171ms)
Mar 18 21:49:28.767: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 7.681037ms)
Mar 18 21:49:28.767: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 7.703136ms)
Mar 18 21:49:28.767: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 7.888209ms)
Mar 18 21:49:28.767: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 8.11409ms)
Mar 18 21:49:28.768: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 9.101205ms)
Mar 18 21:49:28.768: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 9.278936ms)
Mar 18 21:49:28.769: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 9.443436ms)
Mar 18 21:49:28.769: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 9.85847ms)
Mar 18 21:49:28.769: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 9.976412ms)
Mar 18 21:49:28.771: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 12.082919ms)
Mar 18 21:49:28.773: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 13.495902ms)
Mar 18 21:49:28.773: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 13.950173ms)
Mar 18 21:49:28.774: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 14.355088ms)
Mar 18 21:49:28.775: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 15.084297ms)
Mar 18 21:49:28.781: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:462/proxy/: tls qux (200; 6.308705ms)
Mar 18 21:49:28.784: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:1080/proxy/... (200; 8.906919ms)
Mar 18 21:49:28.784: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 9.55056ms)
Mar 18 21:49:28.785: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:1080/proxy/rewri... (200; 9.849563ms)
Mar 18 21:49:28.785: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname2/proxy/: bar (200; 9.559543ms)
Mar 18 21:49:28.785: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:443/proxy/... (200; 10.015431ms)
Mar 18 21:49:28.785: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/https:proxy-service-c8vn5-swjrw:460/proxy/: tls baz (200; 9.871808ms)
Mar 18 21:49:28.785: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 9.705187ms)
Mar 18 21:49:28.785: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname1/proxy/: tls baz (200; 10.677409ms)
Mar 18 21:49:28.785: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/https:proxy-service-c8vn5:tlsportname2/proxy/: tls qux (200; 10.544534ms)
Mar 18 21:49:28.785: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname1/proxy/: foo (200; 10.552663ms)
Mar 18 21:49:28.786: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/http:proxy-service-c8vn5-swjrw:162/proxy/: bar (200; 10.764502ms)
Mar 18 21:49:28.786: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/http:proxy-service-c8vn5:portname1/proxy/: foo (200; 10.649664ms)
Mar 18 21:49:28.786: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/services/proxy-service-c8vn5:portname2/proxy/: bar (200; 10.616246ms)
Mar 18 21:49:28.786: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw/proxy/rewriteme"... (200; 10.747026ms)
Mar 18 21:49:28.786: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4qhgg/pods/proxy-service-c8vn5-swjrw:160/proxy/: foo (200; 10.8618ms)
STEP: deleting ReplicationController proxy-service-c8vn5 in namespace e2e-tests-proxy-4qhgg, will wait for the garbage collector to delete the pods
Mar 18 21:49:28.846: INFO: Deleting ReplicationController proxy-service-c8vn5 took: 7.21514ms
Mar 18 21:49:28.946: INFO: Terminating ReplicationController proxy-service-c8vn5 pods took: 100.2555ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:49:36.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-4qhgg" for this suite.
Mar 18 21:49:42.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:49:42.719: INFO: namespace: e2e-tests-proxy-4qhgg, resource: bindings, ignored listing per whitelist
Mar 18 21:49:42.735: INFO: namespace e2e-tests-proxy-4qhgg deletion completed in 6.083866599s

• [SLOW TEST:17.365 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:49:42.735: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-v77xx
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-v77xx
STEP: Deleting pre-stop pod
Mar 18 21:49:53.819: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:49:53.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-v77xx" for this suite.
Mar 18 21:50:31.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:50:31.854: INFO: namespace: e2e-tests-prestop-v77xx, resource: bindings, ignored listing per whitelist
Mar 18 21:50:31.929: INFO: namespace e2e-tests-prestop-v77xx deletion completed in 38.096755837s

• [SLOW TEST:49.194 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:50:31.929: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 21:50:31.991: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da370861-49c7-11e9-9475-02f976e168bb" in namespace "e2e-tests-projected-b9glv" to be "success or failure"
Mar 18 21:50:31.994: INFO: Pod "downwardapi-volume-da370861-49c7-11e9-9475-02f976e168bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.382893ms
Mar 18 21:50:33.997: INFO: Pod "downwardapi-volume-da370861-49c7-11e9-9475-02f976e168bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005696087s
STEP: Saw pod success
Mar 18 21:50:33.997: INFO: Pod "downwardapi-volume-da370861-49c7-11e9-9475-02f976e168bb" satisfied condition "success or failure"
Mar 18 21:50:33.999: INFO: Trying to get logs from node node-1 pod downwardapi-volume-da370861-49c7-11e9-9475-02f976e168bb container client-container: <nil>
STEP: delete the pod
Mar 18 21:50:34.019: INFO: Waiting for pod downwardapi-volume-da370861-49c7-11e9-9475-02f976e168bb to disappear
Mar 18 21:50:34.035: INFO: Pod downwardapi-volume-da370861-49c7-11e9-9475-02f976e168bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:50:34.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b9glv" for this suite.
Mar 18 21:50:40.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:50:40.106: INFO: namespace: e2e-tests-projected-b9glv, resource: bindings, ignored listing per whitelist
Mar 18 21:50:40.123: INFO: namespace e2e-tests-projected-b9glv deletion completed in 6.084807017s

• [SLOW TEST:8.194 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:50:40.123: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0318 21:50:41.265088      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 21:50:41.265: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:50:41.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2jlmg" for this suite.
Mar 18 21:50:47.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:50:47.304: INFO: namespace: e2e-tests-gc-2jlmg, resource: bindings, ignored listing per whitelist
Mar 18 21:50:47.362: INFO: namespace e2e-tests-gc-2jlmg deletion completed in 6.094418083s

• [SLOW TEST:7.238 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 21:50:47.362: INFO: >>> kubeConfig: /tmp/kubeconfig-818169620
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-4lcm
STEP: Creating a pod to test atomic-volume-subpath
Mar 18 21:50:47.428: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4lcm" in namespace "e2e-tests-subpath-r7w24" to be "success or failure"
Mar 18 21:50:47.431: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.86883ms
Mar 18 21:50:49.434: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0058338s
Mar 18 21:50:51.437: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Running", Reason="", readiness=false. Elapsed: 4.00906308s
Mar 18 21:50:53.446: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Running", Reason="", readiness=false. Elapsed: 6.017392313s
Mar 18 21:50:55.449: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Running", Reason="", readiness=false. Elapsed: 8.020393816s
Mar 18 21:50:57.452: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Running", Reason="", readiness=false. Elapsed: 10.023637205s
Mar 18 21:50:59.455: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Running", Reason="", readiness=false. Elapsed: 12.026581749s
Mar 18 21:51:01.458: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Running", Reason="", readiness=false. Elapsed: 14.030187075s
Mar 18 21:51:03.462: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Running", Reason="", readiness=false. Elapsed: 16.03338858s
Mar 18 21:51:05.465: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Running", Reason="", readiness=false. Elapsed: 18.036446657s
Mar 18 21:51:07.468: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Running", Reason="", readiness=false. Elapsed: 20.039476494s
Mar 18 21:51:09.471: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Running", Reason="", readiness=false. Elapsed: 22.042579031s
Mar 18 21:51:11.474: INFO: Pod "pod-subpath-test-secret-4lcm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.045599267s
STEP: Saw pod success
Mar 18 21:51:11.474: INFO: Pod "pod-subpath-test-secret-4lcm" satisfied condition "success or failure"
Mar 18 21:51:11.476: INFO: Trying to get logs from node node-1 pod pod-subpath-test-secret-4lcm container test-container-subpath-secret-4lcm: <nil>
STEP: delete the pod
Mar 18 21:51:11.494: INFO: Waiting for pod pod-subpath-test-secret-4lcm to disappear
Mar 18 21:51:11.507: INFO: Pod pod-subpath-test-secret-4lcm no longer exists
STEP: Deleting pod pod-subpath-test-secret-4lcm
Mar 18 21:51:11.507: INFO: Deleting pod "pod-subpath-test-secret-4lcm" in namespace "e2e-tests-subpath-r7w24"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 21:51:11.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-r7w24" for this suite.
Mar 18 21:51:17.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 21:51:17.545: INFO: namespace: e2e-tests-subpath-r7w24, resource: bindings, ignored listing per whitelist
Mar 18 21:51:17.601: INFO: namespace e2e-tests-subpath-r7w24 deletion completed in 6.087137593s

• [SLOW TEST:30.238 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSMar 18 21:51:17.601: INFO: Running AfterSuite actions on all nodes
Mar 18 21:51:17.601: INFO: Running AfterSuite actions on node 1
Mar 18 21:51:17.601: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5124.767 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h25m25.546605845s
Test Suite Passed
