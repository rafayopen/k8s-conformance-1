I0327 20:23:04.995164      14 test_context.go:359] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-228394863
I0327 20:23:04.995745      14 e2e.go:224] Starting e2e run "1f4266f4-50ce-11e9-9d23-0ac04cf37a48" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1553718182 - Will randomize all specs
Will run 201 of 2161 specs

Mar 27 20:23:05.423: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:23:05.429: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 27 20:23:05.451: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 27 20:23:05.515: INFO: The status of Pod rke-ingress-controller-deploy-job-8s8mv is Succeeded, skipping waiting
Mar 27 20:23:05.516: INFO: The status of Pod rke-kubedns-addon-deploy-job-8pplg is Succeeded, skipping waiting
Mar 27 20:23:05.516: INFO: The status of Pod rke-metrics-addon-deploy-job-pm9qz is Succeeded, skipping waiting
Mar 27 20:23:05.516: INFO: The status of Pod rke-network-plugin-deploy-job-sffcc is Succeeded, skipping waiting
Mar 27 20:23:05.516: INFO: 9 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 27 20:23:05.516: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Mar 27 20:23:05.516: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 27 20:23:05.532: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Mar 27 20:23:05.532: INFO: e2e test version: v1.13.4
Mar 27 20:23:05.534: INFO: kube-apiserver version: v1.13.4
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:23:05.536: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
Mar 27 20:23:05.732: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 27 20:23:05.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:06.477: INFO: stderr: ""
Mar 27 20:23:06.477: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 20:23:06.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:06.760: INFO: stderr: ""
Mar 27 20:23:06.760: INFO: stdout: "update-demo-nautilus-fbc6w update-demo-nautilus-sjx4q "
Mar 27 20:23:06.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-fbc6w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:06.915: INFO: stderr: ""
Mar 27 20:23:06.915: INFO: stdout: ""
Mar 27 20:23:06.915: INFO: update-demo-nautilus-fbc6w is created but not running
Mar 27 20:23:11.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:12.119: INFO: stderr: ""
Mar 27 20:23:12.119: INFO: stdout: "update-demo-nautilus-fbc6w update-demo-nautilus-sjx4q "
Mar 27 20:23:12.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-fbc6w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:12.259: INFO: stderr: ""
Mar 27 20:23:12.259: INFO: stdout: "true"
Mar 27 20:23:12.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-fbc6w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:12.396: INFO: stderr: ""
Mar 27 20:23:12.396: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 20:23:12.396: INFO: validating pod update-demo-nautilus-fbc6w
Mar 27 20:23:12.411: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 20:23:12.411: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 20:23:12.411: INFO: update-demo-nautilus-fbc6w is verified up and running
Mar 27 20:23:12.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-sjx4q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:12.580: INFO: stderr: ""
Mar 27 20:23:12.581: INFO: stdout: "true"
Mar 27 20:23:12.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-sjx4q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:12.715: INFO: stderr: ""
Mar 27 20:23:12.715: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 20:23:12.715: INFO: validating pod update-demo-nautilus-sjx4q
Mar 27 20:23:12.724: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 20:23:12.724: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 20:23:12.724: INFO: update-demo-nautilus-sjx4q is verified up and running
STEP: scaling down the replication controller
Mar 27 20:23:12.727: INFO: scanned /root for discovery docs: <nil>
Mar 27 20:23:12.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:14.077: INFO: stderr: ""
Mar 27 20:23:14.077: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 20:23:14.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:14.279: INFO: stderr: ""
Mar 27 20:23:14.279: INFO: stdout: "update-demo-nautilus-fbc6w update-demo-nautilus-sjx4q "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 27 20:23:19.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:19.438: INFO: stderr: ""
Mar 27 20:23:19.438: INFO: stdout: "update-demo-nautilus-sjx4q "
Mar 27 20:23:19.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-sjx4q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:19.568: INFO: stderr: ""
Mar 27 20:23:19.568: INFO: stdout: "true"
Mar 27 20:23:19.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-sjx4q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:19.701: INFO: stderr: ""
Mar 27 20:23:19.701: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 20:23:19.701: INFO: validating pod update-demo-nautilus-sjx4q
Mar 27 20:23:19.709: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 20:23:19.709: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 20:23:19.709: INFO: update-demo-nautilus-sjx4q is verified up and running
STEP: scaling up the replication controller
Mar 27 20:23:19.726: INFO: scanned /root for discovery docs: <nil>
Mar 27 20:23:19.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:21.026: INFO: stderr: ""
Mar 27 20:23:21.026: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 20:23:21.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:21.185: INFO: stderr: ""
Mar 27 20:23:21.186: INFO: stdout: "update-demo-nautilus-sjx4q update-demo-nautilus-w2dzb "
Mar 27 20:23:21.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-sjx4q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:21.373: INFO: stderr: ""
Mar 27 20:23:21.373: INFO: stdout: "true"
Mar 27 20:23:21.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-sjx4q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:21.600: INFO: stderr: ""
Mar 27 20:23:21.600: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 20:23:21.600: INFO: validating pod update-demo-nautilus-sjx4q
Mar 27 20:23:21.609: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 20:23:21.609: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 20:23:21.609: INFO: update-demo-nautilus-sjx4q is verified up and running
Mar 27 20:23:21.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-w2dzb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:21.756: INFO: stderr: ""
Mar 27 20:23:21.756: INFO: stdout: "true"
Mar 27 20:23:21.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-w2dzb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:21.955: INFO: stderr: ""
Mar 27 20:23:21.955: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 20:23:21.955: INFO: validating pod update-demo-nautilus-w2dzb
Mar 27 20:23:21.970: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 20:23:21.970: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 20:23:21.970: INFO: update-demo-nautilus-w2dzb is verified up and running
STEP: using delete to clean up resources
Mar 27 20:23:21.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:22.138: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 20:23:22.138: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 27 20:23:22.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-6txjz'
Mar 27 20:23:22.338: INFO: stderr: "No resources found.\n"
Mar 27 20:23:22.338: INFO: stdout: ""
Mar 27 20:23:22.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -l name=update-demo --namespace=e2e-tests-kubectl-6txjz -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 27 20:23:22.520: INFO: stderr: ""
Mar 27 20:23:22.520: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:23:22.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6txjz" for this suite.
Mar 27 20:23:28.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:23:28.795: INFO: namespace: e2e-tests-kubectl-6txjz, resource: bindings, ignored listing per whitelist
Mar 27 20:23:28.860: INFO: namespace e2e-tests-kubectl-6txjz deletion completed in 6.331108535s

• [SLOW TEST:23.324 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:23:28.861: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-rmpfr A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-rmpfr;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-rmpfr A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-rmpfr;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-rmpfr.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-rmpfr.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-rmpfr.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-rmpfr.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-rmpfr.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-rmpfr.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-rmpfr.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-rmpfr.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-rmpfr.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-rmpfr.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-rmpfr.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-rmpfr.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-rmpfr.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 245.254.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.254.245_udp@PTR;check="$$(dig +tcp +noall +answer +search 245.254.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.254.245_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-rmpfr A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-rmpfr;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-rmpfr A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-rmpfr;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-rmpfr.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-rmpfr.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-rmpfr.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-rmpfr.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-rmpfr.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-rmpfr.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-rmpfr.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-rmpfr.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-rmpfr.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-rmpfr.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-rmpfr.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-rmpfr.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-rmpfr.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 245.254.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.254.245_udp@PTR;check="$$(dig +tcp +noall +answer +search 245.254.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.254.245_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 20:23:33.412: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-rmpfr/dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48: the server could not find the requested resource (get pods dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48)
Mar 27 20:23:33.417: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-rmpfr/dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48: the server could not find the requested resource (get pods dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48)
Mar 27 20:23:33.423: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-rmpfr from pod e2e-tests-dns-rmpfr/dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48: the server could not find the requested resource (get pods dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48)
Mar 27 20:23:33.430: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-rmpfr from pod e2e-tests-dns-rmpfr/dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48: the server could not find the requested resource (get pods dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48)
Mar 27 20:23:33.435: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-rmpfr.svc from pod e2e-tests-dns-rmpfr/dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48: the server could not find the requested resource (get pods dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48)
Mar 27 20:23:33.445: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-rmpfr.svc from pod e2e-tests-dns-rmpfr/dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48: the server could not find the requested resource (get pods dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48)
Mar 27 20:23:33.517: INFO: Lookups using e2e-tests-dns-rmpfr/dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-rmpfr jessie_tcp@dns-test-service.e2e-tests-dns-rmpfr jessie_udp@dns-test-service.e2e-tests-dns-rmpfr.svc jessie_tcp@dns-test-service.e2e-tests-dns-rmpfr.svc]

Mar 27 20:23:38.897: INFO: DNS probes using e2e-tests-dns-rmpfr/dns-test-2ee2abcb-50ce-11e9-9d23-0ac04cf37a48 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:23:39.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-rmpfr" for this suite.
Mar 27 20:23:45.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:23:45.616: INFO: namespace: e2e-tests-dns-rmpfr, resource: bindings, ignored listing per whitelist
Mar 27 20:23:45.673: INFO: namespace e2e-tests-dns-rmpfr deletion completed in 6.296095211s

• [SLOW TEST:16.812 seconds]
[sig-network] DNS
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:23:45.678: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 27 20:23:45.882: INFO: Waiting up to 5m0s for pod "pod-38d692a9-50ce-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-jwstt" to be "success or failure"
Mar 27 20:23:45.913: INFO: Pod "pod-38d692a9-50ce-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 31.22874ms
Mar 27 20:23:47.929: INFO: Pod "pod-38d692a9-50ce-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.046918608s
STEP: Saw pod success
Mar 27 20:23:47.929: INFO: Pod "pod-38d692a9-50ce-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:23:47.939: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-38d692a9-50ce-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 20:23:48.055: INFO: Waiting for pod pod-38d692a9-50ce-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:23:48.070: INFO: Pod pod-38d692a9-50ce-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:23:48.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jwstt" for this suite.
Mar 27 20:23:54.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:23:54.242: INFO: namespace: e2e-tests-emptydir-jwstt, resource: bindings, ignored listing per whitelist
Mar 27 20:23:54.406: INFO: namespace e2e-tests-emptydir-jwstt deletion completed in 6.303592987s

• [SLOW TEST:8.728 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:23:54.411: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-3e157bef-50ce-11e9-9d23-0ac04cf37a48
STEP: Creating secret with name s-test-opt-upd-3e157cb0-50ce-11e9-9d23-0ac04cf37a48
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3e157bef-50ce-11e9-9d23-0ac04cf37a48
STEP: Updating secret s-test-opt-upd-3e157cb0-50ce-11e9-9d23-0ac04cf37a48
STEP: Creating secret with name s-test-opt-create-3e157cdb-50ce-11e9-9d23-0ac04cf37a48
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:25:20.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jrhsm" for this suite.
Mar 27 20:25:44.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:25:44.857: INFO: namespace: e2e-tests-projected-jrhsm, resource: bindings, ignored listing per whitelist
Mar 27 20:25:44.892: INFO: namespace e2e-tests-projected-jrhsm deletion completed in 24.215665306s

• [SLOW TEST:110.481 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:25:44.892: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-fwknj
Mar 27 20:25:47.080: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-fwknj
STEP: checking the pod's current state and verifying that restartCount is present
Mar 27 20:25:47.087: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:29:48.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fwknj" for this suite.
Mar 27 20:29:54.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:29:54.610: INFO: namespace: e2e-tests-container-probe-fwknj, resource: bindings, ignored listing per whitelist
Mar 27 20:29:54.701: INFO: namespace e2e-tests-container-probe-fwknj deletion completed in 6.246396074s

• [SLOW TEST:249.808 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:29:54.701: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 27 20:29:54.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-hkvd6'
Mar 27 20:29:55.054: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 27 20:29:55.054: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Mar 27 20:29:55.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-hkvd6'
Mar 27 20:29:55.351: INFO: stderr: ""
Mar 27 20:29:55.351: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:29:55.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hkvd6" for this suite.
Mar 27 20:30:19.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:30:19.605: INFO: namespace: e2e-tests-kubectl-hkvd6, resource: bindings, ignored listing per whitelist
Mar 27 20:30:19.652: INFO: namespace e2e-tests-kubectl-hkvd6 deletion completed in 24.273704258s

• [SLOW TEST:24.951 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:30:19.654: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 27 20:30:23.987: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:24.012: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 20:30:26.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:26.027: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 20:30:28.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:28.020: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 20:30:30.013: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:30.024: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 20:30:32.013: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:32.023: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 20:30:34.016: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:34.025: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 20:30:36.018: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:36.033: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 20:30:38.013: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:38.019: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 20:30:40.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:40.021: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 20:30:42.013: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:42.021: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 20:30:44.013: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 20:30:44.023: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:30:44.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gmbsj" for this suite.
Mar 27 20:31:08.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:31:08.180: INFO: namespace: e2e-tests-container-lifecycle-hook-gmbsj, resource: bindings, ignored listing per whitelist
Mar 27 20:31:08.384: INFO: namespace e2e-tests-container-lifecycle-hook-gmbsj deletion completed in 24.345300094s

• [SLOW TEST:48.730 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:31:08.388: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-cs8sk
Mar 27 20:31:12.600: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-cs8sk
STEP: checking the pod's current state and verifying that restartCount is present
Mar 27 20:31:12.605: INFO: Initial restart count of pod liveness-exec is 0
Mar 27 20:32:02.865: INFO: Restart count of pod e2e-tests-container-probe-cs8sk/liveness-exec is now 1 (50.260495934s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:32:02.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cs8sk" for this suite.
Mar 27 20:32:08.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:32:09.066: INFO: namespace: e2e-tests-container-probe-cs8sk, resource: bindings, ignored listing per whitelist
Mar 27 20:32:09.205: INFO: namespace e2e-tests-container-probe-cs8sk deletion completed in 6.280880331s

• [SLOW TEST:60.818 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:32:09.210: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 20:32:09.467: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 27 20:32:09.499: INFO: Number of nodes with available pods: 0
Mar 27 20:32:09.499: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 27 20:32:09.589: INFO: Number of nodes with available pods: 0
Mar 27 20:32:09.589: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:10.598: INFO: Number of nodes with available pods: 0
Mar 27 20:32:10.599: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:11.606: INFO: Number of nodes with available pods: 1
Mar 27 20:32:11.606: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 27 20:32:11.720: INFO: Number of nodes with available pods: 1
Mar 27 20:32:11.720: INFO: Number of running nodes: 0, number of available pods: 1
Mar 27 20:32:12.726: INFO: Number of nodes with available pods: 0
Mar 27 20:32:12.726: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 27 20:32:12.759: INFO: Number of nodes with available pods: 0
Mar 27 20:32:12.759: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:13.765: INFO: Number of nodes with available pods: 0
Mar 27 20:32:13.765: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:14.766: INFO: Number of nodes with available pods: 0
Mar 27 20:32:14.766: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:15.767: INFO: Number of nodes with available pods: 0
Mar 27 20:32:15.767: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:16.767: INFO: Number of nodes with available pods: 0
Mar 27 20:32:16.767: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:17.768: INFO: Number of nodes with available pods: 0
Mar 27 20:32:17.769: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:18.770: INFO: Number of nodes with available pods: 0
Mar 27 20:32:18.770: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:19.768: INFO: Number of nodes with available pods: 0
Mar 27 20:32:19.768: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:20.768: INFO: Number of nodes with available pods: 0
Mar 27 20:32:20.768: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:21.764: INFO: Number of nodes with available pods: 0
Mar 27 20:32:21.764: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:22.765: INFO: Number of nodes with available pods: 0
Mar 27 20:32:22.765: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:23.767: INFO: Number of nodes with available pods: 0
Mar 27 20:32:23.768: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:24.767: INFO: Number of nodes with available pods: 0
Mar 27 20:32:24.767: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:25.768: INFO: Number of nodes with available pods: 0
Mar 27 20:32:25.768: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:26.768: INFO: Number of nodes with available pods: 0
Mar 27 20:32:26.770: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:27.765: INFO: Number of nodes with available pods: 0
Mar 27 20:32:27.765: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:28.766: INFO: Number of nodes with available pods: 0
Mar 27 20:32:28.766: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:29.765: INFO: Number of nodes with available pods: 0
Mar 27 20:32:29.765: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:30.767: INFO: Number of nodes with available pods: 0
Mar 27 20:32:30.768: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:31.768: INFO: Number of nodes with available pods: 0
Mar 27 20:32:31.768: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:32.765: INFO: Number of nodes with available pods: 0
Mar 27 20:32:32.765: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:33.768: INFO: Number of nodes with available pods: 0
Mar 27 20:32:33.768: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:34.767: INFO: Number of nodes with available pods: 0
Mar 27 20:32:34.768: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:35.767: INFO: Number of nodes with available pods: 0
Mar 27 20:32:35.768: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:36.768: INFO: Number of nodes with available pods: 0
Mar 27 20:32:36.768: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:37.764: INFO: Number of nodes with available pods: 0
Mar 27 20:32:37.765: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:38.767: INFO: Number of nodes with available pods: 0
Mar 27 20:32:38.767: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:39.775: INFO: Number of nodes with available pods: 0
Mar 27 20:32:39.775: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:40.765: INFO: Number of nodes with available pods: 0
Mar 27 20:32:40.765: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:41.765: INFO: Number of nodes with available pods: 0
Mar 27 20:32:41.765: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:42.766: INFO: Number of nodes with available pods: 0
Mar 27 20:32:42.766: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:43.764: INFO: Number of nodes with available pods: 0
Mar 27 20:32:43.765: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:44.843: INFO: Number of nodes with available pods: 0
Mar 27 20:32:44.843: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:45.765: INFO: Number of nodes with available pods: 0
Mar 27 20:32:45.765: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:32:46.783: INFO: Number of nodes with available pods: 1
Mar 27 20:32:46.783: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-t2w2l, will wait for the garbage collector to delete the pods
Mar 27 20:32:46.914: INFO: Deleting DaemonSet.extensions daemon-set took: 32.051515ms
Mar 27 20:32:47.014: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.249167ms
Mar 27 20:33:30.029: INFO: Number of nodes with available pods: 0
Mar 27 20:33:30.029: INFO: Number of running nodes: 0, number of available pods: 0
Mar 27 20:33:30.036: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-t2w2l/daemonsets","resourceVersion":"175995"},"items":null}

Mar 27 20:33:30.042: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-t2w2l/pods","resourceVersion":"175995"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:33:30.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-t2w2l" for this suite.
Mar 27 20:33:36.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:33:36.363: INFO: namespace: e2e-tests-daemonsets-t2w2l, resource: bindings, ignored listing per whitelist
Mar 27 20:33:36.397: INFO: namespace e2e-tests-daemonsets-t2w2l deletion completed in 6.263792153s

• [SLOW TEST:87.188 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:33:36.398: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar 27 20:33:38.681: INFO: Pod pod-hostip-98f27ab5-50cf-11e9-9d23-0ac04cf37a48 has hostIP: 72.2.115.200
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:33:38.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9dzzp" for this suite.
Mar 27 20:34:02.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:34:02.968: INFO: namespace: e2e-tests-pods-9dzzp, resource: bindings, ignored listing per whitelist
Mar 27 20:34:03.009: INFO: namespace e2e-tests-pods-9dzzp deletion completed in 24.315968957s

• [SLOW TEST:26.611 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:34:03.011: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 20:34:03.170: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8c61d30-50cf-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-qjdxd" to be "success or failure"
Mar 27 20:34:03.177: INFO: Pod "downwardapi-volume-a8c61d30-50cf-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 6.669631ms
Mar 27 20:34:05.183: INFO: Pod "downwardapi-volume-a8c61d30-50cf-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012616081s
STEP: Saw pod success
Mar 27 20:34:05.183: INFO: Pod "downwardapi-volume-a8c61d30-50cf-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:34:05.188: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-a8c61d30-50cf-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 20:34:05.282: INFO: Waiting for pod downwardapi-volume-a8c61d30-50cf-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:34:05.333: INFO: Pod downwardapi-volume-a8c61d30-50cf-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:34:05.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qjdxd" for this suite.
Mar 27 20:34:17.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:34:17.547: INFO: namespace: e2e-tests-downward-api-qjdxd, resource: bindings, ignored listing per whitelist
Mar 27 20:34:17.651: INFO: namespace e2e-tests-downward-api-qjdxd deletion completed in 12.297028658s

• [SLOW TEST:14.640 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:34:17.655: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:34:21.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-zcmwn" for this suite.
Mar 27 20:34:28.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:34:28.147: INFO: namespace: e2e-tests-emptydir-wrapper-zcmwn, resource: bindings, ignored listing per whitelist
Mar 27 20:34:28.271: INFO: namespace e2e-tests-emptydir-wrapper-zcmwn deletion completed in 6.257335062s

• [SLOW TEST:10.616 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:34:28.277: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0327 20:34:34.628630      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 27 20:34:34.628: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:34:34.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bw4v2" for this suite.
Mar 27 20:34:42.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:34:42.931: INFO: namespace: e2e-tests-gc-bw4v2, resource: bindings, ignored listing per whitelist
Mar 27 20:34:43.067: INFO: namespace e2e-tests-gc-bw4v2 deletion completed in 8.391747679s

• [SLOW TEST:14.791 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:34:43.077: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 20:34:43.335: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0b62275-50cf-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-84hll" to be "success or failure"
Mar 27 20:34:43.369: INFO: Pod "downwardapi-volume-c0b62275-50cf-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 33.667394ms
Mar 27 20:34:45.374: INFO: Pod "downwardapi-volume-c0b62275-50cf-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03894329s
STEP: Saw pod success
Mar 27 20:34:45.374: INFO: Pod "downwardapi-volume-c0b62275-50cf-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:34:45.379: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-c0b62275-50cf-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 20:34:45.445: INFO: Waiting for pod downwardapi-volume-c0b62275-50cf-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:34:45.465: INFO: Pod downwardapi-volume-c0b62275-50cf-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:34:45.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-84hll" for this suite.
Mar 27 20:34:51.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:34:51.668: INFO: namespace: e2e-tests-projected-84hll, resource: bindings, ignored listing per whitelist
Mar 27 20:34:51.773: INFO: namespace e2e-tests-projected-84hll deletion completed in 6.26934953s

• [SLOW TEST:8.697 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:34:51.774: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 27 20:34:51.931: INFO: Waiting up to 5m0s for pod "pod-c5d4a9e2-50cf-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-s5wgh" to be "success or failure"
Mar 27 20:34:51.936: INFO: Pod "pod-c5d4a9e2-50cf-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 5.522182ms
Mar 27 20:34:53.948: INFO: Pod "pod-c5d4a9e2-50cf-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017316997s
STEP: Saw pod success
Mar 27 20:34:53.948: INFO: Pod "pod-c5d4a9e2-50cf-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:34:53.956: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-c5d4a9e2-50cf-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 20:34:54.107: INFO: Waiting for pod pod-c5d4a9e2-50cf-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:34:54.117: INFO: Pod pod-c5d4a9e2-50cf-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:34:54.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s5wgh" for this suite.
Mar 27 20:35:00.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:35:00.371: INFO: namespace: e2e-tests-emptydir-s5wgh, resource: bindings, ignored listing per whitelist
Mar 27 20:35:00.448: INFO: namespace e2e-tests-emptydir-s5wgh deletion completed in 6.26745863s

• [SLOW TEST:8.674 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:35:00.450: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 20:35:00.662: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cb0840b4-50cf-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-lwnwk" to be "success or failure"
Mar 27 20:35:00.678: INFO: Pod "downwardapi-volume-cb0840b4-50cf-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 16.10908ms
Mar 27 20:35:02.685: INFO: Pod "downwardapi-volume-cb0840b4-50cf-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023213201s
STEP: Saw pod success
Mar 27 20:35:02.686: INFO: Pod "downwardapi-volume-cb0840b4-50cf-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:35:02.719: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-cb0840b4-50cf-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 20:35:02.843: INFO: Waiting for pod downwardapi-volume-cb0840b4-50cf-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:35:02.852: INFO: Pod downwardapi-volume-cb0840b4-50cf-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:35:02.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lwnwk" for this suite.
Mar 27 20:35:08.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:35:09.029: INFO: namespace: e2e-tests-downward-api-lwnwk, resource: bindings, ignored listing per whitelist
Mar 27 20:35:09.143: INFO: namespace e2e-tests-downward-api-lwnwk deletion completed in 6.251234079s

• [SLOW TEST:8.694 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:35:09.149: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-6l9n
STEP: Creating a pod to test atomic-volume-subpath
Mar 27 20:35:09.318: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6l9n" in namespace "e2e-tests-subpath-r2zdf" to be "success or failure"
Mar 27 20:35:09.347: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Pending", Reason="", readiness=false. Elapsed: 29.148918ms
Mar 27 20:35:11.368: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049894807s
Mar 27 20:35:13.374: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Running", Reason="", readiness=false. Elapsed: 4.055194296s
Mar 27 20:35:15.382: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Running", Reason="", readiness=false. Elapsed: 6.063279113s
Mar 27 20:35:17.387: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Running", Reason="", readiness=false. Elapsed: 8.068415517s
Mar 27 20:35:19.397: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Running", Reason="", readiness=false. Elapsed: 10.078194003s
Mar 27 20:35:21.405: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Running", Reason="", readiness=false. Elapsed: 12.086219591s
Mar 27 20:35:23.415: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Running", Reason="", readiness=false. Elapsed: 14.096742995s
Mar 27 20:35:25.426: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Running", Reason="", readiness=false. Elapsed: 16.107835994s
Mar 27 20:35:27.432: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Running", Reason="", readiness=false. Elapsed: 18.113840269s
Mar 27 20:35:29.438: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Running", Reason="", readiness=false. Elapsed: 20.119754405s
Mar 27 20:35:31.444: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Running", Reason="", readiness=false. Elapsed: 22.125653007s
Mar 27 20:35:33.457: INFO: Pod "pod-subpath-test-configmap-6l9n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.138785576s
STEP: Saw pod success
Mar 27 20:35:33.458: INFO: Pod "pod-subpath-test-configmap-6l9n" satisfied condition "success or failure"
Mar 27 20:35:33.465: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-subpath-test-configmap-6l9n container test-container-subpath-configmap-6l9n: <nil>
STEP: delete the pod
Mar 27 20:35:33.549: INFO: Waiting for pod pod-subpath-test-configmap-6l9n to disappear
Mar 27 20:35:33.592: INFO: Pod pod-subpath-test-configmap-6l9n no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6l9n
Mar 27 20:35:33.593: INFO: Deleting pod "pod-subpath-test-configmap-6l9n" in namespace "e2e-tests-subpath-r2zdf"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:35:33.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-r2zdf" for this suite.
Mar 27 20:35:39.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:35:39.720: INFO: namespace: e2e-tests-subpath-r2zdf, resource: bindings, ignored listing per whitelist
Mar 27 20:35:39.905: INFO: namespace e2e-tests-subpath-r2zdf deletion completed in 6.292562236s

• [SLOW TEST:30.756 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:35:39.907: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hm2jh
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 27 20:35:40.052: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 27 20:36:02.442: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.4.80:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hm2jh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 20:36:02.442: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:36:02.696: INFO: Found all expected endpoints: [netserver-0]
Mar 27 20:36:02.702: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.41:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hm2jh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 20:36:02.702: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:36:02.904: INFO: Found all expected endpoints: [netserver-1]
Mar 27 20:36:02.912: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.3.58:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hm2jh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 20:36:02.912: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:36:03.065: INFO: Found all expected endpoints: [netserver-2]
Mar 27 20:36:03.071: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.2.64:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hm2jh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 20:36:03.071: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:36:03.208: INFO: Found all expected endpoints: [netserver-3]
Mar 27 20:36:03.216: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.0.65:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hm2jh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 20:36:03.216: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:36:03.365: INFO: Found all expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:36:03.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hm2jh" for this suite.
Mar 27 20:36:27.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:36:27.549: INFO: namespace: e2e-tests-pod-network-test-hm2jh, resource: bindings, ignored listing per whitelist
Mar 27 20:36:27.660: INFO: namespace e2e-tests-pod-network-test-hm2jh deletion completed in 24.281801733s

• [SLOW TEST:47.754 seconds]
[sig-network] Networking
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:36:27.675: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 27 20:36:27.870: INFO: namespace e2e-tests-kubectl-5kb6h
Mar 27 20:36:27.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-5kb6h'
Mar 27 20:36:28.802: INFO: stderr: ""
Mar 27 20:36:28.802: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 27 20:36:29.814: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 20:36:29.815: INFO: Found 0 / 1
Mar 27 20:36:30.812: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 20:36:30.812: INFO: Found 1 / 1
Mar 27 20:36:30.812: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 27 20:36:30.833: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 20:36:30.834: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 27 20:36:30.835: INFO: wait on redis-master startup in e2e-tests-kubectl-5kb6h 
Mar 27 20:36:30.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 logs redis-master-4vkhn redis-master --namespace=e2e-tests-kubectl-5kb6h'
Mar 27 20:36:31.042: INFO: stderr: ""
Mar 27 20:36:31.042: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Mar 20:36:30.072 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Mar 20:36:30.072 # Server started, Redis version 3.2.12\n1:M 27 Mar 20:36:30.073 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Mar 20:36:30.073 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar 27 20:36:31.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-5kb6h'
Mar 27 20:36:31.293: INFO: stderr: ""
Mar 27 20:36:31.293: INFO: stdout: "service/rm2 exposed\n"
Mar 27 20:36:31.301: INFO: Service rm2 in namespace e2e-tests-kubectl-5kb6h found.
STEP: exposing service
Mar 27 20:36:33.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-5kb6h'
Mar 27 20:36:33.516: INFO: stderr: ""
Mar 27 20:36:33.516: INFO: stdout: "service/rm3 exposed\n"
Mar 27 20:36:33.535: INFO: Service rm3 in namespace e2e-tests-kubectl-5kb6h found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:36:35.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5kb6h" for this suite.
Mar 27 20:36:59.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:36:59.695: INFO: namespace: e2e-tests-kubectl-5kb6h, resource: bindings, ignored listing per whitelist
Mar 27 20:36:59.808: INFO: namespace e2e-tests-kubectl-5kb6h deletion completed in 24.253300756s

• [SLOW TEST:32.134 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:36:59.812: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 27 20:37:00.020: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-a,UID:1230b5bb-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177018,Generation:0,CreationTimestamp:2019-03-27 20:37:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 27 20:37:00.021: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-a,UID:1230b5bb-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177018,Generation:0,CreationTimestamp:2019-03-27 20:37:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 27 20:37:10.043: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-a,UID:1230b5bb-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177036,Generation:0,CreationTimestamp:2019-03-27 20:37:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 27 20:37:10.043: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-a,UID:1230b5bb-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177036,Generation:0,CreationTimestamp:2019-03-27 20:37:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 27 20:37:20.069: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-a,UID:1230b5bb-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177054,Generation:0,CreationTimestamp:2019-03-27 20:37:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 27 20:37:20.069: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-a,UID:1230b5bb-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177054,Generation:0,CreationTimestamp:2019-03-27 20:37:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 27 20:37:30.090: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-a,UID:1230b5bb-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177072,Generation:0,CreationTimestamp:2019-03-27 20:37:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 27 20:37:30.091: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-a,UID:1230b5bb-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177072,Generation:0,CreationTimestamp:2019-03-27 20:37:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 27 20:37:40.114: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-b,UID:2a14e19f-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177090,Generation:0,CreationTimestamp:2019-03-27 20:37:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 27 20:37:40.115: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-b,UID:2a14e19f-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177090,Generation:0,CreationTimestamp:2019-03-27 20:37:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 27 20:37:50.143: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-b,UID:2a14e19f-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177108,Generation:0,CreationTimestamp:2019-03-27 20:37:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 27 20:37:50.143: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-cwm4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-cwm4p/configmaps/e2e-watch-test-configmap-b,UID:2a14e19f-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:177108,Generation:0,CreationTimestamp:2019-03-27 20:37:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:38:00.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-cwm4p" for this suite.
Mar 27 20:38:06.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:38:06.317: INFO: namespace: e2e-tests-watch-cwm4p, resource: bindings, ignored listing per whitelist
Mar 27 20:38:06.441: INFO: namespace e2e-tests-watch-cwm4p deletion completed in 6.28668592s

• [SLOW TEST:66.630 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:38:06.446: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:38:31.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-5wp2b" for this suite.
Mar 27 20:38:37.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:38:37.542: INFO: namespace: e2e-tests-container-runtime-5wp2b, resource: bindings, ignored listing per whitelist
Mar 27 20:38:37.691: INFO: namespace e2e-tests-container-runtime-5wp2b deletion completed in 6.260833686s

• [SLOW TEST:31.246 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:38:37.700: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-4c833e2e-50d0-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 20:38:37.895: INFO: Waiting up to 5m0s for pod "pod-secrets-4c850a7d-50d0-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-secrets-v5wt5" to be "success or failure"
Mar 27 20:38:37.924: INFO: Pod "pod-secrets-4c850a7d-50d0-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 28.907547ms
Mar 27 20:38:39.936: INFO: Pod "pod-secrets-4c850a7d-50d0-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040255568s
STEP: Saw pod success
Mar 27 20:38:39.936: INFO: Pod "pod-secrets-4c850a7d-50d0-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:38:39.952: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-secrets-4c850a7d-50d0-11e9-9d23-0ac04cf37a48 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 20:38:40.035: INFO: Waiting for pod pod-secrets-4c850a7d-50d0-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:38:40.051: INFO: Pod pod-secrets-4c850a7d-50d0-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:38:40.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v5wt5" for this suite.
Mar 27 20:38:46.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:38:46.261: INFO: namespace: e2e-tests-secrets-v5wt5, resource: bindings, ignored listing per whitelist
Mar 27 20:38:46.496: INFO: namespace e2e-tests-secrets-v5wt5 deletion completed in 6.400526245s

• [SLOW TEST:8.796 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:38:46.496: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-drl9g
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-drl9g
STEP: Deleting pre-stop pod
Mar 27 20:38:57.784: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:38:57.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-drl9g" for this suite.
Mar 27 20:39:35.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:39:36.060: INFO: namespace: e2e-tests-prestop-drl9g, resource: bindings, ignored listing per whitelist
Mar 27 20:39:36.086: INFO: namespace e2e-tests-prestop-drl9g deletion completed in 38.253292478s

• [SLOW TEST:49.590 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:39:36.088: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-6f4f9fdf-50d0-11e9-9d23-0ac04cf37a48
STEP: Creating secret with name s-test-opt-upd-6f4fa026-50d0-11e9-9d23-0ac04cf37a48
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6f4f9fdf-50d0-11e9-9d23-0ac04cf37a48
STEP: Updating secret s-test-opt-upd-6f4fa026-50d0-11e9-9d23-0ac04cf37a48
STEP: Creating secret with name s-test-opt-create-6f4fa043-50d0-11e9-9d23-0ac04cf37a48
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:41:11.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cdzr9" for this suite.
Mar 27 20:41:35.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:41:36.066: INFO: namespace: e2e-tests-secrets-cdzr9, resource: bindings, ignored listing per whitelist
Mar 27 20:41:36.167: INFO: namespace e2e-tests-secrets-cdzr9 deletion completed in 24.322954979s

• [SLOW TEST:120.079 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:41:36.170: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 20:41:36.410: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b6eb2fbd-50d0-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-49m8r" to be "success or failure"
Mar 27 20:41:36.430: INFO: Pod "downwardapi-volume-b6eb2fbd-50d0-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 18.912947ms
Mar 27 20:41:38.441: INFO: Pod "downwardapi-volume-b6eb2fbd-50d0-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.030023158s
Mar 27 20:41:40.451: INFO: Pod "downwardapi-volume-b6eb2fbd-50d0-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040457826s
STEP: Saw pod success
Mar 27 20:41:40.451: INFO: Pod "downwardapi-volume-b6eb2fbd-50d0-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:41:40.463: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-b6eb2fbd-50d0-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 20:41:40.560: INFO: Waiting for pod downwardapi-volume-b6eb2fbd-50d0-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:41:40.567: INFO: Pod downwardapi-volume-b6eb2fbd-50d0-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:41:40.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-49m8r" for this suite.
Mar 27 20:41:46.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:41:46.871: INFO: namespace: e2e-tests-projected-49m8r, resource: bindings, ignored listing per whitelist
Mar 27 20:41:46.915: INFO: namespace e2e-tests-projected-49m8r deletion completed in 6.329943491s

• [SLOW TEST:10.745 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:41:46.920: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar 27 20:41:47.688: INFO: created pod pod-service-account-defaultsa
Mar 27 20:41:47.688: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 27 20:41:47.710: INFO: created pod pod-service-account-mountsa
Mar 27 20:41:47.710: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 27 20:41:47.729: INFO: created pod pod-service-account-nomountsa
Mar 27 20:41:47.729: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 27 20:41:47.755: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 27 20:41:47.755: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 27 20:41:47.849: INFO: created pod pod-service-account-mountsa-mountspec
Mar 27 20:41:47.849: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 27 20:41:47.904: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 27 20:41:47.904: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 27 20:41:48.003: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 27 20:41:48.003: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 27 20:41:48.055: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 27 20:41:48.055: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 27 20:41:48.153: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 27 20:41:48.153: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:41:48.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-pf9b8" for this suite.
Mar 27 20:41:56.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:41:56.545: INFO: namespace: e2e-tests-svcaccounts-pf9b8, resource: bindings, ignored listing per whitelist
Mar 27 20:41:56.632: INFO: namespace e2e-tests-svcaccounts-pf9b8 deletion completed in 8.410993498s

• [SLOW TEST:9.713 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:41:56.633: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c30d9cbc-50d0-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 20:41:56.771: INFO: Waiting up to 5m0s for pod "pod-configmaps-c30fd144-50d0-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-configmap-ltl86" to be "success or failure"
Mar 27 20:41:56.788: INFO: Pod "pod-configmaps-c30fd144-50d0-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 17.190694ms
Mar 27 20:41:58.796: INFO: Pod "pod-configmaps-c30fd144-50d0-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02455501s
STEP: Saw pod success
Mar 27 20:41:58.796: INFO: Pod "pod-configmaps-c30fd144-50d0-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:41:58.801: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-configmaps-c30fd144-50d0-11e9-9d23-0ac04cf37a48 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 20:41:58.870: INFO: Waiting for pod pod-configmaps-c30fd144-50d0-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:41:58.876: INFO: Pod pod-configmaps-c30fd144-50d0-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:41:58.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ltl86" for this suite.
Mar 27 20:42:04.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:42:05.083: INFO: namespace: e2e-tests-configmap-ltl86, resource: bindings, ignored listing per whitelist
Mar 27 20:42:05.177: INFO: namespace e2e-tests-configmap-ltl86 deletion completed in 6.277940117s

• [SLOW TEST:8.544 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:42:05.182: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:42:07.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-zjrwk" for this suite.
Mar 27 20:42:47.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:42:47.644: INFO: namespace: e2e-tests-kubelet-test-zjrwk, resource: bindings, ignored listing per whitelist
Mar 27 20:42:47.874: INFO: namespace e2e-tests-kubelet-test-zjrwk deletion completed in 40.327464892s

• [SLOW TEST:42.692 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:42:47.874: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 20:42:48.051: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 27 20:42:53.058: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 27 20:42:53.059: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 27 20:42:53.097: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-j7469,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j7469/deployments/test-cleanup-deployment,UID:e4a0f067-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:178074,Generation:1,CreationTimestamp:2019-03-27 20:42:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar 27 20:42:53.104: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:42:53.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-j7469" for this suite.
Mar 27 20:43:01.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:43:01.371: INFO: namespace: e2e-tests-deployment-j7469, resource: bindings, ignored listing per whitelist
Mar 27 20:43:01.405: INFO: namespace e2e-tests-deployment-j7469 deletion completed in 8.274793938s

• [SLOW TEST:13.531 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:43:01.409: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 27 20:43:01.604: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vrgkc,SelfLink:/api/v1/namespaces/e2e-tests-watch-vrgkc/configmaps/e2e-watch-test-label-changed,UID:e9b039b4-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:178160,Generation:0,CreationTimestamp:2019-03-27 20:43:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 27 20:43:01.604: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vrgkc,SelfLink:/api/v1/namespaces/e2e-tests-watch-vrgkc/configmaps/e2e-watch-test-label-changed,UID:e9b039b4-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:178161,Generation:0,CreationTimestamp:2019-03-27 20:43:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 27 20:43:01.604: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vrgkc,SelfLink:/api/v1/namespaces/e2e-tests-watch-vrgkc/configmaps/e2e-watch-test-label-changed,UID:e9b039b4-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:178163,Generation:0,CreationTimestamp:2019-03-27 20:43:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 27 20:43:11.676: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vrgkc,SelfLink:/api/v1/namespaces/e2e-tests-watch-vrgkc/configmaps/e2e-watch-test-label-changed,UID:e9b039b4-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:178182,Generation:0,CreationTimestamp:2019-03-27 20:43:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 27 20:43:11.676: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vrgkc,SelfLink:/api/v1/namespaces/e2e-tests-watch-vrgkc/configmaps/e2e-watch-test-label-changed,UID:e9b039b4-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:178183,Generation:0,CreationTimestamp:2019-03-27 20:43:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 27 20:43:11.677: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vrgkc,SelfLink:/api/v1/namespaces/e2e-tests-watch-vrgkc/configmaps/e2e-watch-test-label-changed,UID:e9b039b4-50d0-11e9-8df3-90b8d03c5288,ResourceVersion:178184,Generation:0,CreationTimestamp:2019-03-27 20:43:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:43:11.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-vrgkc" for this suite.
Mar 27 20:43:17.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:43:17.768: INFO: namespace: e2e-tests-watch-vrgkc, resource: bindings, ignored listing per whitelist
Mar 27 20:43:17.973: INFO: namespace e2e-tests-watch-vrgkc deletion completed in 6.283733145s

• [SLOW TEST:16.565 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:43:17.973: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-f38c6f23-50d0-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 20:43:18.124: INFO: Waiting up to 5m0s for pod "pod-configmaps-f38d9229-50d0-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-configmap-j84xl" to be "success or failure"
Mar 27 20:43:18.137: INFO: Pod "pod-configmaps-f38d9229-50d0-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 13.652701ms
Mar 27 20:43:20.142: INFO: Pod "pod-configmaps-f38d9229-50d0-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018334647s
STEP: Saw pod success
Mar 27 20:43:20.142: INFO: Pod "pod-configmaps-f38d9229-50d0-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:43:20.148: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-configmaps-f38d9229-50d0-11e9-9d23-0ac04cf37a48 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 20:43:20.236: INFO: Waiting for pod pod-configmaps-f38d9229-50d0-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:43:20.267: INFO: Pod pod-configmaps-f38d9229-50d0-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:43:20.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-j84xl" for this suite.
Mar 27 20:43:26.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:43:26.470: INFO: namespace: e2e-tests-configmap-j84xl, resource: bindings, ignored listing per whitelist
Mar 27 20:43:26.673: INFO: namespace e2e-tests-configmap-j84xl deletion completed in 6.325542995s

• [SLOW TEST:8.700 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:43:26.677: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:43:28.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-ng8dv" for this suite.
Mar 27 20:44:08.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:44:09.242: INFO: namespace: e2e-tests-kubelet-test-ng8dv, resource: bindings, ignored listing per whitelist
Mar 27 20:44:09.254: INFO: namespace e2e-tests-kubelet-test-ng8dv deletion completed in 40.313046498s

• [SLOW TEST:42.577 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:44:09.258: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar 27 20:44:10.124: INFO: Pod name wrapped-volume-race-128638ae-50d1-11e9-9d23-0ac04cf37a48: Found 0 pods out of 5
Mar 27 20:44:15.227: INFO: Pod name wrapped-volume-race-128638ae-50d1-11e9-9d23-0ac04cf37a48: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-128638ae-50d1-11e9-9d23-0ac04cf37a48 in namespace e2e-tests-emptydir-wrapper-g74w9, will wait for the garbage collector to delete the pods
Mar 27 20:44:25.495: INFO: Deleting ReplicationController wrapped-volume-race-128638ae-50d1-11e9-9d23-0ac04cf37a48 took: 36.832318ms
Mar 27 20:44:25.795: INFO: Terminating ReplicationController wrapped-volume-race-128638ae-50d1-11e9-9d23-0ac04cf37a48 pods took: 300.546083ms
STEP: Creating RC which spawns configmap-volume pods
Mar 27 20:45:10.702: INFO: Pod name wrapped-volume-race-369a13df-50d1-11e9-9d23-0ac04cf37a48: Found 0 pods out of 5
Mar 27 20:45:15.713: INFO: Pod name wrapped-volume-race-369a13df-50d1-11e9-9d23-0ac04cf37a48: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-369a13df-50d1-11e9-9d23-0ac04cf37a48 in namespace e2e-tests-emptydir-wrapper-g74w9, will wait for the garbage collector to delete the pods
Mar 27 20:45:27.829: INFO: Deleting ReplicationController wrapped-volume-race-369a13df-50d1-11e9-9d23-0ac04cf37a48 took: 19.889984ms
Mar 27 20:45:28.130: INFO: Terminating ReplicationController wrapped-volume-race-369a13df-50d1-11e9-9d23-0ac04cf37a48 pods took: 300.37919ms
STEP: Creating RC which spawns configmap-volume pods
Mar 27 20:46:10.270: INFO: Pod name wrapped-volume-race-5a2579a2-50d1-11e9-9d23-0ac04cf37a48: Found 0 pods out of 5
Mar 27 20:46:15.290: INFO: Pod name wrapped-volume-race-5a2579a2-50d1-11e9-9d23-0ac04cf37a48: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5a2579a2-50d1-11e9-9d23-0ac04cf37a48 in namespace e2e-tests-emptydir-wrapper-g74w9, will wait for the garbage collector to delete the pods
Mar 27 20:46:27.474: INFO: Deleting ReplicationController wrapped-volume-race-5a2579a2-50d1-11e9-9d23-0ac04cf37a48 took: 45.386483ms
Mar 27 20:46:27.775: INFO: Terminating ReplicationController wrapped-volume-race-5a2579a2-50d1-11e9-9d23-0ac04cf37a48 pods took: 300.584509ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:47:11.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-g74w9" for this suite.
Mar 27 20:47:21.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:47:21.149: INFO: namespace: e2e-tests-emptydir-wrapper-g74w9, resource: bindings, ignored listing per whitelist
Mar 27 20:47:21.274: INFO: namespace e2e-tests-emptydir-wrapper-g74w9 deletion completed in 10.257453384s

• [SLOW TEST:192.017 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:47:21.279: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-849424ef-50d1-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 20:47:21.467: INFO: Waiting up to 5m0s for pod "pod-secrets-8495d736-50d1-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-secrets-t6664" to be "success or failure"
Mar 27 20:47:21.498: INFO: Pod "pod-secrets-8495d736-50d1-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 31.051947ms
Mar 27 20:47:23.505: INFO: Pod "pod-secrets-8495d736-50d1-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.037881176s
Mar 27 20:47:25.511: INFO: Pod "pod-secrets-8495d736-50d1-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044180942s
STEP: Saw pod success
Mar 27 20:47:25.511: INFO: Pod "pod-secrets-8495d736-50d1-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:47:25.515: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-secrets-8495d736-50d1-11e9-9d23-0ac04cf37a48 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 20:47:25.593: INFO: Waiting for pod pod-secrets-8495d736-50d1-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:47:25.613: INFO: Pod pod-secrets-8495d736-50d1-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:47:25.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t6664" for this suite.
Mar 27 20:47:31.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:47:31.685: INFO: namespace: e2e-tests-secrets-t6664, resource: bindings, ignored listing per whitelist
Mar 27 20:47:31.850: INFO: namespace e2e-tests-secrets-t6664 deletion completed in 6.224500715s

• [SLOW TEST:10.572 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:47:31.851: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 27 20:47:32.019: INFO: Waiting up to 5m0s for pod "pod-8ae28e9a-50d1-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-xbn4v" to be "success or failure"
Mar 27 20:47:32.038: INFO: Pod "pod-8ae28e9a-50d1-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 19.468579ms
Mar 27 20:47:34.044: INFO: Pod "pod-8ae28e9a-50d1-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.024913728s
Mar 27 20:47:36.058: INFO: Pod "pod-8ae28e9a-50d1-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039372461s
STEP: Saw pod success
Mar 27 20:47:36.060: INFO: Pod "pod-8ae28e9a-50d1-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:47:36.078: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-8ae28e9a-50d1-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 20:47:36.150: INFO: Waiting for pod pod-8ae28e9a-50d1-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:47:36.164: INFO: Pod pod-8ae28e9a-50d1-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:47:36.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xbn4v" for this suite.
Mar 27 20:47:42.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:47:42.356: INFO: namespace: e2e-tests-emptydir-xbn4v, resource: bindings, ignored listing per whitelist
Mar 27 20:47:42.415: INFO: namespace e2e-tests-emptydir-xbn4v deletion completed in 6.233301878s

• [SLOW TEST:10.564 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:47:42.418: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-912c2766-50d1-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 20:47:42.589: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-912dfa81-50d1-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-l8z65" to be "success or failure"
Mar 27 20:47:42.616: INFO: Pod "pod-projected-configmaps-912dfa81-50d1-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 25.99903ms
Mar 27 20:47:44.621: INFO: Pod "pod-projected-configmaps-912dfa81-50d1-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031589135s
STEP: Saw pod success
Mar 27 20:47:44.621: INFO: Pod "pod-projected-configmaps-912dfa81-50d1-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:47:44.627: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-configmaps-912dfa81-50d1-11e9-9d23-0ac04cf37a48 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 20:47:44.697: INFO: Waiting for pod pod-projected-configmaps-912dfa81-50d1-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:47:44.735: INFO: Pod pod-projected-configmaps-912dfa81-50d1-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:47:44.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l8z65" for this suite.
Mar 27 20:47:50.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:47:51.045: INFO: namespace: e2e-tests-projected-l8z65, resource: bindings, ignored listing per whitelist
Mar 27 20:47:51.136: INFO: namespace e2e-tests-projected-l8z65 deletion completed in 6.328820801s

• [SLOW TEST:8.718 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:47:51.142: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 27 20:47:51.401: INFO: Number of nodes with available pods: 0
Mar 27 20:47:51.401: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:47:52.527: INFO: Number of nodes with available pods: 1
Mar 27 20:47:52.527: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 20:47:53.438: INFO: Number of nodes with available pods: 4
Mar 27 20:47:53.438: INFO: Node k8s-conformance-cluster-1-13-etcd-1 is running more than one daemon pod
Mar 27 20:47:54.421: INFO: Number of nodes with available pods: 5
Mar 27 20:47:54.421: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 27 20:47:54.471: INFO: Number of nodes with available pods: 4
Mar 27 20:47:54.471: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 20:47:55.511: INFO: Number of nodes with available pods: 4
Mar 27 20:47:55.512: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 20:47:56.498: INFO: Number of nodes with available pods: 5
Mar 27 20:47:56.498: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-r9tgn, will wait for the garbage collector to delete the pods
Mar 27 20:47:56.586: INFO: Deleting DaemonSet.extensions daemon-set took: 23.166157ms
Mar 27 20:47:56.687: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.262842ms
Mar 27 20:48:36.699: INFO: Number of nodes with available pods: 0
Mar 27 20:48:36.699: INFO: Number of running nodes: 0, number of available pods: 0
Mar 27 20:48:36.704: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-r9tgn/daemonsets","resourceVersion":"179907"},"items":null}

Mar 27 20:48:36.712: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-r9tgn/pods","resourceVersion":"179907"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:48:36.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-r9tgn" for this suite.
Mar 27 20:48:42.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:48:42.996: INFO: namespace: e2e-tests-daemonsets-r9tgn, resource: bindings, ignored listing per whitelist
Mar 27 20:48:43.001: INFO: namespace e2e-tests-daemonsets-r9tgn deletion completed in 6.21397915s

• [SLOW TEST:51.860 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:48:43.002: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 27 20:48:43.146: INFO: Waiting up to 5m0s for pod "pod-b5480ed1-50d1-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-rg2dm" to be "success or failure"
Mar 27 20:48:43.181: INFO: Pod "pod-b5480ed1-50d1-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 34.675488ms
Mar 27 20:48:45.188: INFO: Pod "pod-b5480ed1-50d1-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.041470937s
STEP: Saw pod success
Mar 27 20:48:45.188: INFO: Pod "pod-b5480ed1-50d1-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:48:45.195: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-b5480ed1-50d1-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 20:48:45.272: INFO: Waiting for pod pod-b5480ed1-50d1-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:48:45.307: INFO: Pod pod-b5480ed1-50d1-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:48:45.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rg2dm" for this suite.
Mar 27 20:48:51.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:48:51.524: INFO: namespace: e2e-tests-emptydir-rg2dm, resource: bindings, ignored listing per whitelist
Mar 27 20:48:51.695: INFO: namespace e2e-tests-emptydir-rg2dm deletion completed in 6.372411683s

• [SLOW TEST:8.694 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:48:51.704: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 27 20:48:51.909: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 27 20:48:51.936: INFO: Waiting for terminating namespaces to be deleted...
Mar 27 20:48:51.942: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-control-1 before test
Mar 27 20:48:51.956: INFO: rke-ingress-controller-deploy-job-8s8mv from kube-system started at 2019-03-26 20:45:05 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.956: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 27 20:48:51.957: INFO: cattle-node-agent-bx6pt from cattle-system started at 2019-03-26 20:45:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.957: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:48:51.957: INFO: rke-kubedns-addon-deploy-job-8pplg from kube-system started at 2019-03-26 20:44:54 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.957: INFO: 	Container rke-kubedns-addon-pod ready: false, restart count 0
Mar 27 20:48:51.957: INFO: rke-metrics-addon-deploy-job-pm9qz from kube-system started at 2019-03-26 20:44:59 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.957: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 27 20:48:51.957: INFO: nginx-ingress-controller-mw49v from ingress-nginx started at 2019-03-26 21:11:22 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.957: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:48:51.957: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-bmkpx from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:48:51.957: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:48:51.957: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:48:51.957: INFO: rke-network-plugin-deploy-job-sffcc from kube-system started at 2019-03-26 20:44:49 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.958: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 27 20:48:51.958: INFO: calico-node-ns648 from kube-system started at 2019-03-26 20:44:52 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.958: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:48:51.958: INFO: sonobuoy-e2e-job-b3f04bfb1b6b4be0 from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:48:51.958: INFO: 	Container e2e ready: true, restart count 0
Mar 27 20:48:51.958: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:48:51.958: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-etcd-1 before test
Mar 27 20:48:51.973: INFO: cattle-node-agent-kh475 from cattle-system started at 2019-03-26 20:45:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.973: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:48:51.973: INFO: nginx-ingress-controller-hfgxf from ingress-nginx started at 2019-03-26 21:11:17 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.973: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:48:51.973: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-dk7z4 from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:48:51.974: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:48:51.974: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:48:51.974: INFO: calico-node-54w8d from kube-system started at 2019-03-26 20:44:52 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.974: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:48:51.974: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-worker-1 before test
Mar 27 20:48:51.987: INFO: calico-node-k5mgj from kube-system started at 2019-03-26 20:46:15 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.987: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:48:51.987: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-x8vsv from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:48:51.987: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:48:51.987: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:48:51.987: INFO: kube-dns-autoscaler-c89df977f-dlths from kube-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.987: INFO: 	Container autoscaler ready: true, restart count 0
Mar 27 20:48:51.987: INFO: default-http-backend-7f8fbb85db-lwxbh from ingress-nginx started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.987: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 27 20:48:51.987: INFO: nginx-ingress-controller-rn5b5 from ingress-nginx started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.987: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:48:51.987: INFO: cattle-node-agent-9jv82 from cattle-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.988: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:48:51.988: INFO: cattle-cluster-agent-6db87bf6bc-p669p from cattle-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.988: INFO: 	Container cluster-register ready: true, restart count 0
Mar 27 20:48:51.988: INFO: kube-dns-5fd74c7488-z4wvz from kube-system started at 2019-03-26 20:46:25 +0000 UTC (3 container statuses recorded)
Mar 27 20:48:51.988: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 27 20:48:51.988: INFO: 	Container kubedns ready: true, restart count 0
Mar 27 20:48:51.988: INFO: 	Container sidecar ready: true, restart count 0
Mar 27 20:48:51.988: INFO: metrics-server-7fbd549b78-dl4j5 from kube-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:51.988: INFO: 	Container metrics-server ready: true, restart count 0
Mar 27 20:48:51.988: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-worker-2 before test
Mar 27 20:48:52.003: INFO: calico-node-297zr from kube-system started at 2019-03-26 20:46:55 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:52.004: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:48:52.004: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-27 20:22:57 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:52.004: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 27 20:48:52.004: INFO: nginx-ingress-controller-kzs5s from ingress-nginx started at 2019-03-26 20:47:15 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:52.004: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:48:52.005: INFO: cattle-node-agent-sshz4 from cattle-system started at 2019-03-26 20:47:15 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:52.005: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:48:52.005: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-x92wh from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:48:52.005: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:48:52.005: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:48:52.005: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-worker-3 before test
Mar 27 20:48:52.022: INFO: nginx-ingress-controller-dqt72 from ingress-nginx started at 2019-03-26 20:46:41 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:52.022: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:48:52.023: INFO: cattle-node-agent-5hjvr from cattle-system started at 2019-03-26 20:46:41 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:52.023: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:48:52.023: INFO: calico-node-fdvdd from kube-system started at 2019-03-26 20:46:31 +0000 UTC (1 container statuses recorded)
Mar 27 20:48:52.023: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:48:52.023: INFO: kube-dns-5fd74c7488-l5xxd from kube-system started at 2019-03-26 20:46:58 +0000 UTC (3 container statuses recorded)
Mar 27 20:48:52.023: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 27 20:48:52.023: INFO: 	Container kubedns ready: true, restart count 0
Mar 27 20:48:52.023: INFO: 	Container sidecar ready: true, restart count 0
Mar 27 20:48:52.023: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-xxzjw from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:48:52.023: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:48:52.023: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158febdd475c7e26], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:48:53.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-6jbhh" for this suite.
Mar 27 20:48:59.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:48:59.275: INFO: namespace: e2e-tests-sched-pred-6jbhh, resource: bindings, ignored listing per whitelist
Mar 27 20:48:59.339: INFO: namespace e2e-tests-sched-pred-6jbhh deletion completed in 6.211334341s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.636 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:48:59.343: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 27 20:48:59.481: INFO: Waiting up to 5m0s for pod "pod-bf0333d7-50d1-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-hzwsm" to be "success or failure"
Mar 27 20:48:59.506: INFO: Pod "pod-bf0333d7-50d1-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 24.731683ms
Mar 27 20:49:01.519: INFO: Pod "pod-bf0333d7-50d1-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037582041s
STEP: Saw pod success
Mar 27 20:49:01.522: INFO: Pod "pod-bf0333d7-50d1-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:49:01.532: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-bf0333d7-50d1-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 20:49:01.604: INFO: Waiting for pod pod-bf0333d7-50d1-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:49:01.620: INFO: Pod pod-bf0333d7-50d1-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:49:01.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hzwsm" for this suite.
Mar 27 20:49:07.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:49:07.883: INFO: namespace: e2e-tests-emptydir-hzwsm, resource: bindings, ignored listing per whitelist
Mar 27 20:49:07.902: INFO: namespace e2e-tests-emptydir-hzwsm deletion completed in 6.252619492s

• [SLOW TEST:8.560 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:49:07.903: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c41f2e6e-50d1-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 20:49:08.083: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c423aa51-50d1-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-49f69" to be "success or failure"
Mar 27 20:49:08.097: INFO: Pod "pod-projected-configmaps-c423aa51-50d1-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 14.398146ms
Mar 27 20:49:10.107: INFO: Pod "pod-projected-configmaps-c423aa51-50d1-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023746769s
STEP: Saw pod success
Mar 27 20:49:10.107: INFO: Pod "pod-projected-configmaps-c423aa51-50d1-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:49:10.114: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-configmaps-c423aa51-50d1-11e9-9d23-0ac04cf37a48 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 20:49:10.194: INFO: Waiting for pod pod-projected-configmaps-c423aa51-50d1-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:49:10.211: INFO: Pod pod-projected-configmaps-c423aa51-50d1-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:49:10.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-49f69" for this suite.
Mar 27 20:49:18.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:49:18.695: INFO: namespace: e2e-tests-projected-49f69, resource: bindings, ignored listing per whitelist
Mar 27 20:49:18.738: INFO: namespace e2e-tests-projected-49f69 deletion completed in 8.440798616s

• [SLOW TEST:10.836 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:49:18.739: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 27 20:49:18.935: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 27 20:49:18.955: INFO: Waiting for terminating namespaces to be deleted...
Mar 27 20:49:18.961: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-control-1 before test
Mar 27 20:49:18.979: INFO: nginx-ingress-controller-mw49v from ingress-nginx started at 2019-03-26 21:11:22 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:18.980: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:49:18.980: INFO: sonobuoy-e2e-job-b3f04bfb1b6b4be0 from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:49:18.980: INFO: 	Container e2e ready: true, restart count 0
Mar 27 20:49:18.981: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:49:18.981: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-bmkpx from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:49:18.981: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:49:18.981: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:49:18.981: INFO: rke-network-plugin-deploy-job-sffcc from kube-system started at 2019-03-26 20:44:49 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:18.981: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 27 20:49:18.981: INFO: calico-node-ns648 from kube-system started at 2019-03-26 20:44:52 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:18.982: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:49:18.982: INFO: rke-ingress-controller-deploy-job-8s8mv from kube-system started at 2019-03-26 20:45:05 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:18.982: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 27 20:49:18.982: INFO: cattle-node-agent-bx6pt from cattle-system started at 2019-03-26 20:45:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:18.983: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:49:18.983: INFO: rke-kubedns-addon-deploy-job-8pplg from kube-system started at 2019-03-26 20:44:54 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:18.983: INFO: 	Container rke-kubedns-addon-pod ready: false, restart count 0
Mar 27 20:49:18.984: INFO: rke-metrics-addon-deploy-job-pm9qz from kube-system started at 2019-03-26 20:44:59 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:18.984: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 27 20:49:18.984: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-etcd-1 before test
Mar 27 20:49:18.997: INFO: calico-node-54w8d from kube-system started at 2019-03-26 20:44:52 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:18.997: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:49:18.997: INFO: cattle-node-agent-kh475 from cattle-system started at 2019-03-26 20:45:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:18.998: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:49:18.998: INFO: nginx-ingress-controller-hfgxf from ingress-nginx started at 2019-03-26 21:11:17 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:18.998: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:49:18.998: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-dk7z4 from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:49:18.999: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:49:18.999: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:49:18.999: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-worker-1 before test
Mar 27 20:49:19.021: INFO: cattle-cluster-agent-6db87bf6bc-p669p from cattle-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.022: INFO: 	Container cluster-register ready: true, restart count 0
Mar 27 20:49:19.023: INFO: kube-dns-5fd74c7488-z4wvz from kube-system started at 2019-03-26 20:46:25 +0000 UTC (3 container statuses recorded)
Mar 27 20:49:19.023: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 27 20:49:19.024: INFO: 	Container kubedns ready: true, restart count 0
Mar 27 20:49:19.024: INFO: 	Container sidecar ready: true, restart count 0
Mar 27 20:49:19.024: INFO: metrics-server-7fbd549b78-dl4j5 from kube-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.024: INFO: 	Container metrics-server ready: true, restart count 0
Mar 27 20:49:19.024: INFO: nginx-ingress-controller-rn5b5 from ingress-nginx started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.025: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:49:19.025: INFO: cattle-node-agent-9jv82 from cattle-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.025: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:49:19.025: INFO: calico-node-k5mgj from kube-system started at 2019-03-26 20:46:15 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.025: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:49:19.025: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-x8vsv from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:49:19.026: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:49:19.026: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:49:19.026: INFO: kube-dns-autoscaler-c89df977f-dlths from kube-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.026: INFO: 	Container autoscaler ready: true, restart count 0
Mar 27 20:49:19.026: INFO: default-http-backend-7f8fbb85db-lwxbh from ingress-nginx started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.027: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 27 20:49:19.027: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-worker-2 before test
Mar 27 20:49:19.045: INFO: calico-node-297zr from kube-system started at 2019-03-26 20:46:55 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.045: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:49:19.045: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-27 20:22:57 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.045: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 27 20:49:19.046: INFO: nginx-ingress-controller-kzs5s from ingress-nginx started at 2019-03-26 20:47:15 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.046: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:49:19.046: INFO: cattle-node-agent-sshz4 from cattle-system started at 2019-03-26 20:47:15 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.046: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:49:19.046: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-x92wh from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:49:19.046: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:49:19.046: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:49:19.046: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-worker-3 before test
Mar 27 20:49:19.080: INFO: calico-node-fdvdd from kube-system started at 2019-03-26 20:46:31 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.080: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:49:19.081: INFO: kube-dns-5fd74c7488-l5xxd from kube-system started at 2019-03-26 20:46:58 +0000 UTC (3 container statuses recorded)
Mar 27 20:49:19.081: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 27 20:49:19.081: INFO: 	Container kubedns ready: true, restart count 0
Mar 27 20:49:19.082: INFO: 	Container sidecar ready: true, restart count 0
Mar 27 20:49:19.082: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-xxzjw from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:49:19.082: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:49:19.082: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:49:19.082: INFO: nginx-ingress-controller-dqt72 from ingress-nginx started at 2019-03-26 20:46:41 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.082: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:49:19.083: INFO: cattle-node-agent-5hjvr from cattle-system started at 2019-03-26 20:46:41 +0000 UTC (1 container statuses recorded)
Mar 27 20:49:19.083: INFO: 	Container agent ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-cd2980ae-50d1-11e9-9d23-0ac04cf37a48 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-cd2980ae-50d1-11e9-9d23-0ac04cf37a48 off the node k8s-conformance-cluster-1-13-etcd-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-cd2980ae-50d1-11e9-9d23-0ac04cf37a48
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:49:25.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-b4tr4" for this suite.
Mar 27 20:49:33.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:49:33.523: INFO: namespace: e2e-tests-sched-pred-b4tr4, resource: bindings, ignored listing per whitelist
Mar 27 20:49:33.606: INFO: namespace e2e-tests-sched-pred-b4tr4 deletion completed in 8.247519759s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.867 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:49:33.610: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Mar 27 20:49:33.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-85ghx'
Mar 27 20:49:34.591: INFO: stderr: ""
Mar 27 20:49:34.591: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar 27 20:49:35.604: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 20:49:35.604: INFO: Found 0 / 1
Mar 27 20:49:36.604: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 20:49:36.604: INFO: Found 1 / 1
Mar 27 20:49:36.604: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 27 20:49:36.615: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 20:49:36.615: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar 27 20:49:36.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 logs redis-master-7rjpl redis-master --namespace=e2e-tests-kubectl-85ghx'
Mar 27 20:49:36.812: INFO: stderr: ""
Mar 27 20:49:36.812: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Mar 20:49:36.084 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Mar 20:49:36.084 # Server started, Redis version 3.2.12\n1:M 27 Mar 20:49:36.084 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Mar 20:49:36.084 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar 27 20:49:36.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 log redis-master-7rjpl redis-master --namespace=e2e-tests-kubectl-85ghx --tail=1'
Mar 27 20:49:36.996: INFO: stderr: ""
Mar 27 20:49:36.996: INFO: stdout: "1:M 27 Mar 20:49:36.084 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar 27 20:49:36.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 log redis-master-7rjpl redis-master --namespace=e2e-tests-kubectl-85ghx --limit-bytes=1'
Mar 27 20:49:37.183: INFO: stderr: ""
Mar 27 20:49:37.183: INFO: stdout: " "
STEP: exposing timestamps
Mar 27 20:49:37.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 log redis-master-7rjpl redis-master --namespace=e2e-tests-kubectl-85ghx --tail=1 --timestamps'
Mar 27 20:49:37.380: INFO: stderr: ""
Mar 27 20:49:37.380: INFO: stdout: "2019-03-27T20:49:36.094313412Z 1:M 27 Mar 20:49:36.084 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar 27 20:49:39.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 log redis-master-7rjpl redis-master --namespace=e2e-tests-kubectl-85ghx --since=1s'
Mar 27 20:49:40.055: INFO: stderr: ""
Mar 27 20:49:40.055: INFO: stdout: ""
Mar 27 20:49:40.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 log redis-master-7rjpl redis-master --namespace=e2e-tests-kubectl-85ghx --since=24h'
Mar 27 20:49:40.235: INFO: stderr: ""
Mar 27 20:49:40.235: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Mar 20:49:36.084 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Mar 20:49:36.084 # Server started, Redis version 3.2.12\n1:M 27 Mar 20:49:36.084 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Mar 20:49:36.084 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Mar 27 20:49:40.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-85ghx'
Mar 27 20:49:40.449: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 20:49:40.449: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar 27 20:49:40.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-85ghx'
Mar 27 20:49:40.675: INFO: stderr: "No resources found.\n"
Mar 27 20:49:40.675: INFO: stdout: ""
Mar 27 20:49:40.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -l name=nginx --namespace=e2e-tests-kubectl-85ghx -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 27 20:49:40.834: INFO: stderr: ""
Mar 27 20:49:40.834: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:49:40.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-85ghx" for this suite.
Mar 27 20:49:46.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:49:47.010: INFO: namespace: e2e-tests-kubectl-85ghx, resource: bindings, ignored listing per whitelist
Mar 27 20:49:47.078: INFO: namespace e2e-tests-kubectl-85ghx deletion completed in 6.230675224s

• [SLOW TEST:13.468 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:49:47.080: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0327 20:49:48.454073      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 27 20:49:48.455: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:49:48.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xthlv" for this suite.
Mar 27 20:49:54.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:49:54.548: INFO: namespace: e2e-tests-gc-xthlv, resource: bindings, ignored listing per whitelist
Mar 27 20:49:54.693: INFO: namespace e2e-tests-gc-xthlv deletion completed in 6.21715365s

• [SLOW TEST:7.613 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:49:54.694: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-e002ad46-50d1-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 20:49:54.845: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e0039758-50d1-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-fd5x2" to be "success or failure"
Mar 27 20:49:54.854: INFO: Pod "pod-projected-secrets-e0039758-50d1-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 8.946955ms
Mar 27 20:49:56.872: INFO: Pod "pod-projected-secrets-e0039758-50d1-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026905929s
STEP: Saw pod success
Mar 27 20:49:56.873: INFO: Pod "pod-projected-secrets-e0039758-50d1-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:49:56.884: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-secrets-e0039758-50d1-11e9-9d23-0ac04cf37a48 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 20:49:56.992: INFO: Waiting for pod pod-projected-secrets-e0039758-50d1-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:49:57.006: INFO: Pod pod-projected-secrets-e0039758-50d1-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:49:57.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fd5x2" for this suite.
Mar 27 20:50:03.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:50:03.295: INFO: namespace: e2e-tests-projected-fd5x2, resource: bindings, ignored listing per whitelist
Mar 27 20:50:03.393: INFO: namespace e2e-tests-projected-fd5x2 deletion completed in 6.331630281s

• [SLOW TEST:8.700 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:50:03.394: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 27 20:50:03.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-sd6hv'
Mar 27 20:50:03.743: INFO: stderr: ""
Mar 27 20:50:03.743: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Mar 27 20:50:03.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-sd6hv'
Mar 27 20:50:06.579: INFO: stderr: ""
Mar 27 20:50:06.579: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:50:06.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sd6hv" for this suite.
Mar 27 20:50:12.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:50:12.762: INFO: namespace: e2e-tests-kubectl-sd6hv, resource: bindings, ignored listing per whitelist
Mar 27 20:50:12.956: INFO: namespace e2e-tests-kubectl-sd6hv deletion completed in 6.361928896s

• [SLOW TEST:9.562 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:50:12.964: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-zfcr9/secret-test-eaee43ae-50d1-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 20:50:13.179: INFO: Waiting up to 5m0s for pod "pod-configmaps-eaf0297a-50d1-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-secrets-zfcr9" to be "success or failure"
Mar 27 20:50:13.223: INFO: Pod "pod-configmaps-eaf0297a-50d1-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 44.393795ms
Mar 27 20:50:15.232: INFO: Pod "pod-configmaps-eaf0297a-50d1-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053491176s
STEP: Saw pod success
Mar 27 20:50:15.233: INFO: Pod "pod-configmaps-eaf0297a-50d1-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:50:15.240: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-configmaps-eaf0297a-50d1-11e9-9d23-0ac04cf37a48 container env-test: <nil>
STEP: delete the pod
Mar 27 20:50:15.384: INFO: Waiting for pod pod-configmaps-eaf0297a-50d1-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:50:15.400: INFO: Pod pod-configmaps-eaf0297a-50d1-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:50:15.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zfcr9" for this suite.
Mar 27 20:50:21.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:50:21.625: INFO: namespace: e2e-tests-secrets-zfcr9, resource: bindings, ignored listing per whitelist
Mar 27 20:50:21.719: INFO: namespace e2e-tests-secrets-zfcr9 deletion completed in 6.272780666s

• [SLOW TEST:8.755 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:50:21.721: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7mp7h
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar 27 20:50:21.935: INFO: Found 0 stateful pods, waiting for 3
Mar 27 20:50:31.947: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 20:50:31.948: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 20:50:31.948: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 27 20:50:32.008: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 27 20:50:42.101: INFO: Updating stateful set ss2
Mar 27 20:50:42.121: INFO: Waiting for Pod e2e-tests-statefulset-7mp7h/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar 27 20:50:52.670: INFO: Found 2 stateful pods, waiting for 3
Mar 27 20:51:02.679: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 20:51:02.679: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 20:51:02.679: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 27 20:51:02.716: INFO: Updating stateful set ss2
Mar 27 20:51:02.746: INFO: Waiting for Pod e2e-tests-statefulset-7mp7h/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 27 20:51:12.794: INFO: Updating stateful set ss2
Mar 27 20:51:12.926: INFO: Waiting for StatefulSet e2e-tests-statefulset-7mp7h/ss2 to complete update
Mar 27 20:51:12.926: INFO: Waiting for Pod e2e-tests-statefulset-7mp7h/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 27 20:51:22.948: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7mp7h
Mar 27 20:51:22.957: INFO: Scaling statefulset ss2 to 0
Mar 27 20:51:52.999: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 20:51:53.007: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:51:53.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7mp7h" for this suite.
Mar 27 20:52:01.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:52:01.300: INFO: namespace: e2e-tests-statefulset-7mp7h, resource: bindings, ignored listing per whitelist
Mar 27 20:52:01.308: INFO: namespace e2e-tests-statefulset-7mp7h deletion completed in 8.231066214s

• [SLOW TEST:99.588 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:52:01.310: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-2b83296d-50d2-11e9-9d23-0ac04cf37a48
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-2b83296d-50d2-11e9-9d23-0ac04cf37a48
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:52:05.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5lkdd" for this suite.
Mar 27 20:52:29.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:52:29.806: INFO: namespace: e2e-tests-configmap-5lkdd, resource: bindings, ignored listing per whitelist
Mar 27 20:52:29.943: INFO: namespace e2e-tests-configmap-5lkdd deletion completed in 24.313903406s

• [SLOW TEST:28.634 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:52:29.950: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar 27 20:52:30.764: INFO: Waiting up to 5m0s for pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-89psx" in namespace "e2e-tests-svcaccounts-fn7mq" to be "success or failure"
Mar 27 20:52:30.782: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-89psx": Phase="Pending", Reason="", readiness=false. Elapsed: 18.105049ms
Mar 27 20:52:32.789: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-89psx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025273863s
Mar 27 20:52:34.802: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-89psx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037528688s
STEP: Saw pod success
Mar 27 20:52:34.802: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-89psx" satisfied condition "success or failure"
Mar 27 20:52:34.809: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-89psx container token-test: <nil>
STEP: delete the pod
Mar 27 20:52:34.878: INFO: Waiting for pod pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-89psx to disappear
Mar 27 20:52:34.888: INFO: Pod pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-89psx no longer exists
STEP: Creating a pod to test consume service account root CA
Mar 27 20:52:34.898: INFO: Waiting up to 5m0s for pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-dsvjs" in namespace "e2e-tests-svcaccounts-fn7mq" to be "success or failure"
Mar 27 20:52:34.937: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-dsvjs": Phase="Pending", Reason="", readiness=false. Elapsed: 39.159714ms
Mar 27 20:52:36.962: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-dsvjs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063321713s
Mar 27 20:52:38.968: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-dsvjs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069839607s
STEP: Saw pod success
Mar 27 20:52:38.968: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-dsvjs" satisfied condition "success or failure"
Mar 27 20:52:38.977: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-dsvjs container root-ca-test: <nil>
STEP: delete the pod
Mar 27 20:52:39.065: INFO: Waiting for pod pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-dsvjs to disappear
Mar 27 20:52:39.070: INFO: Pod pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-dsvjs no longer exists
STEP: Creating a pod to test consume service account namespace
Mar 27 20:52:39.129: INFO: Waiting up to 5m0s for pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-mhq6v" in namespace "e2e-tests-svcaccounts-fn7mq" to be "success or failure"
Mar 27 20:52:39.144: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-mhq6v": Phase="Pending", Reason="", readiness=false. Elapsed: 15.275264ms
Mar 27 20:52:41.150: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-mhq6v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020999001s
Mar 27 20:52:43.160: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-mhq6v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031101368s
STEP: Saw pod success
Mar 27 20:52:43.161: INFO: Pod "pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-mhq6v" satisfied condition "success or failure"
Mar 27 20:52:43.166: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-mhq6v container namespace-test: <nil>
STEP: delete the pod
Mar 27 20:52:43.231: INFO: Waiting for pod pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-mhq6v to disappear
Mar 27 20:52:43.274: INFO: Pod pod-service-account-3cf37e7e-50d2-11e9-9d23-0ac04cf37a48-mhq6v no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:52:43.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-fn7mq" for this suite.
Mar 27 20:52:51.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:52:51.598: INFO: namespace: e2e-tests-svcaccounts-fn7mq, resource: bindings, ignored listing per whitelist
Mar 27 20:52:51.617: INFO: namespace e2e-tests-svcaccounts-fn7mq deletion completed in 8.325864253s

• [SLOW TEST:21.667 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:52:51.619: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 20:52:51.852: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 27 20:52:51.880: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 27 20:52:56.889: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 27 20:52:56.891: INFO: Creating deployment "test-rolling-update-deployment"
Mar 27 20:52:56.915: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 27 20:52:56.927: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 27 20:52:59.001: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 27 20:52:59.009: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 27 20:52:59.036: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-nn8v9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nn8v9/deployments/test-rolling-update-deployment,UID:4c89b233-50d2-11e9-8df3-90b8d03c5288,ResourceVersion:181191,Generation:1,CreationTimestamp:2019-03-27 20:52:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-27 20:52:57 +0000 UTC 2019-03-27 20:52:57 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-27 20:52:58 +0000 UTC 2019-03-27 20:52:56 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 27 20:52:59.044: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-nn8v9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nn8v9/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:4c9189f8-50d2-11e9-8df3-90b8d03c5288,ResourceVersion:181182,Generation:1,CreationTimestamp:2019-03-27 20:52:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 4c89b233-50d2-11e9-8df3-90b8d03c5288 0xc001da88b7 0xc001da88b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 27 20:52:59.044: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 27 20:52:59.046: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-nn8v9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nn8v9/replicasets/test-rolling-update-controller,UID:49887483-50d2-11e9-8df3-90b8d03c5288,ResourceVersion:181190,Generation:2,CreationTimestamp:2019-03-27 20:52:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 4c89b233-50d2-11e9-8df3-90b8d03c5288 0xc001da87f7 0xc001da87f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 27 20:52:59.060: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-pjkdm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-pjkdm,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-nn8v9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nn8v9/pods/test-rolling-update-deployment-68b55d7bc6-pjkdm,UID:4c92d163-50d2-11e9-8df3-90b8d03c5288,ResourceVersion:181181,Generation:0,CreationTimestamp:2019-03-27 20:52:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.4.89/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 4c9189f8-50d2-11e9-8df3-90b8d03c5288 0xc001da9227 0xc001da9228}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cb5v8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cb5v8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-cb5v8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001da9290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001da92b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 20:52:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 20:52:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 20:52:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 20:52:56 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.168,PodIP:10.42.4.89,StartTime:2019-03-27 20:52:56 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-27 20:52:58 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1ee02aabc75d2c7e1141eaa5505635711a0dbf61e054322190c9d833210e062e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:52:59.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-nn8v9" for this suite.
Mar 27 20:53:05.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:53:05.183: INFO: namespace: e2e-tests-deployment-nn8v9, resource: bindings, ignored listing per whitelist
Mar 27 20:53:05.352: INFO: namespace e2e-tests-deployment-nn8v9 deletion completed in 6.274256515s

• [SLOW TEST:13.733 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:53:05.354: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-54bhg.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-54bhg.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-54bhg.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-54bhg.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-54bhg.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-54bhg.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 20:53:09.832: INFO: DNS probes using e2e-tests-dns-54bhg/dns-test-51b18cc4-50d2-11e9-9d23-0ac04cf37a48 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:53:09.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-54bhg" for this suite.
Mar 27 20:53:15.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:53:16.164: INFO: namespace: e2e-tests-dns-54bhg, resource: bindings, ignored listing per whitelist
Mar 27 20:53:16.216: INFO: namespace e2e-tests-dns-54bhg deletion completed in 6.290111794s

• [SLOW TEST:10.863 seconds]
[sig-network] DNS
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:53:16.222: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-582e39ce-50d2-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 20:53:16.450: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-582f7ff8-50d2-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-qldj8" to be "success or failure"
Mar 27 20:53:16.477: INFO: Pod "pod-projected-secrets-582f7ff8-50d2-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 26.846242ms
Mar 27 20:53:18.484: INFO: Pod "pod-projected-secrets-582f7ff8-50d2-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.033387175s
Mar 27 20:53:20.489: INFO: Pod "pod-projected-secrets-582f7ff8-50d2-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03875556s
STEP: Saw pod success
Mar 27 20:53:20.489: INFO: Pod "pod-projected-secrets-582f7ff8-50d2-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:53:20.494: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-secrets-582f7ff8-50d2-11e9-9d23-0ac04cf37a48 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 27 20:53:20.555: INFO: Waiting for pod pod-projected-secrets-582f7ff8-50d2-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:53:20.566: INFO: Pod pod-projected-secrets-582f7ff8-50d2-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:53:20.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qldj8" for this suite.
Mar 27 20:53:26.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:53:26.793: INFO: namespace: e2e-tests-projected-qldj8, resource: bindings, ignored listing per whitelist
Mar 27 20:53:26.889: INFO: namespace e2e-tests-projected-qldj8 deletion completed in 6.296281723s

• [SLOW TEST:10.668 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:53:26.893: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5e85602f-50d2-11e9-9d23-0ac04cf37a48
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5e85602f-50d2-11e9-9d23-0ac04cf37a48
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:54:42.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qlrt5" for this suite.
Mar 27 20:55:06.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:55:06.786: INFO: namespace: e2e-tests-projected-qlrt5, resource: bindings, ignored listing per whitelist
Mar 27 20:55:06.811: INFO: namespace e2e-tests-projected-qlrt5 deletion completed in 24.23752713s

• [SLOW TEST:99.919 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:55:06.812: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar 27 20:55:06.972: INFO: Waiting up to 5m0s for pod "var-expansion-9a0f14fd-50d2-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-var-expansion-4p8gh" to be "success or failure"
Mar 27 20:55:07.000: INFO: Pod "var-expansion-9a0f14fd-50d2-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 28.018943ms
Mar 27 20:55:09.008: INFO: Pod "var-expansion-9a0f14fd-50d2-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035534903s
STEP: Saw pod success
Mar 27 20:55:09.008: INFO: Pod "var-expansion-9a0f14fd-50d2-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:55:09.018: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod var-expansion-9a0f14fd-50d2-11e9-9d23-0ac04cf37a48 container dapi-container: <nil>
STEP: delete the pod
Mar 27 20:55:09.170: INFO: Waiting for pod var-expansion-9a0f14fd-50d2-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:55:09.182: INFO: Pod var-expansion-9a0f14fd-50d2-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:55:09.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4p8gh" for this suite.
Mar 27 20:55:15.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:55:15.323: INFO: namespace: e2e-tests-var-expansion-4p8gh, resource: bindings, ignored listing per whitelist
Mar 27 20:55:15.466: INFO: namespace e2e-tests-var-expansion-4p8gh deletion completed in 6.255140449s

• [SLOW TEST:8.654 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:55:15.468: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9f3a2f13-50d2-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 20:55:15.665: INFO: Waiting up to 5m0s for pod "pod-secrets-9f3be3d3-50d2-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-secrets-mjnc9" to be "success or failure"
Mar 27 20:55:15.692: INFO: Pod "pod-secrets-9f3be3d3-50d2-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 27.055307ms
Mar 27 20:55:17.698: INFO: Pod "pod-secrets-9f3be3d3-50d2-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033565245s
Mar 27 20:55:19.703: INFO: Pod "pod-secrets-9f3be3d3-50d2-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038401311s
STEP: Saw pod success
Mar 27 20:55:19.703: INFO: Pod "pod-secrets-9f3be3d3-50d2-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:55:19.712: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-secrets-9f3be3d3-50d2-11e9-9d23-0ac04cf37a48 container secret-env-test: <nil>
STEP: delete the pod
Mar 27 20:55:19.800: INFO: Waiting for pod pod-secrets-9f3be3d3-50d2-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:55:19.806: INFO: Pod pod-secrets-9f3be3d3-50d2-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:55:19.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mjnc9" for this suite.
Mar 27 20:55:25.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:55:26.111: INFO: namespace: e2e-tests-secrets-mjnc9, resource: bindings, ignored listing per whitelist
Mar 27 20:55:26.214: INFO: namespace e2e-tests-secrets-mjnc9 deletion completed in 6.390143872s

• [SLOW TEST:10.747 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:55:26.217: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 20:55:28.486: INFO: Waiting up to 5m0s for pod "client-envvars-a6e1e7f9-50d2-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-pods-t2f2m" to be "success or failure"
Mar 27 20:55:28.516: INFO: Pod "client-envvars-a6e1e7f9-50d2-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 29.727691ms
Mar 27 20:55:30.524: INFO: Pod "client-envvars-a6e1e7f9-50d2-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038303531s
STEP: Saw pod success
Mar 27 20:55:30.525: INFO: Pod "client-envvars-a6e1e7f9-50d2-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:55:30.531: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod client-envvars-a6e1e7f9-50d2-11e9-9d23-0ac04cf37a48 container env3cont: <nil>
STEP: delete the pod
Mar 27 20:55:30.691: INFO: Waiting for pod client-envvars-a6e1e7f9-50d2-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:55:30.714: INFO: Pod client-envvars-a6e1e7f9-50d2-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:55:30.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-t2f2m" for this suite.
Mar 27 20:56:10.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:56:10.955: INFO: namespace: e2e-tests-pods-t2f2m, resource: bindings, ignored listing per whitelist
Mar 27 20:56:11.052: INFO: namespace e2e-tests-pods-t2f2m deletion completed in 40.307291258s

• [SLOW TEST:44.835 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:56:11.054: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-7vcrl
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7vcrl to expose endpoints map[]
Mar 27 20:56:11.256: INFO: Get endpoints failed (5.385747ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar 27 20:56:12.262: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7vcrl exposes endpoints map[] (1.01047394s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7vcrl
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7vcrl to expose endpoints map[pod1:[100]]
Mar 27 20:56:14.338: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7vcrl exposes endpoints map[pod1:[100]] (2.058325058s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7vcrl
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7vcrl to expose endpoints map[pod2:[101] pod1:[100]]
Mar 27 20:56:16.435: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7vcrl exposes endpoints map[pod1:[100] pod2:[101]] (2.077492016s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7vcrl
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7vcrl to expose endpoints map[pod2:[101]]
Mar 27 20:56:16.696: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7vcrl exposes endpoints map[pod2:[101]] (228.76286ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7vcrl
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7vcrl to expose endpoints map[]
Mar 27 20:56:17.812: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7vcrl exposes endpoints map[] (1.048462158s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:56:17.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7vcrl" for this suite.
Mar 27 20:56:23.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:56:24.107: INFO: namespace: e2e-tests-services-7vcrl, resource: bindings, ignored listing per whitelist
Mar 27 20:56:24.143: INFO: namespace e2e-tests-services-7vcrl deletion completed in 6.242203635s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.089 seconds]
[sig-network] Services
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:56:24.146: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 20:56:24.308: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 27 20:56:29.312: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 27 20:56:29.313: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 27 20:56:31.320: INFO: Creating deployment "test-rollover-deployment"
Mar 27 20:56:31.334: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 27 20:56:33.344: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 27 20:56:33.352: INFO: Ensure that both replica sets have 1 created replica
Mar 27 20:56:33.363: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 27 20:56:33.376: INFO: Updating deployment test-rollover-deployment
Mar 27 20:56:33.376: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 27 20:56:35.391: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 27 20:56:35.401: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 27 20:56:35.412: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 20:56:35.412: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316994, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 20:56:37.423: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 20:56:37.423: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316994, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 20:56:39.424: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 20:56:39.424: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316994, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 20:56:41.423: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 20:56:41.423: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316994, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 20:56:43.434: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 20:56:43.435: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316994, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689316991, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 20:56:45.426: INFO: 
Mar 27 20:56:45.426: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 27 20:56:45.462: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-sw5p4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sw5p4/deployments/test-rollover-deployment,UID:cc587b27-50d2-11e9-8df3-90b8d03c5288,ResourceVersion:181978,Generation:2,CreationTimestamp:2019-03-27 20:56:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-27 20:56:31 +0000 UTC 2019-03-27 20:56:31 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-27 20:56:45 +0000 UTC 2019-03-27 20:56:31 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 27 20:56:45.493: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-sw5p4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sw5p4/replicasets/test-rollover-deployment-6b7f9d6597,UID:cd927c74-50d2-11e9-8df3-90b8d03c5288,ResourceVersion:181969,Generation:2,CreationTimestamp:2019-03-27 20:56:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc587b27-50d2-11e9-8df3-90b8d03c5288 0xc001694d77 0xc001694d78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 27 20:56:45.493: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 27 20:56:45.494: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-sw5p4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sw5p4/replicasets/test-rollover-controller,UID:c82692da-50d2-11e9-8df3-90b8d03c5288,ResourceVersion:181977,Generation:2,CreationTimestamp:2019-03-27 20:56:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc587b27-50d2-11e9-8df3-90b8d03c5288 0xc001694b57 0xc001694b58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 27 20:56:45.494: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-sw5p4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sw5p4/replicasets/test-rollover-deployment-6586df867b,UID:cc5d6db2-50d2-11e9-8df3-90b8d03c5288,ResourceVersion:181940,Generation:2,CreationTimestamp:2019-03-27 20:56:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc587b27-50d2-11e9-8df3-90b8d03c5288 0xc001694c47 0xc001694c48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 27 20:56:45.504: INFO: Pod "test-rollover-deployment-6b7f9d6597-bjt5b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-bjt5b,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-sw5p4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-sw5p4/pods/test-rollover-deployment-6b7f9d6597-bjt5b,UID:cd9de13d-50d2-11e9-8df3-90b8d03c5288,ResourceVersion:181949,Generation:0,CreationTimestamp:2019-03-27 20:56:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.4.91/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 cd927c74-50d2-11e9-8df3-90b8d03c5288 0xc001695ec7 0xc001695ec8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gqj6m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gqj6m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gqj6m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001695f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001695f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 20:56:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 20:56:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 20:56:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 20:56:33 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.168,PodIP:10.42.4.91,StartTime:2019-03-27 20:56:33 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-27 20:56:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://dcc460ac95ab6405bfba24cc60ab480465f9c0d67550fb3171f4cd9963e72469}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:56:45.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-sw5p4" for this suite.
Mar 27 20:56:53.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:56:53.582: INFO: namespace: e2e-tests-deployment-sw5p4, resource: bindings, ignored listing per whitelist
Mar 27 20:56:53.703: INFO: namespace e2e-tests-deployment-sw5p4 deletion completed in 8.188235831s

• [SLOW TEST:29.558 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:56:53.705: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 27 20:56:56.494: INFO: Successfully updated pod "annotationupdated9c32fe6-50d2-11e9-9d23-0ac04cf37a48"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:57:00.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c8g29" for this suite.
Mar 27 20:57:24.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:57:24.795: INFO: namespace: e2e-tests-projected-c8g29, resource: bindings, ignored listing per whitelist
Mar 27 20:57:24.892: INFO: namespace e2e-tests-projected-c8g29 deletion completed in 24.294636009s

• [SLOW TEST:31.188 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:57:24.894: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 27 20:57:25.070: INFO: Waiting up to 5m0s for pod "pod-ec5d9324-50d2-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-k84t6" to be "success or failure"
Mar 27 20:57:25.099: INFO: Pod "pod-ec5d9324-50d2-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 29.893258ms
Mar 27 20:57:27.108: INFO: Pod "pod-ec5d9324-50d2-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038852369s
STEP: Saw pod success
Mar 27 20:57:27.109: INFO: Pod "pod-ec5d9324-50d2-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:57:27.119: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-ec5d9324-50d2-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 20:57:27.229: INFO: Waiting for pod pod-ec5d9324-50d2-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:57:27.237: INFO: Pod pod-ec5d9324-50d2-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:57:27.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-k84t6" for this suite.
Mar 27 20:57:33.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:57:33.380: INFO: namespace: e2e-tests-emptydir-k84t6, resource: bindings, ignored listing per whitelist
Mar 27 20:57:33.511: INFO: namespace e2e-tests-emptydir-k84t6 deletion completed in 6.241951871s

• [SLOW TEST:8.617 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:57:33.512: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 20:57:33.643: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f179f2fb-50d2-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-kxd9k" to be "success or failure"
Mar 27 20:57:33.671: INFO: Pod "downwardapi-volume-f179f2fb-50d2-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 27.712586ms
Mar 27 20:57:35.677: INFO: Pod "downwardapi-volume-f179f2fb-50d2-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03349744s
STEP: Saw pod success
Mar 27 20:57:35.677: INFO: Pod "downwardapi-volume-f179f2fb-50d2-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:57:35.682: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-f179f2fb-50d2-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 20:57:35.761: INFO: Waiting for pod downwardapi-volume-f179f2fb-50d2-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:57:35.795: INFO: Pod downwardapi-volume-f179f2fb-50d2-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:57:35.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kxd9k" for this suite.
Mar 27 20:57:41.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:57:42.031: INFO: namespace: e2e-tests-projected-kxd9k, resource: bindings, ignored listing per whitelist
Mar 27 20:57:42.069: INFO: namespace e2e-tests-projected-kxd9k deletion completed in 6.24671254s

• [SLOW TEST:8.557 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:57:42.070: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 27 20:57:42.203: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 27 20:57:42.221: INFO: Waiting for terminating namespaces to be deleted...
Mar 27 20:57:42.226: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-control-1 before test
Mar 27 20:57:42.238: INFO: rke-kubedns-addon-deploy-job-8pplg from kube-system started at 2019-03-26 20:44:54 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.238: INFO: 	Container rke-kubedns-addon-pod ready: false, restart count 0
Mar 27 20:57:42.239: INFO: rke-metrics-addon-deploy-job-pm9qz from kube-system started at 2019-03-26 20:44:59 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.239: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 27 20:57:42.239: INFO: nginx-ingress-controller-mw49v from ingress-nginx started at 2019-03-26 21:11:22 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.239: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:57:42.239: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-bmkpx from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:57:42.239: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:57:42.239: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:57:42.239: INFO: rke-network-plugin-deploy-job-sffcc from kube-system started at 2019-03-26 20:44:49 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.239: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 27 20:57:42.239: INFO: calico-node-ns648 from kube-system started at 2019-03-26 20:44:52 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.239: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:57:42.239: INFO: sonobuoy-e2e-job-b3f04bfb1b6b4be0 from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:57:42.239: INFO: 	Container e2e ready: true, restart count 0
Mar 27 20:57:42.239: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:57:42.239: INFO: rke-ingress-controller-deploy-job-8s8mv from kube-system started at 2019-03-26 20:45:05 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.240: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 27 20:57:42.240: INFO: cattle-node-agent-bx6pt from cattle-system started at 2019-03-26 20:45:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.240: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:57:42.240: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-etcd-1 before test
Mar 27 20:57:42.254: INFO: calico-node-54w8d from kube-system started at 2019-03-26 20:44:52 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.254: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:57:42.254: INFO: cattle-node-agent-kh475 from cattle-system started at 2019-03-26 20:45:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.255: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:57:42.255: INFO: nginx-ingress-controller-hfgxf from ingress-nginx started at 2019-03-26 21:11:17 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.255: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:57:42.255: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-dk7z4 from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:57:42.255: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:57:42.255: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:57:42.255: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-worker-1 before test
Mar 27 20:57:42.287: INFO: cattle-cluster-agent-6db87bf6bc-p669p from cattle-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.287: INFO: 	Container cluster-register ready: true, restart count 0
Mar 27 20:57:42.287: INFO: kube-dns-5fd74c7488-z4wvz from kube-system started at 2019-03-26 20:46:25 +0000 UTC (3 container statuses recorded)
Mar 27 20:57:42.287: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 27 20:57:42.287: INFO: 	Container kubedns ready: true, restart count 0
Mar 27 20:57:42.287: INFO: 	Container sidecar ready: true, restart count 0
Mar 27 20:57:42.287: INFO: metrics-server-7fbd549b78-dl4j5 from kube-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.287: INFO: 	Container metrics-server ready: true, restart count 0
Mar 27 20:57:42.288: INFO: nginx-ingress-controller-rn5b5 from ingress-nginx started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.288: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:57:42.288: INFO: cattle-node-agent-9jv82 from cattle-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.288: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:57:42.288: INFO: calico-node-k5mgj from kube-system started at 2019-03-26 20:46:15 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.288: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:57:42.288: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-x8vsv from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:57:42.289: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:57:42.289: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:57:42.289: INFO: kube-dns-autoscaler-c89df977f-dlths from kube-system started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.289: INFO: 	Container autoscaler ready: true, restart count 0
Mar 27 20:57:42.289: INFO: default-http-backend-7f8fbb85db-lwxbh from ingress-nginx started at 2019-03-26 20:46:25 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.289: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 27 20:57:42.289: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-worker-2 before test
Mar 27 20:57:42.312: INFO: calico-node-297zr from kube-system started at 2019-03-26 20:46:55 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.312: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:57:42.314: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-27 20:22:57 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.314: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 27 20:57:42.314: INFO: nginx-ingress-controller-kzs5s from ingress-nginx started at 2019-03-26 20:47:15 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.314: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:57:42.314: INFO: cattle-node-agent-sshz4 from cattle-system started at 2019-03-26 20:47:15 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.314: INFO: 	Container agent ready: true, restart count 0
Mar 27 20:57:42.314: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-x92wh from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:57:42.314: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:57:42.314: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:57:42.314: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-13-worker-3 before test
Mar 27 20:57:42.337: INFO: calico-node-fdvdd from kube-system started at 2019-03-26 20:46:31 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.338: INFO: 	Container calico-node ready: true, restart count 0
Mar 27 20:57:42.338: INFO: kube-dns-5fd74c7488-l5xxd from kube-system started at 2019-03-26 20:46:58 +0000 UTC (3 container statuses recorded)
Mar 27 20:57:42.339: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 27 20:57:42.339: INFO: 	Container kubedns ready: true, restart count 0
Mar 27 20:57:42.339: INFO: 	Container sidecar ready: true, restart count 0
Mar 27 20:57:42.339: INFO: sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-xxzjw from heptio-sonobuoy started at 2019-03-27 20:23:00 +0000 UTC (2 container statuses recorded)
Mar 27 20:57:42.339: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 27 20:57:42.339: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 20:57:42.339: INFO: nginx-ingress-controller-dqt72 from ingress-nginx started at 2019-03-26 20:46:41 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.339: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 27 20:57:42.339: INFO: cattle-node-agent-5hjvr from cattle-system started at 2019-03-26 20:46:41 +0000 UTC (1 container statuses recorded)
Mar 27 20:57:42.339: INFO: 	Container agent ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node k8s-conformance-cluster-1-13-control-1
STEP: verifying the node has the label node k8s-conformance-cluster-1-13-etcd-1
STEP: verifying the node has the label node k8s-conformance-cluster-1-13-worker-1
STEP: verifying the node has the label node k8s-conformance-cluster-1-13-worker-2
STEP: verifying the node has the label node k8s-conformance-cluster-1-13-worker-3
Mar 27 20:57:42.651: INFO: Pod cattle-cluster-agent-6db87bf6bc-p669p requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-1
Mar 27 20:57:42.652: INFO: Pod cattle-node-agent-5hjvr requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-3
Mar 27 20:57:42.652: INFO: Pod cattle-node-agent-9jv82 requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-1
Mar 27 20:57:42.652: INFO: Pod cattle-node-agent-bx6pt requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-control-1
Mar 27 20:57:42.652: INFO: Pod cattle-node-agent-kh475 requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-etcd-1
Mar 27 20:57:42.652: INFO: Pod cattle-node-agent-sshz4 requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-2
Mar 27 20:57:42.654: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-2
Mar 27 20:57:42.654: INFO: Pod sonobuoy-e2e-job-b3f04bfb1b6b4be0 requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-control-1
Mar 27 20:57:42.654: INFO: Pod sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-bmkpx requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-control-1
Mar 27 20:57:42.655: INFO: Pod sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-dk7z4 requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-etcd-1
Mar 27 20:57:42.655: INFO: Pod sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-x8vsv requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-1
Mar 27 20:57:42.656: INFO: Pod sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-x92wh requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-2
Mar 27 20:57:42.656: INFO: Pod sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-xxzjw requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-3
Mar 27 20:57:42.656: INFO: Pod default-http-backend-7f8fbb85db-lwxbh requesting resource cpu=10m on Node k8s-conformance-cluster-1-13-worker-1
Mar 27 20:57:42.657: INFO: Pod nginx-ingress-controller-dqt72 requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-3
Mar 27 20:57:42.657: INFO: Pod nginx-ingress-controller-hfgxf requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-etcd-1
Mar 27 20:57:42.657: INFO: Pod nginx-ingress-controller-kzs5s requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-2
Mar 27 20:57:42.658: INFO: Pod nginx-ingress-controller-mw49v requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-control-1
Mar 27 20:57:42.658: INFO: Pod nginx-ingress-controller-rn5b5 requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-1
Mar 27 20:57:42.659: INFO: Pod calico-node-297zr requesting resource cpu=250m on Node k8s-conformance-cluster-1-13-worker-2
Mar 27 20:57:42.659: INFO: Pod calico-node-54w8d requesting resource cpu=250m on Node k8s-conformance-cluster-1-13-etcd-1
Mar 27 20:57:42.660: INFO: Pod calico-node-fdvdd requesting resource cpu=250m on Node k8s-conformance-cluster-1-13-worker-3
Mar 27 20:57:42.660: INFO: Pod calico-node-k5mgj requesting resource cpu=250m on Node k8s-conformance-cluster-1-13-worker-1
Mar 27 20:57:42.661: INFO: Pod calico-node-ns648 requesting resource cpu=250m on Node k8s-conformance-cluster-1-13-control-1
Mar 27 20:57:42.661: INFO: Pod kube-dns-5fd74c7488-l5xxd requesting resource cpu=260m on Node k8s-conformance-cluster-1-13-worker-3
Mar 27 20:57:42.661: INFO: Pod kube-dns-5fd74c7488-z4wvz requesting resource cpu=260m on Node k8s-conformance-cluster-1-13-worker-1
Mar 27 20:57:42.662: INFO: Pod kube-dns-autoscaler-c89df977f-dlths requesting resource cpu=20m on Node k8s-conformance-cluster-1-13-worker-1
Mar 27 20:57:42.662: INFO: Pod metrics-server-7fbd549b78-dl4j5 requesting resource cpu=0m on Node k8s-conformance-cluster-1-13-worker-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6de3e1d-50d2-11e9-9d23-0ac04cf37a48.158fec58d2662101], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4tkxp/filler-pod-f6de3e1d-50d2-11e9-9d23-0ac04cf37a48 to k8s-conformance-cluster-1-13-etcd-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6de3e1d-50d2-11e9-9d23-0ac04cf37a48.158fec5917dab9e7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6de3e1d-50d2-11e9-9d23-0ac04cf37a48.158fec591c29495f], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6de3e1d-50d2-11e9-9d23-0ac04cf37a48.158fec592c12b420], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e23999-50d2-11e9-9d23-0ac04cf37a48.158fec58d4769d23], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4tkxp/filler-pod-f6e23999-50d2-11e9-9d23-0ac04cf37a48 to k8s-conformance-cluster-1-13-worker-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e23999-50d2-11e9-9d23-0ac04cf37a48.158fec5902d14acc], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e23999-50d2-11e9-9d23-0ac04cf37a48.158fec5906b3a630], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e23999-50d2-11e9-9d23-0ac04cf37a48.158fec5915b280e1], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e542f0-50d2-11e9-9d23-0ac04cf37a48.158fec58d65a8646], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4tkxp/filler-pod-f6e542f0-50d2-11e9-9d23-0ac04cf37a48 to k8s-conformance-cluster-1-13-worker-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e542f0-50d2-11e9-9d23-0ac04cf37a48.158fec592711f987], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e542f0-50d2-11e9-9d23-0ac04cf37a48.158fec592b09c9f7], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e542f0-50d2-11e9-9d23-0ac04cf37a48.158fec5937d958d1], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e8ec5f-50d2-11e9-9d23-0ac04cf37a48.158fec58dcd3bda6], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4tkxp/filler-pod-f6e8ec5f-50d2-11e9-9d23-0ac04cf37a48 to k8s-conformance-cluster-1-13-worker-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e8ec5f-50d2-11e9-9d23-0ac04cf37a48.158fec5909b159fa], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e8ec5f-50d2-11e9-9d23-0ac04cf37a48.158fec590bd29399], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6e8ec5f-50d2-11e9-9d23-0ac04cf37a48.158fec591128de6c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6f09ad2-50d2-11e9-9d23-0ac04cf37a48.158fec58e0d35232], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4tkxp/filler-pod-f6f09ad2-50d2-11e9-9d23-0ac04cf37a48 to k8s-conformance-cluster-1-13-control-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6f09ad2-50d2-11e9-9d23-0ac04cf37a48.158fec591bebcf0a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6f09ad2-50d2-11e9-9d23-0ac04cf37a48.158fec591e769d25], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f6f09ad2-50d2-11e9-9d23-0ac04cf37a48.158fec59265a3b1e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158fec59d4dc789f], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 Insufficient cpu.]
STEP: removing the label node off the node k8s-conformance-cluster-1-13-worker-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-conformance-cluster-1-13-control-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-conformance-cluster-1-13-etcd-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-conformance-cluster-1-13-worker-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-conformance-cluster-1-13-worker-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:57:48.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4tkxp" for this suite.
Mar 27 20:57:56.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:57:56.487: INFO: namespace: e2e-tests-sched-pred-4tkxp, resource: bindings, ignored listing per whitelist
Mar 27 20:57:56.760: INFO: namespace e2e-tests-sched-pred-4tkxp deletion completed in 8.343831618s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.691 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:57:56.770: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 27 20:57:56.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-279nr'
Mar 27 20:57:57.135: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 27 20:57:57.135: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar 27 20:57:57.169: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-6h87h]
Mar 27 20:57:57.169: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-6h87h" in namespace "e2e-tests-kubectl-279nr" to be "running and ready"
Mar 27 20:57:57.192: INFO: Pod "e2e-test-nginx-rc-6h87h": Phase="Pending", Reason="", readiness=false. Elapsed: 22.900172ms
Mar 27 20:57:59.201: INFO: Pod "e2e-test-nginx-rc-6h87h": Phase="Running", Reason="", readiness=true. Elapsed: 2.032150074s
Mar 27 20:57:59.201: INFO: Pod "e2e-test-nginx-rc-6h87h" satisfied condition "running and ready"
Mar 27 20:57:59.201: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-6h87h]
Mar 27 20:57:59.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-279nr'
Mar 27 20:57:59.400: INFO: stderr: ""
Mar 27 20:57:59.400: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Mar 27 20:57:59.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-279nr'
Mar 27 20:57:59.551: INFO: stderr: ""
Mar 27 20:57:59.551: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:57:59.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-279nr" for this suite.
Mar 27 20:58:05.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:58:05.670: INFO: namespace: e2e-tests-kubectl-279nr, resource: bindings, ignored listing per whitelist
Mar 27 20:58:05.867: INFO: namespace e2e-tests-kubectl-279nr deletion completed in 6.304007649s

• [SLOW TEST:9.099 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:58:05.869: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-04cde8d2-50d3-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 20:58:06.083: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-04d12ef3-50d3-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-d9hw4" to be "success or failure"
Mar 27 20:58:06.109: INFO: Pod "pod-projected-secrets-04d12ef3-50d3-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 26.464397ms
Mar 27 20:58:08.117: INFO: Pod "pod-projected-secrets-04d12ef3-50d3-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034335754s
STEP: Saw pod success
Mar 27 20:58:08.117: INFO: Pod "pod-projected-secrets-04d12ef3-50d3-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:58:08.125: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-secrets-04d12ef3-50d3-11e9-9d23-0ac04cf37a48 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 27 20:58:08.244: INFO: Waiting for pod pod-projected-secrets-04d12ef3-50d3-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:58:08.280: INFO: Pod pod-projected-secrets-04d12ef3-50d3-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:58:08.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d9hw4" for this suite.
Mar 27 20:58:14.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:58:14.570: INFO: namespace: e2e-tests-projected-d9hw4, resource: bindings, ignored listing per whitelist
Mar 27 20:58:14.608: INFO: namespace e2e-tests-projected-d9hw4 deletion completed in 6.279157684s

• [SLOW TEST:8.740 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:58:14.610: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 20:58:14.768: INFO: Waiting up to 5m0s for pod "downwardapi-volume-09fd26e7-50d3-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-82tng" to be "success or failure"
Mar 27 20:58:14.785: INFO: Pod "downwardapi-volume-09fd26e7-50d3-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 17.176933ms
Mar 27 20:58:16.791: INFO: Pod "downwardapi-volume-09fd26e7-50d3-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.023046217s
Mar 27 20:58:18.801: INFO: Pod "downwardapi-volume-09fd26e7-50d3-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0328516s
STEP: Saw pod success
Mar 27 20:58:18.801: INFO: Pod "downwardapi-volume-09fd26e7-50d3-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:58:18.814: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-09fd26e7-50d3-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 20:58:18.906: INFO: Waiting for pod downwardapi-volume-09fd26e7-50d3-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:58:18.915: INFO: Pod downwardapi-volume-09fd26e7-50d3-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:58:18.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-82tng" for this suite.
Mar 27 20:58:24.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:58:25.216: INFO: namespace: e2e-tests-projected-82tng, resource: bindings, ignored listing per whitelist
Mar 27 20:58:25.270: INFO: namespace e2e-tests-projected-82tng deletion completed in 6.335886226s

• [SLOW TEST:10.660 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:58:25.278: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-xh6n9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 27 20:58:25.444: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 27 20:58:49.821: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.97:8080/dial?request=hostName&protocol=http&host=10.42.2.67&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xh6n9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 20:58:49.821: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:58:50.185: INFO: Waiting for endpoints: map[]
Mar 27 20:58:50.194: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.97:8080/dial?request=hostName&protocol=http&host=10.42.0.88&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xh6n9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 20:58:50.194: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:58:50.364: INFO: Waiting for endpoints: map[]
Mar 27 20:58:50.373: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.97:8080/dial?request=hostName&protocol=http&host=10.42.1.96&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xh6n9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 20:58:50.374: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:58:50.606: INFO: Waiting for endpoints: map[]
Mar 27 20:58:50.615: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.97:8080/dial?request=hostName&protocol=http&host=10.42.4.93&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xh6n9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 20:58:50.616: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:58:50.828: INFO: Waiting for endpoints: map[]
Mar 27 20:58:50.836: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.97:8080/dial?request=hostName&protocol=http&host=10.42.3.62&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xh6n9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 20:58:50.836: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 20:58:50.988: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:58:50.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-xh6n9" for this suite.
Mar 27 20:59:17.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:59:17.136: INFO: namespace: e2e-tests-pod-network-test-xh6n9, resource: bindings, ignored listing per whitelist
Mar 27 20:59:17.309: INFO: namespace e2e-tests-pod-network-test-xh6n9 deletion completed in 26.304981892s

• [SLOW TEST:52.031 seconds]
[sig-network] Networking
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:59:17.310: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-jt4qc in namespace e2e-tests-proxy-kxx9p
I0327 20:59:17.515452      14 runners.go:184] Created replication controller with name: proxy-service-jt4qc, namespace: e2e-tests-proxy-kxx9p, replica count: 1
I0327 20:59:18.566273      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 20:59:19.567013      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 20:59:20.567418      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 20:59:21.568421      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 20:59:22.568842      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 20:59:23.569262      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 20:59:24.569628      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 20:59:25.569922      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 20:59:26.570196      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 20:59:27.570475      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 20:59:28.570785      14 runners.go:184] proxy-service-jt4qc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 27 20:59:28.576: INFO: setup took 11.116889005s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 27 20:59:28.646: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 69.903095ms)
Mar 27 20:59:28.649: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 71.300665ms)
Mar 27 20:59:28.650: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 73.44354ms)
Mar 27 20:59:28.651: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 72.767053ms)
Mar 27 20:59:28.651: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 73.439208ms)
Mar 27 20:59:28.651: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 73.386588ms)
Mar 27 20:59:28.651: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 73.529167ms)
Mar 27 20:59:28.654: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 75.856818ms)
Mar 27 20:59:28.656: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 78.690389ms)
Mar 27 20:59:28.657: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 79.984407ms)
Mar 27 20:59:28.658: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 81.448269ms)
Mar 27 20:59:28.689: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 112.426952ms)
Mar 27 20:59:28.699: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 122.499169ms)
Mar 27 20:59:28.700: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 122.463474ms)
Mar 27 20:59:28.701: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 124.019192ms)
Mar 27 20:59:28.701: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 123.404096ms)
Mar 27 20:59:28.713: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 11.587834ms)
Mar 27 20:59:28.736: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 31.198369ms)
Mar 27 20:59:28.739: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 36.865447ms)
Mar 27 20:59:28.740: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 38.169271ms)
Mar 27 20:59:28.741: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 39.540951ms)
Mar 27 20:59:28.742: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 36.818636ms)
Mar 27 20:59:28.744: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 41.285897ms)
Mar 27 20:59:28.745: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 42.554478ms)
Mar 27 20:59:28.746: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 43.716679ms)
Mar 27 20:59:28.747: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 44.852463ms)
Mar 27 20:59:28.756: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 53.076902ms)
Mar 27 20:59:28.758: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 53.212508ms)
Mar 27 20:59:28.759: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 56.558244ms)
Mar 27 20:59:28.760: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 57.999549ms)
Mar 27 20:59:28.761: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 58.557989ms)
Mar 27 20:59:28.762: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 58.859903ms)
Mar 27 20:59:28.822: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 59.776209ms)
Mar 27 20:59:28.822: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 59.518672ms)
Mar 27 20:59:28.822: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 59.703013ms)
Mar 27 20:59:28.823: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 61.625087ms)
Mar 27 20:59:28.824: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 62.720953ms)
Mar 27 20:59:28.825: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 61.713317ms)
Mar 27 20:59:28.826: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 63.502467ms)
Mar 27 20:59:28.826: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 64.37409ms)
Mar 27 20:59:28.827: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 63.562842ms)
Mar 27 20:59:28.827: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 63.906838ms)
Mar 27 20:59:28.828: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 65.247313ms)
Mar 27 20:59:28.829: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 66.669638ms)
Mar 27 20:59:28.831: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 68.994307ms)
Mar 27 20:59:28.832: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 69.915702ms)
Mar 27 20:59:28.835: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 72.980405ms)
Mar 27 20:59:28.836: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 73.406705ms)
Mar 27 20:59:28.867: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 29.485522ms)
Mar 27 20:59:28.869: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 32.259407ms)
Mar 27 20:59:28.869: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 33.076527ms)
Mar 27 20:59:28.871: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 33.572407ms)
Mar 27 20:59:28.872: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 35.228437ms)
Mar 27 20:59:28.872: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 35.750633ms)
Mar 27 20:59:28.876: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 39.031575ms)
Mar 27 20:59:28.877: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 38.942193ms)
Mar 27 20:59:28.877: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 40.122822ms)
Mar 27 20:59:28.877: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 39.390485ms)
Mar 27 20:59:28.882: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 45.613942ms)
Mar 27 20:59:28.883: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 46.197375ms)
Mar 27 20:59:28.885: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 47.487339ms)
Mar 27 20:59:28.887: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 50.039623ms)
Mar 27 20:59:28.888: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 50.644304ms)
Mar 27 20:59:28.888: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 51.723383ms)
Mar 27 20:59:28.923: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 35.264556ms)
Mar 27 20:59:28.927: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 38.923849ms)
Mar 27 20:59:28.947: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 58.627298ms)
Mar 27 20:59:28.948: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 58.356029ms)
Mar 27 20:59:28.948: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 59.990717ms)
Mar 27 20:59:28.949: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 59.208029ms)
Mar 27 20:59:28.951: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 62.28121ms)
Mar 27 20:59:28.951: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 60.963492ms)
Mar 27 20:59:28.951: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 62.530626ms)
Mar 27 20:59:28.951: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 61.3482ms)
Mar 27 20:59:28.952: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 62.352693ms)
Mar 27 20:59:28.952: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 63.285009ms)
Mar 27 20:59:28.953: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 63.919037ms)
Mar 27 20:59:28.955: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 65.753389ms)
Mar 27 20:59:28.955: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 65.32701ms)
Mar 27 20:59:28.956: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 65.685451ms)
Mar 27 20:59:28.991: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 33.086606ms)
Mar 27 20:59:28.994: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 36.452221ms)
Mar 27 20:59:28.997: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 40.384996ms)
Mar 27 20:59:28.997: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 40.72099ms)
Mar 27 20:59:28.997: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 41.230453ms)
Mar 27 20:59:29.002: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 45.302048ms)
Mar 27 20:59:29.012: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 55.119389ms)
Mar 27 20:59:29.014: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 56.290457ms)
Mar 27 20:59:29.014: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 57.581619ms)
Mar 27 20:59:29.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 63.597099ms)
Mar 27 20:59:29.023: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 65.571283ms)
Mar 27 20:59:29.023: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 65.945058ms)
Mar 27 20:59:29.023: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 67.517866ms)
Mar 27 20:59:29.024: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 67.657371ms)
Mar 27 20:59:29.026: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 69.98001ms)
Mar 27 20:59:29.027: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 70.077997ms)
Mar 27 20:59:29.069: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 41.290744ms)
Mar 27 20:59:29.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 39.671505ms)
Mar 27 20:59:29.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 42.997147ms)
Mar 27 20:59:29.071: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 41.602674ms)
Mar 27 20:59:29.073: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 45.48319ms)
Mar 27 20:59:29.074: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 44.516112ms)
Mar 27 20:59:29.074: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 44.158022ms)
Mar 27 20:59:29.077: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 48.616188ms)
Mar 27 20:59:29.080: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 50.714947ms)
Mar 27 20:59:29.082: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 54.100404ms)
Mar 27 20:59:29.084: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 53.638089ms)
Mar 27 20:59:29.085: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 54.399882ms)
Mar 27 20:59:29.087: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 57.335958ms)
Mar 27 20:59:29.092: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 62.567142ms)
Mar 27 20:59:29.093: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 64.075873ms)
Mar 27 20:59:29.093: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 64.201469ms)
Mar 27 20:59:29.123: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 29.169691ms)
Mar 27 20:59:29.127: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 33.441145ms)
Mar 27 20:59:29.128: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 33.6707ms)
Mar 27 20:59:29.136: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 41.633003ms)
Mar 27 20:59:29.142: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 46.118704ms)
Mar 27 20:59:29.148: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 48.725634ms)
Mar 27 20:59:29.149: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 52.556436ms)
Mar 27 20:59:29.149: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 53.753103ms)
Mar 27 20:59:29.153: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 54.132526ms)
Mar 27 20:59:29.155: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 58.614192ms)
Mar 27 20:59:29.159: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 64.796849ms)
Mar 27 20:59:29.159: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 59.869998ms)
Mar 27 20:59:29.162: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 62.126434ms)
Mar 27 20:59:29.162: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 62.551519ms)
Mar 27 20:59:29.165: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 70.273989ms)
Mar 27 20:59:29.167: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 71.044813ms)
Mar 27 20:59:29.188: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 20.125778ms)
Mar 27 20:59:29.199: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 28.798743ms)
Mar 27 20:59:29.213: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 44.413284ms)
Mar 27 20:59:29.222: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 53.647399ms)
Mar 27 20:59:29.222: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 52.993524ms)
Mar 27 20:59:29.223: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 52.16192ms)
Mar 27 20:59:29.223: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 54.632445ms)
Mar 27 20:59:29.224: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 55.176304ms)
Mar 27 20:59:29.224: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 53.759796ms)
Mar 27 20:59:29.226: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 55.737538ms)
Mar 27 20:59:29.226: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 58.385439ms)
Mar 27 20:59:29.227: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 57.320231ms)
Mar 27 20:59:29.238: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 67.974322ms)
Mar 27 20:59:29.240: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 70.633164ms)
Mar 27 20:59:29.242: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 72.465845ms)
Mar 27 20:59:29.245: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 74.783803ms)
Mar 27 20:59:29.256: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 11.551716ms)
Mar 27 20:59:29.279: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 31.937343ms)
Mar 27 20:59:29.287: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 39.516931ms)
Mar 27 20:59:29.291: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 45.368107ms)
Mar 27 20:59:29.292: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 45.44056ms)
Mar 27 20:59:29.295: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 47.972792ms)
Mar 27 20:59:29.295: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 49.230035ms)
Mar 27 20:59:29.296: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 49.470275ms)
Mar 27 20:59:29.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 50.174855ms)
Mar 27 20:59:29.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 50.968277ms)
Mar 27 20:59:29.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 55.528299ms)
Mar 27 20:59:29.305: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 57.578831ms)
Mar 27 20:59:29.306: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 61.033683ms)
Mar 27 20:59:29.307: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 60.469482ms)
Mar 27 20:59:29.308: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 60.256206ms)
Mar 27 20:59:29.308: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 61.807456ms)
Mar 27 20:59:29.346: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 35.795653ms)
Mar 27 20:59:29.350: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 41.133364ms)
Mar 27 20:59:29.351: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 42.522625ms)
Mar 27 20:59:29.353: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 44.126576ms)
Mar 27 20:59:29.356: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 46.054266ms)
Mar 27 20:59:29.357: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 47.263783ms)
Mar 27 20:59:29.359: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 48.464274ms)
Mar 27 20:59:29.360: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 50.942508ms)
Mar 27 20:59:29.361: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 51.882523ms)
Mar 27 20:59:29.361: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 51.47016ms)
Mar 27 20:59:29.367: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 57.350131ms)
Mar 27 20:59:29.371: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 62.317133ms)
Mar 27 20:59:29.374: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 65.557922ms)
Mar 27 20:59:29.376: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 66.080761ms)
Mar 27 20:59:29.377: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 67.382193ms)
Mar 27 20:59:29.377: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 67.681603ms)
Mar 27 20:59:29.398: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 20.864877ms)
Mar 27 20:59:29.399: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 20.84601ms)
Mar 27 20:59:29.403: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 25.570314ms)
Mar 27 20:59:29.404: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 26.232225ms)
Mar 27 20:59:29.405: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 26.49437ms)
Mar 27 20:59:29.407: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 29.333585ms)
Mar 27 20:59:29.408: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 30.244394ms)
Mar 27 20:59:29.410: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 31.01018ms)
Mar 27 20:59:29.411: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 32.480586ms)
Mar 27 20:59:29.411: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 32.93108ms)
Mar 27 20:59:29.412: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 34.239721ms)
Mar 27 20:59:29.419: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 41.906365ms)
Mar 27 20:59:29.420: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 42.231856ms)
Mar 27 20:59:29.424: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 45.945532ms)
Mar 27 20:59:29.424: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 46.595221ms)
Mar 27 20:59:29.425: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 47.369432ms)
Mar 27 20:59:29.461: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 36.538426ms)
Mar 27 20:59:29.463: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 36.824918ms)
Mar 27 20:59:29.464: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 37.346715ms)
Mar 27 20:59:29.465: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 39.40742ms)
Mar 27 20:59:29.466: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 39.698969ms)
Mar 27 20:59:29.466: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 41.55898ms)
Mar 27 20:59:29.469: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 43.920155ms)
Mar 27 20:59:29.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 46.001825ms)
Mar 27 20:59:29.472: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 45.647618ms)
Mar 27 20:59:29.472: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 47.259187ms)
Mar 27 20:59:29.474: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 48.023599ms)
Mar 27 20:59:29.475: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 49.003574ms)
Mar 27 20:59:29.475: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 49.2841ms)
Mar 27 20:59:29.476: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 50.304187ms)
Mar 27 20:59:29.477: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 51.701633ms)
Mar 27 20:59:29.477: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 51.538097ms)
Mar 27 20:59:29.502: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 22.832255ms)
Mar 27 20:59:29.521: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 43.389705ms)
Mar 27 20:59:29.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 48.007177ms)
Mar 27 20:59:29.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 47.7042ms)
Mar 27 20:59:29.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 48.529134ms)
Mar 27 20:59:29.527: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 47.999792ms)
Mar 27 20:59:29.527: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 48.81905ms)
Mar 27 20:59:29.527: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 48.966861ms)
Mar 27 20:59:29.527: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 48.803369ms)
Mar 27 20:59:29.528: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 49.568956ms)
Mar 27 20:59:29.536: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 57.563262ms)
Mar 27 20:59:29.539: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 61.113407ms)
Mar 27 20:59:29.540: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 62.746388ms)
Mar 27 20:59:29.541: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 64.072065ms)
Mar 27 20:59:29.542: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 63.012714ms)
Mar 27 20:59:29.542: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 64.767574ms)
Mar 27 20:59:29.563: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 20.627738ms)
Mar 27 20:59:29.564: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 20.97492ms)
Mar 27 20:59:29.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 22.771834ms)
Mar 27 20:59:29.570: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 27.759497ms)
Mar 27 20:59:29.574: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 31.110823ms)
Mar 27 20:59:29.577: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 33.87707ms)
Mar 27 20:59:29.590: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 45.925932ms)
Mar 27 20:59:29.590: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 45.996076ms)
Mar 27 20:59:29.590: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 45.910931ms)
Mar 27 20:59:29.590: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 46.908235ms)
Mar 27 20:59:29.591: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 48.039209ms)
Mar 27 20:59:29.591: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 46.748407ms)
Mar 27 20:59:29.599: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 55.924322ms)
Mar 27 20:59:29.601: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 57.374237ms)
Mar 27 20:59:29.603: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 60.253807ms)
Mar 27 20:59:29.604: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 60.037997ms)
Mar 27 20:59:29.636: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 30.702707ms)
Mar 27 20:59:29.638: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 32.282512ms)
Mar 27 20:59:29.638: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 34.24986ms)
Mar 27 20:59:29.639: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 35.47571ms)
Mar 27 20:59:29.640: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 33.891729ms)
Mar 27 20:59:29.641: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 35.900527ms)
Mar 27 20:59:29.644: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 38.837957ms)
Mar 27 20:59:29.644: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 39.617194ms)
Mar 27 20:59:29.645: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 40.830501ms)
Mar 27 20:59:29.652: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 47.681287ms)
Mar 27 20:59:29.653: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 48.526719ms)
Mar 27 20:59:29.655: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 51.231147ms)
Mar 27 20:59:29.655: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 51.046905ms)
Mar 27 20:59:29.656: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 50.685957ms)
Mar 27 20:59:29.656: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 51.922191ms)
Mar 27 20:59:29.657: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 51.815859ms)
Mar 27 20:59:29.686: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 26.384642ms)
Mar 27 20:59:29.691: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 33.173709ms)
Mar 27 20:59:29.700: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 41.292541ms)
Mar 27 20:59:29.707: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 47.533324ms)
Mar 27 20:59:29.708: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 48.989274ms)
Mar 27 20:59:29.708: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 50.466214ms)
Mar 27 20:59:29.708: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 50.72402ms)
Mar 27 20:59:29.709: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 50.731608ms)
Mar 27 20:59:29.710: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 51.981116ms)
Mar 27 20:59:29.711: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 53.18314ms)
Mar 27 20:59:29.728: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 69.897042ms)
Mar 27 20:59:29.731: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 72.722399ms)
Mar 27 20:59:29.732: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 73.465815ms)
Mar 27 20:59:29.733: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 75.254603ms)
Mar 27 20:59:29.733: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 74.635203ms)
Mar 27 20:59:29.734: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 76.684886ms)
Mar 27 20:59:29.764: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 28.267517ms)
Mar 27 20:59:29.779: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 43.012888ms)
Mar 27 20:59:29.792: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 57.894826ms)
Mar 27 20:59:29.794: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 59.605868ms)
Mar 27 20:59:29.795: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 59.683465ms)
Mar 27 20:59:29.796: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 61.934929ms)
Mar 27 20:59:29.797: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 62.593653ms)
Mar 27 20:59:29.798: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 61.931993ms)
Mar 27 20:59:29.799: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 63.179905ms)
Mar 27 20:59:29.799: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 63.55749ms)
Mar 27 20:59:29.799: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 63.682465ms)
Mar 27 20:59:29.799: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 64.063474ms)
Mar 27 20:59:29.799: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 63.217625ms)
Mar 27 20:59:29.800: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 64.433739ms)
Mar 27 20:59:29.800: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 65.869967ms)
Mar 27 20:59:29.801: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 64.800883ms)
Mar 27 20:59:29.836: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 34.342165ms)
Mar 27 20:59:29.845: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 44.085784ms)
Mar 27 20:59:29.845: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 42.374406ms)
Mar 27 20:59:29.853: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 51.784464ms)
Mar 27 20:59:29.860: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 57.843628ms)
Mar 27 20:59:29.861: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 58.574309ms)
Mar 27 20:59:29.861: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 58.207836ms)
Mar 27 20:59:29.862: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 60.343339ms)
Mar 27 20:59:29.864: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 61.662412ms)
Mar 27 20:59:29.865: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 63.002937ms)
Mar 27 20:59:29.865: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 62.005628ms)
Mar 27 20:59:29.866: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 63.567089ms)
Mar 27 20:59:29.872: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 70.552392ms)
Mar 27 20:59:29.873: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 70.830606ms)
Mar 27 20:59:29.874: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 71.567032ms)
Mar 27 20:59:29.876: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 74.455152ms)
Mar 27 20:59:29.906: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 28.089201ms)
Mar 27 20:59:29.907: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:160/proxy/: foo (200; 30.949269ms)
Mar 27 20:59:29.909: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:443/proxy/... (200; 31.328972ms)
Mar 27 20:59:29.913: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 35.611984ms)
Mar 27 20:59:29.914: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:462/proxy/: tls qux (200; 37.463033ms)
Mar 27 20:59:29.916: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:162/proxy/: bar (200; 38.304819ms)
Mar 27 20:59:29.917: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/https:proxy-service-jt4qc-vkbch:460/proxy/: tls baz (200; 39.800204ms)
Mar 27 20:59:29.918: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch:1080/proxy/rewri... (200; 40.845877ms)
Mar 27 20:59:29.919: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/http:proxy-service-jt4qc-vkbch:1080/proxy/... (200; 40.729508ms)
Mar 27 20:59:29.919: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kxx9p/pods/proxy-service-jt4qc-vkbch/proxy/rewriteme"... (200; 41.099936ms)
Mar 27 20:59:29.924: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname2/proxy/: bar (200; 46.438769ms)
Mar 27 20:59:29.924: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname1/proxy/: foo (200; 47.553062ms)
Mar 27 20:59:29.925: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/proxy-service-jt4qc:portname2/proxy/: bar (200; 46.617793ms)
Mar 27 20:59:29.934: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname2/proxy/: tls qux (200; 56.564085ms)
Mar 27 20:59:29.935: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/http:proxy-service-jt4qc:portname1/proxy/: foo (200; 58.063122ms)
Mar 27 20:59:29.936: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kxx9p/services/https:proxy-service-jt4qc:tlsportname1/proxy/: tls baz (200; 58.373932ms)
STEP: deleting ReplicationController proxy-service-jt4qc in namespace e2e-tests-proxy-kxx9p, will wait for the garbage collector to delete the pods
Mar 27 20:59:30.006: INFO: Deleting ReplicationController proxy-service-jt4qc took: 16.014996ms
Mar 27 20:59:30.107: INFO: Terminating ReplicationController proxy-service-jt4qc pods took: 100.397227ms
[AfterEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:59:36.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-kxx9p" for this suite.
Mar 27 20:59:42.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:59:42.874: INFO: namespace: e2e-tests-proxy-kxx9p, resource: bindings, ignored listing per whitelist
Mar 27 20:59:43.101: INFO: namespace e2e-tests-proxy-kxx9p deletion completed in 6.378740906s

• [SLOW TEST:25.792 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:59:43.107: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3ec34a44-50d3-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 20:59:43.332: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3ec55c17-50d3-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-sc9zt" to be "success or failure"
Mar 27 20:59:43.339: INFO: Pod "pod-projected-secrets-3ec55c17-50d3-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 6.929354ms
Mar 27 20:59:45.348: INFO: Pod "pod-projected-secrets-3ec55c17-50d3-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015694072s
STEP: Saw pod success
Mar 27 20:59:45.348: INFO: Pod "pod-projected-secrets-3ec55c17-50d3-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:59:45.360: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-secrets-3ec55c17-50d3-11e9-9d23-0ac04cf37a48 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 27 20:59:45.460: INFO: Waiting for pod pod-projected-secrets-3ec55c17-50d3-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:59:45.467: INFO: Pod pod-projected-secrets-3ec55c17-50d3-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:59:45.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sc9zt" for this suite.
Mar 27 20:59:51.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 20:59:51.816: INFO: namespace: e2e-tests-projected-sc9zt, resource: bindings, ignored listing per whitelist
Mar 27 20:59:51.829: INFO: namespace e2e-tests-projected-sc9zt deletion completed in 6.330604968s

• [SLOW TEST:8.722 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 20:59:51.831: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-43f139e2-50d3-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 20:59:52.009: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-43f33d34-50d3-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-nhxtv" to be "success or failure"
Mar 27 20:59:52.024: INFO: Pod "pod-projected-configmaps-43f33d34-50d3-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 14.838052ms
Mar 27 20:59:54.040: INFO: Pod "pod-projected-configmaps-43f33d34-50d3-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.031727769s
Mar 27 20:59:56.048: INFO: Pod "pod-projected-configmaps-43f33d34-50d3-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039408862s
STEP: Saw pod success
Mar 27 20:59:56.049: INFO: Pod "pod-projected-configmaps-43f33d34-50d3-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 20:59:56.055: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-configmaps-43f33d34-50d3-11e9-9d23-0ac04cf37a48 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 20:59:56.140: INFO: Waiting for pod pod-projected-configmaps-43f33d34-50d3-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 20:59:56.157: INFO: Pod pod-projected-configmaps-43f33d34-50d3-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 20:59:56.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nhxtv" for this suite.
Mar 27 21:00:02.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:00:02.401: INFO: namespace: e2e-tests-projected-nhxtv, resource: bindings, ignored listing per whitelist
Mar 27 21:00:02.511: INFO: namespace e2e-tests-projected-nhxtv deletion completed in 6.335691238s

• [SLOW TEST:10.680 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:00:02.512: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:00:02.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-jjpnc" for this suite.
Mar 27 21:00:08.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:00:09.180: INFO: namespace: e2e-tests-kubelet-test-jjpnc, resource: bindings, ignored listing per whitelist
Mar 27 21:00:09.190: INFO: namespace e2e-tests-kubelet-test-jjpnc deletion completed in 6.271184105s

• [SLOW TEST:6.678 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:00:09.192: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:00:09.322: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e46080d-50d3-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-qrqzc" to be "success or failure"
Mar 27 21:00:09.341: INFO: Pod "downwardapi-volume-4e46080d-50d3-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 18.812572ms
Mar 27 21:00:11.349: INFO: Pod "downwardapi-volume-4e46080d-50d3-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025961422s
STEP: Saw pod success
Mar 27 21:00:11.349: INFO: Pod "downwardapi-volume-4e46080d-50d3-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:00:11.354: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-4e46080d-50d3-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:00:11.428: INFO: Waiting for pod downwardapi-volume-4e46080d-50d3-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:00:11.446: INFO: Pod downwardapi-volume-4e46080d-50d3-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:00:11.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qrqzc" for this suite.
Mar 27 21:00:17.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:00:17.667: INFO: namespace: e2e-tests-downward-api-qrqzc, resource: bindings, ignored listing per whitelist
Mar 27 21:00:17.774: INFO: namespace e2e-tests-downward-api-qrqzc deletion completed in 6.275552886s

• [SLOW TEST:8.582 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:00:17.775: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:00:22.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-vkfzl" for this suite.
Mar 27 21:01:08.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:01:08.272: INFO: namespace: e2e-tests-kubelet-test-vkfzl, resource: bindings, ignored listing per whitelist
Mar 27 21:01:08.311: INFO: namespace e2e-tests-kubelet-test-vkfzl deletion completed in 46.268028472s

• [SLOW TEST:50.537 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:01:08.316: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar 27 21:01:12.600: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-718ddd01-50d3-11e9-9d23-0ac04cf37a48", GenerateName:"", Namespace:"e2e-tests-pods-zl9q4", SelfLink:"/api/v1/namespaces/e2e-tests-pods-zl9q4/pods/pod-submit-remove-718ddd01-50d3-11e9-9d23-0ac04cf37a48", UID:"719077a1-50d3-11e9-8df3-90b8d03c5288", ResourceVersion:"183122", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63689317268, loc:(*time.Location)(0x7b4abe0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"495494843"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.1.103/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-8kd66", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000909d80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8kd66", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000e321b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-conformance-cluster-1-13-etcd-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001fac0c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000e32280)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000e322a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000e322a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000e322ac)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689317268, loc:(*time.Location)(0x7b4abe0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689317270, loc:(*time.Location)(0x7b4abe0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689317270, loc:(*time.Location)(0x7b4abe0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689317268, loc:(*time.Location)(0x7b4abe0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"72.2.115.200", PodIP:"10.42.1.103", StartTime:(*v1.Time)(0xc001eb1d20), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001eb1d40), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d", ContainerID:"docker://568cfeed2cad3c238a0c9968e319675d7580b612bd485123bcbb5d67c563b401"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar 27 21:01:17.648: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:01:17.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zl9q4" for this suite.
Mar 27 21:01:23.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:01:23.774: INFO: namespace: e2e-tests-pods-zl9q4, resource: bindings, ignored listing per whitelist
Mar 27 21:01:23.945: INFO: namespace e2e-tests-pods-zl9q4 deletion completed in 6.280063809s

• [SLOW TEST:15.630 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:01:23.948: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 27 21:01:24.149: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:01:27.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8jp6s" for this suite.
Mar 27 21:01:33.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:01:33.677: INFO: namespace: e2e-tests-init-container-8jp6s, resource: bindings, ignored listing per whitelist
Mar 27 21:01:33.825: INFO: namespace e2e-tests-init-container-8jp6s deletion completed in 6.294925652s

• [SLOW TEST:9.877 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:01:33.830: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:01:33.972: INFO: Creating deployment "nginx-deployment"
Mar 27 21:01:33.989: INFO: Waiting for observed generation 1
Mar 27 21:01:36.019: INFO: Waiting for all required pods to come up
Mar 27 21:01:36.035: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 27 21:01:40.080: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 27 21:01:40.089: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 27 21:01:40.104: INFO: Updating deployment nginx-deployment
Mar 27 21:01:40.104: INFO: Waiting for observed generation 2
Mar 27 21:01:42.151: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 27 21:01:42.242: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 27 21:01:42.255: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 27 21:01:42.349: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 27 21:01:42.349: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 27 21:01:42.357: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 27 21:01:42.386: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 27 21:01:42.386: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 27 21:01:42.424: INFO: Updating deployment nginx-deployment
Mar 27 21:01:42.424: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 27 21:01:42.483: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 27 21:01:44.832: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 27 21:01:45.680: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r9hj8/deployments/nginx-deployment,UID:80bdb138-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183542,Generation:3,CreationTimestamp:2019-03-27 21:01:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-03-27 21:01:42 +0000 UTC 2019-03-27 21:01:42 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-27 21:01:44 +0000 UTC 2019-03-27 21:01:34 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar 27 21:01:45.968: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r9hj8/replicasets/nginx-deployment-65bbdb5f8,UID:84654616-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183525,Generation:3,CreationTimestamp:2019-03-27 21:01:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 80bdb138-50d3-11e9-8df3-90b8d03c5288 0xc00365a437 0xc00365a438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 27 21:01:45.968: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 27 21:01:45.970: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r9hj8/replicasets/nginx-deployment-555b55d965,UID:80c5ee09-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183514,Generation:3,CreationTimestamp:2019-03-27 21:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 80bdb138-50d3-11e9-8df3-90b8d03c5288 0xc00365a377 0xc00365a378}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar 27 21:01:46.206: INFO: Pod "nginx-deployment-555b55d965-2wcqm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2wcqm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-2wcqm,UID:85df761a-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183517,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206c357 0xc00206c358}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206c3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206c3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.168,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.206: INFO: Pod "nginx-deployment-555b55d965-2z87n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2z87n,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-2z87n,UID:860908ab-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183508,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206c497 0xc00206c498}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206c500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206c520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.207: INFO: Pod "nginx-deployment-555b55d965-6ft77" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6ft77,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-6ft77,UID:80cfcdfe-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183323,Generation:0,CreationTimestamp:2019-03-27 21:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.89/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206c5a0 0xc00206c5a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206c600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206c620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.38,PodIP:10.42.0.89,StartTime:2019-03-27 21:01:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-27 21:01:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://2db8b067ef00532eb357c9397a555046dfd8ac28f7de452a038af3191c12ad2b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.208: INFO: Pod "nginx-deployment-555b55d965-8qjwd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8qjwd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-8qjwd,UID:80cfa494-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183331,Generation:0,CreationTimestamp:2019-03-27 21:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.4.96/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206c6f0 0xc00206c6f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206c750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206c770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.168,PodIP:10.42.4.96,StartTime:2019-03-27 21:01:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-27 21:01:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://5419444f612c6e50b23fb36ac14db535839140669e3510130d7e055339e7565d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.209: INFO: Pod "nginx-deployment-555b55d965-8wvjp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8wvjp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-8wvjp,UID:80d6434f-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183321,Generation:0,CreationTimestamp:2019-03-27 21:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.63/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206c840 0xc00206c841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206c8a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206c8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.140,PodIP:10.42.3.63,StartTime:2019-03-27 21:01:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-27 21:01:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://e8acd2a107322548c692afd70e2e694af5bb51e708987f62368340f5a836b03b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.210: INFO: Pod "nginx-deployment-555b55d965-9fj5r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9fj5r,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-9fj5r,UID:80cd9ff9-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183350,Generation:0,CreationTimestamp:2019-03-27 21:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.104/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206c990 0xc00206c991}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206c9f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206ca10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.200,PodIP:10.42.1.104,StartTime:2019-03-27 21:01:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-27 21:01:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://309a3eb38c5ce47642c06bb31254c06319c9960183942c72c0b9b02aaff00d4e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.210: INFO: Pod "nginx-deployment-555b55d965-9qmph" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9qmph,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-9qmph,UID:85d2ca87-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183518,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206d2f0 0xc00206d2f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206d350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206d370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.38,PodIP:,StartTime:2019-03-27 21:01:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.211: INFO: Pod "nginx-deployment-555b55d965-btblv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-btblv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-btblv,UID:86061dce-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183550,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.73/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206d430 0xc00206d431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206d490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206d4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.129,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.211: INFO: Pod "nginx-deployment-555b55d965-bwptl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bwptl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-bwptl,UID:85df5cc6-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183537,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206d567 0xc00206d568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206d5d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206d5f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.200,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.213: INFO: Pod "nginx-deployment-555b55d965-c8vt7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-c8vt7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-c8vt7,UID:86091f29-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183539,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206d6a7 0xc00206d6a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206d710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206d730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.168,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.215: INFO: Pod "nginx-deployment-555b55d965-dv8h8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dv8h8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-dv8h8,UID:80eadb71-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183310,Generation:0,CreationTimestamp:2019-03-27 21:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.69/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206d7f7 0xc00206d7f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206d860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206d880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.129,PodIP:10.42.2.69,StartTime:2019-03-27 21:01:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-27 21:01:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://0a0f4596fdfa93714aae42ae2c260221116a6e1fcb8361186f79b7dfc7842c6e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.215: INFO: Pod "nginx-deployment-555b55d965-dwg2j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dwg2j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-dwg2j,UID:85d32ad6-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183536,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.71/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206d950 0xc00206d951}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206d9b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206d9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.129,PodIP:,StartTime:2019-03-27 21:01:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.216: INFO: Pod "nginx-deployment-555b55d965-h7n2l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-h7n2l,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-h7n2l,UID:80d6859c-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183305,Generation:0,CreationTimestamp:2019-03-27 21:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.68/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206da97 0xc00206da98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206db00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206db20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.129,PodIP:10.42.2.68,StartTime:2019-03-27 21:01:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-27 21:01:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://810eb3dcff9b650293caad0ae00122232218e8f90c38ff08eb0bc1477c666b64}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.216: INFO: Pod "nginx-deployment-555b55d965-lkl68" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lkl68,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-lkl68,UID:85df2b8d-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183529,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206dbe0 0xc00206dbe1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206dc40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206dc60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.38,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.217: INFO: Pod "nginx-deployment-555b55d965-mcz6b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mcz6b,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-mcz6b,UID:80d6726c-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183334,Generation:0,CreationTimestamp:2019-03-27 21:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.4.95/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206dd20 0xc00206dd21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206dd80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206dda0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.168,PodIP:10.42.4.95,StartTime:2019-03-27 21:01:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-27 21:01:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://bb7ea4925a903f39d094b569af92127a776c04043d665220f3e087be9efec04e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.217: INFO: Pod "nginx-deployment-555b55d965-nm2mk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nm2mk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-nm2mk,UID:8609146f-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183509,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206de60 0xc00206de61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206dec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206dee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.218: INFO: Pod "nginx-deployment-555b55d965-pzvhw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pzvhw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-pzvhw,UID:80e85275-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183317,Generation:0,CreationTimestamp:2019-03-27 21:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.64/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc00206df60 0xc00206df61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00206dfc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00206dfe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:34 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.140,PodIP:10.42.3.64,StartTime:2019-03-27 21:01:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-27 21:01:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://a6c56a5d903c4664285f3c9fa8e35f560eb3f229f24c43741f29f5fea3f07a72}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.218: INFO: Pod "nginx-deployment-555b55d965-qhv6j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qhv6j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-qhv6j,UID:85c9f042-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183507,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc000b120a0 0xc000b120a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b12230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b12250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.200,PodIP:,StartTime:2019-03-27 21:01:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.221: INFO: Pod "nginx-deployment-555b55d965-wrbzn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wrbzn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-wrbzn,UID:85df813d-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183551,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.66/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc000b12317 0xc000b12318}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b12380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b123a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.140,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.222: INFO: Pod "nginx-deployment-555b55d965-zzhxd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zzhxd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-555b55d965-zzhxd,UID:86092ae5-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183547,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 80c5ee09-50d3-11e9-8df3-90b8d03c5288 0xc000b124e7 0xc000b124e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b125b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b125d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.38,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.222: INFO: Pod "nginx-deployment-65bbdb5f8-7g47m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7g47m,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-7g47m,UID:85cd80a7-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183489,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b126f0 0xc000b126f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b12760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b12780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.38,PodIP:,StartTime:2019-03-27 21:01:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.222: INFO: Pod "nginx-deployment-65bbdb5f8-7jp9h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7jp9h,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-7jp9h,UID:84a29b31-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183528,Generation:0,CreationTimestamp:2019-03-27 21:01:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.107/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b12bf0 0xc000b12bf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b12cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b12ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.200,PodIP:10.42.1.107,StartTime:2019-03-27 21:01:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.223: INFO: Pod "nginx-deployment-65bbdb5f8-bfr9b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bfr9b,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-bfr9b,UID:85da0003-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183554,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.67/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b12dd0 0xc000b12dd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b12e40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b12e60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.140,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.223: INFO: Pod "nginx-deployment-65bbdb5f8-cgprt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cgprt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-cgprt,UID:846c2a27-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183490,Generation:0,CreationTimestamp:2019-03-27 21:01:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.70/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b132a0 0xc000b132a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b13310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b13330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.129,PodIP:10.42.2.70,StartTime:2019-03-27 21:01:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.224: INFO: Pod "nginx-deployment-65bbdb5f8-j746f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-j746f,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-j746f,UID:86430520-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183560,Generation:0,CreationTimestamp:2019-03-27 21:01:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b13410 0xc000b13411}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b134d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b134f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.38,PodIP:,StartTime:2019-03-27 21:01:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.225: INFO: Pod "nginx-deployment-65bbdb5f8-lw9kp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lw9kp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-lw9kp,UID:8608e19f-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183504,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b135b0 0xc000b135b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b13620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b13640}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.228: INFO: Pod "nginx-deployment-65bbdb5f8-n7xjs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-n7xjs,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-n7xjs,UID:8466d682-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183532,Generation:0,CreationTimestamp:2019-03-27 21:01:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.4.98/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b136c0 0xc000b136c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b13730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b13750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.168,PodIP:,StartTime:2019-03-27 21:01:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.229: INFO: Pod "nginx-deployment-65bbdb5f8-nmmr6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nmmr6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-nmmr6,UID:85d9a039-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183563,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.72/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b13830 0xc000b13831}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b138a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b138c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:42 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.129,PodIP:,StartTime:2019-03-27 21:01:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.229: INFO: Pod "nginx-deployment-65bbdb5f8-rb77g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rb77g,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-rb77g,UID:846c0b17-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183445,Generation:0,CreationTimestamp:2019-03-27 21:01:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.90/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b139a0 0xc000b139a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b13a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b13a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.38,PodIP:,StartTime:2019-03-27 21:01:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.229: INFO: Pod "nginx-deployment-65bbdb5f8-rp76h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rp76h,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-rp76h,UID:8608ee90-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183553,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b13b00 0xc000b13b01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b13b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b13b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.140,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.229: INFO: Pod "nginx-deployment-65bbdb5f8-rsff4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rsff4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-rsff4,UID:86040ac0-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183531,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b13c50 0xc000b13c51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b13cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b13ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.168,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.230: INFO: Pod "nginx-deployment-65bbdb5f8-sdkzp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-sdkzp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-sdkzp,UID:8608fa35-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183552,Generation:0,CreationTimestamp:2019-03-27 21:01:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b13da0 0xc000b13da1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b13e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b13e30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:43 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.200,PodIP:,StartTime:2019-03-27 21:01:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 27 21:01:46.230: INFO: Pod "nginx-deployment-65bbdb5f8-zbqfv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zbqfv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r9hj8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r9hj8/pods/nginx-deployment-65bbdb5f8-zbqfv,UID:84b2770e-50d3-11e9-8df3-90b8d03c5288,ResourceVersion:183526,Generation:0,CreationTimestamp:2019-03-27 21:01:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.65/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84654616-50d3-11e9-8df3-90b8d03c5288 0xc000b13f00 0xc000b13f01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92pvm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92pvm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-92pvm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-worker-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b13f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b13f90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:01:40 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.140,PodIP:10.42.3.65,StartTime:2019-03-27 21:01:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:01:46.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-r9hj8" for this suite.
Mar 27 21:02:01.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:02:01.117: INFO: namespace: e2e-tests-deployment-r9hj8, resource: bindings, ignored listing per whitelist
Mar 27 21:02:01.282: INFO: namespace e2e-tests-deployment-r9hj8 deletion completed in 14.819918597s

• [SLOW TEST:27.453 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:02:01.283: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-96qv
STEP: Creating a pod to test atomic-volume-subpath
Mar 27 21:02:01.517: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-96qv" in namespace "e2e-tests-subpath-jlkfs" to be "success or failure"
Mar 27 21:02:01.568: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Pending", Reason="", readiness=false. Elapsed: 50.990421ms
Mar 27 21:02:03.577: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059211861s
Mar 27 21:02:05.583: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Running", Reason="", readiness=false. Elapsed: 4.065942671s
Mar 27 21:02:07.591: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Running", Reason="", readiness=false. Elapsed: 6.073904085s
Mar 27 21:02:09.631: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Running", Reason="", readiness=false. Elapsed: 8.114030212s
Mar 27 21:02:11.643: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Running", Reason="", readiness=false. Elapsed: 10.125210778s
Mar 27 21:02:13.649: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Running", Reason="", readiness=false. Elapsed: 12.131942744s
Mar 27 21:02:15.656: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Running", Reason="", readiness=false. Elapsed: 14.138502954s
Mar 27 21:02:17.663: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Running", Reason="", readiness=false. Elapsed: 16.145870535s
Mar 27 21:02:19.672: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Running", Reason="", readiness=false. Elapsed: 18.154682796s
Mar 27 21:02:21.692: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Running", Reason="", readiness=false. Elapsed: 20.174445413s
Mar 27 21:02:23.719: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Running", Reason="", readiness=false. Elapsed: 22.201856208s
Mar 27 21:02:25.724: INFO: Pod "pod-subpath-test-downwardapi-96qv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.207056576s
STEP: Saw pod success
Mar 27 21:02:25.724: INFO: Pod "pod-subpath-test-downwardapi-96qv" satisfied condition "success or failure"
Mar 27 21:02:25.729: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-subpath-test-downwardapi-96qv container test-container-subpath-downwardapi-96qv: <nil>
STEP: delete the pod
Mar 27 21:02:25.805: INFO: Waiting for pod pod-subpath-test-downwardapi-96qv to disappear
Mar 27 21:02:25.827: INFO: Pod pod-subpath-test-downwardapi-96qv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-96qv
Mar 27 21:02:25.827: INFO: Deleting pod "pod-subpath-test-downwardapi-96qv" in namespace "e2e-tests-subpath-jlkfs"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:02:25.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jlkfs" for this suite.
Mar 27 21:02:31.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:02:31.970: INFO: namespace: e2e-tests-subpath-jlkfs, resource: bindings, ignored listing per whitelist
Mar 27 21:02:32.119: INFO: namespace e2e-tests-subpath-jlkfs deletion completed in 6.275750114s

• [SLOW TEST:30.835 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:02:32.121: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a38322a7-50d3-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 21:02:32.344: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a384f17a-50d3-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-bjq84" to be "success or failure"
Mar 27 21:02:32.360: INFO: Pod "pod-projected-configmaps-a384f17a-50d3-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 16.631232ms
Mar 27 21:02:34.368: INFO: Pod "pod-projected-configmaps-a384f17a-50d3-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02426814s
STEP: Saw pod success
Mar 27 21:02:34.369: INFO: Pod "pod-projected-configmaps-a384f17a-50d3-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:02:34.377: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-configmaps-a384f17a-50d3-11e9-9d23-0ac04cf37a48 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 21:02:34.465: INFO: Waiting for pod pod-projected-configmaps-a384f17a-50d3-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:02:34.473: INFO: Pod pod-projected-configmaps-a384f17a-50d3-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:02:34.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bjq84" for this suite.
Mar 27 21:02:40.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:02:40.757: INFO: namespace: e2e-tests-projected-bjq84, resource: bindings, ignored listing per whitelist
Mar 27 21:02:40.762: INFO: namespace e2e-tests-projected-bjq84 deletion completed in 6.248258742s

• [SLOW TEST:8.641 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:02:40.766: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar 27 21:02:40.910: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-nf8nz" to be "success or failure"
Mar 27 21:02:40.925: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 15.363675ms
Mar 27 21:02:42.930: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020586992s
STEP: Saw pod success
Mar 27 21:02:42.930: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 27 21:02:42.963: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 27 21:02:43.116: INFO: Waiting for pod pod-host-path-test to disappear
Mar 27 21:02:43.139: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:02:43.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-nf8nz" for this suite.
Mar 27 21:02:49.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:02:49.326: INFO: namespace: e2e-tests-hostpath-nf8nz, resource: bindings, ignored listing per whitelist
Mar 27 21:02:49.416: INFO: namespace e2e-tests-hostpath-nf8nz deletion completed in 6.239212006s

• [SLOW TEST:8.650 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:02:49.417: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-adcdb57e-50d3-11e9-9d23-0ac04cf37a48
STEP: Creating configMap with name cm-test-opt-upd-adcdb660-50d3-11e9-9d23-0ac04cf37a48
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-adcdb57e-50d3-11e9-9d23-0ac04cf37a48
STEP: Updating configmap cm-test-opt-upd-adcdb660-50d3-11e9-9d23-0ac04cf37a48
STEP: Creating configMap with name cm-test-opt-create-adcdb6a3-50d3-11e9-9d23-0ac04cf37a48
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:04:02.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6vndg" for this suite.
Mar 27 21:04:26.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:04:27.236: INFO: namespace: e2e-tests-projected-6vndg, resource: bindings, ignored listing per whitelist
Mar 27 21:04:27.250: INFO: namespace e2e-tests-projected-6vndg deletion completed in 24.32183389s

• [SLOW TEST:97.833 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:04:27.251: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:04:27.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-f5tjn" for this suite.
Mar 27 21:04:33.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:04:33.493: INFO: namespace: e2e-tests-services-f5tjn, resource: bindings, ignored listing per whitelist
Mar 27 21:04:33.675: INFO: namespace e2e-tests-services-f5tjn deletion completed in 6.265176462s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.425 seconds]
[sig-network] Services
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:04:33.677: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-27x5x
I0327 21:04:33.833021      14 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-27x5x, replica count: 1
I0327 21:04:34.883715      14 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 21:04:35.884263      14 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 27 21:04:36.026: INFO: Created: latency-svc-jck8g
Mar 27 21:04:36.054: INFO: Got endpoints: latency-svc-jck8g [69.650987ms]
Mar 27 21:04:36.108: INFO: Created: latency-svc-wlh5p
Mar 27 21:04:36.115: INFO: Got endpoints: latency-svc-wlh5p [60.076431ms]
Mar 27 21:04:36.133: INFO: Created: latency-svc-dh5lp
Mar 27 21:04:36.159: INFO: Got endpoints: latency-svc-dh5lp [100.726748ms]
Mar 27 21:04:36.172: INFO: Created: latency-svc-tn4dx
Mar 27 21:04:36.195: INFO: Created: latency-svc-6cbdx
Mar 27 21:04:36.218: INFO: Got endpoints: latency-svc-6cbdx [162.570755ms]
Mar 27 21:04:36.218: INFO: Got endpoints: latency-svc-tn4dx [163.302612ms]
Mar 27 21:04:36.267: INFO: Created: latency-svc-r5xcq
Mar 27 21:04:36.318: INFO: Created: latency-svc-5rh6p
Mar 27 21:04:36.324: INFO: Got endpoints: latency-svc-r5xcq [268.483517ms]
Mar 27 21:04:36.341: INFO: Got endpoints: latency-svc-5rh6p [285.76026ms]
Mar 27 21:04:36.386: INFO: Created: latency-svc-zzmq9
Mar 27 21:04:36.407: INFO: Got endpoints: latency-svc-zzmq9 [351.795744ms]
Mar 27 21:04:36.439: INFO: Created: latency-svc-njwcc
Mar 27 21:04:36.445: INFO: Got endpoints: latency-svc-njwcc [388.615415ms]
Mar 27 21:04:36.470: INFO: Created: latency-svc-v6bc7
Mar 27 21:04:36.547: INFO: Got endpoints: latency-svc-v6bc7 [491.228564ms]
Mar 27 21:04:36.590: INFO: Created: latency-svc-6ggbf
Mar 27 21:04:36.597: INFO: Got endpoints: latency-svc-6ggbf [541.071664ms]
Mar 27 21:04:36.633: INFO: Created: latency-svc-vrrs5
Mar 27 21:04:36.638: INFO: Got endpoints: latency-svc-vrrs5 [581.331615ms]
Mar 27 21:04:36.654: INFO: Created: latency-svc-7lgd5
Mar 27 21:04:36.694: INFO: Got endpoints: latency-svc-7lgd5 [637.924925ms]
Mar 27 21:04:36.702: INFO: Created: latency-svc-sdnvx
Mar 27 21:04:36.710: INFO: Got endpoints: latency-svc-sdnvx [653.352135ms]
Mar 27 21:04:36.760: INFO: Created: latency-svc-cml77
Mar 27 21:04:36.772: INFO: Got endpoints: latency-svc-cml77 [715.617719ms]
Mar 27 21:04:36.791: INFO: Created: latency-svc-vmvfs
Mar 27 21:04:36.817: INFO: Got endpoints: latency-svc-vmvfs [759.866416ms]
Mar 27 21:04:36.842: INFO: Created: latency-svc-4qdnd
Mar 27 21:04:36.854: INFO: Got endpoints: latency-svc-4qdnd [81.359433ms]
Mar 27 21:04:36.867: INFO: Created: latency-svc-mjmff
Mar 27 21:04:36.899: INFO: Created: latency-svc-f6mqd
Mar 27 21:04:36.916: INFO: Got endpoints: latency-svc-mjmff [801.175382ms]
Mar 27 21:04:36.932: INFO: Created: latency-svc-4pmp2
Mar 27 21:04:36.938: INFO: Got endpoints: latency-svc-f6mqd [778.841911ms]
Mar 27 21:04:36.962: INFO: Created: latency-svc-kmmzz
Mar 27 21:04:36.966: INFO: Got endpoints: latency-svc-4pmp2 [748.451203ms]
Mar 27 21:04:36.983: INFO: Got endpoints: latency-svc-kmmzz [764.505203ms]
Mar 27 21:04:37.008: INFO: Created: latency-svc-5p9vz
Mar 27 21:04:37.015: INFO: Got endpoints: latency-svc-5p9vz [691.262803ms]
Mar 27 21:04:37.041: INFO: Created: latency-svc-hcwcp
Mar 27 21:04:37.067: INFO: Got endpoints: latency-svc-hcwcp [725.725324ms]
Mar 27 21:04:37.081: INFO: Created: latency-svc-sk5rq
Mar 27 21:04:37.105: INFO: Got endpoints: latency-svc-sk5rq [697.137289ms]
Mar 27 21:04:37.117: INFO: Created: latency-svc-bhgqf
Mar 27 21:04:37.125: INFO: Got endpoints: latency-svc-bhgqf [680.436789ms]
Mar 27 21:04:37.153: INFO: Created: latency-svc-lkqk6
Mar 27 21:04:37.164: INFO: Got endpoints: latency-svc-lkqk6 [616.59783ms]
Mar 27 21:04:37.194: INFO: Created: latency-svc-scqxp
Mar 27 21:04:37.207: INFO: Got endpoints: latency-svc-scqxp [609.402337ms]
Mar 27 21:04:37.232: INFO: Created: latency-svc-dcpv4
Mar 27 21:04:37.257: INFO: Got endpoints: latency-svc-dcpv4 [618.941964ms]
Mar 27 21:04:37.275: INFO: Created: latency-svc-ff46p
Mar 27 21:04:37.291: INFO: Got endpoints: latency-svc-ff46p [595.897839ms]
Mar 27 21:04:37.313: INFO: Created: latency-svc-twtxx
Mar 27 21:04:37.320: INFO: Got endpoints: latency-svc-twtxx [609.433129ms]
Mar 27 21:04:37.345: INFO: Created: latency-svc-5b4kq
Mar 27 21:04:37.350: INFO: Got endpoints: latency-svc-5b4kq [532.491148ms]
Mar 27 21:04:37.372: INFO: Created: latency-svc-sjddc
Mar 27 21:04:37.375: INFO: Got endpoints: latency-svc-sjddc [521.398673ms]
Mar 27 21:04:37.405: INFO: Created: latency-svc-jf9h6
Mar 27 21:04:37.427: INFO: Got endpoints: latency-svc-jf9h6 [511.382112ms]
Mar 27 21:04:37.437: INFO: Created: latency-svc-2tb7n
Mar 27 21:04:37.463: INFO: Created: latency-svc-259mc
Mar 27 21:04:37.463: INFO: Got endpoints: latency-svc-2tb7n [525.286732ms]
Mar 27 21:04:37.476: INFO: Got endpoints: latency-svc-259mc [509.196898ms]
Mar 27 21:04:37.499: INFO: Created: latency-svc-svp7s
Mar 27 21:04:37.521: INFO: Got endpoints: latency-svc-svp7s [537.740246ms]
Mar 27 21:04:37.525: INFO: Created: latency-svc-cz2xh
Mar 27 21:04:37.529: INFO: Got endpoints: latency-svc-cz2xh [513.80428ms]
Mar 27 21:04:37.558: INFO: Created: latency-svc-ggn5q
Mar 27 21:04:37.577: INFO: Got endpoints: latency-svc-ggn5q [510.224799ms]
Mar 27 21:04:37.593: INFO: Created: latency-svc-r42fw
Mar 27 21:04:37.604: INFO: Got endpoints: latency-svc-r42fw [499.474745ms]
Mar 27 21:04:37.631: INFO: Created: latency-svc-gwh88
Mar 27 21:04:37.638: INFO: Got endpoints: latency-svc-gwh88 [512.992824ms]
Mar 27 21:04:37.664: INFO: Created: latency-svc-pxdr6
Mar 27 21:04:37.675: INFO: Created: latency-svc-gsxlp
Mar 27 21:04:37.682: INFO: Got endpoints: latency-svc-pxdr6 [517.662808ms]
Mar 27 21:04:37.710: INFO: Got endpoints: latency-svc-gsxlp [502.632249ms]
Mar 27 21:04:37.757: INFO: Created: latency-svc-ws7nx
Mar 27 21:04:37.764: INFO: Got endpoints: latency-svc-ws7nx [506.902874ms]
Mar 27 21:04:37.789: INFO: Created: latency-svc-7fpbc
Mar 27 21:04:37.801: INFO: Got endpoints: latency-svc-7fpbc [510.203081ms]
Mar 27 21:04:37.823: INFO: Created: latency-svc-9zl44
Mar 27 21:04:37.852: INFO: Got endpoints: latency-svc-9zl44 [532.201652ms]
Mar 27 21:04:37.861: INFO: Created: latency-svc-b22vf
Mar 27 21:04:37.865: INFO: Got endpoints: latency-svc-b22vf [515.630264ms]
Mar 27 21:04:37.900: INFO: Created: latency-svc-r7vlg
Mar 27 21:04:37.921: INFO: Created: latency-svc-qqsvk
Mar 27 21:04:37.925: INFO: Got endpoints: latency-svc-r7vlg [549.65141ms]
Mar 27 21:04:37.934: INFO: Got endpoints: latency-svc-qqsvk [506.215024ms]
Mar 27 21:04:37.953: INFO: Created: latency-svc-xg5cb
Mar 27 21:04:37.961: INFO: Got endpoints: latency-svc-xg5cb [497.306613ms]
Mar 27 21:04:37.982: INFO: Created: latency-svc-xv52z
Mar 27 21:04:38.018: INFO: Created: latency-svc-5gkjj
Mar 27 21:04:38.030: INFO: Got endpoints: latency-svc-xv52z [554.755907ms]
Mar 27 21:04:38.053: INFO: Got endpoints: latency-svc-5gkjj [531.775134ms]
Mar 27 21:04:38.073: INFO: Created: latency-svc-l5cjl
Mar 27 21:04:38.095: INFO: Got endpoints: latency-svc-l5cjl [566.292323ms]
Mar 27 21:04:38.108: INFO: Created: latency-svc-p8k55
Mar 27 21:04:38.144: INFO: Got endpoints: latency-svc-p8k55 [566.705922ms]
Mar 27 21:04:38.165: INFO: Created: latency-svc-6tpqg
Mar 27 21:04:38.203: INFO: Got endpoints: latency-svc-6tpqg [599.099235ms]
Mar 27 21:04:38.211: INFO: Created: latency-svc-qx5g6
Mar 27 21:04:38.216: INFO: Got endpoints: latency-svc-qx5g6 [578.162008ms]
Mar 27 21:04:38.248: INFO: Created: latency-svc-xb6rp
Mar 27 21:04:38.300: INFO: Got endpoints: latency-svc-xb6rp [617.81686ms]
Mar 27 21:04:38.306: INFO: Created: latency-svc-6nqbj
Mar 27 21:04:38.316: INFO: Got endpoints: latency-svc-6nqbj [606.643061ms]
Mar 27 21:04:38.373: INFO: Created: latency-svc-j7p5h
Mar 27 21:04:38.373: INFO: Created: latency-svc-bh4bd
Mar 27 21:04:38.383: INFO: Got endpoints: latency-svc-bh4bd [618.923635ms]
Mar 27 21:04:38.430: INFO: Got endpoints: latency-svc-j7p5h [629.147806ms]
Mar 27 21:04:38.464: INFO: Created: latency-svc-9279f
Mar 27 21:04:38.464: INFO: Got endpoints: latency-svc-9279f [612.259103ms]
Mar 27 21:04:38.488: INFO: Created: latency-svc-w8x7z
Mar 27 21:04:38.509: INFO: Got endpoints: latency-svc-w8x7z [643.608625ms]
Mar 27 21:04:38.519: INFO: Created: latency-svc-jvcjc
Mar 27 21:04:38.550: INFO: Created: latency-svc-7vttg
Mar 27 21:04:38.557: INFO: Got endpoints: latency-svc-jvcjc [632.03478ms]
Mar 27 21:04:38.569: INFO: Got endpoints: latency-svc-7vttg [634.795271ms]
Mar 27 21:04:38.603: INFO: Created: latency-svc-zbchl
Mar 27 21:04:38.619: INFO: Got endpoints: latency-svc-zbchl [658.435313ms]
Mar 27 21:04:38.631: INFO: Created: latency-svc-wg7kg
Mar 27 21:04:38.647: INFO: Got endpoints: latency-svc-wg7kg [616.414177ms]
Mar 27 21:04:38.675: INFO: Created: latency-svc-spxrf
Mar 27 21:04:38.691: INFO: Got endpoints: latency-svc-spxrf [638.599391ms]
Mar 27 21:04:38.722: INFO: Created: latency-svc-42zg2
Mar 27 21:04:38.739: INFO: Got endpoints: latency-svc-42zg2 [643.170201ms]
Mar 27 21:04:38.767: INFO: Created: latency-svc-5hqq8
Mar 27 21:04:38.774: INFO: Got endpoints: latency-svc-5hqq8 [629.183764ms]
Mar 27 21:04:38.794: INFO: Created: latency-svc-db7br
Mar 27 21:04:38.813: INFO: Got endpoints: latency-svc-db7br [609.561288ms]
Mar 27 21:04:38.829: INFO: Created: latency-svc-qsgn6
Mar 27 21:04:38.842: INFO: Got endpoints: latency-svc-qsgn6 [625.055277ms]
Mar 27 21:04:38.870: INFO: Created: latency-svc-s6jcn
Mar 27 21:04:38.886: INFO: Got endpoints: latency-svc-s6jcn [586.617427ms]
Mar 27 21:04:38.928: INFO: Created: latency-svc-tsfvt
Mar 27 21:04:38.960: INFO: Got endpoints: latency-svc-tsfvt [643.589157ms]
Mar 27 21:04:38.963: INFO: Created: latency-svc-kvrfl
Mar 27 21:04:38.982: INFO: Got endpoints: latency-svc-kvrfl [599.392995ms]
Mar 27 21:04:39.001: INFO: Created: latency-svc-2v44n
Mar 27 21:04:39.032: INFO: Got endpoints: latency-svc-2v44n [601.484782ms]
Mar 27 21:04:39.051: INFO: Created: latency-svc-dxth4
Mar 27 21:04:39.062: INFO: Got endpoints: latency-svc-dxth4 [597.419766ms]
Mar 27 21:04:39.096: INFO: Created: latency-svc-5lkpk
Mar 27 21:04:39.102: INFO: Got endpoints: latency-svc-5lkpk [592.764698ms]
Mar 27 21:04:39.109: INFO: Created: latency-svc-d6hkt
Mar 27 21:04:39.124: INFO: Got endpoints: latency-svc-d6hkt [567.151826ms]
Mar 27 21:04:39.142: INFO: Created: latency-svc-hxfbv
Mar 27 21:04:39.172: INFO: Created: latency-svc-4wn5t
Mar 27 21:04:39.174: INFO: Got endpoints: latency-svc-hxfbv [605.381938ms]
Mar 27 21:04:39.183: INFO: Got endpoints: latency-svc-4wn5t [563.767381ms]
Mar 27 21:04:39.208: INFO: Created: latency-svc-tptf4
Mar 27 21:04:39.216: INFO: Got endpoints: latency-svc-tptf4 [568.904915ms]
Mar 27 21:04:39.231: INFO: Created: latency-svc-w8dth
Mar 27 21:04:39.245: INFO: Got endpoints: latency-svc-w8dth [554.079794ms]
Mar 27 21:04:39.264: INFO: Created: latency-svc-wkfl6
Mar 27 21:04:39.273: INFO: Got endpoints: latency-svc-wkfl6 [534.556679ms]
Mar 27 21:04:39.292: INFO: Created: latency-svc-nnkfw
Mar 27 21:04:39.306: INFO: Got endpoints: latency-svc-nnkfw [532.600049ms]
Mar 27 21:04:39.316: INFO: Created: latency-svc-l6lx9
Mar 27 21:04:39.331: INFO: Got endpoints: latency-svc-l6lx9 [518.218201ms]
Mar 27 21:04:39.372: INFO: Created: latency-svc-2l8xj
Mar 27 21:04:39.400: INFO: Created: latency-svc-w9wft
Mar 27 21:04:39.403: INFO: Got endpoints: latency-svc-2l8xj [560.955876ms]
Mar 27 21:04:39.416: INFO: Got endpoints: latency-svc-w9wft [529.560106ms]
Mar 27 21:04:39.450: INFO: Created: latency-svc-bqr8p
Mar 27 21:04:39.491: INFO: Created: latency-svc-dsq7s
Mar 27 21:04:39.492: INFO: Got endpoints: latency-svc-bqr8p [532.026537ms]
Mar 27 21:04:39.505: INFO: Got endpoints: latency-svc-dsq7s [522.339735ms]
Mar 27 21:04:39.538: INFO: Created: latency-svc-mfwvm
Mar 27 21:04:39.560: INFO: Got endpoints: latency-svc-mfwvm [527.708904ms]
Mar 27 21:04:39.581: INFO: Created: latency-svc-sfkwz
Mar 27 21:04:39.602: INFO: Got endpoints: latency-svc-sfkwz [539.772639ms]
Mar 27 21:04:39.623: INFO: Created: latency-svc-ksttg
Mar 27 21:04:39.644: INFO: Got endpoints: latency-svc-ksttg [541.901646ms]
Mar 27 21:04:39.651: INFO: Created: latency-svc-rvgkp
Mar 27 21:04:39.697: INFO: Got endpoints: latency-svc-rvgkp [572.801371ms]
Mar 27 21:04:39.724: INFO: Created: latency-svc-xznlb
Mar 27 21:04:39.766: INFO: Got endpoints: latency-svc-xznlb [592.178869ms]
Mar 27 21:04:39.791: INFO: Created: latency-svc-4h5fm
Mar 27 21:04:39.842: INFO: Created: latency-svc-jdwbf
Mar 27 21:04:39.856: INFO: Got endpoints: latency-svc-4h5fm [672.930357ms]
Mar 27 21:04:39.870: INFO: Got endpoints: latency-svc-jdwbf [653.826505ms]
Mar 27 21:04:39.897: INFO: Created: latency-svc-tp48f
Mar 27 21:04:39.914: INFO: Got endpoints: latency-svc-tp48f [668.613817ms]
Mar 27 21:04:39.938: INFO: Created: latency-svc-92tdl
Mar 27 21:04:39.953: INFO: Got endpoints: latency-svc-92tdl [680.064036ms]
Mar 27 21:04:39.975: INFO: Created: latency-svc-ldzdp
Mar 27 21:04:39.996: INFO: Got endpoints: latency-svc-ldzdp [689.328704ms]
Mar 27 21:04:40.008: INFO: Created: latency-svc-rxmbg
Mar 27 21:04:40.032: INFO: Got endpoints: latency-svc-rxmbg [700.721338ms]
Mar 27 21:04:40.048: INFO: Created: latency-svc-vz98r
Mar 27 21:04:40.059: INFO: Got endpoints: latency-svc-vz98r [655.958826ms]
Mar 27 21:04:40.096: INFO: Created: latency-svc-4lw2b
Mar 27 21:04:40.139: INFO: Created: latency-svc-9sv8s
Mar 27 21:04:40.142: INFO: Got endpoints: latency-svc-4lw2b [725.674936ms]
Mar 27 21:04:40.154: INFO: Got endpoints: latency-svc-9sv8s [662.144876ms]
Mar 27 21:04:40.179: INFO: Created: latency-svc-hv82k
Mar 27 21:04:40.198: INFO: Got endpoints: latency-svc-hv82k [692.873171ms]
Mar 27 21:04:40.204: INFO: Created: latency-svc-mknzm
Mar 27 21:04:40.231: INFO: Got endpoints: latency-svc-mknzm [671.11469ms]
Mar 27 21:04:40.256: INFO: Created: latency-svc-7vxck
Mar 27 21:04:40.268: INFO: Got endpoints: latency-svc-7vxck [666.635097ms]
Mar 27 21:04:40.278: INFO: Created: latency-svc-x6sdx
Mar 27 21:04:40.301: INFO: Got endpoints: latency-svc-x6sdx [656.979846ms]
Mar 27 21:04:40.335: INFO: Created: latency-svc-vfzt4
Mar 27 21:04:40.351: INFO: Got endpoints: latency-svc-vfzt4 [653.539825ms]
Mar 27 21:04:40.391: INFO: Created: latency-svc-t6xbv
Mar 27 21:04:40.404: INFO: Got endpoints: latency-svc-t6xbv [637.939248ms]
Mar 27 21:04:40.451: INFO: Created: latency-svc-mflvb
Mar 27 21:04:40.474: INFO: Got endpoints: latency-svc-mflvb [618.177902ms]
Mar 27 21:04:40.509: INFO: Created: latency-svc-thmxz
Mar 27 21:04:40.550: INFO: Got endpoints: latency-svc-thmxz [679.84337ms]
Mar 27 21:04:40.588: INFO: Created: latency-svc-srs2j
Mar 27 21:04:40.592: INFO: Got endpoints: latency-svc-srs2j [678.180564ms]
Mar 27 21:04:40.620: INFO: Created: latency-svc-s8rlv
Mar 27 21:04:40.632: INFO: Got endpoints: latency-svc-s8rlv [678.724289ms]
Mar 27 21:04:40.651: INFO: Created: latency-svc-xgqxx
Mar 27 21:04:40.669: INFO: Created: latency-svc-hprlp
Mar 27 21:04:40.683: INFO: Got endpoints: latency-svc-xgqxx [686.94363ms]
Mar 27 21:04:40.701: INFO: Got endpoints: latency-svc-hprlp [668.92353ms]
Mar 27 21:04:40.720: INFO: Created: latency-svc-stqtt
Mar 27 21:04:40.729: INFO: Got endpoints: latency-svc-stqtt [669.800557ms]
Mar 27 21:04:40.793: INFO: Created: latency-svc-rxxpg
Mar 27 21:04:40.810: INFO: Got endpoints: latency-svc-rxxpg [668.45835ms]
Mar 27 21:04:40.850: INFO: Created: latency-svc-fqbdr
Mar 27 21:04:40.861: INFO: Got endpoints: latency-svc-fqbdr [706.30056ms]
Mar 27 21:04:40.884: INFO: Created: latency-svc-l2h4s
Mar 27 21:04:40.926: INFO: Got endpoints: latency-svc-l2h4s [727.849385ms]
Mar 27 21:04:40.964: INFO: Created: latency-svc-lzk4x
Mar 27 21:04:40.987: INFO: Got endpoints: latency-svc-lzk4x [755.939277ms]
Mar 27 21:04:41.053: INFO: Created: latency-svc-bnt8c
Mar 27 21:04:41.081: INFO: Got endpoints: latency-svc-bnt8c [812.822543ms]
Mar 27 21:04:41.125: INFO: Created: latency-svc-gn4mh
Mar 27 21:04:41.138: INFO: Got endpoints: latency-svc-gn4mh [836.623161ms]
Mar 27 21:04:41.167: INFO: Created: latency-svc-ngrzp
Mar 27 21:04:41.173: INFO: Got endpoints: latency-svc-ngrzp [821.650379ms]
Mar 27 21:04:41.202: INFO: Created: latency-svc-t7l8n
Mar 27 21:04:41.212: INFO: Got endpoints: latency-svc-t7l8n [807.22806ms]
Mar 27 21:04:41.241: INFO: Created: latency-svc-hwq4j
Mar 27 21:04:41.245: INFO: Got endpoints: latency-svc-hwq4j [770.668508ms]
Mar 27 21:04:41.271: INFO: Created: latency-svc-jjw49
Mar 27 21:04:41.285: INFO: Got endpoints: latency-svc-jjw49 [734.924123ms]
Mar 27 21:04:41.319: INFO: Created: latency-svc-x4r5d
Mar 27 21:04:41.329: INFO: Got endpoints: latency-svc-x4r5d [735.984589ms]
Mar 27 21:04:41.340: INFO: Created: latency-svc-z68pj
Mar 27 21:04:41.366: INFO: Got endpoints: latency-svc-z68pj [734.220606ms]
Mar 27 21:04:41.380: INFO: Created: latency-svc-d4bpf
Mar 27 21:04:41.411: INFO: Got endpoints: latency-svc-d4bpf [728.235839ms]
Mar 27 21:04:41.420: INFO: Created: latency-svc-xvg4l
Mar 27 21:04:41.426: INFO: Got endpoints: latency-svc-xvg4l [724.388053ms]
Mar 27 21:04:41.461: INFO: Created: latency-svc-vb5cd
Mar 27 21:04:41.484: INFO: Created: latency-svc-spxcr
Mar 27 21:04:41.485: INFO: Got endpoints: latency-svc-vb5cd [755.94889ms]
Mar 27 21:04:41.503: INFO: Got endpoints: latency-svc-spxcr [692.765236ms]
Mar 27 21:04:41.530: INFO: Created: latency-svc-v4n24
Mar 27 21:04:41.556: INFO: Got endpoints: latency-svc-v4n24 [695.533068ms]
Mar 27 21:04:41.570: INFO: Created: latency-svc-rvmn6
Mar 27 21:04:41.586: INFO: Got endpoints: latency-svc-rvmn6 [660.265956ms]
Mar 27 21:04:41.606: INFO: Created: latency-svc-5kt7f
Mar 27 21:04:41.612: INFO: Got endpoints: latency-svc-5kt7f [624.568586ms]
Mar 27 21:04:41.637: INFO: Created: latency-svc-7q9kz
Mar 27 21:04:41.659: INFO: Got endpoints: latency-svc-7q9kz [577.96436ms]
Mar 27 21:04:41.667: INFO: Created: latency-svc-qhnts
Mar 27 21:04:41.697: INFO: Got endpoints: latency-svc-qhnts [559.111002ms]
Mar 27 21:04:41.710: INFO: Created: latency-svc-ckbpp
Mar 27 21:04:41.729: INFO: Got endpoints: latency-svc-ckbpp [555.91973ms]
Mar 27 21:04:41.742: INFO: Created: latency-svc-thw7l
Mar 27 21:04:41.761: INFO: Got endpoints: latency-svc-thw7l [548.901023ms]
Mar 27 21:04:41.776: INFO: Created: latency-svc-r6xw4
Mar 27 21:04:41.800: INFO: Got endpoints: latency-svc-r6xw4 [554.795074ms]
Mar 27 21:04:41.827: INFO: Created: latency-svc-4ft8l
Mar 27 21:04:41.839: INFO: Got endpoints: latency-svc-4ft8l [553.810488ms]
Mar 27 21:04:41.900: INFO: Created: latency-svc-pdxxp
Mar 27 21:04:41.906: INFO: Got endpoints: latency-svc-pdxxp [577.618155ms]
Mar 27 21:04:41.927: INFO: Created: latency-svc-4shjs
Mar 27 21:04:41.936: INFO: Got endpoints: latency-svc-4shjs [569.215174ms]
Mar 27 21:04:41.966: INFO: Created: latency-svc-nl47n
Mar 27 21:04:41.983: INFO: Got endpoints: latency-svc-nl47n [572.143469ms]
Mar 27 21:04:42.001: INFO: Created: latency-svc-4qq5q
Mar 27 21:04:42.009: INFO: Got endpoints: latency-svc-4qq5q [582.946423ms]
Mar 27 21:04:42.026: INFO: Created: latency-svc-5l2sw
Mar 27 21:04:42.036: INFO: Got endpoints: latency-svc-5l2sw [551.505692ms]
Mar 27 21:04:42.060: INFO: Created: latency-svc-5r5g4
Mar 27 21:04:42.080: INFO: Got endpoints: latency-svc-5r5g4 [577.151883ms]
Mar 27 21:04:42.111: INFO: Created: latency-svc-7tsg2
Mar 27 21:04:42.112: INFO: Created: latency-svc-7vg9x
Mar 27 21:04:42.121: INFO: Got endpoints: latency-svc-7tsg2 [564.576571ms]
Mar 27 21:04:42.134: INFO: Got endpoints: latency-svc-7vg9x [547.707065ms]
Mar 27 21:04:42.161: INFO: Created: latency-svc-5nzxf
Mar 27 21:04:42.170: INFO: Got endpoints: latency-svc-5nzxf [558.554992ms]
Mar 27 21:04:42.184: INFO: Created: latency-svc-4g265
Mar 27 21:04:42.198: INFO: Got endpoints: latency-svc-4g265 [538.194205ms]
Mar 27 21:04:42.214: INFO: Created: latency-svc-8kt54
Mar 27 21:04:42.226: INFO: Got endpoints: latency-svc-8kt54 [528.507631ms]
Mar 27 21:04:42.259: INFO: Created: latency-svc-c2dnd
Mar 27 21:04:42.267: INFO: Got endpoints: latency-svc-c2dnd [537.804521ms]
Mar 27 21:04:42.301: INFO: Created: latency-svc-xbv2k
Mar 27 21:04:42.312: INFO: Got endpoints: latency-svc-xbv2k [551.316942ms]
Mar 27 21:04:42.350: INFO: Created: latency-svc-k9qc7
Mar 27 21:04:42.356: INFO: Got endpoints: latency-svc-k9qc7 [555.905413ms]
Mar 27 21:04:42.375: INFO: Created: latency-svc-ddkcv
Mar 27 21:04:42.425: INFO: Got endpoints: latency-svc-ddkcv [586.187681ms]
Mar 27 21:04:42.429: INFO: Created: latency-svc-r2ntb
Mar 27 21:04:42.437: INFO: Got endpoints: latency-svc-r2ntb [530.870129ms]
Mar 27 21:04:42.455: INFO: Created: latency-svc-lb44f
Mar 27 21:04:42.471: INFO: Got endpoints: latency-svc-lb44f [535.115294ms]
Mar 27 21:04:42.484: INFO: Created: latency-svc-lk78p
Mar 27 21:04:42.498: INFO: Got endpoints: latency-svc-lk78p [514.457281ms]
Mar 27 21:04:42.515: INFO: Created: latency-svc-w8bpr
Mar 27 21:04:42.546: INFO: Got endpoints: latency-svc-w8bpr [537.091486ms]
Mar 27 21:04:42.548: INFO: Created: latency-svc-bl6wd
Mar 27 21:04:42.595: INFO: Created: latency-svc-z4cxm
Mar 27 21:04:42.620: INFO: Got endpoints: latency-svc-bl6wd [583.793198ms]
Mar 27 21:04:42.623: INFO: Created: latency-svc-vtw7q
Mar 27 21:04:42.631: INFO: Got endpoints: latency-svc-z4cxm [550.39738ms]
Mar 27 21:04:42.651: INFO: Created: latency-svc-7mbz2
Mar 27 21:04:42.676: INFO: Created: latency-svc-mb42t
Mar 27 21:04:42.685: INFO: Got endpoints: latency-svc-vtw7q [564.031149ms]
Mar 27 21:04:42.710: INFO: Created: latency-svc-2brtm
Mar 27 21:04:42.732: INFO: Created: latency-svc-dkqbv
Mar 27 21:04:42.744: INFO: Got endpoints: latency-svc-7mbz2 [610.159733ms]
Mar 27 21:04:42.797: INFO: Created: latency-svc-8858s
Mar 27 21:04:42.940: INFO: Created: latency-svc-zfrkt
Mar 27 21:04:42.941: INFO: Created: latency-svc-rbztk
Mar 27 21:04:42.941: INFO: Got endpoints: latency-svc-2brtm [742.793452ms]
Mar 27 21:04:42.941: INFO: Got endpoints: latency-svc-mb42t [770.593946ms]
Mar 27 21:04:42.944: INFO: Got endpoints: latency-svc-dkqbv [718.451683ms]
Mar 27 21:04:42.961: INFO: Got endpoints: latency-svc-8858s [694.389038ms]
Mar 27 21:04:42.980: INFO: Created: latency-svc-sdjmb
Mar 27 21:04:42.982: INFO: Got endpoints: latency-svc-rbztk [669.583724ms]
Mar 27 21:04:43.015: INFO: Created: latency-svc-gbl52
Mar 27 21:04:43.033: INFO: Created: latency-svc-pglb8
Mar 27 21:04:43.036: INFO: Got endpoints: latency-svc-zfrkt [680.221177ms]
Mar 27 21:04:43.061: INFO: Created: latency-svc-m9wht
Mar 27 21:04:43.098: INFO: Created: latency-svc-jc62t
Mar 27 21:04:43.115: INFO: Got endpoints: latency-svc-sdjmb [689.902387ms]
Mar 27 21:04:43.145: INFO: Created: latency-svc-g5hnn
Mar 27 21:04:43.184: INFO: Got endpoints: latency-svc-gbl52 [746.802262ms]
Mar 27 21:04:43.212: INFO: Created: latency-svc-qfw29
Mar 27 21:04:43.218: INFO: Got endpoints: latency-svc-pglb8 [746.712236ms]
Mar 27 21:04:43.232: INFO: Got endpoints: latency-svc-m9wht [734.37153ms]
Mar 27 21:04:43.257: INFO: Created: latency-svc-82zl9
Mar 27 21:04:43.274: INFO: Created: latency-svc-jldh9
Mar 27 21:04:43.286: INFO: Got endpoints: latency-svc-jc62t [740.178911ms]
Mar 27 21:04:43.309: INFO: Created: latency-svc-bs46c
Mar 27 21:04:43.329: INFO: Created: latency-svc-cknnp
Mar 27 21:04:43.340: INFO: Got endpoints: latency-svc-g5hnn [719.912479ms]
Mar 27 21:04:43.355: INFO: Created: latency-svc-b5cxs
Mar 27 21:04:43.365: INFO: Created: latency-svc-lpbws
Mar 27 21:04:43.396: INFO: Got endpoints: latency-svc-qfw29 [765.252513ms]
Mar 27 21:04:43.469: INFO: Created: latency-svc-9ldcc
Mar 27 21:04:43.490: INFO: Created: latency-svc-n5lgq
Mar 27 21:04:43.513: INFO: Got endpoints: latency-svc-jldh9 [769.357995ms]
Mar 27 21:04:43.514: INFO: Got endpoints: latency-svc-82zl9 [828.545989ms]
Mar 27 21:04:43.528: INFO: Created: latency-svc-rs52c
Mar 27 21:04:43.546: INFO: Got endpoints: latency-svc-bs46c [605.155261ms]
Mar 27 21:04:43.562: INFO: Created: latency-svc-sp79n
Mar 27 21:04:43.579: INFO: Created: latency-svc-4zkpg
Mar 27 21:04:43.585: INFO: Got endpoints: latency-svc-cknnp [643.935088ms]
Mar 27 21:04:43.610: INFO: Created: latency-svc-6h4ll
Mar 27 21:04:43.629: INFO: Created: latency-svc-lm79d
Mar 27 21:04:43.643: INFO: Got endpoints: latency-svc-b5cxs [698.400239ms]
Mar 27 21:04:43.679: INFO: Created: latency-svc-l2xcp
Mar 27 21:04:43.703: INFO: Got endpoints: latency-svc-lpbws [741.266211ms]
Mar 27 21:04:43.719: INFO: Created: latency-svc-qdqzm
Mar 27 21:04:43.755: INFO: Got endpoints: latency-svc-9ldcc [773.679332ms]
Mar 27 21:04:43.762: INFO: Created: latency-svc-k5mcf
Mar 27 21:04:43.799: INFO: Got endpoints: latency-svc-n5lgq [762.122559ms]
Mar 27 21:04:43.803: INFO: Created: latency-svc-slz6p
Mar 27 21:04:43.826: INFO: Created: latency-svc-kxb5f
Mar 27 21:04:43.841: INFO: Got endpoints: latency-svc-rs52c [725.708592ms]
Mar 27 21:04:43.889: INFO: Created: latency-svc-kjt77
Mar 27 21:04:43.933: INFO: Got endpoints: latency-svc-sp79n [748.36958ms]
Mar 27 21:04:43.969: INFO: Created: latency-svc-cpkn7
Mar 27 21:04:43.976: INFO: Got endpoints: latency-svc-4zkpg [757.732302ms]
Mar 27 21:04:43.989: INFO: Got endpoints: latency-svc-6h4ll [756.974347ms]
Mar 27 21:04:44.022: INFO: Created: latency-svc-ncqmp
Mar 27 21:04:44.031: INFO: Got endpoints: latency-svc-lm79d [744.692881ms]
Mar 27 21:04:44.059: INFO: Created: latency-svc-kc7vg
Mar 27 21:04:44.084: INFO: Created: latency-svc-f5ddw
Mar 27 21:04:44.088: INFO: Got endpoints: latency-svc-l2xcp [748.157769ms]
Mar 27 21:04:44.110: INFO: Created: latency-svc-g5c4l
Mar 27 21:04:44.132: INFO: Created: latency-svc-2jrjs
Mar 27 21:04:44.139: INFO: Got endpoints: latency-svc-qdqzm [742.285035ms]
Mar 27 21:04:44.178: INFO: Got endpoints: latency-svc-k5mcf [664.769296ms]
Mar 27 21:04:44.227: INFO: Got endpoints: latency-svc-slz6p [712.839605ms]
Mar 27 21:04:44.279: INFO: Got endpoints: latency-svc-kxb5f [733.51269ms]
Mar 27 21:04:44.327: INFO: Got endpoints: latency-svc-kjt77 [742.045778ms]
Mar 27 21:04:44.388: INFO: Got endpoints: latency-svc-cpkn7 [744.881888ms]
Mar 27 21:04:44.427: INFO: Got endpoints: latency-svc-ncqmp [724.423746ms]
Mar 27 21:04:44.485: INFO: Got endpoints: latency-svc-kc7vg [728.918555ms]
Mar 27 21:04:44.527: INFO: Got endpoints: latency-svc-f5ddw [728.602175ms]
Mar 27 21:04:44.582: INFO: Got endpoints: latency-svc-g5c4l [741.282284ms]
Mar 27 21:04:44.628: INFO: Got endpoints: latency-svc-2jrjs [694.956478ms]
Mar 27 21:04:44.628: INFO: Latencies: [60.076431ms 81.359433ms 100.726748ms 162.570755ms 163.302612ms 268.483517ms 285.76026ms 351.795744ms 388.615415ms 491.228564ms 497.306613ms 499.474745ms 502.632249ms 506.215024ms 506.902874ms 509.196898ms 510.203081ms 510.224799ms 511.382112ms 512.992824ms 513.80428ms 514.457281ms 515.630264ms 517.662808ms 518.218201ms 521.398673ms 522.339735ms 525.286732ms 527.708904ms 528.507631ms 529.560106ms 530.870129ms 531.775134ms 532.026537ms 532.201652ms 532.491148ms 532.600049ms 534.556679ms 535.115294ms 537.091486ms 537.740246ms 537.804521ms 538.194205ms 539.772639ms 541.071664ms 541.901646ms 547.707065ms 548.901023ms 549.65141ms 550.39738ms 551.316942ms 551.505692ms 553.810488ms 554.079794ms 554.755907ms 554.795074ms 555.905413ms 555.91973ms 558.554992ms 559.111002ms 560.955876ms 563.767381ms 564.031149ms 564.576571ms 566.292323ms 566.705922ms 567.151826ms 568.904915ms 569.215174ms 572.143469ms 572.801371ms 577.151883ms 577.618155ms 577.96436ms 578.162008ms 581.331615ms 582.946423ms 583.793198ms 586.187681ms 586.617427ms 592.178869ms 592.764698ms 595.897839ms 597.419766ms 599.099235ms 599.392995ms 601.484782ms 605.155261ms 605.381938ms 606.643061ms 609.402337ms 609.433129ms 609.561288ms 610.159733ms 612.259103ms 616.414177ms 616.59783ms 617.81686ms 618.177902ms 618.923635ms 618.941964ms 624.568586ms 625.055277ms 629.147806ms 629.183764ms 632.03478ms 634.795271ms 637.924925ms 637.939248ms 638.599391ms 643.170201ms 643.589157ms 643.608625ms 643.935088ms 653.352135ms 653.539825ms 653.826505ms 655.958826ms 656.979846ms 658.435313ms 660.265956ms 662.144876ms 664.769296ms 666.635097ms 668.45835ms 668.613817ms 668.92353ms 669.583724ms 669.800557ms 671.11469ms 672.930357ms 678.180564ms 678.724289ms 679.84337ms 680.064036ms 680.221177ms 680.436789ms 686.94363ms 689.328704ms 689.902387ms 691.262803ms 692.765236ms 692.873171ms 694.389038ms 694.956478ms 695.533068ms 697.137289ms 698.400239ms 700.721338ms 706.30056ms 712.839605ms 715.617719ms 718.451683ms 719.912479ms 724.388053ms 724.423746ms 725.674936ms 725.708592ms 725.725324ms 727.849385ms 728.235839ms 728.602175ms 728.918555ms 733.51269ms 734.220606ms 734.37153ms 734.924123ms 735.984589ms 740.178911ms 741.266211ms 741.282284ms 742.045778ms 742.285035ms 742.793452ms 744.692881ms 744.881888ms 746.712236ms 746.802262ms 748.157769ms 748.36958ms 748.451203ms 755.939277ms 755.94889ms 756.974347ms 757.732302ms 759.866416ms 762.122559ms 764.505203ms 765.252513ms 769.357995ms 770.593946ms 770.668508ms 773.679332ms 778.841911ms 801.175382ms 807.22806ms 812.822543ms 821.650379ms 828.545989ms 836.623161ms]
Mar 27 21:04:44.628: INFO: 50 %ile: 618.941964ms
Mar 27 21:04:44.628: INFO: 90 %ile: 748.451203ms
Mar 27 21:04:44.628: INFO: 99 %ile: 828.545989ms
Mar 27 21:04:44.628: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:04:44.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-27x5x" for this suite.
Mar 27 21:05:18.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:05:18.821: INFO: namespace: e2e-tests-svc-latency-27x5x, resource: bindings, ignored listing per whitelist
Mar 27 21:05:18.906: INFO: namespace e2e-tests-svc-latency-27x5x deletion completed in 34.259420185s

• [SLOW TEST:45.229 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:05:18.911: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 27 21:05:23.205: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 27 21:05:23.216: INFO: Pod pod-with-poststart-http-hook still exists
Mar 27 21:05:25.216: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 27 21:05:25.222: INFO: Pod pod-with-poststart-http-hook still exists
Mar 27 21:05:27.217: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 27 21:05:27.225: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:05:27.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-xp4px" for this suite.
Mar 27 21:05:51.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:05:51.342: INFO: namespace: e2e-tests-container-lifecycle-hook-xp4px, resource: bindings, ignored listing per whitelist
Mar 27 21:05:51.571: INFO: namespace e2e-tests-container-lifecycle-hook-xp4px deletion completed in 24.328985689s

• [SLOW TEST:32.660 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:05:51.574: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-1a5c403f-50d4-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 21:05:51.742: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1a5e5596-50d4-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-87jjc" to be "success or failure"
Mar 27 21:05:51.762: INFO: Pod "pod-projected-configmaps-1a5e5596-50d4-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 19.312381ms
Mar 27 21:05:53.767: INFO: Pod "pod-projected-configmaps-1a5e5596-50d4-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024567486s
STEP: Saw pod success
Mar 27 21:05:53.767: INFO: Pod "pod-projected-configmaps-1a5e5596-50d4-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:05:53.788: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-configmaps-1a5e5596-50d4-11e9-9d23-0ac04cf37a48 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 21:05:53.884: INFO: Waiting for pod pod-projected-configmaps-1a5e5596-50d4-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:05:53.902: INFO: Pod pod-projected-configmaps-1a5e5596-50d4-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:05:53.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-87jjc" for this suite.
Mar 27 21:05:59.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:06:00.110: INFO: namespace: e2e-tests-projected-87jjc, resource: bindings, ignored listing per whitelist
Mar 27 21:06:00.183: INFO: namespace e2e-tests-projected-87jjc deletion completed in 6.245444588s

• [SLOW TEST:8.610 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:06:00.184: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 27 21:06:02.925: INFO: Successfully updated pod "pod-update-1f7b61bb-50d4-11e9-9d23-0ac04cf37a48"
STEP: verifying the updated pod is in kubernetes
Mar 27 21:06:02.942: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:06:02.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8k987" for this suite.
Mar 27 21:06:26.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:06:27.028: INFO: namespace: e2e-tests-pods-8k987, resource: bindings, ignored listing per whitelist
Mar 27 21:06:27.183: INFO: namespace e2e-tests-pods-8k987 deletion completed in 24.225409519s

• [SLOW TEST:26.999 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:06:27.185: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 27 21:06:27.451: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-9hvh8,SelfLink:/api/v1/namespaces/e2e-tests-watch-9hvh8/configmaps/e2e-watch-test-resource-version,UID:2f94fb86-50d4-11e9-8df3-90b8d03c5288,ResourceVersion:185916,Generation:0,CreationTimestamp:2019-03-27 21:06:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 27 21:06:27.451: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-9hvh8,SelfLink:/api/v1/namespaces/e2e-tests-watch-9hvh8/configmaps/e2e-watch-test-resource-version,UID:2f94fb86-50d4-11e9-8df3-90b8d03c5288,ResourceVersion:185917,Generation:0,CreationTimestamp:2019-03-27 21:06:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:06:27.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-9hvh8" for this suite.
Mar 27 21:06:33.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:06:33.720: INFO: namespace: e2e-tests-watch-9hvh8, resource: bindings, ignored listing per whitelist
Mar 27 21:06:33.812: INFO: namespace e2e-tests-watch-9hvh8 deletion completed in 6.349221424s

• [SLOW TEST:6.628 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:06:33.818: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 27 21:06:34.041: INFO: Waiting up to 5m0s for pod "downward-api-33939f96-50d4-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-n24zq" to be "success or failure"
Mar 27 21:06:34.068: INFO: Pod "downward-api-33939f96-50d4-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 27.033091ms
Mar 27 21:06:36.076: INFO: Pod "downward-api-33939f96-50d4-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035010845s
Mar 27 21:06:38.082: INFO: Pod "downward-api-33939f96-50d4-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041259042s
STEP: Saw pod success
Mar 27 21:06:38.082: INFO: Pod "downward-api-33939f96-50d4-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:06:38.086: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downward-api-33939f96-50d4-11e9-9d23-0ac04cf37a48 container dapi-container: <nil>
STEP: delete the pod
Mar 27 21:06:38.150: INFO: Waiting for pod downward-api-33939f96-50d4-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:06:38.168: INFO: Pod downward-api-33939f96-50d4-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:06:38.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n24zq" for this suite.
Mar 27 21:06:44.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:06:44.390: INFO: namespace: e2e-tests-downward-api-n24zq, resource: bindings, ignored listing per whitelist
Mar 27 21:06:44.477: INFO: namespace e2e-tests-downward-api-n24zq deletion completed in 6.294957322s

• [SLOW TEST:10.660 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:06:44.480: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:06:44.670: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39e86535-50d4-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-pw4r4" to be "success or failure"
Mar 27 21:06:44.802: INFO: Pod "downwardapi-volume-39e86535-50d4-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 131.855087ms
Mar 27 21:06:46.810: INFO: Pod "downwardapi-volume-39e86535-50d4-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.139957725s
STEP: Saw pod success
Mar 27 21:06:46.811: INFO: Pod "downwardapi-volume-39e86535-50d4-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:06:46.815: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-39e86535-50d4-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:06:46.880: INFO: Waiting for pod downwardapi-volume-39e86535-50d4-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:06:46.898: INFO: Pod downwardapi-volume-39e86535-50d4-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:06:46.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pw4r4" for this suite.
Mar 27 21:06:52.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:06:53.013: INFO: namespace: e2e-tests-downward-api-pw4r4, resource: bindings, ignored listing per whitelist
Mar 27 21:06:53.185: INFO: namespace e2e-tests-downward-api-pw4r4 deletion completed in 6.265535704s

• [SLOW TEST:8.705 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:06:53.187: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 27 21:06:53.350: INFO: Waiting up to 5m0s for pod "pod-3f18647c-50d4-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-47fx2" to be "success or failure"
Mar 27 21:06:53.354: INFO: Pod "pod-3f18647c-50d4-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 4.521517ms
Mar 27 21:06:55.361: INFO: Pod "pod-3f18647c-50d4-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011147229s
STEP: Saw pod success
Mar 27 21:06:55.361: INFO: Pod "pod-3f18647c-50d4-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:06:55.369: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-3f18647c-50d4-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 21:06:55.443: INFO: Waiting for pod pod-3f18647c-50d4-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:06:55.460: INFO: Pod pod-3f18647c-50d4-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:06:55.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-47fx2" for this suite.
Mar 27 21:07:01.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:07:01.720: INFO: namespace: e2e-tests-emptydir-47fx2, resource: bindings, ignored listing per whitelist
Mar 27 21:07:01.729: INFO: namespace e2e-tests-emptydir-47fx2 deletion completed in 6.231817973s

• [SLOW TEST:8.543 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:07:01.730: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-442a7ce9-50d4-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 21:07:01.892: INFO: Waiting up to 5m0s for pod "pod-configmaps-442f76c4-50d4-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-configmap-zxjt7" to be "success or failure"
Mar 27 21:07:01.915: INFO: Pod "pod-configmaps-442f76c4-50d4-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 22.259113ms
Mar 27 21:07:03.921: INFO: Pod "pod-configmaps-442f76c4-50d4-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028284704s
Mar 27 21:07:05.945: INFO: Pod "pod-configmaps-442f76c4-50d4-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05238809s
STEP: Saw pod success
Mar 27 21:07:05.945: INFO: Pod "pod-configmaps-442f76c4-50d4-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:07:05.950: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-configmaps-442f76c4-50d4-11e9-9d23-0ac04cf37a48 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 21:07:06.033: INFO: Waiting for pod pod-configmaps-442f76c4-50d4-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:07:06.061: INFO: Pod pod-configmaps-442f76c4-50d4-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:07:06.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zxjt7" for this suite.
Mar 27 21:07:12.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:07:12.164: INFO: namespace: e2e-tests-configmap-zxjt7, resource: bindings, ignored listing per whitelist
Mar 27 21:07:12.307: INFO: namespace e2e-tests-configmap-zxjt7 deletion completed in 6.208180103s

• [SLOW TEST:10.577 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:07:12.309: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:07:12.433: INFO: Creating ReplicaSet my-hostname-basic-4a7a5668-50d4-11e9-9d23-0ac04cf37a48
Mar 27 21:07:12.446: INFO: Pod name my-hostname-basic-4a7a5668-50d4-11e9-9d23-0ac04cf37a48: Found 0 pods out of 1
Mar 27 21:07:17.455: INFO: Pod name my-hostname-basic-4a7a5668-50d4-11e9-9d23-0ac04cf37a48: Found 1 pods out of 1
Mar 27 21:07:17.455: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-4a7a5668-50d4-11e9-9d23-0ac04cf37a48" is running
Mar 27 21:07:17.462: INFO: Pod "my-hostname-basic-4a7a5668-50d4-11e9-9d23-0ac04cf37a48-ldq66" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-27 21:07:12 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-27 21:07:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-27 21:07:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-27 21:07:12 +0000 UTC Reason: Message:}])
Mar 27 21:07:17.462: INFO: Trying to dial the pod
Mar 27 21:07:22.483: INFO: Controller my-hostname-basic-4a7a5668-50d4-11e9-9d23-0ac04cf37a48: Got expected result from replica 1 [my-hostname-basic-4a7a5668-50d4-11e9-9d23-0ac04cf37a48-ldq66]: "my-hostname-basic-4a7a5668-50d4-11e9-9d23-0ac04cf37a48-ldq66", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:07:22.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-sj2lj" for this suite.
Mar 27 21:07:28.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:07:28.732: INFO: namespace: e2e-tests-replicaset-sj2lj, resource: bindings, ignored listing per whitelist
Mar 27 21:07:28.758: INFO: namespace e2e-tests-replicaset-sj2lj deletion completed in 6.264483321s

• [SLOW TEST:16.450 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:07:28.759: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar 27 21:07:28.916: INFO: Pod name pod-release: Found 0 pods out of 1
Mar 27 21:07:33.922: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:07:34.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-fmbzr" for this suite.
Mar 27 21:07:43.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:07:43.198: INFO: namespace: e2e-tests-replication-controller-fmbzr, resource: bindings, ignored listing per whitelist
Mar 27 21:07:43.375: INFO: namespace e2e-tests-replication-controller-fmbzr deletion completed in 8.407715555s

• [SLOW TEST:14.617 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:07:43.379: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 27 21:07:43.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-d4hqv'
Mar 27 21:07:44.004: INFO: stderr: ""
Mar 27 21:07:44.004: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar 27 21:07:54.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-d4hqv -o json'
Mar 27 21:07:54.214: INFO: stderr: ""
Mar 27 21:07:54.214: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.42.1.130/32\"\n        },\n        \"creationTimestamp\": \"2019-03-27T21:07:43Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-d4hqv\",\n        \"resourceVersion\": \"186282\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-d4hqv/pods/e2e-test-nginx-pod\",\n        \"uid\": \"5d462e29-50d4-11e9-8df3-90b8d03c5288\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-8vppb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-conformance-cluster-1-13-etcd-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-8vppb\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-8vppb\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-27T21:07:44Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-27T21:07:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-27T21:07:49Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-27T21:07:43Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f3a2e12d002efd10173d9fde6a203c7ca3b23250307c866c41cea4db72706d70\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-27T21:07:47Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"72.2.115.200\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.1.130\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-27T21:07:44Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 27 21:07:54.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 replace -f - --namespace=e2e-tests-kubectl-d4hqv'
Mar 27 21:07:54.742: INFO: stderr: ""
Mar 27 21:07:54.742: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Mar 27 21:07:54.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-d4hqv'
Mar 27 21:07:56.819: INFO: stderr: ""
Mar 27 21:07:56.819: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:07:56.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d4hqv" for this suite.
Mar 27 21:08:02.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:08:03.083: INFO: namespace: e2e-tests-kubectl-d4hqv, resource: bindings, ignored listing per whitelist
Mar 27 21:08:03.083: INFO: namespace e2e-tests-kubectl-d4hqv deletion completed in 6.24361156s

• [SLOW TEST:19.705 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:08:03.084: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 27 21:08:03.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-klzdq'
Mar 27 21:08:03.542: INFO: stderr: ""
Mar 27 21:08:03.542: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 27 21:08:04.551: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 21:08:04.551: INFO: Found 0 / 1
Mar 27 21:08:05.554: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 21:08:05.555: INFO: Found 1 / 1
Mar 27 21:08:05.555: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 27 21:08:05.563: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 21:08:05.563: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 27 21:08:05.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 patch pod redis-master-wqqn8 --namespace=e2e-tests-kubectl-klzdq -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 27 21:08:05.735: INFO: stderr: ""
Mar 27 21:08:05.735: INFO: stdout: "pod/redis-master-wqqn8 patched\n"
STEP: checking annotations
Mar 27 21:08:05.741: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 21:08:05.741: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:08:05.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-klzdq" for this suite.
Mar 27 21:08:29.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:08:29.817: INFO: namespace: e2e-tests-kubectl-klzdq, resource: bindings, ignored listing per whitelist
Mar 27 21:08:30.014: INFO: namespace e2e-tests-kubectl-klzdq deletion completed in 24.260040001s

• [SLOW TEST:26.930 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:08:30.015: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 27 21:08:30.204: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:08:34.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6655p" for this suite.
Mar 27 21:08:58.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:08:58.510: INFO: namespace: e2e-tests-init-container-6655p, resource: bindings, ignored listing per whitelist
Mar 27 21:08:58.648: INFO: namespace e2e-tests-init-container-6655p deletion completed in 24.275866017s

• [SLOW TEST:28.634 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:08:58.650: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-89e2147d-50d4-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 21:08:58.837: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-89e393aa-50d4-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-f65td" to be "success or failure"
Mar 27 21:08:58.852: INFO: Pod "pod-projected-secrets-89e393aa-50d4-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 14.467637ms
Mar 27 21:09:00.857: INFO: Pod "pod-projected-secrets-89e393aa-50d4-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020082981s
STEP: Saw pod success
Mar 27 21:09:00.858: INFO: Pod "pod-projected-secrets-89e393aa-50d4-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:09:00.862: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-secrets-89e393aa-50d4-11e9-9d23-0ac04cf37a48 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 27 21:09:00.945: INFO: Waiting for pod pod-projected-secrets-89e393aa-50d4-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:09:00.953: INFO: Pod pod-projected-secrets-89e393aa-50d4-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:09:00.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f65td" for this suite.
Mar 27 21:09:07.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:09:07.234: INFO: namespace: e2e-tests-projected-f65td, resource: bindings, ignored listing per whitelist
Mar 27 21:09:07.360: INFO: namespace e2e-tests-projected-f65td deletion completed in 6.375395649s

• [SLOW TEST:8.711 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:09:07.361: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-64w92
Mar 27 21:09:09.597: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-64w92
STEP: checking the pod's current state and verifying that restartCount is present
Mar 27 21:09:09.610: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:13:11.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-64w92" for this suite.
Mar 27 21:13:17.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:13:17.361: INFO: namespace: e2e-tests-container-probe-64w92, resource: bindings, ignored listing per whitelist
Mar 27 21:13:17.459: INFO: namespace e2e-tests-container-probe-64w92 deletion completed in 6.320208337s

• [SLOW TEST:250.099 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:13:17.463: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:13:17.749: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 27 21:13:17.780: INFO: Number of nodes with available pods: 0
Mar 27 21:13:17.780: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 21:13:18.891: INFO: Number of nodes with available pods: 1
Mar 27 21:13:18.891: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 21:13:19.807: INFO: Number of nodes with available pods: 4
Mar 27 21:13:19.807: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:13:20.798: INFO: Number of nodes with available pods: 5
Mar 27 21:13:20.798: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 27 21:13:20.850: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:20.850: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:20.850: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:20.850: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:20.850: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:21.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:21.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:21.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:21.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:21.882: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:22.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:22.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:22.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:22.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:22.882: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:23.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:23.885: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:23.885: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:23.885: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:23.885: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:24.886: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:24.887: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:24.887: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:24.887: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:24.887: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:25.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:25.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:25.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:25.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:25.883: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:26.897: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:26.897: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:26.897: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:26.897: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:26.897: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:27.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:27.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:27.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:27.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:27.883: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:28.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:28.884: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:28.884: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:28.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:28.884: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:29.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:29.881: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:29.881: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:29.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:29.881: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:30.893: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:30.894: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:30.896: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:30.897: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:30.898: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:31.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:31.885: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:31.885: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:31.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:31.886: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:32.886: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:32.886: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:32.886: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:32.887: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:32.887: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:33.886: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:33.886: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:33.886: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:33.887: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:33.887: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:34.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:34.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:34.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:34.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:34.883: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:35.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:35.881: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:35.881: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:35.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:35.881: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:36.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:36.881: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:36.881: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:36.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:36.881: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:37.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:37.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:37.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:37.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:37.883: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:38.898: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:38.899: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:38.899: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:38.899: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:38.899: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:39.887: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:39.888: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:39.888: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:39.889: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:39.889: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:40.889: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:40.889: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:40.889: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:40.890: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:40.890: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:41.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:41.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:41.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:41.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:41.882: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:42.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:42.884: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:42.884: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:42.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:42.884: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:43.886: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:43.886: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:43.887: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:43.887: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:43.887: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:44.891: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:44.892: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:44.894: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:44.895: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:44.895: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:45.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:45.886: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:45.886: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:45.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:45.886: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:46.889: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:46.889: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:46.889: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:46.890: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:46.890: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:47.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:47.884: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:47.884: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:47.885: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:47.885: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:48.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:48.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:48.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:48.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:48.883: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:49.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:49.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:49.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:49.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:49.883: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:50.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:50.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:50.884: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:50.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:50.884: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:51.880: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:51.880: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:51.880: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:51.880: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:51.880: INFO: Wrong image for pod: daemon-set-xv7g8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:51.880: INFO: Pod daemon-set-xv7g8 is not available
Mar 27 21:13:52.931: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:52.931: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:52.931: INFO: Pod daemon-set-gl2fk is not available
Mar 27 21:13:52.931: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:52.931: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:53.888: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:53.888: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:53.888: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:53.888: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:54.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:54.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:54.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:54.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:55.891: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:55.893: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:55.893: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:55.893: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:56.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:56.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:56.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:56.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:57.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:57.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:57.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:57.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:58.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:58.886: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:58.886: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:58.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:59.889: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:59.889: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:59.889: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:13:59.889: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:00.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:00.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:00.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:00.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:01.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:01.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:01.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:01.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:02.888: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:02.888: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:02.888: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:02.888: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:03.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:03.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:03.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:03.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:04.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:04.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:04.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:04.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:05.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:05.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:05.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:05.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:06.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:06.881: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:06.881: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:06.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:07.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:07.881: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:07.881: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:07.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:08.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:08.884: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:08.884: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:08.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:09.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:09.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:09.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:09.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:11.000: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:11.000: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:11.000: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:11.000: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:11.979: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:11.979: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:11.979: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:11.979: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:13.006: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:13.006: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:13.006: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:13.006: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:13.986: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:13.986: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:13.986: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:13.986: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:14.963: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:14.963: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:14.963: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:14.963: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:15.886: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:15.886: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:15.886: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:15.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:16.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:16.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:16.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:16.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:17.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:17.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:17.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:17.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:18.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:18.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:18.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:18.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:19.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:19.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:19.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:19.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:20.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:20.885: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:20.885: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:20.885: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:21.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:21.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:21.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:21.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:22.908: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:22.908: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:22.908: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:22.908: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:23.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:23.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:23.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:23.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:24.893: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:24.894: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:24.894: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:24.894: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:25.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:25.886: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:25.886: INFO: Pod daemon-set-gf756 is not available
Mar 27 21:14:25.886: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:25.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:26.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:26.885: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:26.886: INFO: Pod daemon-set-gf756 is not available
Mar 27 21:14:26.886: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:26.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:27.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:27.885: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:27.885: INFO: Pod daemon-set-gf756 is not available
Mar 27 21:14:27.886: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:27.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:28.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:28.884: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:28.884: INFO: Pod daemon-set-gf756 is not available
Mar 27 21:14:28.884: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:28.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:29.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:29.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:29.882: INFO: Pod daemon-set-gf756 is not available
Mar 27 21:14:29.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:29.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:30.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:30.881: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:30.881: INFO: Pod daemon-set-gf756 is not available
Mar 27 21:14:30.881: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:30.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:31.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:31.882: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:31.882: INFO: Pod daemon-set-gf756 is not available
Mar 27 21:14:31.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:31.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:32.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:32.883: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:32.883: INFO: Pod daemon-set-gf756 is not available
Mar 27 21:14:32.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:32.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:33.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:33.884: INFO: Wrong image for pod: daemon-set-gf756. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:33.885: INFO: Pod daemon-set-gf756 is not available
Mar 27 21:14:33.885: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:33.885: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:34.895: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:34.895: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:34.895: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:35.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:35.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:35.883: INFO: Pod daemon-set-kjpjb is not available
Mar 27 21:14:35.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:36.888: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:36.888: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:36.888: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:37.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:37.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:37.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:38.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:38.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:38.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:39.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:39.884: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:39.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:40.888: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:40.888: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:40.888: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:41.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:41.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:41.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:42.890: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:42.890: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:42.890: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:43.886: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:43.887: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:43.887: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:44.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:44.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:44.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:45.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:45.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:45.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:46.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:46.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:46.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:47.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:47.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:47.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:48.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:48.886: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:48.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:49.890: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:49.891: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:49.891: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:50.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:50.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:50.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:51.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:51.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:51.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:52.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:52.884: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:52.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:53.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:53.881: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:53.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:54.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:54.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:54.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:55.887: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:55.889: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:55.889: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:56.897: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:56.897: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:56.897: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:57.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:57.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:57.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:58.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:58.881: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:58.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:59.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:59.883: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:14:59.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:00.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:00.882: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:00.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:01.893: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:01.894: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:01.894: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:02.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:02.881: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:02.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:03.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:03.881: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:03.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:04.887: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:04.887: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:04.887: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:05.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:05.885: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:05.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:06.886: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:06.886: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:06.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:07.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:07.885: INFO: Wrong image for pod: daemon-set-jcf2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:07.885: INFO: Pod daemon-set-jcf2z is not available
Mar 27 21:15:07.885: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:08.904: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:08.904: INFO: Pod daemon-set-jngfd is not available
Mar 27 21:15:08.904: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:09.888: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:09.888: INFO: Pod daemon-set-jngfd is not available
Mar 27 21:15:09.888: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:10.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:10.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:11.886: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:11.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:12.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:12.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:13.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:13.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:14.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:14.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:15.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:15.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:16.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:16.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:17.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:17.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:18.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:18.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:19.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:19.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:20.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:20.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:21.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:21.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:22.892: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:22.892: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:23.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:23.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:24.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:24.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:25.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:25.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:26.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:26.881: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:27.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:27.885: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:28.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:28.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:29.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:29.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:30.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:30.886: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:31.891: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:31.891: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:32.887: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:32.888: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:33.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:33.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:34.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:34.885: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:35.886: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:35.887: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:36.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:36.885: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:37.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:37.885: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:38.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:38.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:39.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:39.882: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:40.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:40.883: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:41.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:41.884: INFO: Wrong image for pod: daemon-set-tkrrm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:41.884: INFO: Pod daemon-set-tkrrm is not available
Mar 27 21:15:42.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:42.881: INFO: Pod daemon-set-mckcq is not available
Mar 27 21:15:43.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:43.882: INFO: Pod daemon-set-mckcq is not available
Mar 27 21:15:44.887: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:45.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:46.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:47.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:48.899: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:49.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:50.887: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:51.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:52.889: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:53.898: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:54.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:55.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:56.881: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:57.883: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:58.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:15:59.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:00.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:01.889: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:02.886: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:03.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:04.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:05.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:06.895: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:07.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:08.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:09.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:10.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:11.884: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:12.903: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:13.882: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:14.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:15.885: INFO: Wrong image for pod: daemon-set-48f9z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 27 21:16:15.886: INFO: Pod daemon-set-48f9z is not available
Mar 27 21:16:16.894: INFO: Pod daemon-set-fjftk is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 27 21:16:16.945: INFO: Number of nodes with available pods: 4
Mar 27 21:16:16.945: INFO: Node k8s-conformance-cluster-1-13-worker-3 is running more than one daemon pod
Mar 27 21:16:17.969: INFO: Number of nodes with available pods: 5
Mar 27 21:16:17.970: INFO: Number of running nodes: 5, number of available pods: 5
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-c9h7v, will wait for the garbage collector to delete the pods
Mar 27 21:16:18.092: INFO: Deleting DaemonSet.extensions daemon-set took: 24.046491ms
Mar 27 21:16:18.292: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.582638ms
Mar 27 21:16:30.600: INFO: Number of nodes with available pods: 0
Mar 27 21:16:30.601: INFO: Number of running nodes: 0, number of available pods: 0
Mar 27 21:16:30.610: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-c9h7v/daemonsets","resourceVersion":"187543"},"items":null}

Mar 27 21:16:30.615: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-c9h7v/pods","resourceVersion":"187543"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:16:30.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-c9h7v" for this suite.
Mar 27 21:16:38.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:16:38.840: INFO: namespace: e2e-tests-daemonsets-c9h7v, resource: bindings, ignored listing per whitelist
Mar 27 21:16:38.910: INFO: namespace e2e-tests-daemonsets-c9h7v deletion completed in 8.213822784s

• [SLOW TEST:201.447 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:16:38.911: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 27 21:16:39.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-b8p27'
Mar 27 21:16:39.565: INFO: stderr: ""
Mar 27 21:16:39.565: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 21:16:39.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b8p27'
Mar 27 21:16:39.815: INFO: stderr: ""
Mar 27 21:16:39.815: INFO: stdout: "update-demo-nautilus-nqfds update-demo-nautilus-qhs6r "
Mar 27 21:16:39.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-nqfds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b8p27'
Mar 27 21:16:39.990: INFO: stderr: ""
Mar 27 21:16:39.990: INFO: stdout: ""
Mar 27 21:16:39.990: INFO: update-demo-nautilus-nqfds is created but not running
Mar 27 21:16:44.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b8p27'
Mar 27 21:16:45.127: INFO: stderr: ""
Mar 27 21:16:45.127: INFO: stdout: "update-demo-nautilus-nqfds update-demo-nautilus-qhs6r "
Mar 27 21:16:45.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-nqfds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b8p27'
Mar 27 21:16:45.271: INFO: stderr: ""
Mar 27 21:16:45.271: INFO: stdout: "true"
Mar 27 21:16:45.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-nqfds -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b8p27'
Mar 27 21:16:45.424: INFO: stderr: ""
Mar 27 21:16:45.424: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 21:16:45.424: INFO: validating pod update-demo-nautilus-nqfds
Mar 27 21:16:45.437: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 21:16:45.438: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 21:16:45.438: INFO: update-demo-nautilus-nqfds is verified up and running
Mar 27 21:16:45.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-qhs6r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b8p27'
Mar 27 21:16:45.596: INFO: stderr: ""
Mar 27 21:16:45.596: INFO: stdout: "true"
Mar 27 21:16:45.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-qhs6r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b8p27'
Mar 27 21:16:45.744: INFO: stderr: ""
Mar 27 21:16:45.744: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 21:16:45.744: INFO: validating pod update-demo-nautilus-qhs6r
Mar 27 21:16:45.762: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 21:16:45.762: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 21:16:45.762: INFO: update-demo-nautilus-qhs6r is verified up and running
STEP: using delete to clean up resources
Mar 27 21:16:45.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b8p27'
Mar 27 21:16:45.936: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 21:16:45.936: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 27 21:16:45.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-b8p27'
Mar 27 21:16:46.170: INFO: stderr: "No resources found.\n"
Mar 27 21:16:46.170: INFO: stdout: ""
Mar 27 21:16:46.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -l name=update-demo --namespace=e2e-tests-kubectl-b8p27 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 27 21:16:46.349: INFO: stderr: ""
Mar 27 21:16:46.349: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:16:46.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b8p27" for this suite.
Mar 27 21:17:10.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:17:10.643: INFO: namespace: e2e-tests-kubectl-b8p27, resource: bindings, ignored listing per whitelist
Mar 27 21:17:10.687: INFO: namespace e2e-tests-kubectl-b8p27 deletion completed in 24.320369695s

• [SLOW TEST:31.777 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:17:10.695: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar 27 21:17:10.854: INFO: Waiting up to 5m0s for pod "client-containers-af277521-50d5-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-containers-dwkj2" to be "success or failure"
Mar 27 21:17:10.872: INFO: Pod "client-containers-af277521-50d5-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 18.34287ms
Mar 27 21:17:12.882: INFO: Pod "client-containers-af277521-50d5-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.028129916s
Mar 27 21:17:14.888: INFO: Pod "client-containers-af277521-50d5-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033885423s
STEP: Saw pod success
Mar 27 21:17:14.888: INFO: Pod "client-containers-af277521-50d5-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:17:14.894: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod client-containers-af277521-50d5-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 21:17:14.969: INFO: Waiting for pod client-containers-af277521-50d5-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:17:14.977: INFO: Pod client-containers-af277521-50d5-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:17:14.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-dwkj2" for this suite.
Mar 27 21:17:21.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:17:21.199: INFO: namespace: e2e-tests-containers-dwkj2, resource: bindings, ignored listing per whitelist
Mar 27 21:17:21.223: INFO: namespace e2e-tests-containers-dwkj2 deletion completed in 6.221502555s

• [SLOW TEST:10.529 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:17:21.225: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Mar 27 21:17:23.577: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:17:48.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-7wkvq" for this suite.
Mar 27 21:17:54.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:17:54.961: INFO: namespace: e2e-tests-namespaces-7wkvq, resource: bindings, ignored listing per whitelist
Mar 27 21:17:55.107: INFO: namespace e2e-tests-namespaces-7wkvq deletion completed in 6.346801854s
STEP: Destroying namespace "e2e-tests-nsdeletetest-6zdml" for this suite.
Mar 27 21:17:55.117: INFO: Namespace e2e-tests-nsdeletetest-6zdml was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-mwfq8" for this suite.
Mar 27 21:18:01.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:18:01.297: INFO: namespace: e2e-tests-nsdeletetest-mwfq8, resource: bindings, ignored listing per whitelist
Mar 27 21:18:01.374: INFO: namespace e2e-tests-nsdeletetest-mwfq8 deletion completed in 6.255136724s

• [SLOW TEST:40.150 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:18:01.376: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:18:01.541: INFO: (0) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.733565ms)
Mar 27 21:18:01.548: INFO: (1) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.909798ms)
Mar 27 21:18:01.554: INFO: (2) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.882064ms)
Mar 27 21:18:01.560: INFO: (3) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.292453ms)
Mar 27 21:18:01.566: INFO: (4) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.702706ms)
Mar 27 21:18:01.572: INFO: (5) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.624059ms)
Mar 27 21:18:01.580: INFO: (6) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.843355ms)
Mar 27 21:18:01.586: INFO: (7) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.848803ms)
Mar 27 21:18:01.594: INFO: (8) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.749744ms)
Mar 27 21:18:01.600: INFO: (9) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.396939ms)
Mar 27 21:18:01.605: INFO: (10) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.629002ms)
Mar 27 21:18:01.611: INFO: (11) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.625394ms)
Mar 27 21:18:01.618: INFO: (12) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.495183ms)
Mar 27 21:18:01.623: INFO: (13) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.848104ms)
Mar 27 21:18:01.630: INFO: (14) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.549851ms)
Mar 27 21:18:01.637: INFO: (15) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.468622ms)
Mar 27 21:18:01.644: INFO: (16) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.52993ms)
Mar 27 21:18:01.651: INFO: (17) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.421867ms)
Mar 27 21:18:01.657: INFO: (18) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.448496ms)
Mar 27 21:18:01.667: INFO: (19) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 9.311686ms)
[AfterEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:18:01.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-r5vz7" for this suite.
Mar 27 21:18:07.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:18:07.914: INFO: namespace: e2e-tests-proxy-r5vz7, resource: bindings, ignored listing per whitelist
Mar 27 21:18:07.979: INFO: namespace e2e-tests-proxy-r5vz7 deletion completed in 6.298447553s

• [SLOW TEST:6.603 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:18:07.980: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:18:08.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 version'
Mar 27 21:18:08.263: INFO: stderr: ""
Mar 27 21:18:08.263: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.4\", GitCommit:\"c27b913fddd1a6c480c229191a087698aa92f0b1\", GitTreeState:\"clean\", BuildDate:\"2019-02-28T13:37:52Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.4\", GitCommit:\"c27b913fddd1a6c480c229191a087698aa92f0b1\", GitTreeState:\"clean\", BuildDate:\"2019-02-28T13:30:26Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:18:08.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8rq6s" for this suite.
Mar 27 21:18:14.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:18:14.447: INFO: namespace: e2e-tests-kubectl-8rq6s, resource: bindings, ignored listing per whitelist
Mar 27 21:18:14.481: INFO: namespace e2e-tests-kubectl-8rq6s deletion completed in 6.208341232s

• [SLOW TEST:6.501 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:18:14.482: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d52a7b0a-50d5-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 21:18:14.639: INFO: Waiting up to 5m0s for pod "pod-configmaps-d52c5811-50d5-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-configmap-wm474" to be "success or failure"
Mar 27 21:18:14.655: INFO: Pod "pod-configmaps-d52c5811-50d5-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 15.902815ms
Mar 27 21:18:16.683: INFO: Pod "pod-configmaps-d52c5811-50d5-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044795516s
STEP: Saw pod success
Mar 27 21:18:16.684: INFO: Pod "pod-configmaps-d52c5811-50d5-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:18:16.688: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-configmaps-d52c5811-50d5-11e9-9d23-0ac04cf37a48 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 21:18:16.896: INFO: Waiting for pod pod-configmaps-d52c5811-50d5-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:18:16.916: INFO: Pod pod-configmaps-d52c5811-50d5-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:18:16.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wm474" for this suite.
Mar 27 21:18:23.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:18:23.187: INFO: namespace: e2e-tests-configmap-wm474, resource: bindings, ignored listing per whitelist
Mar 27 21:18:23.275: INFO: namespace e2e-tests-configmap-wm474 deletion completed in 6.349756892s

• [SLOW TEST:8.793 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:18:23.281: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-da6b8b54-50d5-11e9-9d23-0ac04cf37a48
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:18:27.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9sz4j" for this suite.
Mar 27 21:18:51.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:18:51.696: INFO: namespace: e2e-tests-configmap-9sz4j, resource: bindings, ignored listing per whitelist
Mar 27 21:18:51.934: INFO: namespace e2e-tests-configmap-9sz4j deletion completed in 24.348000408s

• [SLOW TEST:28.653 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:18:51.936: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:18:52.095: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:18:53.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-r7s84" for this suite.
Mar 27 21:18:59.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:18:59.293: INFO: namespace: e2e-tests-custom-resource-definition-r7s84, resource: bindings, ignored listing per whitelist
Mar 27 21:18:59.426: INFO: namespace e2e-tests-custom-resource-definition-r7s84 deletion completed in 6.19719478s

• [SLOW TEST:7.490 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:18:59.427: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar 27 21:18:59.559: INFO: Waiting up to 5m0s for pod "client-containers-eff08873-50d5-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-containers-qw49z" to be "success or failure"
Mar 27 21:18:59.585: INFO: Pod "client-containers-eff08873-50d5-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 25.298399ms
Mar 27 21:19:01.598: INFO: Pod "client-containers-eff08873-50d5-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038197031s
Mar 27 21:19:03.608: INFO: Pod "client-containers-eff08873-50d5-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048452666s
STEP: Saw pod success
Mar 27 21:19:03.609: INFO: Pod "client-containers-eff08873-50d5-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:19:03.623: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod client-containers-eff08873-50d5-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 21:19:03.703: INFO: Waiting for pod client-containers-eff08873-50d5-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:19:03.718: INFO: Pod client-containers-eff08873-50d5-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:19:03.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-qw49z" for this suite.
Mar 27 21:19:09.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:19:09.953: INFO: namespace: e2e-tests-containers-qw49z, resource: bindings, ignored listing per whitelist
Mar 27 21:19:10.019: INFO: namespace e2e-tests-containers-qw49z deletion completed in 6.272482148s

• [SLOW TEST:10.592 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:19:10.023: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:19:10.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 version --client'
Mar 27 21:19:10.329: INFO: stderr: ""
Mar 27 21:19:10.329: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.4\", GitCommit:\"c27b913fddd1a6c480c229191a087698aa92f0b1\", GitTreeState:\"clean\", BuildDate:\"2019-02-28T13:37:52Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar 27 21:19:10.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-sx7vc'
Mar 27 21:19:12.388: INFO: stderr: ""
Mar 27 21:19:12.388: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar 27 21:19:12.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-sx7vc'
Mar 27 21:19:13.311: INFO: stderr: ""
Mar 27 21:19:13.311: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 27 21:19:14.405: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 21:19:14.405: INFO: Found 0 / 1
Mar 27 21:19:15.412: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 21:19:15.412: INFO: Found 0 / 1
Mar 27 21:19:16.451: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 21:19:16.451: INFO: Found 1 / 1
Mar 27 21:19:16.451: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 27 21:19:16.596: INFO: Selector matched 1 pods for map[app:redis]
Mar 27 21:19:16.596: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 27 21:19:16.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 describe pod redis-master-97zjq --namespace=e2e-tests-kubectl-sx7vc'
Mar 27 21:19:17.222: INFO: stderr: ""
Mar 27 21:19:17.222: INFO: stdout: "Name:               redis-master-97zjq\nNamespace:          e2e-tests-kubectl-sx7vc\nPriority:           0\nPriorityClassName:  <none>\nNode:               k8s-conformance-cluster-1-13-etcd-1/72.2.115.200\nStart Time:         Wed, 27 Mar 2019 21:19:12 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.42.1.143/32\nStatus:             Running\nIP:                 10.42.1.143\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://94f42bf25ad62817a20ad1f6a2e52b6bc65a99c7710f0f3618b0e6cd53238e47\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 27 Mar 2019 21:19:14 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9b82t (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-9b82t:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-9b82t\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                          Message\n  ----    ------     ----  ----                                          -------\n  Normal  Scheduled  5s    default-scheduler                             Successfully assigned e2e-tests-kubectl-sx7vc/redis-master-97zjq to k8s-conformance-cluster-1-13-etcd-1\n  Normal  Pulled     3s    kubelet, k8s-conformance-cluster-1-13-etcd-1  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    3s    kubelet, k8s-conformance-cluster-1-13-etcd-1  Created container\n  Normal  Started    3s    kubelet, k8s-conformance-cluster-1-13-etcd-1  Started container\n"
Mar 27 21:19:17.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 describe rc redis-master --namespace=e2e-tests-kubectl-sx7vc'
Mar 27 21:19:17.448: INFO: stderr: ""
Mar 27 21:19:17.448: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-sx7vc\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  5s    replication-controller  Created pod: redis-master-97zjq\n"
Mar 27 21:19:17.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 describe service redis-master --namespace=e2e-tests-kubectl-sx7vc'
Mar 27 21:19:17.615: INFO: stderr: ""
Mar 27 21:19:17.615: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-sx7vc\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.43.80.208\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.42.1.143:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 27 21:19:17.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 describe node k8s-conformance-cluster-1-13-control-1'
Mar 27 21:19:17.842: INFO: stderr: ""
Mar 27 21:19:17.842: INFO: stdout: "Name:               k8s-conformance-cluster-1-13-control-1\nRoles:              controlplane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=k8s-conformance-cluster-1-13-control-1\n                    node-role.kubernetes.io/controlplane=true\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 72.2.114.38/22\n                    rke.cattle.io/external-ip: 72.2.114.38\n                    rke.cattle.io/internal-ip: 72.2.114.38\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 26 Mar 2019 20:44:30 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 27 Mar 2019 21:19:09 +0000   Tue, 26 Mar 2019 20:44:30 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 27 Mar 2019 21:19:09 +0000   Tue, 26 Mar 2019 20:44:30 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 27 Mar 2019 21:19:09 +0000   Tue, 26 Mar 2019 20:44:30 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 27 Mar 2019 21:19:09 +0000   Tue, 26 Mar 2019 20:45:00 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  72.2.114.38\n  Hostname:    k8s-conformance-cluster-1-13-control-1\nCapacity:\n cpu:                1\n ephemeral-storage:  7688776Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1790148Ki\n pods:               110\nAllocatable:\n cpu:                1\n ephemeral-storage:  7085975950\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1687748Ki\n pods:               110\nSystem Info:\n Machine ID:                 3d6ff2f75c7d3ae927580249a28e7e05\n System UUID:                C3C1717D-7C30-6ABA-8F08-C8A77D52C625\n Boot ID:                    1b270699-ca31-447e-9f9d-6c4447d533ce\n Kernel Version:             4.4.0-137-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.13.4\n Kube-Proxy Version:         v1.13.4\nPodCIDR:                     10.42.0.0/24\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  cattle-system              cattle-node-agent-bx6pt                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         24h\n  heptio-sonobuoy            sonobuoy-e2e-job-b3f04bfb1b6b4be0                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-c97ad45b34ec485e-bmkpx    0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\n  ingress-nginx              nginx-ingress-controller-mw49v                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         24h\n  kube-system                calico-node-ns648                                          250m (25%)    0 (0%)      0 (0%)           0 (0%)         24h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (25%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Mar 27 21:19:17.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 describe namespace e2e-tests-kubectl-sx7vc'
Mar 27 21:19:18.030: INFO: stderr: ""
Mar 27 21:19:18.030: INFO: stdout: "Name:         e2e-tests-kubectl-sx7vc\nLabels:       e2e-framework=kubectl\n              e2e-run=1f4266f4-50ce-11e9-9d23-0ac04cf37a48\nAnnotations:  cattle.io/status:\n                {\"Conditions\":[{\"Type\":\"ResourceQuotaInit\",\"Status\":\"True\",\"Message\":\"\",\"LastUpdateTime\":\"2019-03-27T21:19:11Z\"},{\"Type\":\"InitialRolesPopu...\n              lifecycle.cattle.io/create.namespace-auth: true\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:19:18.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sx7vc" for this suite.
Mar 27 21:19:36.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:19:36.173: INFO: namespace: e2e-tests-kubectl-sx7vc, resource: bindings, ignored listing per whitelist
Mar 27 21:19:36.356: INFO: namespace e2e-tests-kubectl-sx7vc deletion completed in 18.309057478s

• [SLOW TEST:26.333 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:19:36.360: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar 27 21:19:36.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:19:36.997: INFO: stderr: ""
Mar 27 21:19:36.997: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 21:19:36.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:19:37.246: INFO: stderr: ""
Mar 27 21:19:37.246: INFO: stdout: "update-demo-nautilus-c5gvm update-demo-nautilus-zm78r "
Mar 27 21:19:37.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-c5gvm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:19:37.440: INFO: stderr: ""
Mar 27 21:19:37.440: INFO: stdout: ""
Mar 27 21:19:37.440: INFO: update-demo-nautilus-c5gvm is created but not running
Mar 27 21:19:42.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:19:42.594: INFO: stderr: ""
Mar 27 21:19:42.594: INFO: stdout: "update-demo-nautilus-c5gvm update-demo-nautilus-zm78r "
Mar 27 21:19:42.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-c5gvm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:19:42.730: INFO: stderr: ""
Mar 27 21:19:42.730: INFO: stdout: "true"
Mar 27 21:19:42.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-c5gvm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:19:42.995: INFO: stderr: ""
Mar 27 21:19:42.995: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 21:19:42.995: INFO: validating pod update-demo-nautilus-c5gvm
Mar 27 21:19:43.066: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 21:19:43.066: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 21:19:43.066: INFO: update-demo-nautilus-c5gvm is verified up and running
Mar 27 21:19:43.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-zm78r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:19:43.227: INFO: stderr: ""
Mar 27 21:19:43.227: INFO: stdout: "true"
Mar 27 21:19:43.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-nautilus-zm78r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:19:43.411: INFO: stderr: ""
Mar 27 21:19:43.411: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 21:19:43.411: INFO: validating pod update-demo-nautilus-zm78r
Mar 27 21:19:43.422: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 21:19:43.422: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 21:19:43.422: INFO: update-demo-nautilus-zm78r is verified up and running
STEP: rolling-update to new replication controller
Mar 27 21:19:43.431: INFO: scanned /root for discovery docs: <nil>
Mar 27 21:19:43.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:20:06.384: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 27 21:20:06.384: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 21:20:06.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:20:06.612: INFO: stderr: ""
Mar 27 21:20:06.612: INFO: stdout: "update-demo-kitten-qnkbx update-demo-kitten-w79d8 "
Mar 27 21:20:06.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-kitten-qnkbx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:20:06.752: INFO: stderr: ""
Mar 27 21:20:06.752: INFO: stdout: "true"
Mar 27 21:20:06.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-kitten-qnkbx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:20:06.906: INFO: stderr: ""
Mar 27 21:20:06.906: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 27 21:20:06.906: INFO: validating pod update-demo-kitten-qnkbx
Mar 27 21:20:06.916: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 27 21:20:06.916: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 27 21:20:06.916: INFO: update-demo-kitten-qnkbx is verified up and running
Mar 27 21:20:06.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-kitten-w79d8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:20:07.093: INFO: stderr: ""
Mar 27 21:20:07.093: INFO: stdout: "true"
Mar 27 21:20:07.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods update-demo-kitten-w79d8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h579p'
Mar 27 21:20:07.241: INFO: stderr: ""
Mar 27 21:20:07.241: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 27 21:20:07.241: INFO: validating pod update-demo-kitten-w79d8
Mar 27 21:20:07.254: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 27 21:20:07.254: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 27 21:20:07.254: INFO: update-demo-kitten-w79d8 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:20:07.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h579p" for this suite.
Mar 27 21:20:31.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:20:31.515: INFO: namespace: e2e-tests-kubectl-h579p, resource: bindings, ignored listing per whitelist
Mar 27 21:20:31.523: INFO: namespace e2e-tests-kubectl-h579p deletion completed in 24.255976481s

• [SLOW TEST:55.163 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:20:31.525: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-26d76e85-50d6-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 21:20:31.679: INFO: Waiting up to 5m0s for pod "pod-configmaps-26d8d899-50d6-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-configmap-bb4kx" to be "success or failure"
Mar 27 21:20:31.693: INFO: Pod "pod-configmaps-26d8d899-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 12.851118ms
Mar 27 21:20:33.699: INFO: Pod "pod-configmaps-26d8d899-50d6-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.019154718s
Mar 27 21:20:35.705: INFO: Pod "pod-configmaps-26d8d899-50d6-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025212403s
STEP: Saw pod success
Mar 27 21:20:35.705: INFO: Pod "pod-configmaps-26d8d899-50d6-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:20:35.710: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-configmaps-26d8d899-50d6-11e9-9d23-0ac04cf37a48 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 21:20:35.793: INFO: Waiting for pod pod-configmaps-26d8d899-50d6-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:20:35.813: INFO: Pod pod-configmaps-26d8d899-50d6-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:20:35.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bb4kx" for this suite.
Mar 27 21:20:41.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:20:42.033: INFO: namespace: e2e-tests-configmap-bb4kx, resource: bindings, ignored listing per whitelist
Mar 27 21:20:42.104: INFO: namespace e2e-tests-configmap-bb4kx deletion completed in 6.272290615s

• [SLOW TEST:10.579 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:20:42.105: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-7qb2j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7qb2j to expose endpoints map[]
Mar 27 21:20:42.294: INFO: Get endpoints failed (5.926856ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar 27 21:20:43.302: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7qb2j exposes endpoints map[] (1.01449992s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7qb2j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7qb2j to expose endpoints map[pod1:[80]]
Mar 27 21:20:45.382: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7qb2j exposes endpoints map[pod1:[80]] (2.059946156s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7qb2j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7qb2j to expose endpoints map[pod1:[80] pod2:[80]]
Mar 27 21:20:48.494: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7qb2j exposes endpoints map[pod2:[80] pod1:[80]] (3.096978006s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7qb2j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7qb2j to expose endpoints map[pod2:[80]]
Mar 27 21:20:48.565: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7qb2j exposes endpoints map[pod2:[80]] (51.211886ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7qb2j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7qb2j to expose endpoints map[]
Mar 27 21:20:48.655: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7qb2j exposes endpoints map[] (76.948285ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:20:48.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7qb2j" for this suite.
Mar 27 21:21:12.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:21:12.918: INFO: namespace: e2e-tests-services-7qb2j, resource: bindings, ignored listing per whitelist
Mar 27 21:21:13.042: INFO: namespace e2e-tests-services-7qb2j deletion completed in 24.20230511s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:30.938 seconds]
[sig-network] Services
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:21:13.043: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-nbnc
STEP: Creating a pod to test atomic-volume-subpath
Mar 27 21:21:13.254: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-nbnc" in namespace "e2e-tests-subpath-f5l5k" to be "success or failure"
Mar 27 21:21:13.302: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Pending", Reason="", readiness=false. Elapsed: 47.733838ms
Mar 27 21:21:15.323: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068828921s
Mar 27 21:21:17.332: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Running", Reason="", readiness=false. Elapsed: 4.077705181s
Mar 27 21:21:19.339: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Running", Reason="", readiness=false. Elapsed: 6.08433856s
Mar 27 21:21:21.345: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Running", Reason="", readiness=false. Elapsed: 8.09006712s
Mar 27 21:21:23.356: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Running", Reason="", readiness=false. Elapsed: 10.101297991s
Mar 27 21:21:25.366: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Running", Reason="", readiness=false. Elapsed: 12.111251041s
Mar 27 21:21:27.375: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Running", Reason="", readiness=false. Elapsed: 14.120218449s
Mar 27 21:21:29.381: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Running", Reason="", readiness=false. Elapsed: 16.126368442s
Mar 27 21:21:31.387: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Running", Reason="", readiness=false. Elapsed: 18.132753257s
Mar 27 21:21:33.397: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Running", Reason="", readiness=false. Elapsed: 20.142577628s
Mar 27 21:21:35.405: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Running", Reason="", readiness=false. Elapsed: 22.150155676s
Mar 27 21:21:37.414: INFO: Pod "pod-subpath-test-secret-nbnc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.159404292s
STEP: Saw pod success
Mar 27 21:21:37.414: INFO: Pod "pod-subpath-test-secret-nbnc" satisfied condition "success or failure"
Mar 27 21:21:37.427: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-subpath-test-secret-nbnc container test-container-subpath-secret-nbnc: <nil>
STEP: delete the pod
Mar 27 21:21:37.526: INFO: Waiting for pod pod-subpath-test-secret-nbnc to disappear
Mar 27 21:21:37.534: INFO: Pod pod-subpath-test-secret-nbnc no longer exists
STEP: Deleting pod pod-subpath-test-secret-nbnc
Mar 27 21:21:37.534: INFO: Deleting pod "pod-subpath-test-secret-nbnc" in namespace "e2e-tests-subpath-f5l5k"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:21:37.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-f5l5k" for this suite.
Mar 27 21:21:43.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:21:43.704: INFO: namespace: e2e-tests-subpath-f5l5k, resource: bindings, ignored listing per whitelist
Mar 27 21:21:43.777: INFO: namespace e2e-tests-subpath-f5l5k deletion completed in 6.229715799s

• [SLOW TEST:30.734 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:21:43.778: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-47rn6
Mar 27 21:21:45.966: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-47rn6
STEP: checking the pod's current state and verifying that restartCount is present
Mar 27 21:21:45.970: INFO: Initial restart count of pod liveness-http is 0
Mar 27 21:22:06.065: INFO: Restart count of pod e2e-tests-container-probe-47rn6/liveness-http is now 1 (20.094868371s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:22:06.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-47rn6" for this suite.
Mar 27 21:22:12.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:22:12.311: INFO: namespace: e2e-tests-container-probe-47rn6, resource: bindings, ignored listing per whitelist
Mar 27 21:22:12.366: INFO: namespace e2e-tests-container-probe-47rn6 deletion completed in 6.224878987s

• [SLOW TEST:28.588 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:22:12.367: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-k8wrj
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-k8wrj
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-k8wrj
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-k8wrj
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-k8wrj
Mar 27 21:22:16.724: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-k8wrj, name: ss-0, uid: 6535655e-50d6-11e9-8df3-90b8d03c5288, status phase: Pending. Waiting for statefulset controller to delete.
Mar 27 21:22:16.824: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-k8wrj, name: ss-0, uid: 6535655e-50d6-11e9-8df3-90b8d03c5288, status phase: Failed. Waiting for statefulset controller to delete.
Mar 27 21:22:16.852: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-k8wrj, name: ss-0, uid: 6535655e-50d6-11e9-8df3-90b8d03c5288, status phase: Failed. Waiting for statefulset controller to delete.
Mar 27 21:22:16.882: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-k8wrj
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-k8wrj
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-k8wrj and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 27 21:22:21.084: INFO: Deleting all statefulset in ns e2e-tests-statefulset-k8wrj
Mar 27 21:22:21.099: INFO: Scaling statefulset ss to 0
Mar 27 21:22:31.143: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 21:22:31.148: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:22:31.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-k8wrj" for this suite.
Mar 27 21:22:39.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:22:39.327: INFO: namespace: e2e-tests-statefulset-k8wrj, resource: bindings, ignored listing per whitelist
Mar 27 21:22:39.537: INFO: namespace e2e-tests-statefulset-k8wrj deletion completed in 8.335611062s

• [SLOW TEST:27.170 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:22:39.538: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:22:43.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-mjz87" for this suite.
Mar 27 21:22:49.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:22:49.933: INFO: namespace: e2e-tests-kubelet-test-mjz87, resource: bindings, ignored listing per whitelist
Mar 27 21:22:49.964: INFO: namespace e2e-tests-kubelet-test-mjz87 deletion completed in 6.244249885s

• [SLOW TEST:10.427 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:22:49.965: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 27 21:22:50.155: INFO: Waiting up to 5m0s for pod "downward-api-79630270-50d6-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-5jwtd" to be "success or failure"
Mar 27 21:22:50.170: INFO: Pod "downward-api-79630270-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 14.107268ms
Mar 27 21:22:52.179: INFO: Pod "downward-api-79630270-50d6-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.023415519s
Mar 27 21:22:54.186: INFO: Pod "downward-api-79630270-50d6-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030415343s
STEP: Saw pod success
Mar 27 21:22:54.186: INFO: Pod "downward-api-79630270-50d6-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:22:54.191: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downward-api-79630270-50d6-11e9-9d23-0ac04cf37a48 container dapi-container: <nil>
STEP: delete the pod
Mar 27 21:22:54.257: INFO: Waiting for pod downward-api-79630270-50d6-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:22:54.277: INFO: Pod downward-api-79630270-50d6-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:22:54.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5jwtd" for this suite.
Mar 27 21:23:00.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:23:00.544: INFO: namespace: e2e-tests-downward-api-5jwtd, resource: bindings, ignored listing per whitelist
Mar 27 21:23:00.569: INFO: namespace e2e-tests-downward-api-5jwtd deletion completed in 6.278206269s

• [SLOW TEST:10.604 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:23:00.573: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-7fb14199-50d6-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 21:23:00.773: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7fb443ec-50d6-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-8qcr8" to be "success or failure"
Mar 27 21:23:00.796: INFO: Pod "pod-projected-secrets-7fb443ec-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 22.754021ms
Mar 27 21:23:02.802: INFO: Pod "pod-projected-secrets-7fb443ec-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028665678s
Mar 27 21:23:04.812: INFO: Pod "pod-projected-secrets-7fb443ec-50d6-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039422147s
STEP: Saw pod success
Mar 27 21:23:04.812: INFO: Pod "pod-projected-secrets-7fb443ec-50d6-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:23:04.817: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-secrets-7fb443ec-50d6-11e9-9d23-0ac04cf37a48 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 27 21:23:04.902: INFO: Waiting for pod pod-projected-secrets-7fb443ec-50d6-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:23:04.908: INFO: Pod pod-projected-secrets-7fb443ec-50d6-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:23:04.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8qcr8" for this suite.
Mar 27 21:23:10.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:23:11.067: INFO: namespace: e2e-tests-projected-8qcr8, resource: bindings, ignored listing per whitelist
Mar 27 21:23:11.233: INFO: namespace e2e-tests-projected-8qcr8 deletion completed in 6.307766999s

• [SLOW TEST:10.661 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:23:11.236: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 27 21:23:15.982: INFO: Successfully updated pod "pod-update-activedeadlineseconds-8610acbf-50d6-11e9-9d23-0ac04cf37a48"
Mar 27 21:23:15.982: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8610acbf-50d6-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-pods-nkbrx" to be "terminated due to deadline exceeded"
Mar 27 21:23:15.990: INFO: Pod "pod-update-activedeadlineseconds-8610acbf-50d6-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 7.496318ms
Mar 27 21:23:17.998: INFO: Pod "pod-update-activedeadlineseconds-8610acbf-50d6-11e9-9d23-0ac04cf37a48": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.015882731s
Mar 27 21:23:17.998: INFO: Pod "pod-update-activedeadlineseconds-8610acbf-50d6-11e9-9d23-0ac04cf37a48" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:23:17.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nkbrx" for this suite.
Mar 27 21:23:24.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:23:24.177: INFO: namespace: e2e-tests-pods-nkbrx, resource: bindings, ignored listing per whitelist
Mar 27 21:23:24.250: INFO: namespace e2e-tests-pods-nkbrx deletion completed in 6.232955244s

• [SLOW TEST:13.015 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:23:24.252: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 27 21:23:26.451: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-8dcda7d4-50d6-11e9-9d23-0ac04cf37a48,GenerateName:,Namespace:e2e-tests-events-t6wrw,SelfLink:/api/v1/namespaces/e2e-tests-events-t6wrw/pods/send-events-8dcda7d4-50d6-11e9-9d23-0ac04cf37a48,UID:8dcecac0-50d6-11e9-8df3-90b8d03c5288,ResourceVersion:189392,Generation:0,CreationTimestamp:2019-03-27 21:23:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 379959257,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.154/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s6qw4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s6qw4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-s6qw4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b09d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b09da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:23:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:23:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:23:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:23:24 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.200,PodIP:10.42.1.154,StartTime:2019-03-27 21:23:24 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-27 21:23:25 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://52a9d243b543ad58e270f08660da4768a32b890d150ee5696069c179569dd237}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar 27 21:23:28.467: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 27 21:23:30.474: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:23:30.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-t6wrw" for this suite.
Mar 27 21:24:10.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:24:11.940: INFO: namespace: e2e-tests-events-t6wrw, resource: bindings, ignored listing per whitelist
Mar 27 21:24:15.054: INFO: namespace e2e-tests-events-t6wrw deletion completed in 44.526526913s

• [SLOW TEST:50.802 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:24:15.055: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 27 21:24:16.169: INFO: Waiting up to 5m0s for pod "pod-aca9c6ed-50d6-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-f2t7r" to be "success or failure"
Mar 27 21:24:16.197: INFO: Pod "pod-aca9c6ed-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 28.20726ms
Mar 27 21:24:18.206: INFO: Pod "pod-aca9c6ed-50d6-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037424023s
STEP: Saw pod success
Mar 27 21:24:18.206: INFO: Pod "pod-aca9c6ed-50d6-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:24:18.212: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-aca9c6ed-50d6-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 21:24:18.424: INFO: Waiting for pod pod-aca9c6ed-50d6-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:24:18.452: INFO: Pod pod-aca9c6ed-50d6-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:24:18.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f2t7r" for this suite.
Mar 27 21:24:24.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:24:24.678: INFO: namespace: e2e-tests-emptydir-f2t7r, resource: bindings, ignored listing per whitelist
Mar 27 21:24:24.807: INFO: namespace e2e-tests-emptydir-f2t7r deletion completed in 6.32343329s

• [SLOW TEST:9.752 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:24:24.811: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar 27 21:24:24.994: INFO: Waiting up to 5m0s for pod "client-containers-b1ec87a3-50d6-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-containers-5dbqq" to be "success or failure"
Mar 27 21:24:25.013: INFO: Pod "client-containers-b1ec87a3-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 18.288511ms
Mar 27 21:24:27.025: INFO: Pod "client-containers-b1ec87a3-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031132499s
Mar 27 21:24:29.035: INFO: Pod "client-containers-b1ec87a3-50d6-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040583361s
STEP: Saw pod success
Mar 27 21:24:29.035: INFO: Pod "client-containers-b1ec87a3-50d6-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:24:29.045: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod client-containers-b1ec87a3-50d6-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 21:24:29.126: INFO: Waiting for pod client-containers-b1ec87a3-50d6-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:24:29.134: INFO: Pod client-containers-b1ec87a3-50d6-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:24:29.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-5dbqq" for this suite.
Mar 27 21:24:35.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:24:35.291: INFO: namespace: e2e-tests-containers-5dbqq, resource: bindings, ignored listing per whitelist
Mar 27 21:24:35.470: INFO: namespace e2e-tests-containers-5dbqq deletion completed in 6.305556449s

• [SLOW TEST:10.659 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:24:35.477: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 27 21:24:35.620: INFO: PodSpec: initContainers in spec.initContainers
Mar 27 21:25:17.667: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-b8442a8f-50d6-11e9-9d23-0ac04cf37a48", GenerateName:"", Namespace:"e2e-tests-init-container-zdlxx", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-zdlxx/pods/pod-init-b8442a8f-50d6-11e9-9d23-0ac04cf37a48", UID:"b845adec-50d6-11e9-8df3-90b8d03c5288", ResourceVersion:"189695", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63689318675, loc:(*time.Location)(0x7b4abe0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"620942152"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.4.114/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-pm789", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002ba4000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-pm789", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-pm789", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-pm789", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00206d708), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-conformance-cluster-1-13-worker-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003684000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00206de20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00206de40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00206de48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00206de4c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689318675, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689318675, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689318675, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689318675, loc:(*time.Location)(0x7b4abe0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"72.2.113.168", PodIP:"10.42.4.114", StartTime:(*v1.Time)(0xc00268a140), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002b90a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002b9110)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://351753c8a93579415f2a9625e874557bb062fa04ea140728fb9cd9abbe9823a2"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00268a280), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00268a1e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:25:17.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zdlxx" for this suite.
Mar 27 21:25:41.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:25:41.835: INFO: namespace: e2e-tests-init-container-zdlxx, resource: bindings, ignored listing per whitelist
Mar 27 21:25:41.925: INFO: namespace e2e-tests-init-container-zdlxx deletion completed in 24.241028319s

• [SLOW TEST:66.449 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:25:41.929: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:25:42.081: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfdd4ba6-50d6-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-l67kc" to be "success or failure"
Mar 27 21:25:42.119: INFO: Pod "downwardapi-volume-dfdd4ba6-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 37.914449ms
Mar 27 21:25:44.125: INFO: Pod "downwardapi-volume-dfdd4ba6-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043883045s
Mar 27 21:25:46.131: INFO: Pod "downwardapi-volume-dfdd4ba6-50d6-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049829166s
STEP: Saw pod success
Mar 27 21:25:46.131: INFO: Pod "downwardapi-volume-dfdd4ba6-50d6-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:25:46.136: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-dfdd4ba6-50d6-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:25:46.224: INFO: Waiting for pod downwardapi-volume-dfdd4ba6-50d6-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:25:46.240: INFO: Pod downwardapi-volume-dfdd4ba6-50d6-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:25:46.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l67kc" for this suite.
Mar 27 21:25:52.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:25:52.349: INFO: namespace: e2e-tests-projected-l67kc, resource: bindings, ignored listing per whitelist
Mar 27 21:25:52.522: INFO: namespace e2e-tests-projected-l67kc deletion completed in 6.250414093s

• [SLOW TEST:10.595 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:25:52.531: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar 27 21:25:52.723: INFO: Waiting up to 5m0s for pod "var-expansion-e634ca0a-50d6-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-var-expansion-7g9h9" to be "success or failure"
Mar 27 21:25:52.752: INFO: Pod "var-expansion-e634ca0a-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 28.504972ms
Mar 27 21:25:54.759: INFO: Pod "var-expansion-e634ca0a-50d6-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035719835s
STEP: Saw pod success
Mar 27 21:25:54.759: INFO: Pod "var-expansion-e634ca0a-50d6-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:25:54.768: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod var-expansion-e634ca0a-50d6-11e9-9d23-0ac04cf37a48 container dapi-container: <nil>
STEP: delete the pod
Mar 27 21:25:54.874: INFO: Waiting for pod var-expansion-e634ca0a-50d6-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:25:54.891: INFO: Pod var-expansion-e634ca0a-50d6-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:25:54.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-7g9h9" for this suite.
Mar 27 21:26:01.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:26:01.065: INFO: namespace: e2e-tests-var-expansion-7g9h9, resource: bindings, ignored listing per whitelist
Mar 27 21:26:01.250: INFO: namespace e2e-tests-var-expansion-7g9h9 deletion completed in 6.328880862s

• [SLOW TEST:8.720 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:26:01.252: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-eb6a539b-50d6-11e9-9d23-0ac04cf37a48
STEP: Creating secret with name secret-projected-all-test-volume-eb6a5384-50d6-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 27 21:26:01.556: INFO: Waiting up to 5m0s for pod "projected-volume-eb6a531c-50d6-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-wmkvc" to be "success or failure"
Mar 27 21:26:01.568: INFO: Pod "projected-volume-eb6a531c-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 11.927542ms
Mar 27 21:26:03.575: INFO: Pod "projected-volume-eb6a531c-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019055386s
Mar 27 21:26:05.582: INFO: Pod "projected-volume-eb6a531c-50d6-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025691794s
STEP: Saw pod success
Mar 27 21:26:05.582: INFO: Pod "projected-volume-eb6a531c-50d6-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:26:05.590: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod projected-volume-eb6a531c-50d6-11e9-9d23-0ac04cf37a48 container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 27 21:26:05.689: INFO: Waiting for pod projected-volume-eb6a531c-50d6-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:26:05.699: INFO: Pod projected-volume-eb6a531c-50d6-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:26:05.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wmkvc" for this suite.
Mar 27 21:26:11.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:26:11.901: INFO: namespace: e2e-tests-projected-wmkvc, resource: bindings, ignored listing per whitelist
Mar 27 21:26:12.066: INFO: namespace e2e-tests-projected-wmkvc deletion completed in 6.348105486s

• [SLOW TEST:10.814 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:26:12.069: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:26:12.202: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f1d1a2e3-50d6-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-btv95" to be "success or failure"
Mar 27 21:26:12.215: INFO: Pod "downwardapi-volume-f1d1a2e3-50d6-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 13.219539ms
Mar 27 21:26:14.227: INFO: Pod "downwardapi-volume-f1d1a2e3-50d6-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02543286s
STEP: Saw pod success
Mar 27 21:26:14.227: INFO: Pod "downwardapi-volume-f1d1a2e3-50d6-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:26:14.234: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-f1d1a2e3-50d6-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:26:14.344: INFO: Waiting for pod downwardapi-volume-f1d1a2e3-50d6-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:26:14.368: INFO: Pod downwardapi-volume-f1d1a2e3-50d6-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:26:14.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-btv95" for this suite.
Mar 27 21:26:20.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:26:20.661: INFO: namespace: e2e-tests-downward-api-btv95, resource: bindings, ignored listing per whitelist
Mar 27 21:26:20.726: INFO: namespace e2e-tests-downward-api-btv95 deletion completed in 6.324624065s

• [SLOW TEST:8.657 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:26:20.729: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-pgp6
STEP: Creating a pod to test atomic-volume-subpath
Mar 27 21:26:20.877: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-pgp6" in namespace "e2e-tests-subpath-ktlfh" to be "success or failure"
Mar 27 21:26:20.902: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Pending", Reason="", readiness=false. Elapsed: 24.822948ms
Mar 27 21:26:22.907: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030047824s
Mar 27 21:26:24.925: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Running", Reason="", readiness=false. Elapsed: 4.047429721s
Mar 27 21:26:26.934: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Running", Reason="", readiness=false. Elapsed: 6.056741384s
Mar 27 21:26:28.950: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Running", Reason="", readiness=false. Elapsed: 8.072342799s
Mar 27 21:26:30.958: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Running", Reason="", readiness=false. Elapsed: 10.080339805s
Mar 27 21:26:32.970: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Running", Reason="", readiness=false. Elapsed: 12.092950863s
Mar 27 21:26:34.977: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Running", Reason="", readiness=false. Elapsed: 14.099875217s
Mar 27 21:26:36.983: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Running", Reason="", readiness=false. Elapsed: 16.105366266s
Mar 27 21:26:38.993: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Running", Reason="", readiness=false. Elapsed: 18.11589151s
Mar 27 21:26:41.003: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Running", Reason="", readiness=false. Elapsed: 20.125346183s
Mar 27 21:26:43.013: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Running", Reason="", readiness=false. Elapsed: 22.135505991s
Mar 27 21:26:45.019: INFO: Pod "pod-subpath-test-projected-pgp6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.141586529s
STEP: Saw pod success
Mar 27 21:26:45.019: INFO: Pod "pod-subpath-test-projected-pgp6" satisfied condition "success or failure"
Mar 27 21:26:45.031: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-subpath-test-projected-pgp6 container test-container-subpath-projected-pgp6: <nil>
STEP: delete the pod
Mar 27 21:26:45.128: INFO: Waiting for pod pod-subpath-test-projected-pgp6 to disappear
Mar 27 21:26:45.147: INFO: Pod pod-subpath-test-projected-pgp6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-pgp6
Mar 27 21:26:45.147: INFO: Deleting pod "pod-subpath-test-projected-pgp6" in namespace "e2e-tests-subpath-ktlfh"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:26:45.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ktlfh" for this suite.
Mar 27 21:26:51.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:26:51.374: INFO: namespace: e2e-tests-subpath-ktlfh, resource: bindings, ignored listing per whitelist
Mar 27 21:26:51.405: INFO: namespace e2e-tests-subpath-ktlfh deletion completed in 6.227626549s

• [SLOW TEST:30.677 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:26:51.407: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 27 21:26:51.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-65rxc'
Mar 27 21:26:51.705: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 27 21:26:51.705: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar 27 21:26:51.723: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Mar 27 21:26:51.752: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar 27 21:26:51.787: INFO: scanned /root for discovery docs: <nil>
Mar 27 21:26:51.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-65rxc'
Mar 27 21:27:07.904: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 27 21:27:07.904: INFO: stdout: "Created e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37\nScaling up e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar 27 21:27:07.904: INFO: stdout: "Created e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37\nScaling up e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar 27 21:27:07.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-65rxc'
Mar 27 21:27:08.090: INFO: stderr: ""
Mar 27 21:27:08.090: INFO: stdout: "e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37-qkw7t "
Mar 27 21:27:08.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37-qkw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-65rxc'
Mar 27 21:27:08.247: INFO: stderr: ""
Mar 27 21:27:08.247: INFO: stdout: "true"
Mar 27 21:27:08.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37-qkw7t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-65rxc'
Mar 27 21:27:08.415: INFO: stderr: ""
Mar 27 21:27:08.415: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Mar 27 21:27:08.415: INFO: e2e-test-nginx-rc-7daf214d0597f09c201de4806d6b0d37-qkw7t is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Mar 27 21:27:08.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-65rxc'
Mar 27 21:27:08.597: INFO: stderr: ""
Mar 27 21:27:08.597: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:27:08.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-65rxc" for this suite.
Mar 27 21:27:32.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:27:32.895: INFO: namespace: e2e-tests-kubectl-65rxc, resource: bindings, ignored listing per whitelist
Mar 27 21:27:32.965: INFO: namespace e2e-tests-kubectl-65rxc deletion completed in 24.349731893s

• [SLOW TEST:41.557 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:27:32.967: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-rdnt
STEP: Creating a pod to test atomic-volume-subpath
Mar 27 21:27:33.144: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rdnt" in namespace "e2e-tests-subpath-f5lxt" to be "success or failure"
Mar 27 21:27:33.160: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Pending", Reason="", readiness=false. Elapsed: 15.599171ms
Mar 27 21:27:35.173: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027954511s
Mar 27 21:27:37.181: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Running", Reason="", readiness=false. Elapsed: 4.036364249s
Mar 27 21:27:39.188: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Running", Reason="", readiness=false. Elapsed: 6.04378145s
Mar 27 21:27:41.196: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Running", Reason="", readiness=false. Elapsed: 8.051438443s
Mar 27 21:27:43.204: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Running", Reason="", readiness=false. Elapsed: 10.0590966s
Mar 27 21:27:45.210: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Running", Reason="", readiness=false. Elapsed: 12.0658317s
Mar 27 21:27:47.220: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Running", Reason="", readiness=false. Elapsed: 14.075138634s
Mar 27 21:27:49.230: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Running", Reason="", readiness=false. Elapsed: 16.085427443s
Mar 27 21:27:51.240: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Running", Reason="", readiness=false. Elapsed: 18.095137273s
Mar 27 21:27:53.257: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Running", Reason="", readiness=false. Elapsed: 20.112091808s
Mar 27 21:27:55.272: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Running", Reason="", readiness=false. Elapsed: 22.127476864s
Mar 27 21:27:57.282: INFO: Pod "pod-subpath-test-configmap-rdnt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.136929744s
STEP: Saw pod success
Mar 27 21:27:57.282: INFO: Pod "pod-subpath-test-configmap-rdnt" satisfied condition "success or failure"
Mar 27 21:27:57.288: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-subpath-test-configmap-rdnt container test-container-subpath-configmap-rdnt: <nil>
STEP: delete the pod
Mar 27 21:27:57.413: INFO: Waiting for pod pod-subpath-test-configmap-rdnt to disappear
Mar 27 21:27:57.426: INFO: Pod pod-subpath-test-configmap-rdnt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rdnt
Mar 27 21:27:57.426: INFO: Deleting pod "pod-subpath-test-configmap-rdnt" in namespace "e2e-tests-subpath-f5lxt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:27:57.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-f5lxt" for this suite.
Mar 27 21:28:03.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:28:03.721: INFO: namespace: e2e-tests-subpath-f5lxt, resource: bindings, ignored listing per whitelist
Mar 27 21:28:03.746: INFO: namespace e2e-tests-subpath-f5lxt deletion completed in 6.290678318s

• [SLOW TEST:30.780 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:28:03.747: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 27 21:28:06.551: INFO: Successfully updated pod "annotationupdate34690934-50d7-11e9-9d23-0ac04cf37a48"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:28:10.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kf6gh" for this suite.
Mar 27 21:28:34.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:28:35.009: INFO: namespace: e2e-tests-downward-api-kf6gh, resource: bindings, ignored listing per whitelist
Mar 27 21:28:35.009: INFO: namespace e2e-tests-downward-api-kf6gh deletion completed in 24.349812295s

• [SLOW TEST:31.262 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:28:35.011: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:28:35.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-79nq9" for this suite.
Mar 27 21:28:57.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:28:57.422: INFO: namespace: e2e-tests-pods-79nq9, resource: bindings, ignored listing per whitelist
Mar 27 21:28:57.556: INFO: namespace e2e-tests-pods-79nq9 deletion completed in 22.289327188s

• [SLOW TEST:22.546 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:28:57.558: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-54796f58-50d7-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 21:28:57.744: INFO: Waiting up to 5m0s for pod "pod-secrets-547b2803-50d7-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-secrets-4krvf" to be "success or failure"
Mar 27 21:28:57.749: INFO: Pod "pod-secrets-547b2803-50d7-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 4.865605ms
Mar 27 21:28:59.756: INFO: Pod "pod-secrets-547b2803-50d7-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01117527s
STEP: Saw pod success
Mar 27 21:28:59.756: INFO: Pod "pod-secrets-547b2803-50d7-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:28:59.762: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-secrets-547b2803-50d7-11e9-9d23-0ac04cf37a48 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 21:28:59.871: INFO: Waiting for pod pod-secrets-547b2803-50d7-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:28:59.896: INFO: Pod pod-secrets-547b2803-50d7-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:28:59.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4krvf" for this suite.
Mar 27 21:29:05.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:29:06.042: INFO: namespace: e2e-tests-secrets-4krvf, resource: bindings, ignored listing per whitelist
Mar 27 21:29:06.225: INFO: namespace e2e-tests-secrets-4krvf deletion completed in 6.300367253s

• [SLOW TEST:8.667 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:29:06.228: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 27 21:29:13.550: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:13.655: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:15.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:15.777: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:17.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:17.667: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:19.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:19.668: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:21.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:21.669: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:23.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:23.661: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:25.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:25.661: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:27.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:27.667: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:29.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:29.669: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:31.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:31.671: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:33.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:33.663: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:35.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:35.665: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 21:29:37.655: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 21:29:37.660: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:29:37.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9n2zb" for this suite.
Mar 27 21:30:01.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:30:01.797: INFO: namespace: e2e-tests-container-lifecycle-hook-9n2zb, resource: bindings, ignored listing per whitelist
Mar 27 21:30:02.017: INFO: namespace e2e-tests-container-lifecycle-hook-9n2zb deletion completed in 24.330062285s

• [SLOW TEST:55.790 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:30:02.019: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-h4dtd
Mar 27 21:30:04.421: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-h4dtd
STEP: checking the pod's current state and verifying that restartCount is present
Mar 27 21:30:04.432: INFO: Initial restart count of pod liveness-http is 0
Mar 27 21:30:22.501: INFO: Restart count of pod e2e-tests-container-probe-h4dtd/liveness-http is now 1 (18.06913477s elapsed)
Mar 27 21:30:42.581: INFO: Restart count of pod e2e-tests-container-probe-h4dtd/liveness-http is now 2 (38.148756331s elapsed)
Mar 27 21:31:02.642: INFO: Restart count of pod e2e-tests-container-probe-h4dtd/liveness-http is now 3 (58.209754219s elapsed)
Mar 27 21:31:22.716: INFO: Restart count of pod e2e-tests-container-probe-h4dtd/liveness-http is now 4 (1m18.283927336s elapsed)
Mar 27 21:32:33.048: INFO: Restart count of pod e2e-tests-container-probe-h4dtd/liveness-http is now 5 (2m28.616091464s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:32:33.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-h4dtd" for this suite.
Mar 27 21:32:39.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:32:39.338: INFO: namespace: e2e-tests-container-probe-h4dtd, resource: bindings, ignored listing per whitelist
Mar 27 21:32:39.416: INFO: namespace e2e-tests-container-probe-h4dtd deletion completed in 6.243946152s

• [SLOW TEST:157.397 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:32:39.417: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d8b3ff27-50d7-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 21:32:39.563: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d8b52edc-50d7-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-9pnnj" to be "success or failure"
Mar 27 21:32:39.584: INFO: Pod "pod-projected-configmaps-d8b52edc-50d7-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 21.317076ms
Mar 27 21:32:41.602: INFO: Pod "pod-projected-configmaps-d8b52edc-50d7-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039126622s
STEP: Saw pod success
Mar 27 21:32:41.602: INFO: Pod "pod-projected-configmaps-d8b52edc-50d7-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:32:41.611: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-configmaps-d8b52edc-50d7-11e9-9d23-0ac04cf37a48 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 21:32:41.691: INFO: Waiting for pod pod-projected-configmaps-d8b52edc-50d7-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:32:41.792: INFO: Pod pod-projected-configmaps-d8b52edc-50d7-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:32:41.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9pnnj" for this suite.
Mar 27 21:32:47.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:32:48.101: INFO: namespace: e2e-tests-projected-9pnnj, resource: bindings, ignored listing per whitelist
Mar 27 21:32:48.136: INFO: namespace e2e-tests-projected-9pnnj deletion completed in 6.297274856s

• [SLOW TEST:8.720 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:32:48.139: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:32:48.368: INFO: (0) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 10.790261ms)
Mar 27 21:32:48.384: INFO: (1) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 15.712028ms)
Mar 27 21:32:48.395: INFO: (2) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 11.396527ms)
Mar 27 21:32:48.407: INFO: (3) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 11.786705ms)
Mar 27 21:32:48.419: INFO: (4) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 12.084871ms)
Mar 27 21:32:48.429: INFO: (5) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 9.582449ms)
Mar 27 21:32:48.438: INFO: (6) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.369998ms)
Mar 27 21:32:48.448: INFO: (7) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 10.052694ms)
Mar 27 21:32:48.457: INFO: (8) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 9.270625ms)
Mar 27 21:32:48.466: INFO: (9) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 9.095901ms)
Mar 27 21:32:48.475: INFO: (10) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.806346ms)
Mar 27 21:32:48.486: INFO: (11) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 10.823691ms)
Mar 27 21:32:48.494: INFO: (12) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.044992ms)
Mar 27 21:32:48.526: INFO: (13) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 31.206609ms)
Mar 27 21:32:48.546: INFO: (14) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 19.869972ms)
Mar 27 21:32:48.569: INFO: (15) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 23.368759ms)
Mar 27 21:32:48.588: INFO: (16) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 18.218207ms)
Mar 27 21:32:48.608: INFO: (17) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 20.126439ms)
Mar 27 21:32:48.626: INFO: (18) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 17.310555ms)
Mar 27 21:32:48.635: INFO: (19) /api/v1/nodes/k8s-conformance-cluster-1-13-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 9.471019ms)
[AfterEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:32:48.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-fcs5x" for this suite.
Mar 27 21:32:54.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:32:54.790: INFO: namespace: e2e-tests-proxy-fcs5x, resource: bindings, ignored listing per whitelist
Mar 27 21:32:54.854: INFO: namespace e2e-tests-proxy-fcs5x deletion completed in 6.209666298s

• [SLOW TEST:6.716 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:32:54.861: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:32:55.034: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:32:57.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8sggc" for this suite.
Mar 27 21:33:53.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:33:53.393: INFO: namespace: e2e-tests-pods-8sggc, resource: bindings, ignored listing per whitelist
Mar 27 21:33:53.584: INFO: namespace e2e-tests-pods-8sggc deletion completed in 56.336264953s

• [SLOW TEST:58.723 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:33:53.584: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:33:53.752: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04ed663a-50d8-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-f9h8g" to be "success or failure"
Mar 27 21:33:53.766: INFO: Pod "downwardapi-volume-04ed663a-50d8-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 14.26112ms
Mar 27 21:33:55.777: INFO: Pod "downwardapi-volume-04ed663a-50d8-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025754204s
STEP: Saw pod success
Mar 27 21:33:55.779: INFO: Pod "downwardapi-volume-04ed663a-50d8-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:33:55.788: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-04ed663a-50d8-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:33:55.925: INFO: Waiting for pod downwardapi-volume-04ed663a-50d8-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:33:55.932: INFO: Pod downwardapi-volume-04ed663a-50d8-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:33:55.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f9h8g" for this suite.
Mar 27 21:34:02.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:34:02.066: INFO: namespace: e2e-tests-downward-api-f9h8g, resource: bindings, ignored listing per whitelist
Mar 27 21:34:02.175: INFO: namespace e2e-tests-downward-api-f9h8g deletion completed in 6.216945621s

• [SLOW TEST:8.591 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:34:02.176: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar 27 21:34:05.417: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:34:06.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-vthdz" for this suite.
Mar 27 21:34:34.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:34:34.715: INFO: namespace: e2e-tests-replicaset-vthdz, resource: bindings, ignored listing per whitelist
Mar 27 21:34:34.764: INFO: namespace e2e-tests-replicaset-vthdz deletion completed in 28.292948083s

• [SLOW TEST:32.589 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:34:34.765: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 27 21:34:37.570: INFO: Successfully updated pod "labelsupdate1d782224-50d8-11e9-9d23-0ac04cf37a48"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:34:39.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w6gms" for this suite.
Mar 27 21:35:03.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:35:03.748: INFO: namespace: e2e-tests-projected-w6gms, resource: bindings, ignored listing per whitelist
Mar 27 21:35:03.905: INFO: namespace e2e-tests-projected-w6gms deletion completed in 24.254779588s

• [SLOW TEST:29.141 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:35:03.907: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0327 21:35:34.646326      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 27 21:35:34.647: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:35:34.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mzxxd" for this suite.
Mar 27 21:35:42.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:35:42.986: INFO: namespace: e2e-tests-gc-mzxxd, resource: bindings, ignored listing per whitelist
Mar 27 21:35:43.037: INFO: namespace e2e-tests-gc-mzxxd deletion completed in 8.375184179s

• [SLOW TEST:39.131 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:35:43.038: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 27 21:35:43.232: INFO: Waiting up to 5m0s for pod "pod-462ea82f-50d8-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-f7prr" to be "success or failure"
Mar 27 21:35:43.245: INFO: Pod "pod-462ea82f-50d8-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 13.385854ms
Mar 27 21:35:45.252: INFO: Pod "pod-462ea82f-50d8-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020255501s
STEP: Saw pod success
Mar 27 21:35:45.252: INFO: Pod "pod-462ea82f-50d8-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:35:45.260: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-462ea82f-50d8-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 21:35:45.335: INFO: Waiting for pod pod-462ea82f-50d8-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:35:45.343: INFO: Pod pod-462ea82f-50d8-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:35:45.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f7prr" for this suite.
Mar 27 21:35:51.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:35:51.664: INFO: namespace: e2e-tests-emptydir-f7prr, resource: bindings, ignored listing per whitelist
Mar 27 21:35:51.670: INFO: namespace e2e-tests-emptydir-f7prr deletion completed in 6.309731348s

• [SLOW TEST:8.632 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:35:51.678: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:35:51.935: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4b5d8188-50d8-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-l58gl" to be "success or failure"
Mar 27 21:35:51.960: INFO: Pod "downwardapi-volume-4b5d8188-50d8-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 24.120017ms
Mar 27 21:35:53.971: INFO: Pod "downwardapi-volume-4b5d8188-50d8-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035301641s
Mar 27 21:35:55.978: INFO: Pod "downwardapi-volume-4b5d8188-50d8-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042716433s
STEP: Saw pod success
Mar 27 21:35:55.978: INFO: Pod "downwardapi-volume-4b5d8188-50d8-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:35:55.991: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-4b5d8188-50d8-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:35:56.084: INFO: Waiting for pod downwardapi-volume-4b5d8188-50d8-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:35:56.132: INFO: Pod downwardapi-volume-4b5d8188-50d8-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:35:56.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l58gl" for this suite.
Mar 27 21:36:02.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:36:02.234: INFO: namespace: e2e-tests-projected-l58gl, resource: bindings, ignored listing per whitelist
Mar 27 21:36:02.396: INFO: namespace e2e-tests-projected-l58gl deletion completed in 6.256037361s

• [SLOW TEST:10.719 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:36:02.399: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar 27 21:36:02.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 cluster-info'
Mar 27 21:36:02.912: INFO: stderr: ""
Mar 27 21:36:02.912: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:36:02.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-td4dn" for this suite.
Mar 27 21:36:08.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:36:09.091: INFO: namespace: e2e-tests-kubectl-td4dn, resource: bindings, ignored listing per whitelist
Mar 27 21:36:09.156: INFO: namespace e2e-tests-kubectl-td4dn deletion completed in 6.231683395s

• [SLOW TEST:6.757 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:36:09.157: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:36:09.299: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55b85f04-50d8-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-bjlkv" to be "success or failure"
Mar 27 21:36:09.307: INFO: Pod "downwardapi-volume-55b85f04-50d8-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 7.819093ms
Mar 27 21:36:11.315: INFO: Pod "downwardapi-volume-55b85f04-50d8-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.015791306s
Mar 27 21:36:13.322: INFO: Pod "downwardapi-volume-55b85f04-50d8-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023520943s
STEP: Saw pod success
Mar 27 21:36:13.322: INFO: Pod "downwardapi-volume-55b85f04-50d8-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:36:13.337: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-55b85f04-50d8-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:36:13.415: INFO: Waiting for pod downwardapi-volume-55b85f04-50d8-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:36:13.422: INFO: Pod downwardapi-volume-55b85f04-50d8-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:36:13.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bjlkv" for this suite.
Mar 27 21:36:19.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:36:19.552: INFO: namespace: e2e-tests-downward-api-bjlkv, resource: bindings, ignored listing per whitelist
Mar 27 21:36:19.704: INFO: namespace e2e-tests-downward-api-bjlkv deletion completed in 6.258561454s

• [SLOW TEST:10.548 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:36:19.710: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:36:19.821: INFO: Creating deployment "test-recreate-deployment"
Mar 27 21:36:19.831: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 27 21:36:19.841: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Mar 27 21:36:21.856: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 27 21:36:21.860: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689319379, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689319379, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689319379, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689319379, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 21:36:23.866: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 27 21:36:23.889: INFO: Updating deployment test-recreate-deployment
Mar 27 21:36:23.889: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 27 21:36:24.397: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-557dp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-557dp/deployments/test-recreate-deployment,UID:5c00f20d-50d8-11e9-8df3-90b8d03c5288,ResourceVersion:191774,Generation:2,CreationTimestamp:2019-03-27 21:36:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-27 21:36:24 +0000 UTC 2019-03-27 21:36:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-27 21:36:24 +0000 UTC 2019-03-27 21:36:19 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 27 21:36:24.403: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-557dp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-557dp/replicasets/test-recreate-deployment-697fbf54bf,UID:5e7f9f45-50d8-11e9-8df3-90b8d03c5288,ResourceVersion:191771,Generation:1,CreationTimestamp:2019-03-27 21:36:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5c00f20d-50d8-11e9-8df3-90b8d03c5288 0xc000ac99d7 0xc000ac99d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 27 21:36:24.403: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 27 21:36:24.403: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-557dp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-557dp/replicasets/test-recreate-deployment-5dfdcc846d,UID:5c041d7a-50d8-11e9-8df3-90b8d03c5288,ResourceVersion:191760,Generation:2,CreationTimestamp:2019-03-27 21:36:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5c00f20d-50d8-11e9-8df3-90b8d03c5288 0xc000ac98b7 0xc000ac98b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 27 21:36:24.415: INFO: Pod "test-recreate-deployment-697fbf54bf-pkl69" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-pkl69,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-557dp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-557dp/pods/test-recreate-deployment-697fbf54bf-pkl69,UID:5e84af33-50d8-11e9-8df3-90b8d03c5288,ResourceVersion:191775,Generation:0,CreationTimestamp:2019-03-27 21:36:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 5e7f9f45-50d8-11e9-8df3-90b8d03c5288 0xc00364a3b7 0xc00364a3b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zpzxp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zpzxp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zpzxp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-13-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00364a420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00364a440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:36:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:36:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:36:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:36:24 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.200,PodIP:,StartTime:2019-03-27 21:36:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:36:24.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-557dp" for this suite.
Mar 27 21:36:32.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:36:32.619: INFO: namespace: e2e-tests-deployment-557dp, resource: bindings, ignored listing per whitelist
Mar 27 21:36:32.753: INFO: namespace e2e-tests-deployment-557dp deletion completed in 8.323497643s

• [SLOW TEST:13.043 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:36:32.754: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 27 21:36:37.576: INFO: Successfully updated pod "labelsupdate63d67e2d-50d8-11e9-9d23-0ac04cf37a48"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:36:39.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5s28d" for this suite.
Mar 27 21:37:03.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:37:03.890: INFO: namespace: e2e-tests-downward-api-5s28d, resource: bindings, ignored listing per whitelist
Mar 27 21:37:03.940: INFO: namespace e2e-tests-downward-api-5s28d deletion completed in 24.26264116s

• [SLOW TEST:31.187 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:37:03.945: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar 27 21:37:04.103: INFO: Waiting up to 5m0s for pod "client-containers-7663cd5f-50d8-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-containers-qhh7v" to be "success or failure"
Mar 27 21:37:04.130: INFO: Pod "client-containers-7663cd5f-50d8-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 27.378415ms
Mar 27 21:37:06.138: INFO: Pod "client-containers-7663cd5f-50d8-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035358035s
STEP: Saw pod success
Mar 27 21:37:06.139: INFO: Pod "client-containers-7663cd5f-50d8-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:37:06.148: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod client-containers-7663cd5f-50d8-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 21:37:06.256: INFO: Waiting for pod client-containers-7663cd5f-50d8-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:37:06.276: INFO: Pod client-containers-7663cd5f-50d8-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:37:06.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-qhh7v" for this suite.
Mar 27 21:37:12.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:37:12.394: INFO: namespace: e2e-tests-containers-qhh7v, resource: bindings, ignored listing per whitelist
Mar 27 21:37:12.594: INFO: namespace e2e-tests-containers-qhh7v deletion completed in 6.296794111s

• [SLOW TEST:8.650 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:37:12.600: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 27 21:37:17.050: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 27 21:37:17.058: INFO: Pod pod-with-prestop-http-hook still exists
Mar 27 21:37:19.059: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 27 21:37:19.065: INFO: Pod pod-with-prestop-http-hook still exists
Mar 27 21:37:21.059: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 27 21:37:21.064: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:37:21.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9fbhv" for this suite.
Mar 27 21:37:45.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:37:45.244: INFO: namespace: e2e-tests-container-lifecycle-hook-9fbhv, resource: bindings, ignored listing per whitelist
Mar 27 21:37:45.343: INFO: namespace e2e-tests-container-lifecycle-hook-9fbhv deletion completed in 24.243273077s

• [SLOW TEST:32.743 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:37:45.346: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar 27 21:37:45.465: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-228394863 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:37:45.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rd92d" for this suite.
Mar 27 21:37:51.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:37:51.826: INFO: namespace: e2e-tests-kubectl-rd92d, resource: bindings, ignored listing per whitelist
Mar 27 21:37:51.977: INFO: namespace e2e-tests-kubectl-rd92d deletion completed in 6.348547454s

• [SLOW TEST:6.631 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:37:51.981: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:37:58.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-lzlw4" for this suite.
Mar 27 21:38:04.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:38:04.458: INFO: namespace: e2e-tests-namespaces-lzlw4, resource: bindings, ignored listing per whitelist
Mar 27 21:38:04.662: INFO: namespace e2e-tests-namespaces-lzlw4 deletion completed in 6.29486746s
STEP: Destroying namespace "e2e-tests-nsdeletetest-6ttmj" for this suite.
Mar 27 21:38:04.670: INFO: Namespace e2e-tests-nsdeletetest-6ttmj was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-wwz25" for this suite.
Mar 27 21:38:10.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:38:10.886: INFO: namespace: e2e-tests-nsdeletetest-wwz25, resource: bindings, ignored listing per whitelist
Mar 27 21:38:10.910: INFO: namespace e2e-tests-nsdeletetest-wwz25 deletion completed in 6.239358332s

• [SLOW TEST:18.929 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:38:10.911: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0327 21:38:51.146029      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 27 21:38:51.146: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:38:51.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-swc94" for this suite.
Mar 27 21:38:59.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:38:59.672: INFO: namespace: e2e-tests-gc-swc94, resource: bindings, ignored listing per whitelist
Mar 27 21:38:59.672: INFO: namespace e2e-tests-gc-swc94 deletion completed in 8.504846107s

• [SLOW TEST:48.761 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:38:59.673: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 27 21:39:06.087: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6lbhb PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:39:06.088: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:39:06.321: INFO: Exec stderr: ""
Mar 27 21:39:06.321: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6lbhb PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:39:06.322: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:39:06.492: INFO: Exec stderr: ""
Mar 27 21:39:06.492: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6lbhb PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:39:06.492: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:39:06.644: INFO: Exec stderr: ""
Mar 27 21:39:06.645: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6lbhb PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:39:06.645: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:39:06.798: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 27 21:39:06.799: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6lbhb PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:39:06.799: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:39:06.984: INFO: Exec stderr: ""
Mar 27 21:39:06.985: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6lbhb PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:39:06.986: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:39:07.128: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 27 21:39:07.128: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6lbhb PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:39:07.129: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:39:07.288: INFO: Exec stderr: ""
Mar 27 21:39:07.289: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6lbhb PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:39:07.289: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:39:07.406: INFO: Exec stderr: ""
Mar 27 21:39:07.406: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6lbhb PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:39:07.406: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:39:07.549: INFO: Exec stderr: ""
Mar 27 21:39:07.550: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6lbhb PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:39:07.550: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:39:07.679: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:39:07.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-6lbhb" for this suite.
Mar 27 21:39:55.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:39:55.838: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-6lbhb, resource: bindings, ignored listing per whitelist
Mar 27 21:39:56.015: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-6lbhb deletion completed in 48.326824686s

• [SLOW TEST:56.342 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:39:56.023: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-5bxnl
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar 27 21:39:56.267: INFO: Found 0 stateful pods, waiting for 3
Mar 27 21:40:06.275: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 21:40:06.275: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 21:40:06.275: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 21:40:06.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-5bxnl ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 27 21:40:06.636: INFO: stderr: ""
Mar 27 21:40:06.636: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 27 21:40:06.636: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 27 21:40:16.691: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 27 21:40:26.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-5bxnl ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:40:26.988: INFO: stderr: ""
Mar 27 21:40:26.988: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 27 21:40:26.988: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 27 21:40:37.046: INFO: Waiting for StatefulSet e2e-tests-statefulset-5bxnl/ss2 to complete update
Mar 27 21:40:37.046: INFO: Waiting for Pod e2e-tests-statefulset-5bxnl/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 27 21:40:37.046: INFO: Waiting for Pod e2e-tests-statefulset-5bxnl/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 27 21:40:37.046: INFO: Waiting for Pod e2e-tests-statefulset-5bxnl/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 27 21:40:47.061: INFO: Waiting for StatefulSet e2e-tests-statefulset-5bxnl/ss2 to complete update
Mar 27 21:40:47.061: INFO: Waiting for Pod e2e-tests-statefulset-5bxnl/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar 27 21:40:57.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-5bxnl ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 27 21:40:57.431: INFO: stderr: ""
Mar 27 21:40:57.431: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 27 21:40:57.431: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 27 21:41:07.492: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 27 21:41:17.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-5bxnl ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:41:17.828: INFO: stderr: ""
Mar 27 21:41:17.828: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 27 21:41:17.828: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 27 21:41:37.907: INFO: Waiting for StatefulSet e2e-tests-statefulset-5bxnl/ss2 to complete update
Mar 27 21:41:37.908: INFO: Waiting for Pod e2e-tests-statefulset-5bxnl/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 27 21:41:47.941: INFO: Deleting all statefulset in ns e2e-tests-statefulset-5bxnl
Mar 27 21:41:47.954: INFO: Scaling statefulset ss2 to 0
Mar 27 21:42:08.007: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 21:42:08.015: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:42:08.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-5bxnl" for this suite.
Mar 27 21:42:16.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:42:16.307: INFO: namespace: e2e-tests-statefulset-5bxnl, resource: bindings, ignored listing per whitelist
Mar 27 21:42:16.387: INFO: namespace e2e-tests-statefulset-5bxnl deletion completed in 8.272150155s

• [SLOW TEST:140.364 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:42:16.389: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-7h9s2
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 27 21:42:16.552: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 27 21:42:38.906: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.3.77 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7h9s2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:42:38.906: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:42:40.047: INFO: Found all expected endpoints: [netserver-0]
Mar 27 21:42:40.053: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.1.194 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7h9s2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:42:40.054: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:42:41.177: INFO: Found all expected endpoints: [netserver-1]
Mar 27 21:42:41.184: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.0.110 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7h9s2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:42:41.184: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:42:42.349: INFO: Found all expected endpoints: [netserver-2]
Mar 27 21:42:42.356: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.4.121 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7h9s2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:42:42.356: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:42:43.498: INFO: Found all expected endpoints: [netserver-3]
Mar 27 21:42:43.508: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.2.80 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7h9s2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:42:43.508: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:42:44.640: INFO: Found all expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:42:44.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-7h9s2" for this suite.
Mar 27 21:43:08.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:43:08.842: INFO: namespace: e2e-tests-pod-network-test-7h9s2, resource: bindings, ignored listing per whitelist
Mar 27 21:43:08.867: INFO: namespace e2e-tests-pod-network-test-7h9s2 deletion completed in 24.208217388s

• [SLOW TEST:52.479 seconds]
[sig-network] Networking
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:43:08.869: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-7rbkn/configmap-test-4fe2f632-50d9-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 21:43:09.015: INFO: Waiting up to 5m0s for pod "pod-configmaps-4fe44714-50d9-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-configmap-7rbkn" to be "success or failure"
Mar 27 21:43:09.031: INFO: Pod "pod-configmaps-4fe44714-50d9-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 15.927495ms
Mar 27 21:43:11.041: INFO: Pod "pod-configmaps-4fe44714-50d9-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025386026s
STEP: Saw pod success
Mar 27 21:43:11.041: INFO: Pod "pod-configmaps-4fe44714-50d9-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:43:11.050: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-configmaps-4fe44714-50d9-11e9-9d23-0ac04cf37a48 container env-test: <nil>
STEP: delete the pod
Mar 27 21:43:11.205: INFO: Waiting for pod pod-configmaps-4fe44714-50d9-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:43:11.215: INFO: Pod pod-configmaps-4fe44714-50d9-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:43:11.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7rbkn" for this suite.
Mar 27 21:43:17.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:43:17.376: INFO: namespace: e2e-tests-configmap-7rbkn, resource: bindings, ignored listing per whitelist
Mar 27 21:43:17.603: INFO: namespace e2e-tests-configmap-7rbkn deletion completed in 6.336709158s

• [SLOW TEST:8.734 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:43:17.604: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar 27 21:43:17.845: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar 27 21:43:17.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:18.296: INFO: stderr: ""
Mar 27 21:43:18.296: INFO: stdout: "service/redis-slave created\n"
Mar 27 21:43:18.296: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar 27 21:43:18.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:18.754: INFO: stderr: ""
Mar 27 21:43:18.754: INFO: stdout: "service/redis-master created\n"
Mar 27 21:43:18.754: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 27 21:43:18.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:19.209: INFO: stderr: ""
Mar 27 21:43:19.209: INFO: stdout: "service/frontend created\n"
Mar 27 21:43:19.210: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar 27 21:43:19.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:19.622: INFO: stderr: ""
Mar 27 21:43:19.622: INFO: stdout: "deployment.extensions/frontend created\n"
Mar 27 21:43:19.622: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 27 21:43:19.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:20.200: INFO: stderr: ""
Mar 27 21:43:20.200: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar 27 21:43:20.200: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar 27 21:43:20.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:21.019: INFO: stderr: ""
Mar 27 21:43:21.019: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar 27 21:43:21.019: INFO: Waiting for all frontend pods to be Running.
Mar 27 21:43:26.079: INFO: Waiting for frontend to serve content.
Mar 27 21:43:31.273: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Mar 27 21:43:36.377: INFO: Trying to add a new entry to the guestbook.
Mar 27 21:43:36.463: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar 27 21:43:36.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:36.699: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 21:43:36.699: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 27 21:43:36.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:36.945: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 21:43:36.945: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 27 21:43:36.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:37.235: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 21:43:37.235: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 27 21:43:37.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:37.424: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 21:43:37.424: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 27 21:43:37.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:37.805: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 21:43:37.805: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 27 21:43:37.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hvrws'
Mar 27 21:43:38.186: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 21:43:38.186: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:43:38.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hvrws" for this suite.
Mar 27 21:44:18.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:44:18.462: INFO: namespace: e2e-tests-kubectl-hvrws, resource: bindings, ignored listing per whitelist
Mar 27 21:44:18.483: INFO: namespace e2e-tests-kubectl-hvrws deletion completed in 40.248120627s

• [SLOW TEST:60.880 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:44:18.499: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 27 21:44:18.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-rbfkc'
Mar 27 21:44:18.893: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 27 21:44:18.893: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Mar 27 21:44:20.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-rbfkc'
Mar 27 21:44:21.113: INFO: stderr: ""
Mar 27 21:44:21.113: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:44:21.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rbfkc" for this suite.
Mar 27 21:44:35.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:44:35.292: INFO: namespace: e2e-tests-kubectl-rbfkc, resource: bindings, ignored listing per whitelist
Mar 27 21:44:35.480: INFO: namespace e2e-tests-kubectl-rbfkc deletion completed in 14.350852118s

• [SLOW TEST:16.982 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:44:35.484: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 21:44:35.815: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"83980195-50d9-11e9-8df3-90b8d03c5288", Controller:(*bool)(0xc001fb211a), BlockOwnerDeletion:(*bool)(0xc001fb211b)}}
Mar 27 21:44:35.857: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"83910066-50d9-11e9-8df3-90b8d03c5288", Controller:(*bool)(0xc001fb2436), BlockOwnerDeletion:(*bool)(0xc001fb2437)}}
Mar 27 21:44:35.891: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"83944411-50d9-11e9-8df3-90b8d03c5288", Controller:(*bool)(0xc001fb27a2), BlockOwnerDeletion:(*bool)(0xc001fb27a3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:44:40.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mckbx" for this suite.
Mar 27 21:44:46.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:44:47.100: INFO: namespace: e2e-tests-gc-mckbx, resource: bindings, ignored listing per whitelist
Mar 27 21:44:47.163: INFO: namespace e2e-tests-gc-mckbx deletion completed in 6.21862774s

• [SLOW TEST:11.679 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:44:47.165: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0327 21:44:57.401519      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 27 21:44:57.401: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:44:57.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-s6j2q" for this suite.
Mar 27 21:45:03.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:45:03.570: INFO: namespace: e2e-tests-gc-s6j2q, resource: bindings, ignored listing per whitelist
Mar 27 21:45:03.641: INFO: namespace e2e-tests-gc-s6j2q deletion completed in 6.221560873s

• [SLOW TEST:16.476 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:45:03.642: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 27 21:45:03.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-96wv7'
Mar 27 21:45:03.999: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 27 21:45:03.999: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Mar 27 21:45:08.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-96wv7'
Mar 27 21:45:08.327: INFO: stderr: ""
Mar 27 21:45:08.327: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:45:08.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-96wv7" for this suite.
Mar 27 21:45:14.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:45:14.572: INFO: namespace: e2e-tests-kubectl-96wv7, resource: bindings, ignored listing per whitelist
Mar 27 21:45:14.580: INFO: namespace e2e-tests-kubectl-96wv7 deletion completed in 6.241302743s

• [SLOW TEST:10.938 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:45:14.581: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar 27 21:45:14.712: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-228394863 proxy --unix-socket=/tmp/kubectl-proxy-unix777534466/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:45:14.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-55x22" for this suite.
Mar 27 21:45:20.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:45:21.049: INFO: namespace: e2e-tests-kubectl-55x22, resource: bindings, ignored listing per whitelist
Mar 27 21:45:21.086: INFO: namespace e2e-tests-kubectl-55x22 deletion completed in 6.265846908s

• [SLOW TEST:6.505 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:45:21.089: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 27 21:45:21.443: INFO: Number of nodes with available pods: 0
Mar 27 21:45:21.443: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 21:45:22.521: INFO: Number of nodes with available pods: 0
Mar 27 21:45:22.521: INFO: Node k8s-conformance-cluster-1-13-control-1 is running more than one daemon pod
Mar 27 21:45:23.460: INFO: Number of nodes with available pods: 4
Mar 27 21:45:23.460: INFO: Node k8s-conformance-cluster-1-13-etcd-1 is running more than one daemon pod
Mar 27 21:45:24.468: INFO: Number of nodes with available pods: 5
Mar 27 21:45:24.469: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 27 21:45:24.537: INFO: Number of nodes with available pods: 4
Mar 27 21:45:24.537: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:25.564: INFO: Number of nodes with available pods: 4
Mar 27 21:45:25.564: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:26.560: INFO: Number of nodes with available pods: 4
Mar 27 21:45:26.560: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:27.554: INFO: Number of nodes with available pods: 4
Mar 27 21:45:27.554: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:28.554: INFO: Number of nodes with available pods: 4
Mar 27 21:45:28.554: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:29.562: INFO: Number of nodes with available pods: 4
Mar 27 21:45:29.562: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:30.566: INFO: Number of nodes with available pods: 4
Mar 27 21:45:30.566: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:31.564: INFO: Number of nodes with available pods: 4
Mar 27 21:45:31.564: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:32.566: INFO: Number of nodes with available pods: 4
Mar 27 21:45:32.566: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:33.557: INFO: Number of nodes with available pods: 4
Mar 27 21:45:33.557: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:34.558: INFO: Number of nodes with available pods: 4
Mar 27 21:45:34.558: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:35.563: INFO: Number of nodes with available pods: 4
Mar 27 21:45:35.563: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:36.564: INFO: Number of nodes with available pods: 4
Mar 27 21:45:36.564: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:37.556: INFO: Number of nodes with available pods: 4
Mar 27 21:45:37.556: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:38.557: INFO: Number of nodes with available pods: 4
Mar 27 21:45:38.558: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:39.567: INFO: Number of nodes with available pods: 4
Mar 27 21:45:39.567: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:40.556: INFO: Number of nodes with available pods: 4
Mar 27 21:45:40.556: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:41.561: INFO: Number of nodes with available pods: 4
Mar 27 21:45:41.561: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:42.553: INFO: Number of nodes with available pods: 4
Mar 27 21:45:42.553: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:43.569: INFO: Number of nodes with available pods: 4
Mar 27 21:45:43.569: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:44.565: INFO: Number of nodes with available pods: 4
Mar 27 21:45:44.565: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:45.556: INFO: Number of nodes with available pods: 4
Mar 27 21:45:45.556: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:46.558: INFO: Number of nodes with available pods: 4
Mar 27 21:45:46.558: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:47.571: INFO: Number of nodes with available pods: 4
Mar 27 21:45:47.572: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:48.560: INFO: Number of nodes with available pods: 4
Mar 27 21:45:48.560: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:49.562: INFO: Number of nodes with available pods: 4
Mar 27 21:45:49.562: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:50.563: INFO: Number of nodes with available pods: 4
Mar 27 21:45:50.564: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:51.554: INFO: Number of nodes with available pods: 4
Mar 27 21:45:51.555: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:52.561: INFO: Number of nodes with available pods: 4
Mar 27 21:45:52.561: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:53.561: INFO: Number of nodes with available pods: 4
Mar 27 21:45:53.561: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:54.552: INFO: Number of nodes with available pods: 4
Mar 27 21:45:54.552: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:55.551: INFO: Number of nodes with available pods: 4
Mar 27 21:45:55.551: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:56.555: INFO: Number of nodes with available pods: 4
Mar 27 21:45:56.555: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:57.559: INFO: Number of nodes with available pods: 4
Mar 27 21:45:57.559: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:58.580: INFO: Number of nodes with available pods: 4
Mar 27 21:45:58.580: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:45:59.555: INFO: Number of nodes with available pods: 4
Mar 27 21:45:59.555: INFO: Node k8s-conformance-cluster-1-13-worker-2 is running more than one daemon pod
Mar 27 21:46:00.554: INFO: Number of nodes with available pods: 5
Mar 27 21:46:00.554: INFO: Number of running nodes: 5, number of available pods: 5
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-hgvgl, will wait for the garbage collector to delete the pods
Mar 27 21:46:00.634: INFO: Deleting DaemonSet.extensions daemon-set took: 19.456118ms
Mar 27 21:46:00.835: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.5405ms
Mar 27 21:46:44.943: INFO: Number of nodes with available pods: 0
Mar 27 21:46:44.943: INFO: Number of running nodes: 0, number of available pods: 0
Mar 27 21:46:44.951: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hgvgl/daemonsets","resourceVersion":"194376"},"items":null}

Mar 27 21:46:44.958: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hgvgl/pods","resourceVersion":"194376"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:46:45.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hgvgl" for this suite.
Mar 27 21:46:51.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:46:51.169: INFO: namespace: e2e-tests-daemonsets-hgvgl, resource: bindings, ignored listing per whitelist
Mar 27 21:46:51.256: INFO: namespace e2e-tests-daemonsets-hgvgl deletion completed in 6.237992944s

• [SLOW TEST:90.167 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:46:51.258: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Mar 27 21:46:51.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 create -f - --namespace=e2e-tests-kubectl-2tvpn'
Mar 27 21:46:51.944: INFO: stderr: ""
Mar 27 21:46:51.944: INFO: stdout: "pod/pause created\n"
Mar 27 21:46:51.944: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 27 21:46:51.945: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-2tvpn" to be "running and ready"
Mar 27 21:46:51.959: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.912439ms
Mar 27 21:46:53.966: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.021127044s
Mar 27 21:46:53.966: INFO: Pod "pause" satisfied condition "running and ready"
Mar 27 21:46:53.966: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 27 21:46:53.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-2tvpn'
Mar 27 21:46:54.150: INFO: stderr: ""
Mar 27 21:46:54.150: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 27 21:46:54.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pod pause -L testing-label --namespace=e2e-tests-kubectl-2tvpn'
Mar 27 21:46:54.288: INFO: stderr: ""
Mar 27 21:46:54.288: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 27 21:46:54.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 label pods pause testing-label- --namespace=e2e-tests-kubectl-2tvpn'
Mar 27 21:46:54.446: INFO: stderr: ""
Mar 27 21:46:54.446: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 27 21:46:54.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pod pause -L testing-label --namespace=e2e-tests-kubectl-2tvpn'
Mar 27 21:46:54.613: INFO: stderr: ""
Mar 27 21:46:54.613: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Mar 27 21:46:54.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2tvpn'
Mar 27 21:46:54.852: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 21:46:54.852: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 27 21:46:54.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-2tvpn'
Mar 27 21:46:55.025: INFO: stderr: "No resources found.\n"
Mar 27 21:46:55.026: INFO: stdout: ""
Mar 27 21:46:55.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 get pods -l name=pause --namespace=e2e-tests-kubectl-2tvpn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 27 21:46:55.170: INFO: stderr: ""
Mar 27 21:46:55.170: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:46:55.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2tvpn" for this suite.
Mar 27 21:47:01.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:47:01.344: INFO: namespace: e2e-tests-kubectl-2tvpn, resource: bindings, ignored listing per whitelist
Mar 27 21:47:01.430: INFO: namespace e2e-tests-kubectl-2tvpn deletion completed in 6.241771307s

• [SLOW TEST:10.172 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:47:01.432: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-da8cbd24-50d9-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 21:47:01.664: INFO: Waiting up to 5m0s for pod "pod-secrets-da8f1315-50d9-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-secrets-f8tj2" to be "success or failure"
Mar 27 21:47:01.680: INFO: Pod "pod-secrets-da8f1315-50d9-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 15.843206ms
Mar 27 21:47:03.686: INFO: Pod "pod-secrets-da8f1315-50d9-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021286166s
Mar 27 21:47:05.693: INFO: Pod "pod-secrets-da8f1315-50d9-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028416076s
STEP: Saw pod success
Mar 27 21:47:05.693: INFO: Pod "pod-secrets-da8f1315-50d9-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:47:05.698: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-secrets-da8f1315-50d9-11e9-9d23-0ac04cf37a48 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 21:47:05.762: INFO: Waiting for pod pod-secrets-da8f1315-50d9-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:47:05.791: INFO: Pod pod-secrets-da8f1315-50d9-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:47:05.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-f8tj2" for this suite.
Mar 27 21:47:11.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:47:12.240: INFO: namespace: e2e-tests-secrets-f8tj2, resource: bindings, ignored listing per whitelist
Mar 27 21:47:12.244: INFO: namespace e2e-tests-secrets-f8tj2 deletion completed in 6.435265653s

• [SLOW TEST:10.813 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:47:12.246: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 27 21:47:12.465: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cjsrs,SelfLink:/api/v1/namespaces/e2e-tests-watch-cjsrs/configmaps/e2e-watch-test-watch-closed,UID:e0fe44f3-50d9-11e9-8df3-90b8d03c5288,ResourceVersion:194536,Generation:0,CreationTimestamp:2019-03-27 21:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 27 21:47:12.466: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cjsrs,SelfLink:/api/v1/namespaces/e2e-tests-watch-cjsrs/configmaps/e2e-watch-test-watch-closed,UID:e0fe44f3-50d9-11e9-8df3-90b8d03c5288,ResourceVersion:194537,Generation:0,CreationTimestamp:2019-03-27 21:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 27 21:47:12.517: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cjsrs,SelfLink:/api/v1/namespaces/e2e-tests-watch-cjsrs/configmaps/e2e-watch-test-watch-closed,UID:e0fe44f3-50d9-11e9-8df3-90b8d03c5288,ResourceVersion:194538,Generation:0,CreationTimestamp:2019-03-27 21:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 27 21:47:12.518: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cjsrs,SelfLink:/api/v1/namespaces/e2e-tests-watch-cjsrs/configmaps/e2e-watch-test-watch-closed,UID:e0fe44f3-50d9-11e9-8df3-90b8d03c5288,ResourceVersion:194539,Generation:0,CreationTimestamp:2019-03-27 21:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:47:12.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-cjsrs" for this suite.
Mar 27 21:47:18.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:47:18.673: INFO: namespace: e2e-tests-watch-cjsrs, resource: bindings, ignored listing per whitelist
Mar 27 21:47:18.747: INFO: namespace e2e-tests-watch-cjsrs deletion completed in 6.213503716s

• [SLOW TEST:6.501 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:47:18.748: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:47:18.892: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e4d3b90f-50d9-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-xsv99" to be "success or failure"
Mar 27 21:47:18.907: INFO: Pod "downwardapi-volume-e4d3b90f-50d9-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 15.132964ms
Mar 27 21:47:20.912: INFO: Pod "downwardapi-volume-e4d3b90f-50d9-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.020030595s
Mar 27 21:47:22.917: INFO: Pod "downwardapi-volume-e4d3b90f-50d9-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024856934s
STEP: Saw pod success
Mar 27 21:47:22.917: INFO: Pod "downwardapi-volume-e4d3b90f-50d9-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:47:22.922: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-e4d3b90f-50d9-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:47:22.998: INFO: Waiting for pod downwardapi-volume-e4d3b90f-50d9-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:47:23.019: INFO: Pod downwardapi-volume-e4d3b90f-50d9-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:47:23.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xsv99" for this suite.
Mar 27 21:47:29.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:47:29.171: INFO: namespace: e2e-tests-downward-api-xsv99, resource: bindings, ignored listing per whitelist
Mar 27 21:47:29.355: INFO: namespace e2e-tests-downward-api-xsv99 deletion completed in 6.321350191s

• [SLOW TEST:10.607 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:47:29.355: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 27 21:47:29.475: INFO: Waiting up to 5m0s for pod "pod-eb231450-50d9-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-kgz5k" to be "success or failure"
Mar 27 21:47:29.518: INFO: Pod "pod-eb231450-50d9-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 42.367878ms
Mar 27 21:47:31.527: INFO: Pod "pod-eb231450-50d9-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.051222559s
Mar 27 21:47:33.532: INFO: Pod "pod-eb231450-50d9-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057097928s
STEP: Saw pod success
Mar 27 21:47:33.533: INFO: Pod "pod-eb231450-50d9-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:47:33.537: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-eb231450-50d9-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 21:47:33.601: INFO: Waiting for pod pod-eb231450-50d9-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:47:33.649: INFO: Pod pod-eb231450-50d9-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:47:33.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kgz5k" for this suite.
Mar 27 21:47:39.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:47:39.752: INFO: namespace: e2e-tests-emptydir-kgz5k, resource: bindings, ignored listing per whitelist
Mar 27 21:47:39.908: INFO: namespace e2e-tests-emptydir-kgz5k deletion completed in 6.247708914s

• [SLOW TEST:10.553 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:47:39.914: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-f17d5c63-50d9-11e9-9d23-0ac04cf37a48
STEP: Creating configMap with name cm-test-opt-upd-f17d5ca9-50d9-11e9-9d23-0ac04cf37a48
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f17d5c63-50d9-11e9-9d23-0ac04cf37a48
STEP: Updating configmap cm-test-opt-upd-f17d5ca9-50d9-11e9-9d23-0ac04cf37a48
STEP: Creating configMap with name cm-test-opt-create-f17d5cc3-50d9-11e9-9d23-0ac04cf37a48
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:47:44.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5w8wk" for this suite.
Mar 27 21:48:08.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:48:08.589: INFO: namespace: e2e-tests-configmap-5w8wk, resource: bindings, ignored listing per whitelist
Mar 27 21:48:08.724: INFO: namespace e2e-tests-configmap-5w8wk deletion completed in 24.328384593s

• [SLOW TEST:28.811 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:48:08.725: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 27 21:48:08.948: INFO: Waiting up to 5m0s for pod "pod-02a962a6-50da-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-kgzk8" to be "success or failure"
Mar 27 21:48:08.977: INFO: Pod "pod-02a962a6-50da-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 29.7712ms
Mar 27 21:48:10.984: INFO: Pod "pod-02a962a6-50da-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036422564s
STEP: Saw pod success
Mar 27 21:48:10.985: INFO: Pod "pod-02a962a6-50da-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:48:10.992: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-02a962a6-50da-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 21:48:11.081: INFO: Waiting for pod pod-02a962a6-50da-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:48:11.099: INFO: Pod pod-02a962a6-50da-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:48:11.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kgzk8" for this suite.
Mar 27 21:48:17.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:48:17.322: INFO: namespace: e2e-tests-emptydir-kgzk8, resource: bindings, ignored listing per whitelist
Mar 27 21:48:17.461: INFO: namespace e2e-tests-emptydir-kgzk8 deletion completed in 6.350344979s

• [SLOW TEST:8.736 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:48:17.462: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:48:17.649: INFO: Waiting up to 5m0s for pod "downwardapi-volume-07d7d2a0-50da-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-cjt8t" to be "success or failure"
Mar 27 21:48:17.695: INFO: Pod "downwardapi-volume-07d7d2a0-50da-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 46.247568ms
Mar 27 21:48:19.703: INFO: Pod "downwardapi-volume-07d7d2a0-50da-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054079746s
Mar 27 21:48:21.711: INFO: Pod "downwardapi-volume-07d7d2a0-50da-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061892554s
STEP: Saw pod success
Mar 27 21:48:21.711: INFO: Pod "downwardapi-volume-07d7d2a0-50da-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:48:21.719: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-07d7d2a0-50da-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:48:21.812: INFO: Waiting for pod downwardapi-volume-07d7d2a0-50da-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:48:21.820: INFO: Pod downwardapi-volume-07d7d2a0-50da-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:48:21.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cjt8t" for this suite.
Mar 27 21:48:27.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:48:27.996: INFO: namespace: e2e-tests-downward-api-cjt8t, resource: bindings, ignored listing per whitelist
Mar 27 21:48:28.125: INFO: namespace e2e-tests-downward-api-cjt8t deletion completed in 6.289365901s

• [SLOW TEST:10.663 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:48:28.127: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dvwrd
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-dvwrd
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-dvwrd
Mar 27 21:48:28.335: INFO: Found 0 stateful pods, waiting for 1
Mar 27 21:48:38.344: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 27 21:48:38.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 27 21:48:38.670: INFO: stderr: ""
Mar 27 21:48:38.670: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 27 21:48:38.670: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 27 21:48:38.678: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 27 21:48:48.683: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 21:48:48.684: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 21:48:48.731: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Mar 27 21:48:48.732: INFO: ss-0  k8s-conformance-cluster-1-13-etcd-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  }]
Mar 27 21:48:48.732: INFO: ss-1                                       Pending         []
Mar 27 21:48:48.732: INFO: 
Mar 27 21:48:48.732: INFO: StatefulSet ss has not reached scale 3, at 2
Mar 27 21:48:49.740: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.980852498s
Mar 27 21:48:50.746: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972603717s
Mar 27 21:48:51.758: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.966427895s
Mar 27 21:48:52.769: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.955021326s
Mar 27 21:48:53.780: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.943431237s
Mar 27 21:48:54.797: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.932344121s
Mar 27 21:48:55.804: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.915466809s
Mar 27 21:48:56.810: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.908837734s
Mar 27 21:48:57.817: INFO: Verifying statefulset ss doesn't scale past 3 for another 902.734082ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-dvwrd
Mar 27 21:48:58.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:48:59.166: INFO: stderr: ""
Mar 27 21:48:59.166: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 27 21:48:59.166: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 27 21:48:59.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:48:59.482: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 27 21:48:59.482: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 27 21:48:59.482: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 27 21:48:59.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:48:59.888: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 27 21:48:59.888: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 27 21:48:59.888: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 27 21:48:59.895: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 21:48:59.895: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 21:48:59.895: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 27 21:48:59.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 27 21:49:00.254: INFO: stderr: ""
Mar 27 21:49:00.254: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 27 21:49:00.254: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 27 21:49:00.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 27 21:49:00.509: INFO: stderr: ""
Mar 27 21:49:00.509: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 27 21:49:00.510: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 27 21:49:00.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 27 21:49:00.834: INFO: stderr: ""
Mar 27 21:49:00.834: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 27 21:49:00.834: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 27 21:49:00.834: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 21:49:00.840: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 27 21:49:11.040: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 21:49:11.041: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 21:49:11.041: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 21:49:11.345: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 27 21:49:11.345: INFO: ss-0  k8s-conformance-cluster-1-13-etcd-1     Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  }]
Mar 27 21:49:11.345: INFO: ss-1  k8s-conformance-cluster-1-13-worker-2   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:11.346: INFO: ss-2  k8s-conformance-cluster-1-13-control-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:11.346: INFO: 
Mar 27 21:49:11.346: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 27 21:49:12.437: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 27 21:49:12.437: INFO: ss-0  k8s-conformance-cluster-1-13-etcd-1     Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  }]
Mar 27 21:49:12.437: INFO: ss-1  k8s-conformance-cluster-1-13-worker-2   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:12.437: INFO: ss-2  k8s-conformance-cluster-1-13-control-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:12.437: INFO: 
Mar 27 21:49:12.438: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 27 21:49:13.543: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 27 21:49:13.543: INFO: ss-0  k8s-conformance-cluster-1-13-etcd-1     Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  }]
Mar 27 21:49:13.543: INFO: ss-1  k8s-conformance-cluster-1-13-worker-2   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:13.543: INFO: ss-2  k8s-conformance-cluster-1-13-control-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:13.543: INFO: 
Mar 27 21:49:13.543: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 27 21:49:14.624: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 27 21:49:14.625: INFO: ss-0  k8s-conformance-cluster-1-13-etcd-1     Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  }]
Mar 27 21:49:14.625: INFO: ss-1  k8s-conformance-cluster-1-13-worker-2   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:14.625: INFO: ss-2  k8s-conformance-cluster-1-13-control-1  Pending  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:14.625: INFO: 
Mar 27 21:49:14.625: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 27 21:49:15.936: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
Mar 27 21:49:15.936: INFO: ss-0  k8s-conformance-cluster-1-13-etcd-1    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:28 +0000 UTC  }]
Mar 27 21:49:15.937: INFO: ss-1  k8s-conformance-cluster-1-13-worker-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:15.937: INFO: 
Mar 27 21:49:15.937: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 27 21:49:16.945: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
Mar 27 21:49:16.945: INFO: ss-1  k8s-conformance-cluster-1-13-worker-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:16.946: INFO: 
Mar 27 21:49:16.946: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 27 21:49:17.954: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
Mar 27 21:49:17.954: INFO: ss-1  k8s-conformance-cluster-1-13-worker-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:17.954: INFO: 
Mar 27 21:49:17.954: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 27 21:49:18.963: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
Mar 27 21:49:18.963: INFO: ss-1  k8s-conformance-cluster-1-13-worker-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:18.963: INFO: 
Mar 27 21:49:18.963: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 27 21:49:19.969: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
Mar 27 21:49:19.969: INFO: ss-1  k8s-conformance-cluster-1-13-worker-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:19.969: INFO: 
Mar 27 21:49:19.969: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 27 21:49:20.977: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
Mar 27 21:49:20.978: INFO: ss-1  k8s-conformance-cluster-1-13-worker-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:49:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-27 21:48:48 +0000 UTC  }]
Mar 27 21:49:20.978: INFO: 
Mar 27 21:49:20.978: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-dvwrd
Mar 27 21:49:21.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:49:22.227: INFO: rc: 1
Mar 27 21:49:22.230: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc002211a40 exit status 1 <nil> <nil> true [0xc0018367e0 0xc0018367f8 0xc001836810] [0xc0018367e0 0xc0018367f8 0xc001836810] [0xc0018367f0 0xc001836808] [0x932a40 0x932a40] 0xc001a99380 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Mar 27 21:49:32.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:49:32.362: INFO: rc: 1
Mar 27 21:49:32.362: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002211e60 exit status 1 <nil> <nil> true [0xc001836818 0xc001836830 0xc001836848] [0xc001836818 0xc001836830 0xc001836848] [0xc001836828 0xc001836840] [0x932a40 0x932a40] 0xc001a99740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:49:42.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:49:42.491: INFO: rc: 1
Mar 27 21:49:42.491: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0022ec270 exit status 1 <nil> <nil> true [0xc001836850 0xc001836868 0xc001836880] [0xc001836850 0xc001836868 0xc001836880] [0xc001836860 0xc001836878] [0x932a40 0x932a40] 0xc001a99aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:49:52.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:49:52.628: INFO: rc: 1
Mar 27 21:49:52.628: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0022ec660 exit status 1 <nil> <nil> true [0xc001836888 0xc0018368a0 0xc0018368b8] [0xc001836888 0xc0018368a0 0xc0018368b8] [0xc001836898 0xc0018368b0] [0x932a40 0x932a40] 0xc001a99e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:50:02.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:50:02.747: INFO: rc: 1
Mar 27 21:50:02.748: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0022ecb10 exit status 1 <nil> <nil> true [0xc0018368c0 0xc0018368d8 0xc0018368f0] [0xc0018368c0 0xc0018368d8 0xc0018368f0] [0xc0018368d0 0xc0018368e8] [0x932a40 0x932a40] 0xc00266a120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:50:12.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:50:12.957: INFO: rc: 1
Mar 27 21:50:12.957: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0022ed050 exit status 1 <nil> <nil> true [0xc0018368f8 0xc001836910 0xc001836928] [0xc0018368f8 0xc001836910 0xc001836928] [0xc001836908 0xc001836920] [0x932a40 0x932a40] 0xc00266a420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:50:22.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:50:23.091: INFO: rc: 1
Mar 27 21:50:23.092: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0022ed4a0 exit status 1 <nil> <nil> true [0xc001836930 0xc001836948 0xc001836960] [0xc001836930 0xc001836948 0xc001836960] [0xc001836940 0xc001836958] [0x932a40 0x932a40] 0xc00266a720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:50:33.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:50:33.234: INFO: rc: 1
Mar 27 21:50:33.234: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002210390 exit status 1 <nil> <nil> true [0xc001836010 0xc001836028 0xc001836040] [0xc001836010 0xc001836028 0xc001836040] [0xc001836020 0xc001836038] [0x932a40 0x932a40] 0xc001a98ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:50:43.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:50:43.379: INFO: rc: 1
Mar 27 21:50:43.379: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002210750 exit status 1 <nil> <nil> true [0xc001836048 0xc001836060 0xc001836078] [0xc001836048 0xc001836060 0xc001836078] [0xc001836058 0xc001836070] [0x932a40 0x932a40] 0xc001a99440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:50:53.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:50:53.560: INFO: rc: 1
Mar 27 21:50:53.560: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002210d50 exit status 1 <nil> <nil> true [0xc001836080 0xc001836098 0xc0018360b0] [0xc001836080 0xc001836098 0xc0018360b0] [0xc001836090 0xc0018360a8] [0x932a40 0x932a40] 0xc001a99800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:51:03.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:51:03.704: INFO: rc: 1
Mar 27 21:51:03.704: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002211110 exit status 1 <nil> <nil> true [0xc0018360b8 0xc0018360d0 0xc0018360e8] [0xc0018360b8 0xc0018360d0 0xc0018360e8] [0xc0018360c8 0xc0018360e0] [0x932a40 0x932a40] 0xc001a99bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:51:13.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:51:13.860: INFO: rc: 1
Mar 27 21:51:13.860: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0022119b0 exit status 1 <nil> <nil> true [0xc0018360f0 0xc001836108 0xc001836120] [0xc0018360f0 0xc001836108 0xc001836120] [0xc001836100 0xc001836118] [0x932a40 0x932a40] 0xc001a99ec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:51:23.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:51:23.990: INFO: rc: 1
Mar 27 21:51:23.990: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002211e00 exit status 1 <nil> <nil> true [0xc001836128 0xc001836140 0xc001836158] [0xc001836128 0xc001836140 0xc001836158] [0xc001836138 0xc001836150] [0x932a40 0x932a40] 0xc0020d61e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:51:33.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:51:34.147: INFO: rc: 1
Mar 27 21:51:34.147: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f26240 exit status 1 <nil> <nil> true [0xc001836160 0xc001836178 0xc001836190] [0xc001836160 0xc001836178 0xc001836190] [0xc001836170 0xc001836188] [0x932a40 0x932a40] 0xc0020d6540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:51:44.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:51:44.291: INFO: rc: 1
Mar 27 21:51:44.292: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f26600 exit status 1 <nil> <nil> true [0xc001836198 0xc0018361b0 0xc0018361c8] [0xc001836198 0xc0018361b0 0xc0018361c8] [0xc0018361a8 0xc0018361c0] [0x932a40 0x932a40] 0xc0020d6900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:51:54.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:51:54.482: INFO: rc: 1
Mar 27 21:51:54.483: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f269c0 exit status 1 <nil> <nil> true [0xc0018361d0 0xc0018361e8 0xc001836200] [0xc0018361d0 0xc0018361e8 0xc001836200] [0xc0018361e0 0xc0018361f8] [0x932a40 0x932a40] 0xc0020d6c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:52:04.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:52:04.663: INFO: rc: 1
Mar 27 21:52:04.663: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f26d80 exit status 1 <nil> <nil> true [0xc001836208 0xc001836220 0xc001836238] [0xc001836208 0xc001836220 0xc001836238] [0xc001836218 0xc001836230] [0x932a40 0x932a40] 0xc0020d6f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:52:14.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:52:14.819: INFO: rc: 1
Mar 27 21:52:14.819: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f27380 exit status 1 <nil> <nil> true [0xc001836240 0xc001836258 0xc001836270] [0xc001836240 0xc001836258 0xc001836270] [0xc001836250 0xc001836268] [0x932a40 0x932a40] 0xc0020d74a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:52:24.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:52:24.945: INFO: rc: 1
Mar 27 21:52:24.945: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f27740 exit status 1 <nil> <nil> true [0xc001836278 0xc001836290 0xc0018362a8] [0xc001836278 0xc001836290 0xc0018362a8] [0xc001836288 0xc0018362a0] [0x932a40 0x932a40] 0xc00363c000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:52:34.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:52:35.085: INFO: rc: 1
Mar 27 21:52:35.086: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0022103c0 exit status 1 <nil> <nil> true [0xc001836010 0xc001836028 0xc001836040] [0xc001836010 0xc001836028 0xc001836040] [0xc001836020 0xc001836038] [0x932a40 0x932a40] 0xc0020d6240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:52:45.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:52:45.227: INFO: rc: 1
Mar 27 21:52:45.227: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0022107b0 exit status 1 <nil> <nil> true [0xc001836048 0xc001836060 0xc001836078] [0xc001836048 0xc001836060 0xc001836078] [0xc001836058 0xc001836070] [0x932a40 0x932a40] 0xc0020d65a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:52:55.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:52:55.365: INFO: rc: 1
Mar 27 21:52:55.365: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002210de0 exit status 1 <nil> <nil> true [0xc001836080 0xc001836098 0xc0018360b0] [0xc001836080 0xc001836098 0xc0018360b0] [0xc001836090 0xc0018360a8] [0x932a40 0x932a40] 0xc0020d6960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:53:05.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:53:05.529: INFO: rc: 1
Mar 27 21:53:05.529: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0022111d0 exit status 1 <nil> <nil> true [0xc0018360b8 0xc0018360d0 0xc0018360e8] [0xc0018360b8 0xc0018360d0 0xc0018360e8] [0xc0018360c8 0xc0018360e0] [0x932a40 0x932a40] 0xc0020d6c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:53:15.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:53:15.662: INFO: rc: 1
Mar 27 21:53:15.662: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002211aa0 exit status 1 <nil> <nil> true [0xc0018360f0 0xc001836108 0xc001836120] [0xc0018360f0 0xc001836108 0xc001836120] [0xc001836100 0xc001836118] [0x932a40 0x932a40] 0xc0020d6fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:53:25.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:53:25.780: INFO: rc: 1
Mar 27 21:53:25.780: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002211ef0 exit status 1 <nil> <nil> true [0xc001836128 0xc001836140 0xc001836158] [0xc001836128 0xc001836140 0xc001836158] [0xc001836138 0xc001836150] [0x932a40 0x932a40] 0xc0020d75c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:53:35.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:53:35.969: INFO: rc: 1
Mar 27 21:53:35.969: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f26330 exit status 1 <nil> <nil> true [0xc001836160 0xc001836178 0xc001836190] [0xc001836160 0xc001836178 0xc001836190] [0xc001836170 0xc001836188] [0x932a40 0x932a40] 0xc001a981e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:53:45.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:53:46.110: INFO: rc: 1
Mar 27 21:53:46.110: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f26720 exit status 1 <nil> <nil> true [0xc001836198 0xc0018361b0 0xc0018361c8] [0xc001836198 0xc0018361b0 0xc0018361c8] [0xc0018361a8 0xc0018361c0] [0x932a40 0x932a40] 0xc001a98f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:53:56.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:53:56.280: INFO: rc: 1
Mar 27 21:53:56.281: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f26b10 exit status 1 <nil> <nil> true [0xc0018361d0 0xc0018361e8 0xc001836200] [0xc0018361d0 0xc0018361e8 0xc001836200] [0xc0018361e0 0xc0018361f8] [0x932a40 0x932a40] 0xc001a995c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:54:06.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:54:06.416: INFO: rc: 1
Mar 27 21:54:06.416: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f27140 exit status 1 <nil> <nil> true [0xc001836208 0xc001836220 0xc001836238] [0xc001836208 0xc001836220 0xc001836238] [0xc001836218 0xc001836230] [0x932a40 0x932a40] 0xc001a99980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:54:16.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:54:16.537: INFO: rc: 1
Mar 27 21:54:16.537: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000f27530 exit status 1 <nil> <nil> true [0xc001836240 0xc001836258 0xc001836270] [0xc001836240 0xc001836258 0xc001836270] [0xc001836250 0xc001836268] [0x932a40 0x932a40] 0xc001a99ce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 27 21:54:26.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-dvwrd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:54:26.669: INFO: rc: 1
Mar 27 21:54:26.670: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Mar 27 21:54:26.670: INFO: Scaling statefulset ss to 0
Mar 27 21:54:26.691: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 27 21:54:26.699: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dvwrd
Mar 27 21:54:26.705: INFO: Scaling statefulset ss to 0
Mar 27 21:54:26.734: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 21:54:26.742: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:54:26.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dvwrd" for this suite.
Mar 27 21:54:32.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:54:32.929: INFO: namespace: e2e-tests-statefulset-dvwrd, resource: bindings, ignored listing per whitelist
Mar 27 21:54:33.057: INFO: namespace e2e-tests-statefulset-dvwrd deletion completed in 6.263107876s

• [SLOW TEST:364.931 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:54:33.059: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e7b470e8-50da-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 21:54:33.314: INFO: Waiting up to 5m0s for pod "pod-secrets-e7c31793-50da-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-secrets-bfmlq" to be "success or failure"
Mar 27 21:54:33.326: INFO: Pod "pod-secrets-e7c31793-50da-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 11.981984ms
Mar 27 21:54:35.331: INFO: Pod "pod-secrets-e7c31793-50da-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016752125s
STEP: Saw pod success
Mar 27 21:54:35.331: INFO: Pod "pod-secrets-e7c31793-50da-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:54:35.337: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-secrets-e7c31793-50da-11e9-9d23-0ac04cf37a48 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 21:54:35.468: INFO: Waiting for pod pod-secrets-e7c31793-50da-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:54:35.488: INFO: Pod pod-secrets-e7c31793-50da-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:54:35.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bfmlq" for this suite.
Mar 27 21:54:41.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:54:41.727: INFO: namespace: e2e-tests-secrets-bfmlq, resource: bindings, ignored listing per whitelist
Mar 27 21:54:41.815: INFO: namespace e2e-tests-secrets-bfmlq deletion completed in 6.316235437s
STEP: Destroying namespace "e2e-tests-secret-namespace-qmr4z" for this suite.
Mar 27 21:54:47.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:54:48.088: INFO: namespace: e2e-tests-secret-namespace-qmr4z, resource: bindings, ignored listing per whitelist
Mar 27 21:54:48.156: INFO: namespace e2e-tests-secret-namespace-qmr4z deletion completed in 6.340535523s

• [SLOW TEST:15.097 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:54:48.160: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-f0bdedc9-50da-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 21:54:48.403: INFO: Waiting up to 5m0s for pod "pod-configmaps-f0c023b4-50da-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-configmap-cbqhn" to be "success or failure"
Mar 27 21:54:48.421: INFO: Pod "pod-configmaps-f0c023b4-50da-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 18.456208ms
Mar 27 21:54:50.428: INFO: Pod "pod-configmaps-f0c023b4-50da-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025085751s
Mar 27 21:54:52.434: INFO: Pod "pod-configmaps-f0c023b4-50da-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031549967s
STEP: Saw pod success
Mar 27 21:54:52.434: INFO: Pod "pod-configmaps-f0c023b4-50da-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:54:52.444: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-configmaps-f0c023b4-50da-11e9-9d23-0ac04cf37a48 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 21:54:52.508: INFO: Waiting for pod pod-configmaps-f0c023b4-50da-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:54:52.532: INFO: Pod pod-configmaps-f0c023b4-50da-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:54:52.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cbqhn" for this suite.
Mar 27 21:54:58.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:54:58.643: INFO: namespace: e2e-tests-configmap-cbqhn, resource: bindings, ignored listing per whitelist
Mar 27 21:54:58.738: INFO: namespace e2e-tests-configmap-cbqhn deletion completed in 6.195906708s

• [SLOW TEST:10.578 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:54:58.740: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:54:58.898: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f701e735-50da-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-djcqz" to be "success or failure"
Mar 27 21:54:58.931: INFO: Pod "downwardapi-volume-f701e735-50da-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 32.021361ms
Mar 27 21:55:00.937: INFO: Pod "downwardapi-volume-f701e735-50da-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038301931s
Mar 27 21:55:02.943: INFO: Pod "downwardapi-volume-f701e735-50da-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044657285s
STEP: Saw pod success
Mar 27 21:55:02.943: INFO: Pod "downwardapi-volume-f701e735-50da-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:55:02.949: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-f701e735-50da-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:55:03.032: INFO: Waiting for pod downwardapi-volume-f701e735-50da-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:55:03.040: INFO: Pod downwardapi-volume-f701e735-50da-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:55:03.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-djcqz" for this suite.
Mar 27 21:55:09.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:55:09.241: INFO: namespace: e2e-tests-projected-djcqz, resource: bindings, ignored listing per whitelist
Mar 27 21:55:09.325: INFO: namespace e2e-tests-projected-djcqz deletion completed in 6.267593486s

• [SLOW TEST:10.585 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:55:09.327: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 27 21:55:09.505: INFO: Waiting up to 5m0s for pod "downward-api-fd54a520-50da-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-h9rt7" to be "success or failure"
Mar 27 21:55:09.520: INFO: Pod "downward-api-fd54a520-50da-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 14.261964ms
Mar 27 21:55:11.525: INFO: Pod "downward-api-fd54a520-50da-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019916729s
STEP: Saw pod success
Mar 27 21:55:11.526: INFO: Pod "downward-api-fd54a520-50da-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:55:11.531: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downward-api-fd54a520-50da-11e9-9d23-0ac04cf37a48 container dapi-container: <nil>
STEP: delete the pod
Mar 27 21:55:11.637: INFO: Waiting for pod downward-api-fd54a520-50da-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:55:11.643: INFO: Pod downward-api-fd54a520-50da-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:55:11.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-h9rt7" for this suite.
Mar 27 21:55:17.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:55:17.907: INFO: namespace: e2e-tests-downward-api-h9rt7, resource: bindings, ignored listing per whitelist
Mar 27 21:55:17.977: INFO: namespace e2e-tests-downward-api-h9rt7 deletion completed in 6.319978154s

• [SLOW TEST:8.650 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:55:17.987: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 27 21:55:18.136: INFO: Waiting up to 5m0s for pod "pod-027bf950-50db-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-tsc8x" to be "success or failure"
Mar 27 21:55:18.156: INFO: Pod "pod-027bf950-50db-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 20.026272ms
Mar 27 21:55:20.165: INFO: Pod "pod-027bf950-50db-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.029069444s
Mar 27 21:55:22.171: INFO: Pod "pod-027bf950-50db-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035367087s
STEP: Saw pod success
Mar 27 21:55:22.171: INFO: Pod "pod-027bf950-50db-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:55:22.180: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-027bf950-50db-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 21:55:22.253: INFO: Waiting for pod pod-027bf950-50db-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:55:22.262: INFO: Pod pod-027bf950-50db-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:55:22.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tsc8x" for this suite.
Mar 27 21:55:28.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:55:28.510: INFO: namespace: e2e-tests-emptydir-tsc8x, resource: bindings, ignored listing per whitelist
Mar 27 21:55:28.531: INFO: namespace e2e-tests-emptydir-tsc8x deletion completed in 6.251816712s

• [SLOW TEST:10.544 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:55:28.533: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-rr8ms
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-rr8ms
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-rr8ms
Mar 27 21:55:28.706: INFO: Found 0 stateful pods, waiting for 1
Mar 27 21:55:38.712: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 27 21:55:38.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-rr8ms ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 27 21:55:39.024: INFO: stderr: ""
Mar 27 21:55:39.024: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 27 21:55:39.024: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 27 21:55:39.032: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 27 21:55:49.039: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 21:55:49.039: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 21:55:49.075: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999531s
Mar 27 21:55:50.081: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.985225792s
Mar 27 21:55:51.092: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.978660831s
Mar 27 21:55:52.098: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.96851472s
Mar 27 21:55:53.105: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.96141709s
Mar 27 21:55:54.112: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.954959781s
Mar 27 21:55:55.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.931243221s
Mar 27 21:55:56.146: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.924740444s
Mar 27 21:55:57.154: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.913561052s
Mar 27 21:55:58.164: INFO: Verifying statefulset ss doesn't scale past 1 for another 904.94162ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-rr8ms
Mar 27 21:55:59.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-rr8ms ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:55:59.521: INFO: stderr: ""
Mar 27 21:55:59.522: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 27 21:55:59.522: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 27 21:55:59.531: INFO: Found 1 stateful pods, waiting for 3
Mar 27 21:56:09.539: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 21:56:09.539: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 21:56:09.539: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 27 21:56:09.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-rr8ms ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 27 21:56:09.851: INFO: stderr: ""
Mar 27 21:56:09.851: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 27 21:56:09.851: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 27 21:56:09.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-rr8ms ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 27 21:56:10.275: INFO: stderr: ""
Mar 27 21:56:10.275: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 27 21:56:10.275: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 27 21:56:10.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-rr8ms ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 27 21:56:10.726: INFO: stderr: ""
Mar 27 21:56:10.726: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 27 21:56:10.726: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 27 21:56:10.726: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 21:56:10.735: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 27 21:56:20.759: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 21:56:20.759: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 21:56:20.760: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 21:56:20.797: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999701s
Mar 27 21:56:21.804: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990512417s
Mar 27 21:56:22.887: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984070456s
Mar 27 21:56:23.901: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.900326425s
Mar 27 21:56:24.916: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.882952659s
Mar 27 21:56:25.924: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.871263124s
Mar 27 21:56:26.932: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.863014124s
Mar 27 21:56:27.942: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.85577783s
Mar 27 21:56:28.971: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.844968192s
Mar 27 21:56:29.983: INFO: Verifying statefulset ss doesn't scale past 3 for another 816.449555ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-rr8ms
Mar 27 21:56:30.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-rr8ms ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:56:31.316: INFO: stderr: ""
Mar 27 21:56:31.316: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 27 21:56:31.316: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 27 21:56:31.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-rr8ms ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:56:31.679: INFO: stderr: ""
Mar 27 21:56:31.679: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 27 21:56:31.679: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 27 21:56:31.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 exec --namespace=e2e-tests-statefulset-rr8ms ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 27 21:56:31.974: INFO: stderr: ""
Mar 27 21:56:31.974: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 27 21:56:31.974: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 27 21:56:31.974: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 27 21:56:52.015: INFO: Deleting all statefulset in ns e2e-tests-statefulset-rr8ms
Mar 27 21:56:52.021: INFO: Scaling statefulset ss to 0
Mar 27 21:56:52.038: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 21:56:52.048: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:56:52.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-rr8ms" for this suite.
Mar 27 21:57:00.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:57:00.296: INFO: namespace: e2e-tests-statefulset-rr8ms, resource: bindings, ignored listing per whitelist
Mar 27 21:57:00.364: INFO: namespace e2e-tests-statefulset-rr8ms deletion completed in 8.268857935s

• [SLOW TEST:91.832 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:57:00.366: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 21:57:00.583: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f8532ba-50db-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-7g4fn" to be "success or failure"
Mar 27 21:57:00.616: INFO: Pod "downwardapi-volume-3f8532ba-50db-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 32.700321ms
Mar 27 21:57:02.622: INFO: Pod "downwardapi-volume-3f8532ba-50db-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.038563376s
Mar 27 21:57:04.627: INFO: Pod "downwardapi-volume-3f8532ba-50db-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043871979s
STEP: Saw pod success
Mar 27 21:57:04.627: INFO: Pod "downwardapi-volume-3f8532ba-50db-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:57:04.632: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-3f8532ba-50db-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 21:57:04.692: INFO: Waiting for pod downwardapi-volume-3f8532ba-50db-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:57:04.711: INFO: Pod downwardapi-volume-3f8532ba-50db-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:57:04.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7g4fn" for this suite.
Mar 27 21:57:10.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:57:10.888: INFO: namespace: e2e-tests-projected-7g4fn, resource: bindings, ignored listing per whitelist
Mar 27 21:57:10.982: INFO: namespace e2e-tests-projected-7g4fn deletion completed in 6.258720288s

• [SLOW TEST:10.617 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:57:10.988: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-45df347f-50db-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 21:57:11.218: INFO: Waiting up to 5m0s for pod "pod-configmaps-45e16764-50db-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-configmap-mrgj7" to be "success or failure"
Mar 27 21:57:11.235: INFO: Pod "pod-configmaps-45e16764-50db-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 17.688332ms
Mar 27 21:57:13.242: INFO: Pod "pod-configmaps-45e16764-50db-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023938995s
STEP: Saw pod success
Mar 27 21:57:13.242: INFO: Pod "pod-configmaps-45e16764-50db-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 21:57:13.248: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-configmaps-45e16764-50db-11e9-9d23-0ac04cf37a48 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 21:57:13.363: INFO: Waiting for pod pod-configmaps-45e16764-50db-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 21:57:13.375: INFO: Pod pod-configmaps-45e16764-50db-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:57:13.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mrgj7" for this suite.
Mar 27 21:57:19.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:57:19.549: INFO: namespace: e2e-tests-configmap-mrgj7, resource: bindings, ignored listing per whitelist
Mar 27 21:57:19.649: INFO: namespace e2e-tests-configmap-mrgj7 deletion completed in 6.24828287s

• [SLOW TEST:8.661 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:57:19.652: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 27 21:57:19.762: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:57:23.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-58b9h" for this suite.
Mar 27 21:57:29.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:57:30.211: INFO: namespace: e2e-tests-init-container-58b9h, resource: bindings, ignored listing per whitelist
Mar 27 21:57:30.278: INFO: namespace e2e-tests-init-container-58b9h deletion completed in 6.420888225s

• [SLOW TEST:10.626 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:57:30.281: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0327 21:57:40.813428      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 27 21:57:40.813: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:57:40.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rllqz" for this suite.
Mar 27 21:57:48.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:57:48.924: INFO: namespace: e2e-tests-gc-rllqz, resource: bindings, ignored listing per whitelist
Mar 27 21:57:49.063: INFO: namespace e2e-tests-gc-rllqz deletion completed in 8.229900579s

• [SLOW TEST:18.783 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:57:49.071: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-tkcc5
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 27 21:57:49.268: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 27 21:58:11.623: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.225:8080/dial?request=hostName&protocol=udp&host=10.42.3.80&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-tkcc5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:58:11.623: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:58:11.791: INFO: Waiting for endpoints: map[]
Mar 27 21:58:11.799: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.225:8080/dial?request=hostName&protocol=udp&host=10.42.0.117&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-tkcc5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:58:11.799: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:58:11.945: INFO: Waiting for endpoints: map[]
Mar 27 21:58:11.955: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.225:8080/dial?request=hostName&protocol=udp&host=10.42.4.131&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-tkcc5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:58:11.955: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:58:12.202: INFO: Waiting for endpoints: map[]
Mar 27 21:58:12.215: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.225:8080/dial?request=hostName&protocol=udp&host=10.42.2.84&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-tkcc5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:58:12.215: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:58:12.370: INFO: Waiting for endpoints: map[]
Mar 27 21:58:12.376: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.225:8080/dial?request=hostName&protocol=udp&host=10.42.1.224&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-tkcc5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 21:58:12.376: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
Mar 27 21:58:12.591: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:58:12.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-tkcc5" for this suite.
Mar 27 21:58:36.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:58:36.797: INFO: namespace: e2e-tests-pod-network-test-tkcc5, resource: bindings, ignored listing per whitelist
Mar 27 21:58:36.929: INFO: namespace e2e-tests-pod-network-test-tkcc5 deletion completed in 24.306624776s

• [SLOW TEST:47.858 seconds]
[sig-network] Networking
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:58:36.930: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar 27 21:58:37.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 --namespace=e2e-tests-kubectl-kc7hv run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 27 21:58:39.411: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 27 21:58:39.411: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:58:41.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kc7hv" for this suite.
Mar 27 21:58:47.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 21:58:47.721: INFO: namespace: e2e-tests-kubectl-kc7hv, resource: bindings, ignored listing per whitelist
Mar 27 21:58:47.745: INFO: namespace e2e-tests-kubectl-kc7hv deletion completed in 6.311281751s

• [SLOW TEST:10.816 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 21:58:47.747: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 21:59:47.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-7z7pc" for this suite.
Mar 27 22:00:12.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:00:12.204: INFO: namespace: e2e-tests-container-probe-7z7pc, resource: bindings, ignored listing per whitelist
Mar 27 22:00:12.269: INFO: namespace e2e-tests-container-probe-7z7pc deletion completed in 24.241514824s

• [SLOW TEST:84.522 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:00:12.270: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 27 22:00:12.452: INFO: Waiting up to 5m0s for pod "pod-b1e6a13b-50db-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-wmr46" to be "success or failure"
Mar 27 22:00:12.477: INFO: Pod "pod-b1e6a13b-50db-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 25.166264ms
Mar 27 22:00:14.484: INFO: Pod "pod-b1e6a13b-50db-11e9-9d23-0ac04cf37a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.032020172s
Mar 27 22:00:16.491: INFO: Pod "pod-b1e6a13b-50db-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039246324s
STEP: Saw pod success
Mar 27 22:00:16.491: INFO: Pod "pod-b1e6a13b-50db-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 22:00:16.499: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-b1e6a13b-50db-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 22:00:16.580: INFO: Waiting for pod pod-b1e6a13b-50db-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 22:00:16.613: INFO: Pod pod-b1e6a13b-50db-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:00:16.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wmr46" for this suite.
Mar 27 22:00:22.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:00:22.989: INFO: namespace: e2e-tests-emptydir-wmr46, resource: bindings, ignored listing per whitelist
Mar 27 22:00:23.073: INFO: namespace e2e-tests-emptydir-wmr46 deletion completed in 6.414890988s

• [SLOW TEST:10.804 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:00:23.079: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 27 22:00:23.332: INFO: Waiting up to 5m0s for pod "downward-api-b860a2b9-50db-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-6p7wj" to be "success or failure"
Mar 27 22:00:23.361: INFO: Pod "downward-api-b860a2b9-50db-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 28.178178ms
Mar 27 22:00:25.369: INFO: Pod "downward-api-b860a2b9-50db-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03575059s
STEP: Saw pod success
Mar 27 22:00:25.369: INFO: Pod "downward-api-b860a2b9-50db-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 22:00:25.378: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downward-api-b860a2b9-50db-11e9-9d23-0ac04cf37a48 container dapi-container: <nil>
STEP: delete the pod
Mar 27 22:00:25.519: INFO: Waiting for pod downward-api-b860a2b9-50db-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 22:00:25.534: INFO: Pod downward-api-b860a2b9-50db-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:00:25.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6p7wj" for this suite.
Mar 27 22:00:31.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:00:31.658: INFO: namespace: e2e-tests-downward-api-6p7wj, resource: bindings, ignored listing per whitelist
Mar 27 22:00:31.850: INFO: namespace e2e-tests-downward-api-6p7wj deletion completed in 6.267891345s

• [SLOW TEST:8.772 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:00:31.876: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 27 22:00:32.033: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd92f9a7-50db-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-hbsq6" to be "success or failure"
Mar 27 22:00:32.052: INFO: Pod "downwardapi-volume-bd92f9a7-50db-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 19.341924ms
Mar 27 22:00:34.058: INFO: Pod "downwardapi-volume-bd92f9a7-50db-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024546913s
Mar 27 22:00:36.063: INFO: Pod "downwardapi-volume-bd92f9a7-50db-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03033944s
STEP: Saw pod success
Mar 27 22:00:36.064: INFO: Pod "downwardapi-volume-bd92f9a7-50db-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 22:00:36.069: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downwardapi-volume-bd92f9a7-50db-11e9-9d23-0ac04cf37a48 container client-container: <nil>
STEP: delete the pod
Mar 27 22:00:36.163: INFO: Waiting for pod downwardapi-volume-bd92f9a7-50db-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 22:00:36.173: INFO: Pod downwardapi-volume-bd92f9a7-50db-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:00:36.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hbsq6" for this suite.
Mar 27 22:00:42.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:00:42.356: INFO: namespace: e2e-tests-projected-hbsq6, resource: bindings, ignored listing per whitelist
Mar 27 22:00:42.568: INFO: namespace e2e-tests-projected-hbsq6 deletion completed in 6.369446798s

• [SLOW TEST:10.693 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:00:42.573: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 27 22:00:42.834: INFO: Waiting up to 5m0s for pod "pod-c3ff0d45-50db-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-emptydir-wrg85" to be "success or failure"
Mar 27 22:00:42.957: INFO: Pod "pod-c3ff0d45-50db-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 123.297428ms
Mar 27 22:00:45.002: INFO: Pod "pod-c3ff0d45-50db-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.167424081s
STEP: Saw pod success
Mar 27 22:00:45.002: INFO: Pod "pod-c3ff0d45-50db-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 22:00:45.023: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-c3ff0d45-50db-11e9-9d23-0ac04cf37a48 container test-container: <nil>
STEP: delete the pod
Mar 27 22:00:45.127: INFO: Waiting for pod pod-c3ff0d45-50db-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 22:00:45.135: INFO: Pod pod-c3ff0d45-50db-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:00:45.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrg85" for this suite.
Mar 27 22:00:51.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:00:51.247: INFO: namespace: e2e-tests-emptydir-wrg85, resource: bindings, ignored listing per whitelist
Mar 27 22:00:51.439: INFO: namespace e2e-tests-emptydir-wrg85 deletion completed in 6.285770443s

• [SLOW TEST:8.868 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:00:51.443: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 22:00:51.689: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Mar 27 22:00:51.707: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mnzps/daemonsets","resourceVersion":"197339"},"items":null}

Mar 27 22:00:51.712: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mnzps/pods","resourceVersion":"197339"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:00:51.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mnzps" for this suite.
Mar 27 22:00:57.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:00:58.090: INFO: namespace: e2e-tests-daemonsets-mnzps, resource: bindings, ignored listing per whitelist
Mar 27 22:00:58.101: INFO: namespace e2e-tests-daemonsets-mnzps deletion completed in 6.312013842s

S [SKIPPING] [6.659 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar 27 22:00:51.689: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:00:58.105: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 22:00:58.288: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:01:02.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9xpp5" for this suite.
Mar 27 22:01:48.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:01:48.609: INFO: namespace: e2e-tests-pods-9xpp5, resource: bindings, ignored listing per whitelist
Mar 27 22:01:48.644: INFO: namespace e2e-tests-pods-9xpp5 deletion completed in 46.275732028s

• [SLOW TEST:50.539 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:01:48.647: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 27 22:02:14.900: INFO: Container started at 2019-03-27 22:01:50 +0000 UTC, pod became ready at 2019-03-27 22:02:13 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:02:14.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kzcdr" for this suite.
Mar 27 22:02:38.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:02:39.075: INFO: namespace: e2e-tests-container-probe-kzcdr, resource: bindings, ignored listing per whitelist
Mar 27 22:02:39.136: INFO: namespace e2e-tests-container-probe-kzcdr deletion completed in 24.219482821s

• [SLOW TEST:50.490 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:02:39.139: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-096f443f-50dc-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 22:02:39.300: INFO: Waiting up to 5m0s for pod "pod-secrets-09709039-50dc-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-secrets-hq2st" to be "success or failure"
Mar 27 22:02:39.319: INFO: Pod "pod-secrets-09709039-50dc-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 18.939626ms
Mar 27 22:02:41.324: INFO: Pod "pod-secrets-09709039-50dc-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023949058s
STEP: Saw pod success
Mar 27 22:02:41.324: INFO: Pod "pod-secrets-09709039-50dc-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 22:02:41.330: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-secrets-09709039-50dc-11e9-9d23-0ac04cf37a48 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 22:02:41.459: INFO: Waiting for pod pod-secrets-09709039-50dc-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 22:02:41.471: INFO: Pod pod-secrets-09709039-50dc-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:02:41.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hq2st" for this suite.
Mar 27 22:02:47.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:02:47.569: INFO: namespace: e2e-tests-secrets-hq2st, resource: bindings, ignored listing per whitelist
Mar 27 22:02:47.806: INFO: namespace e2e-tests-secrets-hq2st deletion completed in 6.299870518s

• [SLOW TEST:8.668 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:02:47.812: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-0ea7063b-50dc-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 22:02:48.107: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0eacb006-50dc-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-projected-c8jxj" to be "success or failure"
Mar 27 22:02:48.124: INFO: Pod "pod-projected-configmaps-0eacb006-50dc-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 16.346192ms
Mar 27 22:02:50.131: INFO: Pod "pod-projected-configmaps-0eacb006-50dc-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023755723s
Mar 27 22:02:52.142: INFO: Pod "pod-projected-configmaps-0eacb006-50dc-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03430065s
STEP: Saw pod success
Mar 27 22:02:52.142: INFO: Pod "pod-projected-configmaps-0eacb006-50dc-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 22:02:52.147: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-projected-configmaps-0eacb006-50dc-11e9-9d23-0ac04cf37a48 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 22:02:52.227: INFO: Waiting for pod pod-projected-configmaps-0eacb006-50dc-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 22:02:52.253: INFO: Pod pod-projected-configmaps-0eacb006-50dc-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:02:52.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c8jxj" for this suite.
Mar 27 22:02:58.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:02:58.510: INFO: namespace: e2e-tests-projected-c8jxj, resource: bindings, ignored listing per whitelist
Mar 27 22:02:58.553: INFO: namespace e2e-tests-projected-c8jxj deletion completed in 6.28887227s

• [SLOW TEST:10.741 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:02:58.556: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar 27 22:02:58.727: INFO: Waiting up to 5m0s for pod "var-expansion-15025344-50dc-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-var-expansion-4dh74" to be "success or failure"
Mar 27 22:02:58.757: INFO: Pod "var-expansion-15025344-50dc-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 29.58887ms
Mar 27 22:03:00.764: INFO: Pod "var-expansion-15025344-50dc-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036856078s
STEP: Saw pod success
Mar 27 22:03:00.764: INFO: Pod "var-expansion-15025344-50dc-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 22:03:00.769: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod var-expansion-15025344-50dc-11e9-9d23-0ac04cf37a48 container dapi-container: <nil>
STEP: delete the pod
Mar 27 22:03:00.826: INFO: Waiting for pod var-expansion-15025344-50dc-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 22:03:00.844: INFO: Pod var-expansion-15025344-50dc-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:03:00.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4dh74" for this suite.
Mar 27 22:03:06.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:03:06.984: INFO: namespace: e2e-tests-var-expansion-4dh74, resource: bindings, ignored listing per whitelist
Mar 27 22:03:07.070: INFO: namespace e2e-tests-var-expansion-4dh74 deletion completed in 6.213063241s

• [SLOW TEST:8.515 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:03:07.072: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-1a121582-50dc-11e9-9d23-0ac04cf37a48
Mar 27 22:03:07.206: INFO: Pod name my-hostname-basic-1a121582-50dc-11e9-9d23-0ac04cf37a48: Found 0 pods out of 1
Mar 27 22:03:12.215: INFO: Pod name my-hostname-basic-1a121582-50dc-11e9-9d23-0ac04cf37a48: Found 1 pods out of 1
Mar 27 22:03:12.215: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1a121582-50dc-11e9-9d23-0ac04cf37a48" are running
Mar 27 22:03:12.223: INFO: Pod "my-hostname-basic-1a121582-50dc-11e9-9d23-0ac04cf37a48-5725b" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-27 22:03:07 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-27 22:03:08 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-27 22:03:08 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-27 22:03:07 +0000 UTC Reason: Message:}])
Mar 27 22:03:12.223: INFO: Trying to dial the pod
Mar 27 22:03:17.265: INFO: Controller my-hostname-basic-1a121582-50dc-11e9-9d23-0ac04cf37a48: Got expected result from replica 1 [my-hostname-basic-1a121582-50dc-11e9-9d23-0ac04cf37a48-5725b]: "my-hostname-basic-1a121582-50dc-11e9-9d23-0ac04cf37a48-5725b", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:03:17.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-xmm9m" for this suite.
Mar 27 22:03:23.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:03:23.386: INFO: namespace: e2e-tests-replication-controller-xmm9m, resource: bindings, ignored listing per whitelist
Mar 27 22:03:23.532: INFO: namespace e2e-tests-replication-controller-xmm9m deletion completed in 6.241296918s

• [SLOW TEST:16.461 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:03:23.541: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 27 22:03:23.710: INFO: Waiting up to 5m0s for pod "downward-api-23e6156b-50dc-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-downward-api-lvg9p" to be "success or failure"
Mar 27 22:03:23.738: INFO: Pod "downward-api-23e6156b-50dc-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 27.876717ms
Mar 27 22:03:25.751: INFO: Pod "downward-api-23e6156b-50dc-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040191628s
Mar 27 22:03:27.764: INFO: Pod "downward-api-23e6156b-50dc-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053425289s
STEP: Saw pod success
Mar 27 22:03:27.765: INFO: Pod "downward-api-23e6156b-50dc-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 22:03:27.775: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod downward-api-23e6156b-50dc-11e9-9d23-0ac04cf37a48 container dapi-container: <nil>
STEP: delete the pod
Mar 27 22:03:27.872: INFO: Waiting for pod downward-api-23e6156b-50dc-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 22:03:27.913: INFO: Pod downward-api-23e6156b-50dc-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:03:27.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lvg9p" for this suite.
Mar 27 22:03:33.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:03:34.057: INFO: namespace: e2e-tests-downward-api-lvg9p, resource: bindings, ignored listing per whitelist
Mar 27 22:03:34.178: INFO: namespace e2e-tests-downward-api-lvg9p deletion completed in 6.248269639s

• [SLOW TEST:10.637 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:03:34.179: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar 27 22:03:34.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-228394863 api-versions'
Mar 27 22:03:34.455: INFO: stderr: ""
Mar 27 22:03:34.455: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:03:34.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rkxkx" for this suite.
Mar 27 22:03:40.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:03:40.746: INFO: namespace: e2e-tests-kubectl-rkxkx, resource: bindings, ignored listing per whitelist
Mar 27 22:03:40.772: INFO: namespace e2e-tests-kubectl-rkxkx deletion completed in 6.309106744s

• [SLOW TEST:6.593 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:03:40.778: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-lsxjc/configmap-test-2e2a31ef-50dc-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume configMaps
Mar 27 22:03:40.939: INFO: Waiting up to 5m0s for pod "pod-configmaps-2e2cbc53-50dc-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-configmap-lsxjc" to be "success or failure"
Mar 27 22:03:40.999: INFO: Pod "pod-configmaps-2e2cbc53-50dc-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 59.826184ms
Mar 27 22:03:43.006: INFO: Pod "pod-configmaps-2e2cbc53-50dc-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067035336s
Mar 27 22:03:45.014: INFO: Pod "pod-configmaps-2e2cbc53-50dc-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074858042s
STEP: Saw pod success
Mar 27 22:03:45.015: INFO: Pod "pod-configmaps-2e2cbc53-50dc-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 22:03:45.020: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-configmaps-2e2cbc53-50dc-11e9-9d23-0ac04cf37a48 container env-test: <nil>
STEP: delete the pod
Mar 27 22:03:45.100: INFO: Waiting for pod pod-configmaps-2e2cbc53-50dc-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 22:03:45.113: INFO: Pod pod-configmaps-2e2cbc53-50dc-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:03:45.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lsxjc" for this suite.
Mar 27 22:03:51.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:03:51.419: INFO: namespace: e2e-tests-configmap-lsxjc, resource: bindings, ignored listing per whitelist
Mar 27 22:03:51.563: INFO: namespace e2e-tests-configmap-lsxjc deletion completed in 6.402565521s

• [SLOW TEST:10.786 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:03:51.565: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:03:56.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-gr9xc" for this suite.
Mar 27 22:04:20.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:04:20.901: INFO: namespace: e2e-tests-replication-controller-gr9xc, resource: bindings, ignored listing per whitelist
Mar 27 22:04:21.069: INFO: namespace e2e-tests-replication-controller-gr9xc deletion completed in 24.243247714s

• [SLOW TEST:29.504 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 27 22:04:21.070: INFO: >>> kubeConfig: /tmp/kubeconfig-228394863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-462d0156-50dc-11e9-9d23-0ac04cf37a48
STEP: Creating a pod to test consume secrets
Mar 27 22:04:21.213: INFO: Waiting up to 5m0s for pod "pod-secrets-462e3ccd-50dc-11e9-9d23-0ac04cf37a48" in namespace "e2e-tests-secrets-cjkjz" to be "success or failure"
Mar 27 22:04:21.227: INFO: Pod "pod-secrets-462e3ccd-50dc-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 14.09325ms
Mar 27 22:04:23.234: INFO: Pod "pod-secrets-462e3ccd-50dc-11e9-9d23-0ac04cf37a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021103112s
Mar 27 22:04:25.240: INFO: Pod "pod-secrets-462e3ccd-50dc-11e9-9d23-0ac04cf37a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027288847s
STEP: Saw pod success
Mar 27 22:04:25.240: INFO: Pod "pod-secrets-462e3ccd-50dc-11e9-9d23-0ac04cf37a48" satisfied condition "success or failure"
Mar 27 22:04:25.245: INFO: Trying to get logs from node k8s-conformance-cluster-1-13-etcd-1 pod pod-secrets-462e3ccd-50dc-11e9-9d23-0ac04cf37a48 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 22:04:25.304: INFO: Waiting for pod pod-secrets-462e3ccd-50dc-11e9-9d23-0ac04cf37a48 to disappear
Mar 27 22:04:25.324: INFO: Pod pod-secrets-462e3ccd-50dc-11e9-9d23-0ac04cf37a48 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 27 22:04:25.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cjkjz" for this suite.
Mar 27 22:04:31.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 27 22:04:31.486: INFO: namespace: e2e-tests-secrets-cjkjz, resource: bindings, ignored listing per whitelist
Mar 27 22:04:31.606: INFO: namespace e2e-tests-secrets-cjkjz deletion completed in 6.25793972s

• [SLOW TEST:10.536 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSMar 27 22:04:31.607: INFO: Running AfterSuite actions on all nodes
Mar 27 22:04:31.608: INFO: Running AfterSuite actions on node 1
Mar 27 22:04:31.608: INFO: Skipping dumping logs from cluster

Ran 200 of 2161 Specs in 6086.188 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1961 Skipped PASS

Ginkgo ran 1 suite in 1h41m28.945895533s
Test Suite Passed
