I1205 15:22:07.237675      13 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-292959027
I1205 15:22:07.242519      13 e2e.go:224] Starting e2e run "8644b6e4-f8a1-11e8-a7f8-ceaf58ef2674" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544023325 - Will randomize all specs
Will run 201 of 1946 specs

Dec  5 15:22:07.826: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:22:07.831: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  5 15:22:07.847: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  5 15:22:07.884: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  5 15:22:07.884: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Dec  5 15:22:07.884: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  5 15:22:07.894: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  5 15:22:07.895: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-apiserver' (0 seconds elapsed)
Dec  5 15:22:07.895: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  5 15:22:07.895: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'pod-checkpointer' (0 seconds elapsed)
Dec  5 15:22:07.895: INFO: e2e test version: v1.13.0
Dec  5 15:22:07.897: INFO: kube-apiserver version: v1.13.0
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:22:07.897: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
Dec  5 15:22:07.965: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-8763780a-f8a1-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 15:22:07.982: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-876437e5-f8a1-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-tpk2d" to be "success or failure"
Dec  5 15:22:07.996: INFO: Pod "pod-projected-secrets-876437e5-f8a1-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 13.531591ms
Dec  5 15:22:10.001: INFO: Pod "pod-projected-secrets-876437e5-f8a1-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018982918s
Dec  5 15:22:12.005: INFO: Pod "pod-projected-secrets-876437e5-f8a1-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022591408s
STEP: Saw pod success
Dec  5 15:22:12.005: INFO: Pod "pod-projected-secrets-876437e5-f8a1-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:22:12.007: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-secrets-876437e5-f8a1-11e8-a7f8-ceaf58ef2674 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 15:22:12.048: INFO: Waiting for pod pod-projected-secrets-876437e5-f8a1-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:22:12.053: INFO: Pod pod-projected-secrets-876437e5-f8a1-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:22:12.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tpk2d" for this suite.
Dec  5 15:22:18.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:22:18.113: INFO: namespace: e2e-tests-projected-tpk2d, resource: bindings, ignored listing per whitelist
Dec  5 15:22:18.168: INFO: namespace e2e-tests-projected-tpk2d deletion completed in 6.112797138s

• [SLOW TEST:10.272 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:22:18.170: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8d8312d8-f8a1-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 15:22:18.252: INFO: Waiting up to 5m0s for pod "pod-configmaps-8d83aea9-f8a1-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-configmap-6ph68" to be "success or failure"
Dec  5 15:22:18.255: INFO: Pod "pod-configmaps-8d83aea9-f8a1-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.809257ms
Dec  5 15:22:20.261: INFO: Pod "pod-configmaps-8d83aea9-f8a1-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008739201s
STEP: Saw pod success
Dec  5 15:22:20.261: INFO: Pod "pod-configmaps-8d83aea9-f8a1-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:22:20.271: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-configmaps-8d83aea9-f8a1-11e8-a7f8-ceaf58ef2674 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 15:22:20.309: INFO: Waiting for pod pod-configmaps-8d83aea9-f8a1-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:22:20.314: INFO: Pod pod-configmaps-8d83aea9-f8a1-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:22:20.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6ph68" for this suite.
Dec  5 15:22:26.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:22:26.340: INFO: namespace: e2e-tests-configmap-6ph68, resource: bindings, ignored listing per whitelist
Dec  5 15:22:26.396: INFO: namespace e2e-tests-configmap-6ph68 deletion completed in 6.079525687s

• [SLOW TEST:8.226 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:22:26.398: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:22:53.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-jm7kr" for this suite.
Dec  5 15:22:59.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:22:59.750: INFO: namespace: e2e-tests-container-runtime-jm7kr, resource: bindings, ignored listing per whitelist
Dec  5 15:22:59.754: INFO: namespace e2e-tests-container-runtime-jm7kr deletion completed in 6.082264624s

• [SLOW TEST:33.356 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:22:59.757: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zmnqj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 15:22:59.822: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 15:23:19.905: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.0.9:8080/dial?request=hostName&protocol=http&host=10.2.1.3&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-zmnqj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:23:19.905: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:23:20.009: INFO: Waiting for endpoints: map[]
Dec  5 15:23:20.012: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.0.9:8080/dial?request=hostName&protocol=http&host=10.2.0.8&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-zmnqj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:23:20.012: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:23:20.109: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:23:20.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zmnqj" for this suite.
Dec  5 15:23:42.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:23:42.360: INFO: namespace: e2e-tests-pod-network-test-zmnqj, resource: bindings, ignored listing per whitelist
Dec  5 15:23:42.427: INFO: namespace e2e-tests-pod-network-test-zmnqj deletion completed in 22.103890336s

• [SLOW TEST:42.671 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:23:42.429: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  5 15:23:46.561: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 15:23:46.564: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 15:23:48.564: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 15:23:48.567: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 15:23:50.564: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 15:23:50.572: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 15:23:52.564: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 15:23:52.569: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 15:23:54.564: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 15:23:54.567: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 15:23:56.564: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 15:23:56.568: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 15:23:58.564: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 15:23:58.567: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 15:24:00.564: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 15:24:00.567: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:24:00.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-48xxs" for this suite.
Dec  5 15:24:22.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:24:22.639: INFO: namespace: e2e-tests-container-lifecycle-hook-48xxs, resource: bindings, ignored listing per whitelist
Dec  5 15:24:22.668: INFO: namespace e2e-tests-container-lifecycle-hook-48xxs deletion completed in 22.090856922s

• [SLOW TEST:40.239 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:24:22.669: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec  5 15:24:22.743: INFO: Waiting up to 5m0s for pod "var-expansion-d7b7561e-f8a1-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-var-expansion-nhlb6" to be "success or failure"
Dec  5 15:24:22.750: INFO: Pod "var-expansion-d7b7561e-f8a1-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.61147ms
Dec  5 15:24:24.754: INFO: Pod "var-expansion-d7b7561e-f8a1-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010377191s
STEP: Saw pod success
Dec  5 15:24:24.754: INFO: Pod "var-expansion-d7b7561e-f8a1-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:24:24.756: INFO: Trying to get logs from node ip-10-0-40-84 pod var-expansion-d7b7561e-f8a1-11e8-a7f8-ceaf58ef2674 container dapi-container: <nil>
STEP: delete the pod
Dec  5 15:24:24.774: INFO: Waiting for pod var-expansion-d7b7561e-f8a1-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:24:24.775: INFO: Pod var-expansion-d7b7561e-f8a1-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:24:24.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-nhlb6" for this suite.
Dec  5 15:24:30.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:24:30.832: INFO: namespace: e2e-tests-var-expansion-nhlb6, resource: bindings, ignored listing per whitelist
Dec  5 15:24:30.921: INFO: namespace e2e-tests-var-expansion-nhlb6 deletion completed in 6.1419341s

• [SLOW TEST:8.252 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:24:30.921: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-dca56ede-f8a1-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 15:24:31.028: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dca6e065-f8a1-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-zjhrn" to be "success or failure"
Dec  5 15:24:31.033: INFO: Pod "pod-projected-configmaps-dca6e065-f8a1-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.561901ms
Dec  5 15:24:33.036: INFO: Pod "pod-projected-configmaps-dca6e065-f8a1-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008028498s
STEP: Saw pod success
Dec  5 15:24:33.036: INFO: Pod "pod-projected-configmaps-dca6e065-f8a1-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:24:33.038: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-configmaps-dca6e065-f8a1-11e8-a7f8-ceaf58ef2674 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 15:24:33.054: INFO: Waiting for pod pod-projected-configmaps-dca6e065-f8a1-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:24:33.057: INFO: Pod pod-projected-configmaps-dca6e065-f8a1-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:24:33.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zjhrn" for this suite.
Dec  5 15:24:39.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:24:39.128: INFO: namespace: e2e-tests-projected-zjhrn, resource: bindings, ignored listing per whitelist
Dec  5 15:24:39.168: INFO: namespace e2e-tests-projected-zjhrn deletion completed in 6.107931508s

• [SLOW TEST:8.247 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:24:39.169: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  5 15:24:39.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-n5fzx'
Dec  5 15:24:39.663: INFO: stderr: ""
Dec  5 15:24:39.663: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 15:24:40.690: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 15:24:40.690: INFO: Found 0 / 1
Dec  5 15:24:41.666: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 15:24:41.666: INFO: Found 0 / 1
Dec  5 15:24:42.666: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 15:24:42.666: INFO: Found 1 / 1
Dec  5 15:24:42.666: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  5 15:24:42.668: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 15:24:42.668: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 15:24:42.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 patch pod redis-master-db2nc --namespace=e2e-tests-kubectl-n5fzx -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  5 15:24:42.764: INFO: stderr: ""
Dec  5 15:24:42.764: INFO: stdout: "pod/redis-master-db2nc patched\n"
STEP: checking annotations
Dec  5 15:24:42.767: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 15:24:42.767: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:24:42.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n5fzx" for this suite.
Dec  5 15:25:04.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:25:04.824: INFO: namespace: e2e-tests-kubectl-n5fzx, resource: bindings, ignored listing per whitelist
Dec  5 15:25:04.894: INFO: namespace e2e-tests-kubectl-n5fzx deletion completed in 22.12393092s

• [SLOW TEST:25.725 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:25:04.894: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 15:25:23.909: INFO: Container started at 2018-12-05 15:25:07 +0000 UTC, pod became ready at 2018-12-05 15:25:23 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:25:23.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4rwf7" for this suite.
Dec  5 15:25:45.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:25:45.957: INFO: namespace: e2e-tests-container-probe-4rwf7, resource: bindings, ignored listing per whitelist
Dec  5 15:25:46.004: INFO: namespace e2e-tests-container-probe-4rwf7 deletion completed in 22.091518478s

• [SLOW TEST:41.110 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:25:46.006: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec  5 15:25:48.186: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:26:12.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-xgqx4" for this suite.
Dec  5 15:26:18.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:26:18.312: INFO: namespace: e2e-tests-namespaces-xgqx4, resource: bindings, ignored listing per whitelist
Dec  5 15:26:18.328: INFO: namespace e2e-tests-namespaces-xgqx4 deletion completed in 6.082812837s
STEP: Destroying namespace "e2e-tests-nsdeletetest-r47bd" for this suite.
Dec  5 15:26:18.330: INFO: Namespace e2e-tests-nsdeletetest-r47bd was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-hklp2" for this suite.
Dec  5 15:26:24.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:26:24.390: INFO: namespace: e2e-tests-nsdeletetest-hklp2, resource: bindings, ignored listing per whitelist
Dec  5 15:26:24.411: INFO: namespace e2e-tests-nsdeletetest-hklp2 deletion completed in 6.081628148s

• [SLOW TEST:38.406 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:26:24.413: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2048306b-f8a2-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 15:26:24.492: INFO: Waiting up to 5m0s for pod "pod-secrets-2048e7ad-f8a2-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-secrets-j4zsz" to be "success or failure"
Dec  5 15:26:24.496: INFO: Pod "pod-secrets-2048e7ad-f8a2-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.545627ms
Dec  5 15:26:26.503: INFO: Pod "pod-secrets-2048e7ad-f8a2-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010718447s
STEP: Saw pod success
Dec  5 15:26:26.503: INFO: Pod "pod-secrets-2048e7ad-f8a2-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:26:26.504: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-secrets-2048e7ad-f8a2-11e8-a7f8-ceaf58ef2674 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 15:26:26.533: INFO: Waiting for pod pod-secrets-2048e7ad-f8a2-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:26:26.537: INFO: Pod pod-secrets-2048e7ad-f8a2-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:26:26.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j4zsz" for this suite.
Dec  5 15:26:32.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:26:32.612: INFO: namespace: e2e-tests-secrets-j4zsz, resource: bindings, ignored listing per whitelist
Dec  5 15:26:32.624: INFO: namespace e2e-tests-secrets-j4zsz deletion completed in 6.084744379s

• [SLOW TEST:8.212 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:26:32.626: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 15:26:32.705: INFO: Waiting up to 5m0s for pod "downwardapi-volume-252d3c3d-f8a2-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-lszbl" to be "success or failure"
Dec  5 15:26:32.710: INFO: Pod "downwardapi-volume-252d3c3d-f8a2-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.357283ms
Dec  5 15:26:34.714: INFO: Pod "downwardapi-volume-252d3c3d-f8a2-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00892638s
STEP: Saw pod success
Dec  5 15:26:34.714: INFO: Pod "downwardapi-volume-252d3c3d-f8a2-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:26:34.715: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-252d3c3d-f8a2-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 15:26:34.734: INFO: Waiting for pod downwardapi-volume-252d3c3d-f8a2-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:26:34.769: INFO: Pod downwardapi-volume-252d3c3d-f8a2-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:26:34.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lszbl" for this suite.
Dec  5 15:26:40.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:26:40.865: INFO: namespace: e2e-tests-downward-api-lszbl, resource: bindings, ignored listing per whitelist
Dec  5 15:26:40.919: INFO: namespace e2e-tests-downward-api-lszbl deletion completed in 6.1459837s

• [SLOW TEST:8.293 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:26:40.919: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 15:26:41.036: INFO: (0) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 26.516728ms)
Dec  5 15:26:41.039: INFO: (1) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.582327ms)
Dec  5 15:26:41.043: INFO: (2) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.051386ms)
Dec  5 15:26:41.045: INFO: (3) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.336917ms)
Dec  5 15:26:41.047: INFO: (4) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.467738ms)
Dec  5 15:26:41.050: INFO: (5) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.653988ms)
Dec  5 15:26:41.053: INFO: (6) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.387949ms)
Dec  5 15:26:41.055: INFO: (7) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.443944ms)
Dec  5 15:26:41.057: INFO: (8) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.365736ms)
Dec  5 15:26:41.060: INFO: (9) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.629926ms)
Dec  5 15:26:41.063: INFO: (10) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.501791ms)
Dec  5 15:26:41.065: INFO: (11) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.403669ms)
Dec  5 15:26:41.068: INFO: (12) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.462252ms)
Dec  5 15:26:41.070: INFO: (13) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.397262ms)
Dec  5 15:26:41.073: INFO: (14) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.71435ms)
Dec  5 15:26:41.075: INFO: (15) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.454321ms)
Dec  5 15:26:41.079: INFO: (16) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.427565ms)
Dec  5 15:26:41.082: INFO: (17) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.02403ms)
Dec  5 15:26:41.084: INFO: (18) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.647476ms)
Dec  5 15:26:41.087: INFO: (19) /api/v1/nodes/ip-10-0-12-134:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.357459ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:26:41.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5qxsp" for this suite.
Dec  5 15:26:47.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:26:47.187: INFO: namespace: e2e-tests-proxy-5qxsp, resource: bindings, ignored listing per whitelist
Dec  5 15:26:47.187: INFO: namespace e2e-tests-proxy-5qxsp deletion completed in 6.092883932s

• [SLOW TEST:6.268 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:26:47.189: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1205 15:26:57.339389      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 15:26:57.339: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:26:57.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cqhpq" for this suite.
Dec  5 15:27:03.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:27:03.382: INFO: namespace: e2e-tests-gc-cqhpq, resource: bindings, ignored listing per whitelist
Dec  5 15:27:03.424: INFO: namespace e2e-tests-gc-cqhpq deletion completed in 6.082711998s

• [SLOW TEST:16.235 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:27:03.425: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  5 15:27:03.497: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 15:27:03.502: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 15:27:03.504: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-12-134 before test
Dec  5 15:27:03.510: INFO: kube-proxy-2hslj from kube-system started at 2018-12-05 05:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 15:27:03.510: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 15:27:03.510: INFO: calico-node-p6sb5 from kube-system started at 2018-12-05 05:33:47 +0000 UTC (2 container statuses recorded)
Dec  5 15:27:03.510: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 15:27:03.510: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 15:27:03.511: INFO: sonobuoy-e2e-job-4df755f956e944ee from heptio-sonobuoy started at 2018-12-05 15:21:37 +0000 UTC (2 container statuses recorded)
Dec  5 15:27:03.511: INFO: 	Container e2e ready: true, restart count 0
Dec  5 15:27:03.511: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 15:27:03.511: INFO: sonobuoy-systemd-logs-daemon-set-6778acf1ee8d4b8d-5rq4f from heptio-sonobuoy started at 2018-12-05 15:21:37 +0000 UTC (2 container statuses recorded)
Dec  5 15:27:03.511: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 15:27:03.511: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 15:27:03.511: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-40-84 before test
Dec  5 15:27:03.516: INFO: calico-node-nkjpz from kube-system started at 2018-12-05 05:33:46 +0000 UTC (2 container statuses recorded)
Dec  5 15:27:03.516: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 15:27:03.516: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 15:27:03.516: INFO: kube-proxy-gzgch from kube-system started at 2018-12-05 05:33:46 +0000 UTC (1 container statuses recorded)
Dec  5 15:27:03.517: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 15:27:03.517: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-05 05:37:35 +0000 UTC (1 container statuses recorded)
Dec  5 15:27:03.517: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 15:27:03.517: INFO: sonobuoy-systemd-logs-daemon-set-6778acf1ee8d4b8d-8k8kp from heptio-sonobuoy started at 2018-12-05 15:21:37 +0000 UTC (2 container statuses recorded)
Dec  5 15:27:03.517: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 15:27:03.517: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-38c24f1c-f8a2-11e8-a7f8-ceaf58ef2674 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-38c24f1c-f8a2-11e8-a7f8-ceaf58ef2674 off the node ip-10-0-40-84
STEP: verifying the node doesn't have the label kubernetes.io/e2e-38c24f1c-f8a2-11e8-a7f8-ceaf58ef2674
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:27:07.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-cttpc" for this suite.
Dec  5 15:27:25.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:27:25.639: INFO: namespace: e2e-tests-sched-pred-cttpc, resource: bindings, ignored listing per whitelist
Dec  5 15:27:25.691: INFO: namespace e2e-tests-sched-pred-cttpc deletion completed in 18.082692422s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:22.266 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:27:25.692: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-rpg47
Dec  5 15:27:27.775: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-rpg47
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 15:27:27.777: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:31:28.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rpg47" for this suite.
Dec  5 15:31:34.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:31:34.305: INFO: namespace: e2e-tests-container-probe-rpg47, resource: bindings, ignored listing per whitelist
Dec  5 15:31:34.325: INFO: namespace e2e-tests-container-probe-rpg47 deletion completed in 6.084896819s

• [SLOW TEST:248.633 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:31:34.327: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 15:31:34.399: INFO: Waiting up to 5m0s for pod "downward-api-d900f828-f8a2-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-s7hvx" to be "success or failure"
Dec  5 15:31:34.403: INFO: Pod "downward-api-d900f828-f8a2-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 3.821641ms
Dec  5 15:31:36.407: INFO: Pod "downward-api-d900f828-f8a2-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007340895s
STEP: Saw pod success
Dec  5 15:31:36.407: INFO: Pod "downward-api-d900f828-f8a2-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:31:36.409: INFO: Trying to get logs from node ip-10-0-40-84 pod downward-api-d900f828-f8a2-11e8-a7f8-ceaf58ef2674 container dapi-container: <nil>
STEP: delete the pod
Dec  5 15:31:36.433: INFO: Waiting for pod downward-api-d900f828-f8a2-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:31:36.436: INFO: Pod downward-api-d900f828-f8a2-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:31:36.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s7hvx" for this suite.
Dec  5 15:31:42.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:31:42.464: INFO: namespace: e2e-tests-downward-api-s7hvx, resource: bindings, ignored listing per whitelist
Dec  5 15:31:42.518: INFO: namespace e2e-tests-downward-api-s7hvx deletion completed in 6.079426875s

• [SLOW TEST:8.192 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:31:42.520: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 15:31:42.581: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:31:44.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-556lf" for this suite.
Dec  5 15:32:34.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:32:34.672: INFO: namespace: e2e-tests-pods-556lf, resource: bindings, ignored listing per whitelist
Dec  5 15:32:34.713: INFO: namespace e2e-tests-pods-556lf deletion completed in 50.09984228s

• [SLOW TEST:52.194 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:32:34.714: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-fcff7873-f8a2-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 15:32:34.789: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fcfff665-f8a2-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-6hhp6" to be "success or failure"
Dec  5 15:32:34.795: INFO: Pod "pod-projected-secrets-fcfff665-f8a2-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.507493ms
Dec  5 15:32:36.799: INFO: Pod "pod-projected-secrets-fcfff665-f8a2-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009212699s
STEP: Saw pod success
Dec  5 15:32:36.799: INFO: Pod "pod-projected-secrets-fcfff665-f8a2-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:32:36.801: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-secrets-fcfff665-f8a2-11e8-a7f8-ceaf58ef2674 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 15:32:36.823: INFO: Waiting for pod pod-projected-secrets-fcfff665-f8a2-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:32:36.833: INFO: Pod pod-projected-secrets-fcfff665-f8a2-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:32:36.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6hhp6" for this suite.
Dec  5 15:32:42.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:32:42.910: INFO: namespace: e2e-tests-projected-6hhp6, resource: bindings, ignored listing per whitelist
Dec  5 15:32:42.963: INFO: namespace e2e-tests-projected-6hhp6 deletion completed in 6.126010117s

• [SLOW TEST:8.249 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:32:42.967: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-kk8mv
Dec  5 15:32:45.048: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-kk8mv
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 15:32:45.050: INFO: Initial restart count of pod liveness-exec is 0
Dec  5 15:33:39.151: INFO: Restart count of pod e2e-tests-container-probe-kk8mv/liveness-exec is now 1 (54.100341625s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:33:39.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kk8mv" for this suite.
Dec  5 15:33:45.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:33:45.204: INFO: namespace: e2e-tests-container-probe-kk8mv, resource: bindings, ignored listing per whitelist
Dec  5 15:33:45.244: INFO: namespace e2e-tests-container-probe-kk8mv deletion completed in 6.078994837s

• [SLOW TEST:62.278 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:33:45.246: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 15:33:45.352: INFO: Waiting up to 5m0s for pod "downward-api-270dd92d-f8a3-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-qm644" to be "success or failure"
Dec  5 15:33:45.419: INFO: Pod "downward-api-270dd92d-f8a3-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 67.403104ms
Dec  5 15:33:47.422: INFO: Pod "downward-api-270dd92d-f8a3-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0704996s
Dec  5 15:33:49.425: INFO: Pod "downward-api-270dd92d-f8a3-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.073630883s
STEP: Saw pod success
Dec  5 15:33:49.425: INFO: Pod "downward-api-270dd92d-f8a3-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:33:49.427: INFO: Trying to get logs from node ip-10-0-12-134 pod downward-api-270dd92d-f8a3-11e8-a7f8-ceaf58ef2674 container dapi-container: <nil>
STEP: delete the pod
Dec  5 15:33:49.452: INFO: Waiting for pod downward-api-270dd92d-f8a3-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:33:49.468: INFO: Pod downward-api-270dd92d-f8a3-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:33:49.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qm644" for this suite.
Dec  5 15:33:55.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:33:55.516: INFO: namespace: e2e-tests-downward-api-qm644, resource: bindings, ignored listing per whitelist
Dec  5 15:33:55.551: INFO: namespace e2e-tests-downward-api-qm644 deletion completed in 6.079795116s

• [SLOW TEST:10.306 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:33:55.554: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xcdl4
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-xcdl4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-xcdl4
Dec  5 15:33:55.649: INFO: Found 0 stateful pods, waiting for 1
Dec  5 15:34:05.653: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  5 15:34:05.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-xcdl4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 15:34:05.839: INFO: stderr: ""
Dec  5 15:34:05.839: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 15:34:05.839: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 15:34:05.842: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  5 15:34:15.846: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 15:34:15.846: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 15:34:15.863: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999052s
Dec  5 15:34:16.867: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993905494s
Dec  5 15:34:17.870: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990298279s
Dec  5 15:34:18.874: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986779522s
Dec  5 15:34:19.877: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.983163994s
Dec  5 15:34:20.881: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.979952228s
Dec  5 15:34:21.885: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.976360636s
Dec  5 15:34:22.888: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.972736338s
Dec  5 15:34:23.892: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.969053776s
Dec  5 15:34:24.895: INFO: Verifying statefulset ss doesn't scale past 1 for another 965.492487ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-xcdl4
Dec  5 15:34:25.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-xcdl4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 15:34:26.083: INFO: stderr: ""
Dec  5 15:34:26.083: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 15:34:26.083: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 15:34:26.086: INFO: Found 1 stateful pods, waiting for 3
Dec  5 15:34:36.089: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 15:34:36.089: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 15:34:36.089: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  5 15:34:36.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-xcdl4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 15:34:36.276: INFO: stderr: ""
Dec  5 15:34:36.276: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 15:34:36.276: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 15:34:36.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-xcdl4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 15:34:36.446: INFO: stderr: ""
Dec  5 15:34:36.446: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 15:34:36.446: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 15:34:36.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-xcdl4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 15:34:36.639: INFO: stderr: ""
Dec  5 15:34:36.639: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 15:34:36.639: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 15:34:36.639: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 15:34:36.642: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  5 15:34:46.648: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 15:34:46.648: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 15:34:46.648: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 15:34:46.661: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999993737s
Dec  5 15:34:47.665: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993585637s
Dec  5 15:34:48.669: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989669573s
Dec  5 15:34:49.674: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98597936s
Dec  5 15:34:50.691: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.967226275s
Dec  5 15:34:51.695: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.963516784s
Dec  5 15:34:52.699: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.959492448s
Dec  5 15:34:53.703: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955613851s
Dec  5 15:34:54.707: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.951843979s
Dec  5 15:34:55.710: INFO: Verifying statefulset ss doesn't scale past 3 for another 948.296382ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-xcdl4
Dec  5 15:34:56.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-xcdl4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 15:34:56.889: INFO: stderr: ""
Dec  5 15:34:56.889: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 15:34:56.889: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 15:34:56.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-xcdl4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 15:34:57.062: INFO: stderr: ""
Dec  5 15:34:57.063: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 15:34:57.063: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 15:34:57.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-xcdl4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 15:34:57.295: INFO: stderr: ""
Dec  5 15:34:57.295: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 15:34:57.295: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 15:34:57.295: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 15:35:27.309: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xcdl4
Dec  5 15:35:27.312: INFO: Scaling statefulset ss to 0
Dec  5 15:35:27.321: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 15:35:27.323: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:35:27.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xcdl4" for this suite.
Dec  5 15:35:33.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:35:33.431: INFO: namespace: e2e-tests-statefulset-xcdl4, resource: bindings, ignored listing per whitelist
Dec  5 15:35:33.467: INFO: namespace e2e-tests-statefulset-xcdl4 deletion completed in 6.116676391s

• [SLOW TEST:97.913 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:35:33.467: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 15:35:33.580: INFO: Waiting up to 5m0s for pod "downwardapi-volume-678e1125-f8a3-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-dsdrn" to be "success or failure"
Dec  5 15:35:33.611: INFO: Pod "downwardapi-volume-678e1125-f8a3-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 30.397993ms
Dec  5 15:35:35.615: INFO: Pod "downwardapi-volume-678e1125-f8a3-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034075678s
STEP: Saw pod success
Dec  5 15:35:35.615: INFO: Pod "downwardapi-volume-678e1125-f8a3-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:35:35.617: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-678e1125-f8a3-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 15:35:35.636: INFO: Waiting for pod downwardapi-volume-678e1125-f8a3-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:35:35.641: INFO: Pod downwardapi-volume-678e1125-f8a3-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:35:35.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dsdrn" for this suite.
Dec  5 15:35:41.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:35:41.674: INFO: namespace: e2e-tests-projected-dsdrn, resource: bindings, ignored listing per whitelist
Dec  5 15:35:41.728: INFO: namespace e2e-tests-projected-dsdrn deletion completed in 6.083980901s

• [SLOW TEST:8.261 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:35:41.730: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-nc7v
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 15:35:41.864: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-nc7v" in namespace "e2e-tests-subpath-47lgs" to be "success or failure"
Dec  5 15:35:41.868: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Pending", Reason="", readiness=false. Elapsed: 4.130417ms
Dec  5 15:35:43.872: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007790991s
Dec  5 15:35:45.876: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Running", Reason="", readiness=false. Elapsed: 4.011594626s
Dec  5 15:35:47.879: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Running", Reason="", readiness=false. Elapsed: 6.015226034s
Dec  5 15:35:49.883: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Running", Reason="", readiness=false. Elapsed: 8.019061135s
Dec  5 15:35:51.886: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Running", Reason="", readiness=false. Elapsed: 10.022461724s
Dec  5 15:35:53.890: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Running", Reason="", readiness=false. Elapsed: 12.025702123s
Dec  5 15:35:55.893: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Running", Reason="", readiness=false. Elapsed: 14.029068858s
Dec  5 15:35:57.896: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Running", Reason="", readiness=false. Elapsed: 16.032093984s
Dec  5 15:35:59.899: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Running", Reason="", readiness=false. Elapsed: 18.035459886s
Dec  5 15:36:01.903: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Running", Reason="", readiness=false. Elapsed: 20.038767557s
Dec  5 15:36:03.906: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Running", Reason="", readiness=false. Elapsed: 22.042294499s
Dec  5 15:36:05.910: INFO: Pod "pod-subpath-test-secret-nc7v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.045759903s
STEP: Saw pod success
Dec  5 15:36:05.910: INFO: Pod "pod-subpath-test-secret-nc7v" satisfied condition "success or failure"
Dec  5 15:36:05.911: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-subpath-test-secret-nc7v container test-container-subpath-secret-nc7v: <nil>
STEP: delete the pod
Dec  5 15:36:05.937: INFO: Waiting for pod pod-subpath-test-secret-nc7v to disappear
Dec  5 15:36:05.940: INFO: Pod pod-subpath-test-secret-nc7v no longer exists
STEP: Deleting pod pod-subpath-test-secret-nc7v
Dec  5 15:36:05.940: INFO: Deleting pod "pod-subpath-test-secret-nc7v" in namespace "e2e-tests-subpath-47lgs"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:36:05.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-47lgs" for this suite.
Dec  5 15:36:11.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:36:12.015: INFO: namespace: e2e-tests-subpath-47lgs, resource: bindings, ignored listing per whitelist
Dec  5 15:36:12.027: INFO: namespace e2e-tests-subpath-47lgs deletion completed in 6.082824142s

• [SLOW TEST:30.298 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:36:12.029: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec  5 15:36:12.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:12.447: INFO: stderr: ""
Dec  5 15:36:12.447: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 15:36:12.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:12.553: INFO: stderr: ""
Dec  5 15:36:12.553: INFO: stdout: "update-demo-nautilus-k6wf2 update-demo-nautilus-w5xg6 "
Dec  5 15:36:12.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-k6wf2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:12.639: INFO: stderr: ""
Dec  5 15:36:12.639: INFO: stdout: ""
Dec  5 15:36:12.639: INFO: update-demo-nautilus-k6wf2 is created but not running
Dec  5 15:36:17.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:17.733: INFO: stderr: ""
Dec  5 15:36:17.733: INFO: stdout: "update-demo-nautilus-k6wf2 update-demo-nautilus-w5xg6 "
Dec  5 15:36:17.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-k6wf2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:17.818: INFO: stderr: ""
Dec  5 15:36:17.818: INFO: stdout: "true"
Dec  5 15:36:17.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-k6wf2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:17.917: INFO: stderr: ""
Dec  5 15:36:17.917: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 15:36:17.917: INFO: validating pod update-demo-nautilus-k6wf2
Dec  5 15:36:17.921: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 15:36:17.921: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 15:36:17.921: INFO: update-demo-nautilus-k6wf2 is verified up and running
Dec  5 15:36:17.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-w5xg6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:18.005: INFO: stderr: ""
Dec  5 15:36:18.005: INFO: stdout: "true"
Dec  5 15:36:18.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-w5xg6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:18.090: INFO: stderr: ""
Dec  5 15:36:18.091: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 15:36:18.091: INFO: validating pod update-demo-nautilus-w5xg6
Dec  5 15:36:18.094: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 15:36:18.094: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 15:36:18.094: INFO: update-demo-nautilus-w5xg6 is verified up and running
STEP: rolling-update to new replication controller
Dec  5 15:36:18.095: INFO: scanned /root for discovery docs: <nil>
Dec  5 15:36:18.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:40.543: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  5 15:36:40.543: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 15:36:40.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:40.656: INFO: stderr: ""
Dec  5 15:36:40.656: INFO: stdout: "update-demo-kitten-5k8n7 update-demo-kitten-k48xl "
Dec  5 15:36:40.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-kitten-5k8n7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:40.834: INFO: stderr: ""
Dec  5 15:36:40.834: INFO: stdout: "true"
Dec  5 15:36:40.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-kitten-5k8n7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:40.946: INFO: stderr: ""
Dec  5 15:36:40.946: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  5 15:36:40.946: INFO: validating pod update-demo-kitten-5k8n7
Dec  5 15:36:40.950: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  5 15:36:40.950: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  5 15:36:40.950: INFO: update-demo-kitten-5k8n7 is verified up and running
Dec  5 15:36:40.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-kitten-k48xl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:41.035: INFO: stderr: ""
Dec  5 15:36:41.035: INFO: stdout: "true"
Dec  5 15:36:41.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-kitten-k48xl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4q5mm'
Dec  5 15:36:41.121: INFO: stderr: ""
Dec  5 15:36:41.121: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  5 15:36:41.121: INFO: validating pod update-demo-kitten-k48xl
Dec  5 15:36:41.126: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  5 15:36:41.126: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  5 15:36:41.126: INFO: update-demo-kitten-k48xl is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:36:41.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4q5mm" for this suite.
Dec  5 15:37:03.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:37:03.190: INFO: namespace: e2e-tests-kubectl-4q5mm, resource: bindings, ignored listing per whitelist
Dec  5 15:37:03.221: INFO: namespace e2e-tests-kubectl-4q5mm deletion completed in 22.091706134s

• [SLOW TEST:51.192 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:37:03.223: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec  5 15:37:05.371: INFO: Pod pod-hostip-9d0c78ee-f8a3-11e8-a7f8-ceaf58ef2674 has hostIP: 10.0.40.84
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:37:05.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-c4w8f" for this suite.
Dec  5 15:37:27.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:37:27.427: INFO: namespace: e2e-tests-pods-c4w8f, resource: bindings, ignored listing per whitelist
Dec  5 15:37:27.454: INFO: namespace e2e-tests-pods-c4w8f deletion completed in 22.079994873s

• [SLOW TEST:24.231 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:37:27.455: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 15:37:27.515: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  5 15:37:27.525: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  5 15:37:32.529: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 15:37:32.529: INFO: Creating deployment "test-rolling-update-deployment"
Dec  5 15:37:32.535: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  5 15:37:32.543: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  5 15:37:34.549: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  5 15:37:34.550: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679621052, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679621052, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679621052, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679621052, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 15:37:36.553: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 15:37:36.559: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-2kwpp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2kwpp/deployments/test-rolling-update-deployment,UID:ae785d56-f8a3-11e8-ab6c-06b570ab0412,ResourceVersion:53140,Generation:1,CreationTimestamp:2018-12-05 15:37:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-05 15:37:32 +0000 UTC 2018-12-05 15:37:32 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-05 15:37:35 +0000 UTC 2018-12-05 15:37:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  5 15:37:36.561: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-2kwpp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2kwpp/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:ae7c20fc-f8a3-11e8-ab6c-06b570ab0412,ResourceVersion:53131,Generation:1,CreationTimestamp:2018-12-05 15:37:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ae785d56-f8a3-11e8-ab6c-06b570ab0412 0xc001676267 0xc001676268}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  5 15:37:36.561: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  5 15:37:36.561: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-2kwpp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2kwpp/replicasets/test-rolling-update-controller,UID:ab7b35f9-f8a3-11e8-ab6c-06b570ab0412,ResourceVersion:53139,Generation:2,CreationTimestamp:2018-12-05 15:37:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ae785d56-f8a3-11e8-ab6c-06b570ab0412 0xc001676087 0xc001676088}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 15:37:36.564: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-t96wz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-t96wz,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-2kwpp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2kwpp/pods/test-rolling-update-deployment-68b55d7bc6-t96wz,UID:ae7d4d9b-f8a3-11e8-ab6c-06b570ab0412,ResourceVersion:53130,Generation:0,CreationTimestamp:2018-12-05 15:37:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.9/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 ae7c20fc-f8a3-11e8-ab6c-06b570ab0412 0xc00127a397 0xc00127a398}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vq2qr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vq2qr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vq2qr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00127a410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00127a4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:37:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:37:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:37:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:37:32 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:10.2.1.9,StartTime:2018-12-05 15:37:32 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-05 15:37:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9392da46fa4d2ccffa9f8549e44094c51bb7c773ebaecde29a6dc743a63458c3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:37:36.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2kwpp" for this suite.
Dec  5 15:37:42.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:37:42.604: INFO: namespace: e2e-tests-deployment-2kwpp, resource: bindings, ignored listing per whitelist
Dec  5 15:37:42.648: INFO: namespace e2e-tests-deployment-2kwpp deletion completed in 6.081520759s

• [SLOW TEST:15.193 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:37:42.650: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-b48a0a45-f8a3-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 15:37:42.721: INFO: Waiting up to 5m0s for pod "pod-configmaps-b48a8fa4-f8a3-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-configmap-gz24x" to be "success or failure"
Dec  5 15:37:42.726: INFO: Pod "pod-configmaps-b48a8fa4-f8a3-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.144455ms
Dec  5 15:37:44.730: INFO: Pod "pod-configmaps-b48a8fa4-f8a3-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00822431s
STEP: Saw pod success
Dec  5 15:37:44.730: INFO: Pod "pod-configmaps-b48a8fa4-f8a3-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:37:44.732: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-configmaps-b48a8fa4-f8a3-11e8-a7f8-ceaf58ef2674 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 15:37:44.755: INFO: Waiting for pod pod-configmaps-b48a8fa4-f8a3-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:37:44.758: INFO: Pod pod-configmaps-b48a8fa4-f8a3-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:37:44.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gz24x" for this suite.
Dec  5 15:37:50.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:37:50.851: INFO: namespace: e2e-tests-configmap-gz24x, resource: bindings, ignored listing per whitelist
Dec  5 15:37:50.871: INFO: namespace e2e-tests-configmap-gz24x deletion completed in 6.110942456s

• [SLOW TEST:8.221 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:37:50.872: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b9707fa9-f8a3-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 15:37:50.942: INFO: Waiting up to 5m0s for pod "pod-secrets-b9710525-f8a3-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-secrets-t4k2q" to be "success or failure"
Dec  5 15:37:50.952: INFO: Pod "pod-secrets-b9710525-f8a3-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 9.253577ms
Dec  5 15:37:52.955: INFO: Pod "pod-secrets-b9710525-f8a3-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012497249s
STEP: Saw pod success
Dec  5 15:37:52.955: INFO: Pod "pod-secrets-b9710525-f8a3-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:37:52.957: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-secrets-b9710525-f8a3-11e8-a7f8-ceaf58ef2674 container secret-env-test: <nil>
STEP: delete the pod
Dec  5 15:37:52.974: INFO: Waiting for pod pod-secrets-b9710525-f8a3-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:37:52.977: INFO: Pod pod-secrets-b9710525-f8a3-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:37:52.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t4k2q" for this suite.
Dec  5 15:37:58.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:37:59.030: INFO: namespace: e2e-tests-secrets-t4k2q, resource: bindings, ignored listing per whitelist
Dec  5 15:37:59.094: INFO: namespace e2e-tests-secrets-t4k2q deletion completed in 6.113194638s

• [SLOW TEST:8.222 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:37:59.095: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 15:38:01.702: INFO: Successfully updated pod "annotationupdatebe58d0b4-f8a3-11e8-a7f8-ceaf58ef2674"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:38:03.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tf72p" for this suite.
Dec  5 15:38:25.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:38:25.825: INFO: namespace: e2e-tests-downward-api-tf72p, resource: bindings, ignored listing per whitelist
Dec  5 15:38:25.829: INFO: namespace e2e-tests-downward-api-tf72p deletion completed in 22.10449146s

• [SLOW TEST:26.734 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:38:25.831: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:38:36.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-87qlh" for this suite.
Dec  5 15:38:58.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:38:59.017: INFO: namespace: e2e-tests-replication-controller-87qlh, resource: bindings, ignored listing per whitelist
Dec  5 15:38:59.039: INFO: namespace e2e-tests-replication-controller-87qlh deletion completed in 22.089721732s

• [SLOW TEST:33.209 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:38:59.041: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:38:59.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kmlk9" for this suite.
Dec  5 15:39:21.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:39:21.160: INFO: namespace: e2e-tests-pods-kmlk9, resource: bindings, ignored listing per whitelist
Dec  5 15:39:21.208: INFO: namespace e2e-tests-pods-kmlk9 deletion completed in 22.083501783s

• [SLOW TEST:22.167 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:39:21.210: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  5 15:39:26.316: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:39:26.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-kzjx2" for this suite.
Dec  5 15:39:48.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:39:48.418: INFO: namespace: e2e-tests-replicaset-kzjx2, resource: bindings, ignored listing per whitelist
Dec  5 15:39:48.442: INFO: namespace e2e-tests-replicaset-kzjx2 deletion completed in 22.102365499s

• [SLOW TEST:27.232 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:39:48.443: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 15:39:51.045: INFO: Successfully updated pod "labelsupdateff84d4e7-f8a3-11e8-a7f8-ceaf58ef2674"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:39:55.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jkgng" for this suite.
Dec  5 15:40:17.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:40:17.191: INFO: namespace: e2e-tests-downward-api-jkgng, resource: bindings, ignored listing per whitelist
Dec  5 15:40:17.197: INFO: namespace e2e-tests-downward-api-jkgng deletion completed in 22.122321867s

• [SLOW TEST:28.754 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:40:17.199: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-10ac0dfd-f8a4-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 15:40:17.298: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-10acba6e-f8a4-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-fv599" to be "success or failure"
Dec  5 15:40:17.307: INFO: Pod "pod-projected-configmaps-10acba6e-f8a4-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 8.887703ms
Dec  5 15:40:19.311: INFO: Pod "pod-projected-configmaps-10acba6e-f8a4-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012355827s
STEP: Saw pod success
Dec  5 15:40:19.311: INFO: Pod "pod-projected-configmaps-10acba6e-f8a4-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:40:19.313: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-configmaps-10acba6e-f8a4-11e8-a7f8-ceaf58ef2674 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 15:40:19.331: INFO: Waiting for pod pod-projected-configmaps-10acba6e-f8a4-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:40:19.334: INFO: Pod pod-projected-configmaps-10acba6e-f8a4-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:40:19.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fv599" for this suite.
Dec  5 15:40:25.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:40:25.464: INFO: namespace: e2e-tests-projected-fv599, resource: bindings, ignored listing per whitelist
Dec  5 15:40:25.500: INFO: namespace e2e-tests-projected-fv599 deletion completed in 6.162974696s

• [SLOW TEST:8.301 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:40:25.503: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  5 15:40:25.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-tcjbf'
Dec  5 15:40:25.823: INFO: stderr: ""
Dec  5 15:40:25.823: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 15:40:25.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tcjbf'
Dec  5 15:40:25.949: INFO: stderr: ""
Dec  5 15:40:25.949: INFO: stdout: "update-demo-nautilus-v8nds update-demo-nautilus-xrhcw "
Dec  5 15:40:25.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-v8nds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tcjbf'
Dec  5 15:40:26.090: INFO: stderr: ""
Dec  5 15:40:26.090: INFO: stdout: ""
Dec  5 15:40:26.090: INFO: update-demo-nautilus-v8nds is created but not running
Dec  5 15:40:31.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tcjbf'
Dec  5 15:40:31.189: INFO: stderr: ""
Dec  5 15:40:31.189: INFO: stdout: "update-demo-nautilus-v8nds update-demo-nautilus-xrhcw "
Dec  5 15:40:31.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-v8nds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tcjbf'
Dec  5 15:40:31.285: INFO: stderr: ""
Dec  5 15:40:31.285: INFO: stdout: "true"
Dec  5 15:40:31.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-v8nds -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tcjbf'
Dec  5 15:40:31.380: INFO: stderr: ""
Dec  5 15:40:31.380: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 15:40:31.380: INFO: validating pod update-demo-nautilus-v8nds
Dec  5 15:40:31.389: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 15:40:31.389: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 15:40:31.389: INFO: update-demo-nautilus-v8nds is verified up and running
Dec  5 15:40:31.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-xrhcw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tcjbf'
Dec  5 15:40:31.484: INFO: stderr: ""
Dec  5 15:40:31.484: INFO: stdout: "true"
Dec  5 15:40:31.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-xrhcw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tcjbf'
Dec  5 15:40:31.584: INFO: stderr: ""
Dec  5 15:40:31.584: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 15:40:31.584: INFO: validating pod update-demo-nautilus-xrhcw
Dec  5 15:40:31.588: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 15:40:31.588: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 15:40:31.588: INFO: update-demo-nautilus-xrhcw is verified up and running
STEP: using delete to clean up resources
Dec  5 15:40:31.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tcjbf'
Dec  5 15:40:31.683: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 15:40:31.683: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  5 15:40:31.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-tcjbf'
Dec  5 15:40:31.875: INFO: stderr: "No resources found.\n"
Dec  5 15:40:31.875: INFO: stdout: ""
Dec  5 15:40:31.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -l name=update-demo --namespace=e2e-tests-kubectl-tcjbf -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 15:40:32.052: INFO: stderr: ""
Dec  5 15:40:32.052: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:40:32.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tcjbf" for this suite.
Dec  5 15:40:54.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:40:54.125: INFO: namespace: e2e-tests-kubectl-tcjbf, resource: bindings, ignored listing per whitelist
Dec  5 15:40:54.175: INFO: namespace e2e-tests-kubectl-tcjbf deletion completed in 22.116162804s

• [SLOW TEST:28.672 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:40:54.175: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 15:40:54.283: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"26b64c5d-f8a4-11e8-ab6c-06b570ab0412", Controller:(*bool)(0xc001117bbe), BlockOwnerDeletion:(*bool)(0xc001117bbf)}}
Dec  5 15:40:54.299: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"26b37c12-f8a4-11e8-ab6c-06b570ab0412", Controller:(*bool)(0xc000a0004e), BlockOwnerDeletion:(*bool)(0xc000a0004f)}}
Dec  5 15:40:54.322: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"26b4e438-f8a4-11e8-ab6c-06b570ab0412", Controller:(*bool)(0xc000a00bae), BlockOwnerDeletion:(*bool)(0xc000a00baf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:40:59.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k2vlb" for this suite.
Dec  5 15:41:05.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:41:05.386: INFO: namespace: e2e-tests-gc-k2vlb, resource: bindings, ignored listing per whitelist
Dec  5 15:41:05.468: INFO: namespace e2e-tests-gc-k2vlb deletion completed in 6.119779006s

• [SLOW TEST:11.293 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:41:05.470: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec  5 15:41:05.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 api-versions'
Dec  5 15:41:05.620: INFO: stderr: ""
Dec  5 15:41:05.620: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:41:05.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cxsp7" for this suite.
Dec  5 15:41:11.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:41:11.661: INFO: namespace: e2e-tests-kubectl-cxsp7, resource: bindings, ignored listing per whitelist
Dec  5 15:41:11.708: INFO: namespace e2e-tests-kubectl-cxsp7 deletion completed in 6.08436776s

• [SLOW TEST:6.238 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:41:11.711: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-312614a1-f8a4-11e8-a7f8-ceaf58ef2674
Dec  5 15:41:11.777: INFO: Pod name my-hostname-basic-312614a1-f8a4-11e8-a7f8-ceaf58ef2674: Found 0 pods out of 1
Dec  5 15:41:16.781: INFO: Pod name my-hostname-basic-312614a1-f8a4-11e8-a7f8-ceaf58ef2674: Found 1 pods out of 1
Dec  5 15:41:16.781: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-312614a1-f8a4-11e8-a7f8-ceaf58ef2674" are running
Dec  5 15:41:16.782: INFO: Pod "my-hostname-basic-312614a1-f8a4-11e8-a7f8-ceaf58ef2674-9v9z6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 15:41:11 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 15:41:15 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 15:41:15 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 15:41:11 +0000 UTC Reason: Message:}])
Dec  5 15:41:16.782: INFO: Trying to dial the pod
Dec  5 15:41:21.793: INFO: Controller my-hostname-basic-312614a1-f8a4-11e8-a7f8-ceaf58ef2674: Got expected result from replica 1 [my-hostname-basic-312614a1-f8a4-11e8-a7f8-ceaf58ef2674-9v9z6]: "my-hostname-basic-312614a1-f8a4-11e8-a7f8-ceaf58ef2674-9v9z6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:41:21.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-tnnhc" for this suite.
Dec  5 15:41:27.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:41:27.887: INFO: namespace: e2e-tests-replication-controller-tnnhc, resource: bindings, ignored listing per whitelist
Dec  5 15:41:27.889: INFO: namespace e2e-tests-replication-controller-tnnhc deletion completed in 6.08356257s

• [SLOW TEST:16.179 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:41:27.891: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 15:41:27.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3acc1d5e-f8a4-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-nv5rp" to be "success or failure"
Dec  5 15:41:27.971: INFO: Pod "downwardapi-volume-3acc1d5e-f8a4-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 3.811672ms
Dec  5 15:41:29.975: INFO: Pod "downwardapi-volume-3acc1d5e-f8a4-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00714863s
STEP: Saw pod success
Dec  5 15:41:29.975: INFO: Pod "downwardapi-volume-3acc1d5e-f8a4-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:41:29.976: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-3acc1d5e-f8a4-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 15:41:29.993: INFO: Waiting for pod downwardapi-volume-3acc1d5e-f8a4-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:41:29.996: INFO: Pod downwardapi-volume-3acc1d5e-f8a4-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:41:29.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nv5rp" for this suite.
Dec  5 15:41:36.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:41:36.050: INFO: namespace: e2e-tests-downward-api-nv5rp, resource: bindings, ignored listing per whitelist
Dec  5 15:41:36.088: INFO: namespace e2e-tests-downward-api-nv5rp deletion completed in 6.089046138s

• [SLOW TEST:8.197 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:41:36.089: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  5 15:41:40.202: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6cxl PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:41:40.202: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:41:40.296: INFO: Exec stderr: ""
Dec  5 15:41:40.296: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6cxl PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:41:40.296: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:41:40.393: INFO: Exec stderr: ""
Dec  5 15:41:40.394: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6cxl PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:41:40.394: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:41:40.483: INFO: Exec stderr: ""
Dec  5 15:41:40.483: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6cxl PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:41:40.483: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:41:40.582: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  5 15:41:40.582: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6cxl PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:41:40.582: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:41:40.689: INFO: Exec stderr: ""
Dec  5 15:41:40.689: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6cxl PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:41:40.689: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:41:40.777: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  5 15:41:40.777: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6cxl PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:41:40.777: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:41:40.861: INFO: Exec stderr: ""
Dec  5 15:41:40.861: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6cxl PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:41:40.861: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:41:40.961: INFO: Exec stderr: ""
Dec  5 15:41:40.961: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6cxl PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:41:40.961: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:41:41.052: INFO: Exec stderr: ""
Dec  5 15:41:41.053: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-v6cxl PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:41:41.053: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:41:41.141: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:41:41.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-v6cxl" for this suite.
Dec  5 15:42:27.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:42:27.202: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-v6cxl, resource: bindings, ignored listing per whitelist
Dec  5 15:42:27.230: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-v6cxl deletion completed in 46.085632789s

• [SLOW TEST:51.142 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:42:27.233: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 15:42:27.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 version'
Dec  5 15:42:27.374: INFO: stderr: ""
Dec  5 15:42:27.374: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T20:56:12Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:42:27.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8v6mt" for this suite.
Dec  5 15:42:33.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:42:33.427: INFO: namespace: e2e-tests-kubectl-8v6mt, resource: bindings, ignored listing per whitelist
Dec  5 15:42:33.459: INFO: namespace e2e-tests-kubectl-8v6mt deletion completed in 6.081836425s

• [SLOW TEST:6.227 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:42:33.463: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-l9szz
I1205 15:42:33.529074      13 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-l9szz, replica count: 1
I1205 15:42:34.579718      13 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 15:42:35.579973      13 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 15:42:35.692: INFO: Created: latency-svc-wf6dn
Dec  5 15:42:35.709: INFO: Got endpoints: latency-svc-wf6dn [29.723842ms]
Dec  5 15:42:35.744: INFO: Created: latency-svc-mcp4c
Dec  5 15:42:35.755: INFO: Created: latency-svc-wpljs
Dec  5 15:42:35.764: INFO: Got endpoints: latency-svc-mcp4c [53.896472ms]
Dec  5 15:42:35.767: INFO: Got endpoints: latency-svc-wpljs [56.557216ms]
Dec  5 15:42:35.779: INFO: Created: latency-svc-rvqg2
Dec  5 15:42:35.791: INFO: Created: latency-svc-27ldx
Dec  5 15:42:35.805: INFO: Got endpoints: latency-svc-rvqg2 [94.60635ms]
Dec  5 15:42:35.807: INFO: Created: latency-svc-xjrpl
Dec  5 15:42:35.830: INFO: Created: latency-svc-rkc8n
Dec  5 15:42:35.830: INFO: Got endpoints: latency-svc-xjrpl [117.210876ms]
Dec  5 15:42:35.830: INFO: Got endpoints: latency-svc-27ldx [119.889767ms]
Dec  5 15:42:35.848: INFO: Created: latency-svc-gnxbf
Dec  5 15:42:35.855: INFO: Got endpoints: latency-svc-rkc8n [144.879123ms]
Dec  5 15:42:35.866: INFO: Created: latency-svc-sgmm2
Dec  5 15:42:35.872: INFO: Got endpoints: latency-svc-gnxbf [161.387043ms]
Dec  5 15:42:35.880: INFO: Got endpoints: latency-svc-sgmm2 [75.018468ms]
Dec  5 15:42:35.888: INFO: Created: latency-svc-q8xv9
Dec  5 15:42:35.901: INFO: Created: latency-svc-w26nk
Dec  5 15:42:35.905: INFO: Got endpoints: latency-svc-q8xv9 [194.223082ms]
Dec  5 15:42:35.912: INFO: Got endpoints: latency-svc-w26nk [201.284555ms]
Dec  5 15:42:35.924: INFO: Created: latency-svc-f5tr7
Dec  5 15:42:35.933: INFO: Created: latency-svc-8pfp2
Dec  5 15:42:35.948: INFO: Got endpoints: latency-svc-8pfp2 [236.080165ms]
Dec  5 15:42:35.949: INFO: Got endpoints: latency-svc-f5tr7 [236.789073ms]
Dec  5 15:42:35.955: INFO: Created: latency-svc-bmvlx
Dec  5 15:42:35.971: INFO: Created: latency-svc-pdm72
Dec  5 15:42:35.977: INFO: Got endpoints: latency-svc-bmvlx [264.300195ms]
Dec  5 15:42:35.983: INFO: Got endpoints: latency-svc-pdm72 [270.958991ms]
Dec  5 15:42:35.994: INFO: Created: latency-svc-5g4fj
Dec  5 15:42:36.006: INFO: Created: latency-svc-btbcz
Dec  5 15:42:36.011: INFO: Got endpoints: latency-svc-5g4fj [298.113718ms]
Dec  5 15:42:36.020: INFO: Got endpoints: latency-svc-btbcz [308.325064ms]
Dec  5 15:42:36.029: INFO: Created: latency-svc-vzhh6
Dec  5 15:42:36.047: INFO: Got endpoints: latency-svc-vzhh6 [282.727743ms]
Dec  5 15:42:36.055: INFO: Created: latency-svc-dsrp6
Dec  5 15:42:36.075: INFO: Created: latency-svc-rrk5p
Dec  5 15:42:36.083: INFO: Created: latency-svc-7f9gk
Dec  5 15:42:36.083: INFO: Got endpoints: latency-svc-dsrp6 [315.784279ms]
Dec  5 15:42:36.102: INFO: Created: latency-svc-nrvcm
Dec  5 15:42:36.102: INFO: Got endpoints: latency-svc-7f9gk [271.298424ms]
Dec  5 15:42:36.102: INFO: Got endpoints: latency-svc-rrk5p [272.047111ms]
Dec  5 15:42:36.119: INFO: Got endpoints: latency-svc-nrvcm [263.622341ms]
Dec  5 15:42:36.122: INFO: Created: latency-svc-bvm4x
Dec  5 15:42:36.139: INFO: Created: latency-svc-5prjv
Dec  5 15:42:36.146: INFO: Got endpoints: latency-svc-5prjv [266.208821ms]
Dec  5 15:42:36.147: INFO: Got endpoints: latency-svc-bvm4x [274.722085ms]
Dec  5 15:42:36.159: INFO: Created: latency-svc-x4ktn
Dec  5 15:42:36.170: INFO: Created: latency-svc-s6bxn
Dec  5 15:42:36.173: INFO: Got endpoints: latency-svc-x4ktn [268.162621ms]
Dec  5 15:42:36.187: INFO: Created: latency-svc-sj59z
Dec  5 15:42:36.191: INFO: Got endpoints: latency-svc-s6bxn [278.718762ms]
Dec  5 15:42:36.203: INFO: Created: latency-svc-bgmzz
Dec  5 15:42:36.208: INFO: Got endpoints: latency-svc-sj59z [259.393744ms]
Dec  5 15:42:36.217: INFO: Got endpoints: latency-svc-bgmzz [268.737133ms]
Dec  5 15:42:36.225: INFO: Created: latency-svc-dswsx
Dec  5 15:42:36.241: INFO: Got endpoints: latency-svc-dswsx [264.028872ms]
Dec  5 15:42:36.243: INFO: Created: latency-svc-tqqbs
Dec  5 15:42:36.257: INFO: Got endpoints: latency-svc-tqqbs [273.221002ms]
Dec  5 15:42:36.260: INFO: Created: latency-svc-bw7b7
Dec  5 15:42:36.274: INFO: Created: latency-svc-nbdbr
Dec  5 15:42:36.279: INFO: Got endpoints: latency-svc-bw7b7 [267.833594ms]
Dec  5 15:42:36.284: INFO: Created: latency-svc-627m9
Dec  5 15:42:36.298: INFO: Got endpoints: latency-svc-627m9 [251.237215ms]
Dec  5 15:42:36.299: INFO: Got endpoints: latency-svc-nbdbr [277.97546ms]
Dec  5 15:42:36.309: INFO: Created: latency-svc-t79qm
Dec  5 15:42:36.322: INFO: Created: latency-svc-wpmbd
Dec  5 15:42:36.329: INFO: Got endpoints: latency-svc-t79qm [246.037879ms]
Dec  5 15:42:36.338: INFO: Created: latency-svc-ntcf2
Dec  5 15:42:36.354: INFO: Created: latency-svc-cprx6
Dec  5 15:42:36.354: INFO: Got endpoints: latency-svc-ntcf2 [252.129474ms]
Dec  5 15:42:36.355: INFO: Got endpoints: latency-svc-wpmbd [253.015785ms]
Dec  5 15:42:36.372: INFO: Got endpoints: latency-svc-cprx6 [252.685259ms]
Dec  5 15:42:36.373: INFO: Created: latency-svc-pd8kc
Dec  5 15:42:36.382: INFO: Got endpoints: latency-svc-pd8kc [234.870031ms]
Dec  5 15:42:36.392: INFO: Created: latency-svc-pnsqc
Dec  5 15:42:36.403: INFO: Created: latency-svc-tgs4d
Dec  5 15:42:36.414: INFO: Got endpoints: latency-svc-pnsqc [266.629013ms]
Dec  5 15:42:36.422: INFO: Got endpoints: latency-svc-tgs4d [248.533984ms]
Dec  5 15:42:36.428: INFO: Created: latency-svc-zpprk
Dec  5 15:42:36.440: INFO: Created: latency-svc-vskcn
Dec  5 15:42:36.448: INFO: Got endpoints: latency-svc-zpprk [256.763585ms]
Dec  5 15:42:36.451: INFO: Got endpoints: latency-svc-vskcn [243.319128ms]
Dec  5 15:42:36.465: INFO: Created: latency-svc-k68tz
Dec  5 15:42:36.478: INFO: Created: latency-svc-59qjp
Dec  5 15:42:36.491: INFO: Created: latency-svc-klzrw
Dec  5 15:42:36.493: INFO: Got endpoints: latency-svc-59qjp [251.452776ms]
Dec  5 15:42:36.493: INFO: Got endpoints: latency-svc-k68tz [275.371546ms]
Dec  5 15:42:36.505: INFO: Got endpoints: latency-svc-klzrw [247.500461ms]
Dec  5 15:42:36.513: INFO: Created: latency-svc-9kd6h
Dec  5 15:42:36.527: INFO: Created: latency-svc-rvjnq
Dec  5 15:42:36.532: INFO: Got endpoints: latency-svc-9kd6h [253.102606ms]
Dec  5 15:42:36.548: INFO: Created: latency-svc-zmphv
Dec  5 15:42:36.563: INFO: Created: latency-svc-w85z7
Dec  5 15:42:36.569: INFO: Got endpoints: latency-svc-rvjnq [270.755916ms]
Dec  5 15:42:36.577: INFO: Created: latency-svc-8298q
Dec  5 15:42:36.599: INFO: Created: latency-svc-rkcpg
Dec  5 15:42:36.612: INFO: Got endpoints: latency-svc-zmphv [313.286327ms]
Dec  5 15:42:36.618: INFO: Created: latency-svc-fhwp9
Dec  5 15:42:36.631: INFO: Created: latency-svc-cm8cq
Dec  5 15:42:36.641: INFO: Created: latency-svc-mvvgh
Dec  5 15:42:36.651: INFO: Created: latency-svc-tk99d
Dec  5 15:42:36.660: INFO: Got endpoints: latency-svc-w85z7 [330.933062ms]
Dec  5 15:42:36.668: INFO: Created: latency-svc-2lbnr
Dec  5 15:42:36.677: INFO: Created: latency-svc-62lqq
Dec  5 15:42:36.684: INFO: Created: latency-svc-wrjgq
Dec  5 15:42:36.693: INFO: Created: latency-svc-v9dw9
Dec  5 15:42:36.704: INFO: Created: latency-svc-7dbvx
Dec  5 15:42:36.711: INFO: Got endpoints: latency-svc-8298q [356.774422ms]
Dec  5 15:42:36.723: INFO: Created: latency-svc-ht7fr
Dec  5 15:42:36.732: INFO: Created: latency-svc-5qcm6
Dec  5 15:42:36.740: INFO: Created: latency-svc-hfz7l
Dec  5 15:42:36.748: INFO: Created: latency-svc-dzzct
Dec  5 15:42:36.758: INFO: Created: latency-svc-mft8l
Dec  5 15:42:36.761: INFO: Got endpoints: latency-svc-rkcpg [405.486126ms]
Dec  5 15:42:36.774: INFO: Created: latency-svc-clppc
Dec  5 15:42:36.799: INFO: Got endpoints: latency-svc-fhwp9 [426.941547ms]
Dec  5 15:42:36.814: INFO: Created: latency-svc-h5fmm
Dec  5 15:42:36.857: INFO: Got endpoints: latency-svc-cm8cq [475.361864ms]
Dec  5 15:42:36.883: INFO: Created: latency-svc-bjdkk
Dec  5 15:42:36.902: INFO: Got endpoints: latency-svc-mvvgh [487.787108ms]
Dec  5 15:42:36.918: INFO: Created: latency-svc-dc9qq
Dec  5 15:42:36.952: INFO: Got endpoints: latency-svc-tk99d [529.599889ms]
Dec  5 15:42:36.971: INFO: Created: latency-svc-6mjv6
Dec  5 15:42:37.015: INFO: Got endpoints: latency-svc-2lbnr [566.887607ms]
Dec  5 15:42:37.038: INFO: Created: latency-svc-tzlcb
Dec  5 15:42:37.055: INFO: Got endpoints: latency-svc-62lqq [603.896649ms]
Dec  5 15:42:37.080: INFO: Created: latency-svc-tlrcl
Dec  5 15:42:37.103: INFO: Got endpoints: latency-svc-wrjgq [610.472657ms]
Dec  5 15:42:37.118: INFO: Created: latency-svc-d6vxc
Dec  5 15:42:37.150: INFO: Got endpoints: latency-svc-v9dw9 [656.981263ms]
Dec  5 15:42:37.170: INFO: Created: latency-svc-twqmk
Dec  5 15:42:37.198: INFO: Got endpoints: latency-svc-7dbvx [693.447378ms]
Dec  5 15:42:37.219: INFO: Created: latency-svc-wsjqw
Dec  5 15:42:37.254: INFO: Got endpoints: latency-svc-ht7fr [721.933152ms]
Dec  5 15:42:37.269: INFO: Created: latency-svc-c9f7w
Dec  5 15:42:37.301: INFO: Got endpoints: latency-svc-5qcm6 [731.804636ms]
Dec  5 15:42:37.317: INFO: Created: latency-svc-cvn6g
Dec  5 15:42:37.352: INFO: Got endpoints: latency-svc-hfz7l [739.891665ms]
Dec  5 15:42:37.367: INFO: Created: latency-svc-zz5k6
Dec  5 15:42:37.403: INFO: Got endpoints: latency-svc-dzzct [742.982818ms]
Dec  5 15:42:37.415: INFO: Created: latency-svc-lv9lm
Dec  5 15:42:37.451: INFO: Got endpoints: latency-svc-mft8l [739.680443ms]
Dec  5 15:42:37.464: INFO: Created: latency-svc-zlmf5
Dec  5 15:42:37.503: INFO: Got endpoints: latency-svc-clppc [742.512912ms]
Dec  5 15:42:37.525: INFO: Created: latency-svc-h4682
Dec  5 15:42:37.552: INFO: Got endpoints: latency-svc-h5fmm [752.814686ms]
Dec  5 15:42:37.564: INFO: Created: latency-svc-jrp4g
Dec  5 15:42:37.602: INFO: Got endpoints: latency-svc-bjdkk [744.995732ms]
Dec  5 15:42:37.615: INFO: Created: latency-svc-6d2wp
Dec  5 15:42:37.657: INFO: Got endpoints: latency-svc-dc9qq [755.119943ms]
Dec  5 15:42:37.672: INFO: Created: latency-svc-nxfct
Dec  5 15:42:37.700: INFO: Got endpoints: latency-svc-6mjv6 [748.016624ms]
Dec  5 15:42:37.716: INFO: Created: latency-svc-kjj8q
Dec  5 15:42:37.751: INFO: Got endpoints: latency-svc-tzlcb [735.955553ms]
Dec  5 15:42:37.763: INFO: Created: latency-svc-kr4k7
Dec  5 15:42:37.802: INFO: Got endpoints: latency-svc-tlrcl [746.90926ms]
Dec  5 15:42:37.817: INFO: Created: latency-svc-bnqsc
Dec  5 15:42:37.852: INFO: Got endpoints: latency-svc-d6vxc [748.924526ms]
Dec  5 15:42:37.868: INFO: Created: latency-svc-nf7fs
Dec  5 15:42:37.902: INFO: Got endpoints: latency-svc-twqmk [751.660818ms]
Dec  5 15:42:37.916: INFO: Created: latency-svc-rls8z
Dec  5 15:42:37.951: INFO: Got endpoints: latency-svc-wsjqw [753.002687ms]
Dec  5 15:42:37.962: INFO: Created: latency-svc-dh7fw
Dec  5 15:42:38.003: INFO: Got endpoints: latency-svc-c9f7w [748.499554ms]
Dec  5 15:42:38.017: INFO: Created: latency-svc-zbj5b
Dec  5 15:42:38.051: INFO: Got endpoints: latency-svc-cvn6g [749.957099ms]
Dec  5 15:42:38.065: INFO: Created: latency-svc-8p9gs
Dec  5 15:42:38.101: INFO: Got endpoints: latency-svc-zz5k6 [749.108802ms]
Dec  5 15:42:38.115: INFO: Created: latency-svc-crv49
Dec  5 15:42:38.151: INFO: Got endpoints: latency-svc-lv9lm [748.110609ms]
Dec  5 15:42:38.167: INFO: Created: latency-svc-mm7db
Dec  5 15:42:38.202: INFO: Got endpoints: latency-svc-zlmf5 [750.369799ms]
Dec  5 15:42:38.214: INFO: Created: latency-svc-qnj4l
Dec  5 15:42:38.251: INFO: Got endpoints: latency-svc-h4682 [747.530669ms]
Dec  5 15:42:38.267: INFO: Created: latency-svc-4rjj6
Dec  5 15:42:38.302: INFO: Got endpoints: latency-svc-jrp4g [749.731542ms]
Dec  5 15:42:38.316: INFO: Created: latency-svc-rrpt6
Dec  5 15:42:38.353: INFO: Got endpoints: latency-svc-6d2wp [750.048206ms]
Dec  5 15:42:38.368: INFO: Created: latency-svc-v87cv
Dec  5 15:42:38.403: INFO: Got endpoints: latency-svc-nxfct [745.408128ms]
Dec  5 15:42:38.416: INFO: Created: latency-svc-lxxfv
Dec  5 15:42:38.449: INFO: Got endpoints: latency-svc-kjj8q [748.815038ms]
Dec  5 15:42:38.486: INFO: Created: latency-svc-cllnz
Dec  5 15:42:38.534: INFO: Got endpoints: latency-svc-kr4k7 [782.775933ms]
Dec  5 15:42:38.559: INFO: Created: latency-svc-42mrv
Dec  5 15:42:38.561: INFO: Got endpoints: latency-svc-bnqsc [758.900664ms]
Dec  5 15:42:38.576: INFO: Created: latency-svc-87fck
Dec  5 15:42:38.602: INFO: Got endpoints: latency-svc-nf7fs [749.654581ms]
Dec  5 15:42:38.620: INFO: Created: latency-svc-tt9fh
Dec  5 15:42:38.649: INFO: Got endpoints: latency-svc-rls8z [746.572001ms]
Dec  5 15:42:38.665: INFO: Created: latency-svc-2lsgr
Dec  5 15:42:38.701: INFO: Got endpoints: latency-svc-dh7fw [749.18322ms]
Dec  5 15:42:38.719: INFO: Created: latency-svc-jr4vw
Dec  5 15:42:38.749: INFO: Got endpoints: latency-svc-zbj5b [745.546078ms]
Dec  5 15:42:38.763: INFO: Created: latency-svc-tv5vz
Dec  5 15:42:38.803: INFO: Got endpoints: latency-svc-8p9gs [751.227467ms]
Dec  5 15:42:38.817: INFO: Created: latency-svc-6jbvh
Dec  5 15:42:38.864: INFO: Got endpoints: latency-svc-crv49 [762.379873ms]
Dec  5 15:42:38.889: INFO: Created: latency-svc-vrzm7
Dec  5 15:42:38.901: INFO: Got endpoints: latency-svc-mm7db [749.148256ms]
Dec  5 15:42:38.914: INFO: Created: latency-svc-b7hhj
Dec  5 15:42:38.951: INFO: Got endpoints: latency-svc-qnj4l [749.388706ms]
Dec  5 15:42:38.967: INFO: Created: latency-svc-8slwn
Dec  5 15:42:38.999: INFO: Got endpoints: latency-svc-4rjj6 [748.17516ms]
Dec  5 15:42:39.016: INFO: Created: latency-svc-nb5sd
Dec  5 15:42:39.050: INFO: Got endpoints: latency-svc-rrpt6 [747.193596ms]
Dec  5 15:42:39.064: INFO: Created: latency-svc-rm6rw
Dec  5 15:42:39.110: INFO: Got endpoints: latency-svc-v87cv [757.387084ms]
Dec  5 15:42:39.124: INFO: Created: latency-svc-kzznj
Dec  5 15:42:39.153: INFO: Got endpoints: latency-svc-lxxfv [750.148737ms]
Dec  5 15:42:39.167: INFO: Created: latency-svc-4xs9b
Dec  5 15:42:39.205: INFO: Got endpoints: latency-svc-cllnz [755.206552ms]
Dec  5 15:42:39.220: INFO: Created: latency-svc-899gh
Dec  5 15:42:39.254: INFO: Got endpoints: latency-svc-42mrv [719.488953ms]
Dec  5 15:42:39.268: INFO: Created: latency-svc-bqxfs
Dec  5 15:42:39.303: INFO: Got endpoints: latency-svc-87fck [741.448725ms]
Dec  5 15:42:39.316: INFO: Created: latency-svc-r82xp
Dec  5 15:42:39.350: INFO: Got endpoints: latency-svc-tt9fh [747.121674ms]
Dec  5 15:42:39.365: INFO: Created: latency-svc-b74jq
Dec  5 15:42:39.403: INFO: Got endpoints: latency-svc-2lsgr [753.88868ms]
Dec  5 15:42:39.419: INFO: Created: latency-svc-wt6gq
Dec  5 15:42:39.450: INFO: Got endpoints: latency-svc-jr4vw [748.944912ms]
Dec  5 15:42:39.465: INFO: Created: latency-svc-mhmgw
Dec  5 15:42:39.502: INFO: Got endpoints: latency-svc-tv5vz [753.284854ms]
Dec  5 15:42:39.521: INFO: Created: latency-svc-lx4gk
Dec  5 15:42:39.552: INFO: Got endpoints: latency-svc-6jbvh [749.321897ms]
Dec  5 15:42:39.564: INFO: Created: latency-svc-kqzmx
Dec  5 15:42:39.601: INFO: Got endpoints: latency-svc-vrzm7 [737.257738ms]
Dec  5 15:42:39.618: INFO: Created: latency-svc-6cpv7
Dec  5 15:42:39.651: INFO: Got endpoints: latency-svc-b7hhj [749.879968ms]
Dec  5 15:42:39.666: INFO: Created: latency-svc-jk68s
Dec  5 15:42:39.702: INFO: Got endpoints: latency-svc-8slwn [750.714971ms]
Dec  5 15:42:39.717: INFO: Created: latency-svc-5mw8b
Dec  5 15:42:39.751: INFO: Got endpoints: latency-svc-nb5sd [751.536322ms]
Dec  5 15:42:39.764: INFO: Created: latency-svc-txwrm
Dec  5 15:42:39.803: INFO: Got endpoints: latency-svc-rm6rw [753.473919ms]
Dec  5 15:42:39.817: INFO: Created: latency-svc-htvqt
Dec  5 15:42:39.850: INFO: Got endpoints: latency-svc-kzznj [739.633602ms]
Dec  5 15:42:39.864: INFO: Created: latency-svc-jpjl6
Dec  5 15:42:39.903: INFO: Got endpoints: latency-svc-4xs9b [749.361848ms]
Dec  5 15:42:39.918: INFO: Created: latency-svc-5bp44
Dec  5 15:42:39.953: INFO: Got endpoints: latency-svc-899gh [748.351979ms]
Dec  5 15:42:39.968: INFO: Created: latency-svc-vjllk
Dec  5 15:42:40.003: INFO: Got endpoints: latency-svc-bqxfs [749.091912ms]
Dec  5 15:42:40.020: INFO: Created: latency-svc-kx7fk
Dec  5 15:42:40.053: INFO: Got endpoints: latency-svc-r82xp [749.342753ms]
Dec  5 15:42:40.070: INFO: Created: latency-svc-4z8sv
Dec  5 15:42:40.100: INFO: Got endpoints: latency-svc-b74jq [750.464146ms]
Dec  5 15:42:40.134: INFO: Created: latency-svc-5s92c
Dec  5 15:42:40.152: INFO: Got endpoints: latency-svc-wt6gq [749.144343ms]
Dec  5 15:42:40.167: INFO: Created: latency-svc-bxsjn
Dec  5 15:42:40.201: INFO: Got endpoints: latency-svc-mhmgw [750.819861ms]
Dec  5 15:42:40.219: INFO: Created: latency-svc-lschm
Dec  5 15:42:40.250: INFO: Got endpoints: latency-svc-lx4gk [747.869171ms]
Dec  5 15:42:40.266: INFO: Created: latency-svc-sh2g5
Dec  5 15:42:40.303: INFO: Got endpoints: latency-svc-kqzmx [750.561728ms]
Dec  5 15:42:40.316: INFO: Created: latency-svc-6t9ns
Dec  5 15:42:40.349: INFO: Got endpoints: latency-svc-6cpv7 [747.119251ms]
Dec  5 15:42:40.365: INFO: Created: latency-svc-ss79s
Dec  5 15:42:40.402: INFO: Got endpoints: latency-svc-jk68s [751.295045ms]
Dec  5 15:42:40.417: INFO: Created: latency-svc-m8xrl
Dec  5 15:42:40.451: INFO: Got endpoints: latency-svc-5mw8b [748.586343ms]
Dec  5 15:42:40.467: INFO: Created: latency-svc-pl67q
Dec  5 15:42:40.503: INFO: Got endpoints: latency-svc-txwrm [751.187861ms]
Dec  5 15:42:40.517: INFO: Created: latency-svc-wvdjn
Dec  5 15:42:40.553: INFO: Got endpoints: latency-svc-htvqt [749.410491ms]
Dec  5 15:42:40.567: INFO: Created: latency-svc-vxjw8
Dec  5 15:42:40.601: INFO: Got endpoints: latency-svc-jpjl6 [750.790845ms]
Dec  5 15:42:40.617: INFO: Created: latency-svc-7drfb
Dec  5 15:42:40.657: INFO: Got endpoints: latency-svc-5bp44 [753.757386ms]
Dec  5 15:42:40.709: INFO: Got endpoints: latency-svc-vjllk [755.796611ms]
Dec  5 15:42:40.710: INFO: Created: latency-svc-d5nwd
Dec  5 15:42:40.723: INFO: Created: latency-svc-jh4bd
Dec  5 15:42:40.752: INFO: Got endpoints: latency-svc-kx7fk [748.681798ms]
Dec  5 15:42:40.767: INFO: Created: latency-svc-h2k2c
Dec  5 15:42:40.805: INFO: Got endpoints: latency-svc-4z8sv [752.325033ms]
Dec  5 15:42:40.827: INFO: Created: latency-svc-mzh8b
Dec  5 15:42:40.854: INFO: Got endpoints: latency-svc-5s92c [753.874172ms]
Dec  5 15:42:40.874: INFO: Created: latency-svc-b9cwk
Dec  5 15:42:40.907: INFO: Got endpoints: latency-svc-bxsjn [754.753584ms]
Dec  5 15:42:40.921: INFO: Created: latency-svc-h5tsp
Dec  5 15:42:40.952: INFO: Got endpoints: latency-svc-lschm [750.563345ms]
Dec  5 15:42:40.968: INFO: Created: latency-svc-b4pd2
Dec  5 15:42:41.000: INFO: Got endpoints: latency-svc-sh2g5 [749.639727ms]
Dec  5 15:42:41.019: INFO: Created: latency-svc-twzfz
Dec  5 15:42:41.052: INFO: Got endpoints: latency-svc-6t9ns [748.849744ms]
Dec  5 15:42:41.070: INFO: Created: latency-svc-s2mhk
Dec  5 15:42:41.109: INFO: Got endpoints: latency-svc-ss79s [760.25587ms]
Dec  5 15:42:41.124: INFO: Created: latency-svc-vgvkn
Dec  5 15:42:41.150: INFO: Got endpoints: latency-svc-m8xrl [747.38435ms]
Dec  5 15:42:41.164: INFO: Created: latency-svc-fh5gd
Dec  5 15:42:41.203: INFO: Got endpoints: latency-svc-pl67q [751.706718ms]
Dec  5 15:42:41.221: INFO: Created: latency-svc-xdgbh
Dec  5 15:42:41.253: INFO: Got endpoints: latency-svc-wvdjn [750.307484ms]
Dec  5 15:42:41.267: INFO: Created: latency-svc-lrxgd
Dec  5 15:42:41.302: INFO: Got endpoints: latency-svc-vxjw8 [749.505893ms]
Dec  5 15:42:41.319: INFO: Created: latency-svc-wtnmm
Dec  5 15:42:41.350: INFO: Got endpoints: latency-svc-7drfb [748.640514ms]
Dec  5 15:42:41.365: INFO: Created: latency-svc-n7h7r
Dec  5 15:42:41.401: INFO: Got endpoints: latency-svc-d5nwd [744.072018ms]
Dec  5 15:42:41.418: INFO: Created: latency-svc-t2k6j
Dec  5 15:42:41.451: INFO: Got endpoints: latency-svc-jh4bd [741.334198ms]
Dec  5 15:42:41.464: INFO: Created: latency-svc-rzt8b
Dec  5 15:42:41.502: INFO: Got endpoints: latency-svc-h2k2c [749.415211ms]
Dec  5 15:42:41.517: INFO: Created: latency-svc-gvbm6
Dec  5 15:42:41.550: INFO: Got endpoints: latency-svc-mzh8b [744.708655ms]
Dec  5 15:42:41.564: INFO: Created: latency-svc-vfhms
Dec  5 15:42:41.612: INFO: Got endpoints: latency-svc-b9cwk [757.45721ms]
Dec  5 15:42:41.626: INFO: Created: latency-svc-mvrmw
Dec  5 15:42:41.652: INFO: Got endpoints: latency-svc-h5tsp [744.44243ms]
Dec  5 15:42:41.667: INFO: Created: latency-svc-bpjhl
Dec  5 15:42:41.700: INFO: Got endpoints: latency-svc-b4pd2 [748.374448ms]
Dec  5 15:42:41.722: INFO: Created: latency-svc-mqhjx
Dec  5 15:42:41.751: INFO: Got endpoints: latency-svc-twzfz [751.098174ms]
Dec  5 15:42:41.765: INFO: Created: latency-svc-4j5w7
Dec  5 15:42:41.803: INFO: Got endpoints: latency-svc-s2mhk [750.960497ms]
Dec  5 15:42:41.819: INFO: Created: latency-svc-9kwt8
Dec  5 15:42:41.852: INFO: Got endpoints: latency-svc-vgvkn [742.788276ms]
Dec  5 15:42:41.867: INFO: Created: latency-svc-b4w94
Dec  5 15:42:41.901: INFO: Got endpoints: latency-svc-fh5gd [751.031535ms]
Dec  5 15:42:41.915: INFO: Created: latency-svc-mlpnp
Dec  5 15:42:41.951: INFO: Got endpoints: latency-svc-xdgbh [748.055402ms]
Dec  5 15:42:41.968: INFO: Created: latency-svc-vwbxl
Dec  5 15:42:42.003: INFO: Got endpoints: latency-svc-lrxgd [749.809932ms]
Dec  5 15:42:42.019: INFO: Created: latency-svc-fpsz6
Dec  5 15:42:42.050: INFO: Got endpoints: latency-svc-wtnmm [747.096543ms]
Dec  5 15:42:42.065: INFO: Created: latency-svc-kvskt
Dec  5 15:42:42.118: INFO: Got endpoints: latency-svc-n7h7r [767.552043ms]
Dec  5 15:42:42.136: INFO: Created: latency-svc-jg9dd
Dec  5 15:42:42.162: INFO: Got endpoints: latency-svc-t2k6j [760.966305ms]
Dec  5 15:42:42.176: INFO: Created: latency-svc-7qgmt
Dec  5 15:42:42.205: INFO: Got endpoints: latency-svc-rzt8b [754.140001ms]
Dec  5 15:42:42.220: INFO: Created: latency-svc-rwjzx
Dec  5 15:42:42.251: INFO: Got endpoints: latency-svc-gvbm6 [749.42337ms]
Dec  5 15:42:42.266: INFO: Created: latency-svc-9sgd9
Dec  5 15:42:42.300: INFO: Got endpoints: latency-svc-vfhms [749.594783ms]
Dec  5 15:42:42.318: INFO: Created: latency-svc-6nd6p
Dec  5 15:42:42.350: INFO: Got endpoints: latency-svc-mvrmw [737.570346ms]
Dec  5 15:42:42.367: INFO: Created: latency-svc-vrltk
Dec  5 15:42:42.403: INFO: Got endpoints: latency-svc-bpjhl [751.644287ms]
Dec  5 15:42:42.419: INFO: Created: latency-svc-rxjlv
Dec  5 15:42:42.453: INFO: Got endpoints: latency-svc-mqhjx [752.448175ms]
Dec  5 15:42:42.468: INFO: Created: latency-svc-sc6fb
Dec  5 15:42:42.502: INFO: Got endpoints: latency-svc-4j5w7 [750.538959ms]
Dec  5 15:42:42.519: INFO: Created: latency-svc-bjflv
Dec  5 15:42:42.551: INFO: Got endpoints: latency-svc-9kwt8 [747.803984ms]
Dec  5 15:42:42.562: INFO: Created: latency-svc-d9nrl
Dec  5 15:42:42.601: INFO: Got endpoints: latency-svc-b4w94 [748.834947ms]
Dec  5 15:42:42.618: INFO: Created: latency-svc-kzzv2
Dec  5 15:42:42.649: INFO: Got endpoints: latency-svc-mlpnp [747.790044ms]
Dec  5 15:42:42.676: INFO: Created: latency-svc-sgxxq
Dec  5 15:42:42.702: INFO: Got endpoints: latency-svc-vwbxl [750.60768ms]
Dec  5 15:42:42.716: INFO: Created: latency-svc-lszfz
Dec  5 15:42:42.752: INFO: Got endpoints: latency-svc-fpsz6 [748.788064ms]
Dec  5 15:42:42.766: INFO: Created: latency-svc-d4pj8
Dec  5 15:42:42.803: INFO: Got endpoints: latency-svc-kvskt [752.948993ms]
Dec  5 15:42:42.815: INFO: Created: latency-svc-4t24v
Dec  5 15:42:42.863: INFO: Got endpoints: latency-svc-jg9dd [745.533953ms]
Dec  5 15:42:42.893: INFO: Created: latency-svc-jwsrq
Dec  5 15:42:42.914: INFO: Got endpoints: latency-svc-7qgmt [750.983786ms]
Dec  5 15:42:42.939: INFO: Created: latency-svc-tlrjc
Dec  5 15:42:42.952: INFO: Got endpoints: latency-svc-rwjzx [746.905187ms]
Dec  5 15:42:42.965: INFO: Created: latency-svc-thndb
Dec  5 15:42:43.002: INFO: Got endpoints: latency-svc-9sgd9 [750.998525ms]
Dec  5 15:42:43.018: INFO: Created: latency-svc-dbs7k
Dec  5 15:42:43.094: INFO: Got endpoints: latency-svc-6nd6p [793.963839ms]
Dec  5 15:42:43.120: INFO: Got endpoints: latency-svc-vrltk [769.971733ms]
Dec  5 15:42:43.144: INFO: Created: latency-svc-7pfvq
Dec  5 15:42:43.166: INFO: Created: latency-svc-2sm7t
Dec  5 15:42:43.174: INFO: Got endpoints: latency-svc-rxjlv [770.419179ms]
Dec  5 15:42:43.218: INFO: Created: latency-svc-989bf
Dec  5 15:42:43.220: INFO: Got endpoints: latency-svc-sc6fb [767.03273ms]
Dec  5 15:42:43.256: INFO: Created: latency-svc-zqzxm
Dec  5 15:42:43.270: INFO: Got endpoints: latency-svc-bjflv [767.91214ms]
Dec  5 15:42:43.309: INFO: Created: latency-svc-q2kzs
Dec  5 15:42:43.362: INFO: Got endpoints: latency-svc-d9nrl [810.290795ms]
Dec  5 15:42:43.400: INFO: Got endpoints: latency-svc-kzzv2 [799.033403ms]
Dec  5 15:42:43.434: INFO: Created: latency-svc-zclh4
Dec  5 15:42:43.459: INFO: Got endpoints: latency-svc-sgxxq [809.920179ms]
Dec  5 15:42:43.468: INFO: Created: latency-svc-kvh42
Dec  5 15:42:43.518: INFO: Got endpoints: latency-svc-lszfz [815.69858ms]
Dec  5 15:42:43.530: INFO: Created: latency-svc-tst5d
Dec  5 15:42:43.573: INFO: Got endpoints: latency-svc-d4pj8 [820.50941ms]
Dec  5 15:42:43.586: INFO: Got endpoints: latency-svc-4t24v [782.931037ms]
Dec  5 15:42:43.611: INFO: Created: latency-svc-wc4sq
Dec  5 15:42:43.638: INFO: Got endpoints: latency-svc-jwsrq [774.618495ms]
Dec  5 15:42:43.659: INFO: Created: latency-svc-kr97r
Dec  5 15:42:43.688: INFO: Got endpoints: latency-svc-tlrjc [773.715428ms]
Dec  5 15:42:43.714: INFO: Got endpoints: latency-svc-thndb [761.487562ms]
Dec  5 15:42:43.769: INFO: Got endpoints: latency-svc-dbs7k [766.584865ms]
Dec  5 15:42:43.823: INFO: Got endpoints: latency-svc-7pfvq [729.21175ms]
Dec  5 15:42:43.870: INFO: Got endpoints: latency-svc-2sm7t [749.73817ms]
Dec  5 15:42:43.902: INFO: Got endpoints: latency-svc-989bf [727.892466ms]
Dec  5 15:42:43.951: INFO: Got endpoints: latency-svc-zqzxm [730.673066ms]
Dec  5 15:42:44.003: INFO: Got endpoints: latency-svc-q2kzs [732.986016ms]
Dec  5 15:42:44.099: INFO: Got endpoints: latency-svc-zclh4 [737.310281ms]
Dec  5 15:42:44.160: INFO: Got endpoints: latency-svc-kvh42 [759.589357ms]
Dec  5 15:42:44.218: INFO: Got endpoints: latency-svc-tst5d [758.353799ms]
Dec  5 15:42:44.220: INFO: Got endpoints: latency-svc-wc4sq [701.373256ms]
Dec  5 15:42:44.265: INFO: Got endpoints: latency-svc-kr97r [692.025308ms]
Dec  5 15:42:44.265: INFO: Latencies: [53.896472ms 56.557216ms 75.018468ms 94.60635ms 117.210876ms 119.889767ms 144.879123ms 161.387043ms 194.223082ms 201.284555ms 234.870031ms 236.080165ms 236.789073ms 243.319128ms 246.037879ms 247.500461ms 248.533984ms 251.237215ms 251.452776ms 252.129474ms 252.685259ms 253.015785ms 253.102606ms 256.763585ms 259.393744ms 263.622341ms 264.028872ms 264.300195ms 266.208821ms 266.629013ms 267.833594ms 268.162621ms 268.737133ms 270.755916ms 270.958991ms 271.298424ms 272.047111ms 273.221002ms 274.722085ms 275.371546ms 277.97546ms 278.718762ms 282.727743ms 298.113718ms 308.325064ms 313.286327ms 315.784279ms 330.933062ms 356.774422ms 405.486126ms 426.941547ms 475.361864ms 487.787108ms 529.599889ms 566.887607ms 603.896649ms 610.472657ms 656.981263ms 692.025308ms 693.447378ms 701.373256ms 719.488953ms 721.933152ms 727.892466ms 729.21175ms 730.673066ms 731.804636ms 732.986016ms 735.955553ms 737.257738ms 737.310281ms 737.570346ms 739.633602ms 739.680443ms 739.891665ms 741.334198ms 741.448725ms 742.512912ms 742.788276ms 742.982818ms 744.072018ms 744.44243ms 744.708655ms 744.995732ms 745.408128ms 745.533953ms 745.546078ms 746.572001ms 746.905187ms 746.90926ms 747.096543ms 747.119251ms 747.121674ms 747.193596ms 747.38435ms 747.530669ms 747.790044ms 747.803984ms 747.869171ms 748.016624ms 748.055402ms 748.110609ms 748.17516ms 748.351979ms 748.374448ms 748.499554ms 748.586343ms 748.640514ms 748.681798ms 748.788064ms 748.815038ms 748.834947ms 748.849744ms 748.924526ms 748.944912ms 749.091912ms 749.108802ms 749.144343ms 749.148256ms 749.18322ms 749.321897ms 749.342753ms 749.361848ms 749.388706ms 749.410491ms 749.415211ms 749.42337ms 749.505893ms 749.594783ms 749.639727ms 749.654581ms 749.731542ms 749.73817ms 749.809932ms 749.879968ms 749.957099ms 750.048206ms 750.148737ms 750.307484ms 750.369799ms 750.464146ms 750.538959ms 750.561728ms 750.563345ms 750.60768ms 750.714971ms 750.790845ms 750.819861ms 750.960497ms 750.983786ms 750.998525ms 751.031535ms 751.098174ms 751.187861ms 751.227467ms 751.295045ms 751.536322ms 751.644287ms 751.660818ms 751.706718ms 752.325033ms 752.448175ms 752.814686ms 752.948993ms 753.002687ms 753.284854ms 753.473919ms 753.757386ms 753.874172ms 753.88868ms 754.140001ms 754.753584ms 755.119943ms 755.206552ms 755.796611ms 757.387084ms 757.45721ms 758.353799ms 758.900664ms 759.589357ms 760.25587ms 760.966305ms 761.487562ms 762.379873ms 766.584865ms 767.03273ms 767.552043ms 767.91214ms 769.971733ms 770.419179ms 773.715428ms 774.618495ms 782.775933ms 782.931037ms 793.963839ms 799.033403ms 809.920179ms 810.290795ms 815.69858ms 820.50941ms]
Dec  5 15:42:44.266: INFO: 50 %ile: 748.055402ms
Dec  5 15:42:44.266: INFO: 90 %ile: 760.25587ms
Dec  5 15:42:44.266: INFO: 99 %ile: 815.69858ms
Dec  5 15:42:44.266: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:42:44.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-l9szz" for this suite.
Dec  5 15:43:04.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:43:04.366: INFO: namespace: e2e-tests-svc-latency-l9szz, resource: bindings, ignored listing per whitelist
Dec  5 15:43:04.376: INFO: namespace e2e-tests-svc-latency-l9szz deletion completed in 20.097860383s

• [SLOW TEST:30.913 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:43:04.378: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-gfsld/configmap-test-744ebf6a-f8a4-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 15:43:04.454: INFO: Waiting up to 5m0s for pod "pod-configmaps-744f526d-f8a4-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-configmap-gfsld" to be "success or failure"
Dec  5 15:43:04.461: INFO: Pod "pod-configmaps-744f526d-f8a4-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.308563ms
Dec  5 15:43:06.464: INFO: Pod "pod-configmaps-744f526d-f8a4-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009650489s
STEP: Saw pod success
Dec  5 15:43:06.464: INFO: Pod "pod-configmaps-744f526d-f8a4-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:43:06.467: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-configmaps-744f526d-f8a4-11e8-a7f8-ceaf58ef2674 container env-test: <nil>
STEP: delete the pod
Dec  5 15:43:06.489: INFO: Waiting for pod pod-configmaps-744f526d-f8a4-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:43:06.493: INFO: Pod pod-configmaps-744f526d-f8a4-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:43:06.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gfsld" for this suite.
Dec  5 15:43:12.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:43:12.586: INFO: namespace: e2e-tests-configmap-gfsld, resource: bindings, ignored listing per whitelist
Dec  5 15:43:12.589: INFO: namespace e2e-tests-configmap-gfsld deletion completed in 6.09405489s

• [SLOW TEST:8.212 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:43:12.592: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 15:43:12.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-4qdvh'
Dec  5 15:43:12.758: INFO: stderr: ""
Dec  5 15:43:12.758: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Dec  5 15:43:12.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-4qdvh'
Dec  5 15:43:20.532: INFO: stderr: ""
Dec  5 15:43:20.532: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:43:20.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4qdvh" for this suite.
Dec  5 15:43:26.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:43:26.615: INFO: namespace: e2e-tests-kubectl-4qdvh, resource: bindings, ignored listing per whitelist
Dec  5 15:43:26.623: INFO: namespace e2e-tests-kubectl-4qdvh deletion completed in 6.088333401s

• [SLOW TEST:14.032 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:43:26.626: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  5 15:43:27.182: INFO: Pod name wrapped-volume-race-81da6ceb-f8a4-11e8-a7f8-ceaf58ef2674: Found 0 pods out of 5
Dec  5 15:43:32.188: INFO: Pod name wrapped-volume-race-81da6ceb-f8a4-11e8-a7f8-ceaf58ef2674: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-81da6ceb-f8a4-11e8-a7f8-ceaf58ef2674 in namespace e2e-tests-emptydir-wrapper-8g2t8, will wait for the garbage collector to delete the pods
Dec  5 15:43:44.266: INFO: Deleting ReplicationController wrapped-volume-race-81da6ceb-f8a4-11e8-a7f8-ceaf58ef2674 took: 7.395717ms
Dec  5 15:43:44.368: INFO: Terminating ReplicationController wrapped-volume-race-81da6ceb-f8a4-11e8-a7f8-ceaf58ef2674 pods took: 102.871234ms
STEP: Creating RC which spawns configmap-volume pods
Dec  5 15:44:21.385: INFO: Pod name wrapped-volume-race-a22890ff-f8a4-11e8-a7f8-ceaf58ef2674: Found 0 pods out of 5
Dec  5 15:44:26.392: INFO: Pod name wrapped-volume-race-a22890ff-f8a4-11e8-a7f8-ceaf58ef2674: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a22890ff-f8a4-11e8-a7f8-ceaf58ef2674 in namespace e2e-tests-emptydir-wrapper-8g2t8, will wait for the garbage collector to delete the pods
Dec  5 15:44:38.475: INFO: Deleting ReplicationController wrapped-volume-race-a22890ff-f8a4-11e8-a7f8-ceaf58ef2674 took: 12.958398ms
Dec  5 15:44:38.575: INFO: Terminating ReplicationController wrapped-volume-race-a22890ff-f8a4-11e8-a7f8-ceaf58ef2674 pods took: 100.314037ms
STEP: Creating RC which spawns configmap-volume pods
Dec  5 15:45:22.994: INFO: Pod name wrapped-volume-race-c6e109aa-f8a4-11e8-a7f8-ceaf58ef2674: Found 0 pods out of 5
Dec  5 15:45:28.000: INFO: Pod name wrapped-volume-race-c6e109aa-f8a4-11e8-a7f8-ceaf58ef2674: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c6e109aa-f8a4-11e8-a7f8-ceaf58ef2674 in namespace e2e-tests-emptydir-wrapper-8g2t8, will wait for the garbage collector to delete the pods
Dec  5 15:45:40.086: INFO: Deleting ReplicationController wrapped-volume-race-c6e109aa-f8a4-11e8-a7f8-ceaf58ef2674 took: 11.334538ms
Dec  5 15:45:40.199: INFO: Terminating ReplicationController wrapped-volume-race-c6e109aa-f8a4-11e8-a7f8-ceaf58ef2674 pods took: 113.019926ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:46:23.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-8g2t8" for this suite.
Dec  5 15:46:29.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:46:29.542: INFO: namespace: e2e-tests-emptydir-wrapper-8g2t8, resource: bindings, ignored listing per whitelist
Dec  5 15:46:29.593: INFO: namespace e2e-tests-emptydir-wrapper-8g2t8 deletion completed in 6.086109647s

• [SLOW TEST:182.968 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:46:29.595: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:46:31.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qtclg" for this suite.
Dec  5 15:47:09.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:47:09.737: INFO: namespace: e2e-tests-kubelet-test-qtclg, resource: bindings, ignored listing per whitelist
Dec  5 15:47:09.831: INFO: namespace e2e-tests-kubelet-test-qtclg deletion completed in 38.137144243s

• [SLOW TEST:40.236 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:47:09.833: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-06a470bb-f8a5-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 15:47:09.968: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-06a52e3d-f8a5-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-vvjjg" to be "success or failure"
Dec  5 15:47:10.002: INFO: Pod "pod-projected-configmaps-06a52e3d-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 33.655301ms
Dec  5 15:47:12.005: INFO: Pod "pod-projected-configmaps-06a52e3d-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036936569s
STEP: Saw pod success
Dec  5 15:47:12.005: INFO: Pod "pod-projected-configmaps-06a52e3d-f8a5-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:47:12.007: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-configmaps-06a52e3d-f8a5-11e8-a7f8-ceaf58ef2674 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 15:47:12.031: INFO: Waiting for pod pod-projected-configmaps-06a52e3d-f8a5-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:47:12.035: INFO: Pod pod-projected-configmaps-06a52e3d-f8a5-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:47:12.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vvjjg" for this suite.
Dec  5 15:47:18.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:47:18.132: INFO: namespace: e2e-tests-projected-vvjjg, resource: bindings, ignored listing per whitelist
Dec  5 15:47:18.132: INFO: namespace e2e-tests-projected-vvjjg deletion completed in 6.094638891s

• [SLOW TEST:8.299 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:47:18.134: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 15:47:18.216: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b8fdda4-f8a5-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-b889t" to be "success or failure"
Dec  5 15:47:18.226: INFO: Pod "downwardapi-volume-0b8fdda4-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 10.252458ms
Dec  5 15:47:20.229: INFO: Pod "downwardapi-volume-0b8fdda4-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013522926s
STEP: Saw pod success
Dec  5 15:47:20.229: INFO: Pod "downwardapi-volume-0b8fdda4-f8a5-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:47:20.231: INFO: Trying to get logs from node ip-10-0-12-134 pod downwardapi-volume-0b8fdda4-f8a5-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 15:47:20.250: INFO: Waiting for pod downwardapi-volume-0b8fdda4-f8a5-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:47:20.301: INFO: Pod downwardapi-volume-0b8fdda4-f8a5-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:47:20.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b889t" for this suite.
Dec  5 15:47:26.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:47:26.355: INFO: namespace: e2e-tests-projected-b889t, resource: bindings, ignored listing per whitelist
Dec  5 15:47:26.394: INFO: namespace e2e-tests-projected-b889t deletion completed in 6.08282124s

• [SLOW TEST:8.261 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:47:26.396: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-107d21a5-f8a5-11e8-a7f8-ceaf58ef2674
STEP: Creating secret with name secret-projected-all-test-volume-107d2187-f8a5-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  5 15:47:26.487: INFO: Waiting up to 5m0s for pod "projected-volume-107d2147-f8a5-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-fjtkl" to be "success or failure"
Dec  5 15:47:26.499: INFO: Pod "projected-volume-107d2147-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 11.402658ms
Dec  5 15:47:28.502: INFO: Pod "projected-volume-107d2147-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014705625s
STEP: Saw pod success
Dec  5 15:47:28.502: INFO: Pod "projected-volume-107d2147-f8a5-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:47:28.504: INFO: Trying to get logs from node ip-10-0-40-84 pod projected-volume-107d2147-f8a5-11e8-a7f8-ceaf58ef2674 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  5 15:47:28.542: INFO: Waiting for pod projected-volume-107d2147-f8a5-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:47:28.546: INFO: Pod projected-volume-107d2147-f8a5-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:47:28.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fjtkl" for this suite.
Dec  5 15:47:34.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:47:34.583: INFO: namespace: e2e-tests-projected-fjtkl, resource: bindings, ignored listing per whitelist
Dec  5 15:47:34.635: INFO: namespace e2e-tests-projected-fjtkl deletion completed in 6.086161535s

• [SLOW TEST:8.240 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:47:34.637: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hp48q
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 15:47:34.698: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 15:47:52.779: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.2.1.27 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hp48q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:47:52.779: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:47:53.890: INFO: Found all expected endpoints: [netserver-0]
Dec  5 15:47:53.893: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.2.0.54 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hp48q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 15:47:53.893: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 15:47:55.013: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:47:55.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hp48q" for this suite.
Dec  5 15:48:17.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:48:17.062: INFO: namespace: e2e-tests-pod-network-test-hp48q, resource: bindings, ignored listing per whitelist
Dec  5 15:48:17.098: INFO: namespace e2e-tests-pod-network-test-hp48q deletion completed in 22.081933139s

• [SLOW TEST:42.462 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:48:17.102: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  5 15:48:17.164: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 15:48:17.169: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 15:48:17.171: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-12-134 before test
Dec  5 15:48:17.175: INFO: sonobuoy-e2e-job-4df755f956e944ee from heptio-sonobuoy started at 2018-12-05 15:21:37 +0000 UTC (2 container statuses recorded)
Dec  5 15:48:17.175: INFO: 	Container e2e ready: true, restart count 0
Dec  5 15:48:17.175: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 15:48:17.175: INFO: sonobuoy-systemd-logs-daemon-set-6778acf1ee8d4b8d-5rq4f from heptio-sonobuoy started at 2018-12-05 15:21:37 +0000 UTC (2 container statuses recorded)
Dec  5 15:48:17.176: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 15:48:17.176: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 15:48:17.176: INFO: calico-node-p6sb5 from kube-system started at 2018-12-05 05:33:47 +0000 UTC (2 container statuses recorded)
Dec  5 15:48:17.176: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 15:48:17.176: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 15:48:17.176: INFO: kube-proxy-2hslj from kube-system started at 2018-12-05 05:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 15:48:17.176: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 15:48:17.176: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-40-84 before test
Dec  5 15:48:17.185: INFO: calico-node-nkjpz from kube-system started at 2018-12-05 05:33:46 +0000 UTC (2 container statuses recorded)
Dec  5 15:48:17.185: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 15:48:17.185: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 15:48:17.185: INFO: kube-proxy-gzgch from kube-system started at 2018-12-05 05:33:46 +0000 UTC (1 container statuses recorded)
Dec  5 15:48:17.185: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 15:48:17.185: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-05 05:37:35 +0000 UTC (1 container statuses recorded)
Dec  5 15:48:17.185: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 15:48:17.185: INFO: sonobuoy-systemd-logs-daemon-set-6778acf1ee8d4b8d-8k8kp from heptio-sonobuoy started at 2018-12-05 15:21:37 +0000 UTC (2 container statuses recorded)
Dec  5 15:48:17.185: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 15:48:17.185: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-10-0-12-134
STEP: verifying the node has the label node ip-10-0-40-84
Dec  5 15:48:17.237: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-40-84
Dec  5 15:48:17.237: INFO: Pod sonobuoy-e2e-job-4df755f956e944ee requesting resource cpu=0m on Node ip-10-0-12-134
Dec  5 15:48:17.237: INFO: Pod sonobuoy-systemd-logs-daemon-set-6778acf1ee8d4b8d-5rq4f requesting resource cpu=0m on Node ip-10-0-12-134
Dec  5 15:48:17.237: INFO: Pod sonobuoy-systemd-logs-daemon-set-6778acf1ee8d4b8d-8k8kp requesting resource cpu=0m on Node ip-10-0-40-84
Dec  5 15:48:17.237: INFO: Pod calico-node-nkjpz requesting resource cpu=250m on Node ip-10-0-40-84
Dec  5 15:48:17.237: INFO: Pod calico-node-p6sb5 requesting resource cpu=250m on Node ip-10-0-12-134
Dec  5 15:48:17.238: INFO: Pod kube-proxy-2hslj requesting resource cpu=0m on Node ip-10-0-12-134
Dec  5 15:48:17.238: INFO: Pod kube-proxy-gzgch requesting resource cpu=0m on Node ip-10-0-40-84
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2ebf5184-f8a5-11e8-a7f8-ceaf58ef2674.156d7a76a540153b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-p2xc8/filler-pod-2ebf5184-f8a5-11e8-a7f8-ceaf58ef2674 to ip-10-0-12-134]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2ebf5184-f8a5-11e8-a7f8-ceaf58ef2674.156d7a76cce6b195], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2ebf5184-f8a5-11e8-a7f8-ceaf58ef2674.156d7a76d1243204], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2ebf5184-f8a5-11e8-a7f8-ceaf58ef2674.156d7a76d9e9973a], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2ec0fc58-f8a5-11e8-a7f8-ceaf58ef2674.156d7a76a5f9bea6], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-p2xc8/filler-pod-2ec0fc58-f8a5-11e8-a7f8-ceaf58ef2674 to ip-10-0-40-84]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2ec0fc58-f8a5-11e8-a7f8-ceaf58ef2674.156d7a76cc6bab5a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2ec0fc58-f8a5-11e8-a7f8-ceaf58ef2674.156d7a76cf1814c1], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2ec0fc58-f8a5-11e8-a7f8-ceaf58ef2674.156d7a76d855cd12], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156d7a771e8550a4], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-0-12-134
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-40-84
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:48:20.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-p2xc8" for this suite.
Dec  5 15:48:26.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:48:26.457: INFO: namespace: e2e-tests-sched-pred-p2xc8, resource: bindings, ignored listing per whitelist
Dec  5 15:48:26.463: INFO: namespace e2e-tests-sched-pred-p2xc8 deletion completed in 6.085712672s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.362 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:48:26.465: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec  5 15:48:26.539: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  5 15:48:26.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:26.992: INFO: stderr: ""
Dec  5 15:48:26.992: INFO: stdout: "service/redis-slave created\n"
Dec  5 15:48:26.992: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  5 15:48:26.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:27.238: INFO: stderr: ""
Dec  5 15:48:27.238: INFO: stdout: "service/redis-master created\n"
Dec  5 15:48:27.238: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  5 15:48:27.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:27.475: INFO: stderr: ""
Dec  5 15:48:27.475: INFO: stdout: "service/frontend created\n"
Dec  5 15:48:27.475: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  5 15:48:27.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:27.703: INFO: stderr: ""
Dec  5 15:48:27.703: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  5 15:48:27.703: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  5 15:48:27.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:27.937: INFO: stderr: ""
Dec  5 15:48:27.937: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  5 15:48:27.937: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  5 15:48:27.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:28.216: INFO: stderr: ""
Dec  5 15:48:28.216: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  5 15:48:28.216: INFO: Waiting for all frontend pods to be Running.
Dec  5 15:48:48.267: INFO: Waiting for frontend to serve content.
Dec  5 15:48:53.327: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec  5 15:48:58.339: INFO: Trying to add a new entry to the guestbook.
Dec  5 15:48:58.353: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  5 15:48:58.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:58.486: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 15:48:58.486: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 15:48:58.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:58.611: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 15:48:58.611: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 15:48:58.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:58.748: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 15:48:58.748: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 15:48:58.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:58.856: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 15:48:58.856: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 15:48:58.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:59.015: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 15:48:59.015: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 15:48:59.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bgxc8'
Dec  5 15:48:59.180: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 15:48:59.180: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:48:59.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bgxc8" for this suite.
Dec  5 15:49:37.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:49:37.252: INFO: namespace: e2e-tests-kubectl-bgxc8, resource: bindings, ignored listing per whitelist
Dec  5 15:49:37.294: INFO: namespace e2e-tests-kubectl-bgxc8 deletion completed in 38.110833945s

• [SLOW TEST:70.830 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:49:37.296: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-5e812a4d-f8a5-11e8-a7f8-ceaf58ef2674
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-5e812a4d-f8a5-11e8-a7f8-ceaf58ef2674
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:49:41.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wgq8j" for this suite.
Dec  5 15:50:03.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:50:03.469: INFO: namespace: e2e-tests-configmap-wgq8j, resource: bindings, ignored listing per whitelist
Dec  5 15:50:03.505: INFO: namespace e2e-tests-configmap-wgq8j deletion completed in 22.087905248s

• [SLOW TEST:26.210 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:50:03.507: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-kvzxd.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-kvzxd.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-kvzxd.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-kvzxd.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-kvzxd.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-kvzxd.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 15:50:17.687: INFO: DNS probes using e2e-tests-dns-kvzxd/dns-test-6e210af5-f8a5-11e8-a7f8-ceaf58ef2674 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:50:17.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-kvzxd" for this suite.
Dec  5 15:50:23.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:50:23.788: INFO: namespace: e2e-tests-dns-kvzxd, resource: bindings, ignored listing per whitelist
Dec  5 15:50:23.837: INFO: namespace e2e-tests-dns-kvzxd deletion completed in 6.114173922s

• [SLOW TEST:20.331 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:50:23.838: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 15:50:23.930: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  5 15:50:28.934: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 15:50:28.934: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 15:50:28.959: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-lqgcq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lqgcq/deployments/test-cleanup-deployment,UID:7d3f72c0-f8a5-11e8-ab6c-06b570ab0412,ResourceVersion:57493,Generation:1,CreationTimestamp:2018-12-05 15:50:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec  5 15:50:28.967: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec  5 15:50:28.967: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec  5 15:50:28.968: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-lqgcq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lqgcq/replicasets/test-cleanup-controller,UID:7a41863c-f8a5-11e8-ab6c-06b570ab0412,ResourceVersion:57494,Generation:1,CreationTimestamp:2018-12-05 15:50:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 7d3f72c0-f8a5-11e8-ab6c-06b570ab0412 0xc001429507 0xc001429508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  5 15:50:28.973: INFO: Pod "test-cleanup-controller-hwhg9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-hwhg9,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-lqgcq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lqgcq/pods/test-cleanup-controller-hwhg9,UID:7a43e75c-f8a5-11e8-ab6c-06b570ab0412,ResourceVersion:57487,Generation:0,CreationTimestamp:2018-12-05 15:50:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.0.63/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 7a41863c-f8a5-11e8-ab6c-06b570ab0412 0xc001429ad7 0xc001429ad8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dkrds {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dkrds,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dkrds true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001429b50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001429b70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:50:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:50:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:50:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:50:23 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:10.2.0.63,StartTime:2018-12-05 15:50:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 15:50:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://e67428fcde22918761288c8dbd597a8fad8ec9cbbd718e82c9ee8004e5a19cb5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:50:28.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lqgcq" for this suite.
Dec  5 15:50:35.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:50:35.673: INFO: namespace: e2e-tests-deployment-lqgcq, resource: bindings, ignored listing per whitelist
Dec  5 15:50:35.713: INFO: namespace e2e-tests-deployment-lqgcq deletion completed in 6.111073513s

• [SLOW TEST:11.875 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:50:35.715: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  5 15:50:35.795: INFO: Waiting up to 5m0s for pod "pod-81544073-f8a5-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-7frcd" to be "success or failure"
Dec  5 15:50:35.799: INFO: Pod "pod-81544073-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 3.921498ms
Dec  5 15:50:37.803: INFO: Pod "pod-81544073-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0071562s
STEP: Saw pod success
Dec  5 15:50:37.803: INFO: Pod "pod-81544073-f8a5-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:50:37.804: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-81544073-f8a5-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 15:50:37.826: INFO: Waiting for pod pod-81544073-f8a5-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:50:37.829: INFO: Pod pod-81544073-f8a5-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:50:37.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7frcd" for this suite.
Dec  5 15:50:43.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:50:43.927: INFO: namespace: e2e-tests-emptydir-7frcd, resource: bindings, ignored listing per whitelist
Dec  5 15:50:43.928: INFO: namespace e2e-tests-emptydir-7frcd deletion completed in 6.095936816s

• [SLOW TEST:8.213 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:50:43.929: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  5 15:50:43.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:44.183: INFO: stderr: ""
Dec  5 15:50:44.183: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 15:50:44.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:44.296: INFO: stderr: ""
Dec  5 15:50:44.296: INFO: stdout: "update-demo-nautilus-28zd2 update-demo-nautilus-qzqlp "
Dec  5 15:50:44.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-28zd2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:44.385: INFO: stderr: ""
Dec  5 15:50:44.385: INFO: stdout: ""
Dec  5 15:50:44.385: INFO: update-demo-nautilus-28zd2 is created but not running
Dec  5 15:50:49.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:49.481: INFO: stderr: ""
Dec  5 15:50:49.481: INFO: stdout: "update-demo-nautilus-28zd2 update-demo-nautilus-qzqlp "
Dec  5 15:50:49.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-28zd2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:49.581: INFO: stderr: ""
Dec  5 15:50:49.581: INFO: stdout: "true"
Dec  5 15:50:49.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-28zd2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:49.667: INFO: stderr: ""
Dec  5 15:50:49.667: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 15:50:49.667: INFO: validating pod update-demo-nautilus-28zd2
Dec  5 15:50:49.680: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 15:50:49.680: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 15:50:49.680: INFO: update-demo-nautilus-28zd2 is verified up and running
Dec  5 15:50:49.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-qzqlp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:49.766: INFO: stderr: ""
Dec  5 15:50:49.766: INFO: stdout: "true"
Dec  5 15:50:49.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-qzqlp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:49.853: INFO: stderr: ""
Dec  5 15:50:49.853: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 15:50:49.853: INFO: validating pod update-demo-nautilus-qzqlp
Dec  5 15:50:49.867: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 15:50:49.867: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 15:50:49.867: INFO: update-demo-nautilus-qzqlp is verified up and running
STEP: scaling down the replication controller
Dec  5 15:50:49.868: INFO: scanned /root for discovery docs: <nil>
Dec  5 15:50:49.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:51.023: INFO: stderr: ""
Dec  5 15:50:51.023: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 15:50:51.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:51.119: INFO: stderr: ""
Dec  5 15:50:51.119: INFO: stdout: "update-demo-nautilus-28zd2 update-demo-nautilus-qzqlp "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  5 15:50:56.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:50:56.217: INFO: stderr: ""
Dec  5 15:50:56.217: INFO: stdout: "update-demo-nautilus-28zd2 update-demo-nautilus-qzqlp "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  5 15:51:01.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:01.311: INFO: stderr: ""
Dec  5 15:51:01.311: INFO: stdout: "update-demo-nautilus-28zd2 update-demo-nautilus-qzqlp "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  5 15:51:06.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:06.410: INFO: stderr: ""
Dec  5 15:51:06.410: INFO: stdout: "update-demo-nautilus-28zd2 "
Dec  5 15:51:06.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-28zd2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:06.501: INFO: stderr: ""
Dec  5 15:51:06.501: INFO: stdout: "true"
Dec  5 15:51:06.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-28zd2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:06.586: INFO: stderr: ""
Dec  5 15:51:06.586: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 15:51:06.586: INFO: validating pod update-demo-nautilus-28zd2
Dec  5 15:51:06.591: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 15:51:06.591: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 15:51:06.591: INFO: update-demo-nautilus-28zd2 is verified up and running
STEP: scaling up the replication controller
Dec  5 15:51:06.592: INFO: scanned /root for discovery docs: <nil>
Dec  5 15:51:06.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:07.709: INFO: stderr: ""
Dec  5 15:51:07.709: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 15:51:07.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:07.799: INFO: stderr: ""
Dec  5 15:51:07.799: INFO: stdout: "update-demo-nautilus-28zd2 update-demo-nautilus-2crqs "
Dec  5 15:51:07.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-28zd2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:07.884: INFO: stderr: ""
Dec  5 15:51:07.884: INFO: stdout: "true"
Dec  5 15:51:07.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-28zd2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:07.973: INFO: stderr: ""
Dec  5 15:51:07.973: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 15:51:07.973: INFO: validating pod update-demo-nautilus-28zd2
Dec  5 15:51:07.977: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 15:51:07.977: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 15:51:07.977: INFO: update-demo-nautilus-28zd2 is verified up and running
Dec  5 15:51:07.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-2crqs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:08.063: INFO: stderr: ""
Dec  5 15:51:08.063: INFO: stdout: ""
Dec  5 15:51:08.063: INFO: update-demo-nautilus-2crqs is created but not running
Dec  5 15:51:13.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:13.157: INFO: stderr: ""
Dec  5 15:51:13.157: INFO: stdout: "update-demo-nautilus-28zd2 update-demo-nautilus-2crqs "
Dec  5 15:51:13.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-28zd2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:13.238: INFO: stderr: ""
Dec  5 15:51:13.238: INFO: stdout: "true"
Dec  5 15:51:13.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-28zd2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:13.324: INFO: stderr: ""
Dec  5 15:51:13.324: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 15:51:13.324: INFO: validating pod update-demo-nautilus-28zd2
Dec  5 15:51:13.328: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 15:51:13.328: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 15:51:13.328: INFO: update-demo-nautilus-28zd2 is verified up and running
Dec  5 15:51:13.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-2crqs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:13.417: INFO: stderr: ""
Dec  5 15:51:13.417: INFO: stdout: "true"
Dec  5 15:51:13.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods update-demo-nautilus-2crqs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:13.502: INFO: stderr: ""
Dec  5 15:51:13.502: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 15:51:13.502: INFO: validating pod update-demo-nautilus-2crqs
Dec  5 15:51:13.506: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 15:51:13.506: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 15:51:13.506: INFO: update-demo-nautilus-2crqs is verified up and running
STEP: using delete to clean up resources
Dec  5 15:51:13.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:13.594: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 15:51:13.594: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  5 15:51:13.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-nbqxg'
Dec  5 15:51:13.773: INFO: stderr: "No resources found.\n"
Dec  5 15:51:13.773: INFO: stdout: ""
Dec  5 15:51:13.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -l name=update-demo --namespace=e2e-tests-kubectl-nbqxg -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 15:51:13.941: INFO: stderr: ""
Dec  5 15:51:13.941: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:51:13.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nbqxg" for this suite.
Dec  5 15:51:35.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:51:36.029: INFO: namespace: e2e-tests-kubectl-nbqxg, resource: bindings, ignored listing per whitelist
Dec  5 15:51:36.039: INFO: namespace e2e-tests-kubectl-nbqxg deletion completed in 22.095035152s

• [SLOW TEST:52.110 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:51:36.041: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-q97w
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 15:51:36.118: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-q97w" in namespace "e2e-tests-subpath-dj5rq" to be "success or failure"
Dec  5 15:51:36.123: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.331074ms
Dec  5 15:51:38.126: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008244688s
Dec  5 15:51:40.140: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Running", Reason="", readiness=false. Elapsed: 4.021902133s
Dec  5 15:51:42.144: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Running", Reason="", readiness=false. Elapsed: 6.02527928s
Dec  5 15:51:44.147: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Running", Reason="", readiness=false. Elapsed: 8.02898774s
Dec  5 15:51:46.151: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Running", Reason="", readiness=false. Elapsed: 10.032659539s
Dec  5 15:51:48.154: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Running", Reason="", readiness=false. Elapsed: 12.035821845s
Dec  5 15:51:50.163: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Running", Reason="", readiness=false. Elapsed: 14.044344104s
Dec  5 15:51:52.166: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Running", Reason="", readiness=false. Elapsed: 16.048049653s
Dec  5 15:51:54.170: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Running", Reason="", readiness=false. Elapsed: 18.051843867s
Dec  5 15:51:56.173: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Running", Reason="", readiness=false. Elapsed: 20.055072024s
Dec  5 15:51:58.177: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Running", Reason="", readiness=false. Elapsed: 22.058336642s
Dec  5 15:52:00.197: INFO: Pod "pod-subpath-test-projected-q97w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.078977385s
STEP: Saw pod success
Dec  5 15:52:00.197: INFO: Pod "pod-subpath-test-projected-q97w" satisfied condition "success or failure"
Dec  5 15:52:00.202: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-subpath-test-projected-q97w container test-container-subpath-projected-q97w: <nil>
STEP: delete the pod
Dec  5 15:52:00.222: INFO: Waiting for pod pod-subpath-test-projected-q97w to disappear
Dec  5 15:52:00.228: INFO: Pod pod-subpath-test-projected-q97w no longer exists
STEP: Deleting pod pod-subpath-test-projected-q97w
Dec  5 15:52:00.228: INFO: Deleting pod "pod-subpath-test-projected-q97w" in namespace "e2e-tests-subpath-dj5rq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:52:00.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dj5rq" for this suite.
Dec  5 15:52:06.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:52:06.283: INFO: namespace: e2e-tests-subpath-dj5rq, resource: bindings, ignored listing per whitelist
Dec  5 15:52:06.318: INFO: namespace e2e-tests-subpath-dj5rq deletion completed in 6.085944192s

• [SLOW TEST:30.278 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:52:06.320: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-ns9xl
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-ns9xl
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-ns9xl
Dec  5 15:52:06.450: INFO: Found 0 stateful pods, waiting for 1
Dec  5 15:52:16.453: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  5 15:52:16.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-ns9xl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 15:52:16.674: INFO: stderr: ""
Dec  5 15:52:16.674: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 15:52:16.674: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 15:52:16.691: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  5 15:52:26.701: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 15:52:26.701: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 15:52:26.730: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Dec  5 15:52:26.732: INFO: ss-0  ip-10-0-40-84  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:06 +0000 UTC  }]
Dec  5 15:52:26.732: INFO: ss-1                 Pending         []
Dec  5 15:52:26.732: INFO: 
Dec  5 15:52:26.732: INFO: StatefulSet ss has not reached scale 3, at 2
Dec  5 15:52:27.737: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.978017405s
Dec  5 15:52:28.741: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972753057s
Dec  5 15:52:29.745: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.969063651s
Dec  5 15:52:30.749: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965471979s
Dec  5 15:52:31.752: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.961735612s
Dec  5 15:52:32.756: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.958192777s
Dec  5 15:52:33.759: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.954448612s
Dec  5 15:52:34.763: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.950773486s
Dec  5 15:52:35.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 946.991333ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-ns9xl
Dec  5 15:52:36.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-ns9xl ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 15:52:36.968: INFO: stderr: ""
Dec  5 15:52:36.968: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 15:52:36.968: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 15:52:36.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-ns9xl ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 15:52:37.147: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  5 15:52:37.147: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 15:52:37.147: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 15:52:37.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-ns9xl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 15:52:37.346: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  5 15:52:37.346: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 15:52:37.346: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 15:52:37.349: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec  5 15:52:47.355: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 15:52:47.355: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 15:52:47.355: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  5 15:52:47.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-ns9xl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 15:52:47.622: INFO: stderr: ""
Dec  5 15:52:47.622: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 15:52:47.622: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 15:52:47.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-ns9xl ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 15:52:47.801: INFO: stderr: ""
Dec  5 15:52:47.801: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 15:52:47.801: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 15:52:47.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-ns9xl ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 15:52:48.000: INFO: stderr: ""
Dec  5 15:52:48.000: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 15:52:48.001: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 15:52:48.001: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 15:52:48.004: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  5 15:52:58.010: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 15:52:58.010: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 15:52:58.010: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 15:52:58.023: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Dec  5 15:52:58.023: INFO: ss-0  ip-10-0-40-84   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:06 +0000 UTC  }]
Dec  5 15:52:58.023: INFO: ss-1  ip-10-0-12-134  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  }]
Dec  5 15:52:58.023: INFO: ss-2  ip-10-0-40-84   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  }]
Dec  5 15:52:58.023: INFO: 
Dec  5 15:52:58.023: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 15:52:59.027: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Dec  5 15:52:59.028: INFO: ss-0  ip-10-0-40-84   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:06 +0000 UTC  }]
Dec  5 15:52:59.028: INFO: ss-1  ip-10-0-12-134  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  }]
Dec  5 15:52:59.028: INFO: ss-2  ip-10-0-40-84   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  }]
Dec  5 15:52:59.028: INFO: 
Dec  5 15:52:59.028: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 15:53:00.031: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Dec  5 15:53:00.031: INFO: ss-0  ip-10-0-40-84   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:06 +0000 UTC  }]
Dec  5 15:53:00.031: INFO: ss-1  ip-10-0-12-134  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  }]
Dec  5 15:53:00.032: INFO: ss-2  ip-10-0-40-84   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  }]
Dec  5 15:53:00.032: INFO: 
Dec  5 15:53:00.032: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 15:53:01.035: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Dec  5 15:53:01.035: INFO: ss-1  ip-10-0-12-134  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  }]
Dec  5 15:53:01.035: INFO: 
Dec  5 15:53:01.035: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  5 15:53:02.039: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Dec  5 15:53:02.039: INFO: ss-1  ip-10-0-12-134  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:52:26 +0000 UTC  }]
Dec  5 15:53:02.039: INFO: 
Dec  5 15:53:02.039: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  5 15:53:03.042: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.977507183s
Dec  5 15:53:04.046: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.974044433s
Dec  5 15:53:05.049: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.97063611s
Dec  5 15:53:06.053: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.967221759s
Dec  5 15:53:07.056: INFO: Verifying statefulset ss doesn't scale past 0 for another 963.592576ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-ns9xl
Dec  5 15:53:08.059: INFO: Scaling statefulset ss to 0
Dec  5 15:53:08.066: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 15:53:08.068: INFO: Deleting all statefulset in ns e2e-tests-statefulset-ns9xl
Dec  5 15:53:08.070: INFO: Scaling statefulset ss to 0
Dec  5 15:53:08.077: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 15:53:08.078: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:53:08.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-ns9xl" for this suite.
Dec  5 15:53:14.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:53:14.188: INFO: namespace: e2e-tests-statefulset-ns9xl, resource: bindings, ignored listing per whitelist
Dec  5 15:53:14.244: INFO: namespace e2e-tests-statefulset-ns9xl deletion completed in 6.15068512s

• [SLOW TEST:67.925 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:53:14.246: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:53:16.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-r9pp6" for this suite.
Dec  5 15:53:22.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:53:22.527: INFO: namespace: e2e-tests-emptydir-wrapper-r9pp6, resource: bindings, ignored listing per whitelist
Dec  5 15:53:22.567: INFO: namespace e2e-tests-emptydir-wrapper-r9pp6 deletion completed in 6.079790991s

• [SLOW TEST:8.321 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:53:22.569: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  5 15:53:22.637: INFO: Waiting up to 5m0s for pod "pod-e4c68244-f8a5-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-vqm86" to be "success or failure"
Dec  5 15:53:22.643: INFO: Pod "pod-e4c68244-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.553306ms
Dec  5 15:53:24.646: INFO: Pod "pod-e4c68244-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009050166s
Dec  5 15:53:26.649: INFO: Pod "pod-e4c68244-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012020983s
STEP: Saw pod success
Dec  5 15:53:26.649: INFO: Pod "pod-e4c68244-f8a5-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:53:26.651: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-e4c68244-f8a5-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 15:53:26.673: INFO: Waiting for pod pod-e4c68244-f8a5-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:53:26.675: INFO: Pod pod-e4c68244-f8a5-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:53:26.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vqm86" for this suite.
Dec  5 15:53:32.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:53:32.711: INFO: namespace: e2e-tests-emptydir-vqm86, resource: bindings, ignored listing per whitelist
Dec  5 15:53:32.765: INFO: namespace e2e-tests-emptydir-vqm86 deletion completed in 6.086252652s

• [SLOW TEST:10.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:53:32.768: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-eaddf488-f8a5-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 15:53:32.875: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-eadfcc39-f8a5-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-qx2np" to be "success or failure"
Dec  5 15:53:32.890: INFO: Pod "pod-projected-secrets-eadfcc39-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 14.740206ms
Dec  5 15:53:34.893: INFO: Pod "pod-projected-secrets-eadfcc39-f8a5-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018060687s
STEP: Saw pod success
Dec  5 15:53:34.893: INFO: Pod "pod-projected-secrets-eadfcc39-f8a5-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:53:34.895: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-secrets-eadfcc39-f8a5-11e8-a7f8-ceaf58ef2674 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 15:53:34.912: INFO: Waiting for pod pod-projected-secrets-eadfcc39-f8a5-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:53:34.916: INFO: Pod pod-projected-secrets-eadfcc39-f8a5-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:53:34.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qx2np" for this suite.
Dec  5 15:53:40.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:53:40.979: INFO: namespace: e2e-tests-projected-qx2np, resource: bindings, ignored listing per whitelist
Dec  5 15:53:40.998: INFO: namespace e2e-tests-projected-qx2np deletion completed in 6.079049108s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:53:41.000: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 15:53:41.060: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:53:44.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dkxrn" for this suite.
Dec  5 15:53:50.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:53:50.354: INFO: namespace: e2e-tests-init-container-dkxrn, resource: bindings, ignored listing per whitelist
Dec  5 15:53:50.417: INFO: namespace e2e-tests-init-container-dkxrn deletion completed in 6.164694438s

• [SLOW TEST:9.418 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:53:50.419: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 15:53:50.484: INFO: Creating ReplicaSet my-hostname-basic-f5609ccf-f8a5-11e8-a7f8-ceaf58ef2674
Dec  5 15:53:50.492: INFO: Pod name my-hostname-basic-f5609ccf-f8a5-11e8-a7f8-ceaf58ef2674: Found 0 pods out of 1
Dec  5 15:53:55.495: INFO: Pod name my-hostname-basic-f5609ccf-f8a5-11e8-a7f8-ceaf58ef2674: Found 1 pods out of 1
Dec  5 15:53:55.495: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f5609ccf-f8a5-11e8-a7f8-ceaf58ef2674" is running
Dec  5 15:53:55.497: INFO: Pod "my-hostname-basic-f5609ccf-f8a5-11e8-a7f8-ceaf58ef2674-zv8xs" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 15:53:50 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 15:53:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 15:53:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 15:53:50 +0000 UTC Reason: Message:}])
Dec  5 15:53:55.497: INFO: Trying to dial the pod
Dec  5 15:54:00.510: INFO: Controller my-hostname-basic-f5609ccf-f8a5-11e8-a7f8-ceaf58ef2674: Got expected result from replica 1 [my-hostname-basic-f5609ccf-f8a5-11e8-a7f8-ceaf58ef2674-zv8xs]: "my-hostname-basic-f5609ccf-f8a5-11e8-a7f8-ceaf58ef2674-zv8xs", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:54:00.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-z2h4z" for this suite.
Dec  5 15:54:06.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:54:06.596: INFO: namespace: e2e-tests-replicaset-z2h4z, resource: bindings, ignored listing per whitelist
Dec  5 15:54:06.600: INFO: namespace e2e-tests-replicaset-z2h4z deletion completed in 6.086868604s

• [SLOW TEST:16.181 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:54:06.602: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec  5 15:54:06.665: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-292959027 proxy --unix-socket=/tmp/kubectl-proxy-unix144969974/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:54:06.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xsrcv" for this suite.
Dec  5 15:54:12.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:54:12.823: INFO: namespace: e2e-tests-kubectl-xsrcv, resource: bindings, ignored listing per whitelist
Dec  5 15:54:12.865: INFO: namespace e2e-tests-kubectl-xsrcv deletion completed in 6.12753032s

• [SLOW TEST:6.263 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:54:12.865: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  5 15:54:14.951: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-02c0f72a-f8a6-11e8-a7f8-ceaf58ef2674,GenerateName:,Namespace:e2e-tests-events-fw64w,SelfLink:/api/v1/namespaces/e2e-tests-events-fw64w/pods/send-events-02c0f72a-f8a6-11e8-a7f8-ceaf58ef2674,UID:02c15127-f8a6-11e8-ab6c-06b570ab0412,ResourceVersion:58343,Generation:0,CreationTimestamp:2018-12-05 15:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 926040133,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.0.75/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-x8wnj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-x8wnj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-x8wnj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000adf5e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000adf600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:54:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:54:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:54:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:54:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:10.2.0.75,StartTime:2018-12-05 15:54:12 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-05 15:54:13 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://f6de8e074349e44c0a1a6748d2636c78f6b0448622c6b2835d82f27cb078e482}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  5 15:54:16.954: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  5 15:54:18.958: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:54:18.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-fw64w" for this suite.
Dec  5 15:54:56.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:54:57.061: INFO: namespace: e2e-tests-events-fw64w, resource: bindings, ignored listing per whitelist
Dec  5 15:54:57.092: INFO: namespace e2e-tests-events-fw64w deletion completed in 38.114791411s

• [SLOW TEST:44.226 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:54:57.093: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 15:54:57.177: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d1f951e-f8a6-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-j8frk" to be "success or failure"
Dec  5 15:54:57.186: INFO: Pod "downwardapi-volume-1d1f951e-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 9.291524ms
Dec  5 15:54:59.189: INFO: Pod "downwardapi-volume-1d1f951e-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012514751s
STEP: Saw pod success
Dec  5 15:54:59.189: INFO: Pod "downwardapi-volume-1d1f951e-f8a6-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:54:59.191: INFO: Trying to get logs from node ip-10-0-12-134 pod downwardapi-volume-1d1f951e-f8a6-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 15:54:59.231: INFO: Waiting for pod downwardapi-volume-1d1f951e-f8a6-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:54:59.234: INFO: Pod downwardapi-volume-1d1f951e-f8a6-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:54:59.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j8frk" for this suite.
Dec  5 15:55:05.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:55:05.338: INFO: namespace: e2e-tests-downward-api-j8frk, resource: bindings, ignored listing per whitelist
Dec  5 15:55:05.351: INFO: namespace e2e-tests-downward-api-j8frk deletion completed in 6.11321536s

• [SLOW TEST:8.258 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:55:05.352: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 15:55:05.525: INFO: Creating deployment "test-recreate-deployment"
Dec  5 15:55:05.531: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  5 15:55:05.538: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec  5 15:55:07.545: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  5 15:55:07.548: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  5 15:55:07.567: INFO: Updating deployment test-recreate-deployment
Dec  5 15:55:07.567: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 15:55:07.702: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-d8dwj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d8dwj/deployments/test-recreate-deployment,UID:221b1d13-f8a6-11e8-ab6c-06b570ab0412,ResourceVersion:58499,Generation:2,CreationTimestamp:2018-12-05 15:55:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-05 15:55:07 +0000 UTC 2018-12-05 15:55:07 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-05 15:55:07 +0000 UTC 2018-12-05 15:55:05 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  5 15:55:07.708: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-d8dwj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d8dwj/replicasets/test-recreate-deployment-697fbf54bf,UID:235cffd9-f8a6-11e8-ab6c-06b570ab0412,ResourceVersion:58498,Generation:1,CreationTimestamp:2018-12-05 15:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 221b1d13-f8a6-11e8-ab6c-06b570ab0412 0xc00114bef7 0xc00114bef8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 15:55:07.709: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  5 15:55:07.710: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-d8dwj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d8dwj/replicasets/test-recreate-deployment-5dfdcc846d,UID:221d2251-f8a6-11e8-ab6c-06b570ab0412,ResourceVersion:58488,Generation:2,CreationTimestamp:2018-12-05 15:55:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 221b1d13-f8a6-11e8-ab6c-06b570ab0412 0xc00114bdd7 0xc00114bdd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 15:55:07.713: INFO: Pod "test-recreate-deployment-697fbf54bf-wzrwq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-wzrwq,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-d8dwj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8dwj/pods/test-recreate-deployment-697fbf54bf-wzrwq,UID:235e1776-f8a6-11e8-ab6c-06b570ab0412,ResourceVersion:58500,Generation:0,CreationTimestamp:2018-12-05 15:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 235cffd9-f8a6-11e8-ab6c-06b570ab0412 0xc0027c1117 0xc0027c1118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kd8fr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kd8fr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kd8fr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027c1310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027c1330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 15:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 15:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:55:07.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-d8dwj" for this suite.
Dec  5 15:55:13.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:55:13.770: INFO: namespace: e2e-tests-deployment-d8dwj, resource: bindings, ignored listing per whitelist
Dec  5 15:55:13.837: INFO: namespace e2e-tests-deployment-d8dwj deletion completed in 6.120567739s

• [SLOW TEST:8.486 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:55:13.839: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1205 15:55:19.957758      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 15:55:19.957: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:55:19.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kq822" for this suite.
Dec  5 15:55:25.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:55:26.024: INFO: namespace: e2e-tests-gc-kq822, resource: bindings, ignored listing per whitelist
Dec  5 15:55:26.075: INFO: namespace e2e-tests-gc-kq822 deletion completed in 6.114334661s

• [SLOW TEST:12.236 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:55:26.077: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 15:55:26.153: INFO: (0) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.261801ms)
Dec  5 15:55:26.157: INFO: (1) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.222578ms)
Dec  5 15:55:26.160: INFO: (2) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.27878ms)
Dec  5 15:55:26.163: INFO: (3) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.210324ms)
Dec  5 15:55:26.167: INFO: (4) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.290084ms)
Dec  5 15:55:26.170: INFO: (5) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.580175ms)
Dec  5 15:55:26.174: INFO: (6) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.558129ms)
Dec  5 15:55:26.177: INFO: (7) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.46287ms)
Dec  5 15:55:26.182: INFO: (8) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.214031ms)
Dec  5 15:55:26.186: INFO: (9) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.466538ms)
Dec  5 15:55:26.189: INFO: (10) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.060731ms)
Dec  5 15:55:26.192: INFO: (11) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.121067ms)
Dec  5 15:55:26.196: INFO: (12) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.015039ms)
Dec  5 15:55:26.199: INFO: (13) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.097395ms)
Dec  5 15:55:26.202: INFO: (14) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.169789ms)
Dec  5 15:55:26.205: INFO: (15) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.108062ms)
Dec  5 15:55:26.208: INFO: (16) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.01496ms)
Dec  5 15:55:26.212: INFO: (17) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.275847ms)
Dec  5 15:55:26.215: INFO: (18) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.267695ms)
Dec  5 15:55:26.220: INFO: (19) /api/v1/nodes/ip-10-0-12-134/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.595516ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:55:26.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-77cz8" for this suite.
Dec  5 15:55:32.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:55:32.286: INFO: namespace: e2e-tests-proxy-77cz8, resource: bindings, ignored listing per whitelist
Dec  5 15:55:32.326: INFO: namespace e2e-tests-proxy-77cz8 deletion completed in 6.103160948s

• [SLOW TEST:6.249 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:55:32.328: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 15:55:32.464: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3226c4f4-f8a6-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-fq8zg" to be "success or failure"
Dec  5 15:55:32.471: INFO: Pod "downwardapi-volume-3226c4f4-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.96635ms
Dec  5 15:55:34.474: INFO: Pod "downwardapi-volume-3226c4f4-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009576562s
STEP: Saw pod success
Dec  5 15:55:34.474: INFO: Pod "downwardapi-volume-3226c4f4-f8a6-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:55:34.477: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-3226c4f4-f8a6-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 15:55:34.496: INFO: Waiting for pod downwardapi-volume-3226c4f4-f8a6-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:55:34.501: INFO: Pod downwardapi-volume-3226c4f4-f8a6-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:55:34.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fq8zg" for this suite.
Dec  5 15:55:40.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:55:40.565: INFO: namespace: e2e-tests-downward-api-fq8zg, resource: bindings, ignored listing per whitelist
Dec  5 15:55:40.600: INFO: namespace e2e-tests-downward-api-fq8zg deletion completed in 6.095545958s

• [SLOW TEST:8.273 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:55:40.602: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-37249a6a-f8a6-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 15:55:40.862: INFO: Waiting up to 5m0s for pod "pod-configmaps-37289d72-f8a6-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-configmap-pnd8w" to be "success or failure"
Dec  5 15:55:40.873: INFO: Pod "pod-configmaps-37289d72-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 10.598594ms
Dec  5 15:55:42.877: INFO: Pod "pod-configmaps-37289d72-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01429845s
STEP: Saw pod success
Dec  5 15:55:42.877: INFO: Pod "pod-configmaps-37289d72-f8a6-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:55:42.880: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-configmaps-37289d72-f8a6-11e8-a7f8-ceaf58ef2674 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 15:55:42.901: INFO: Waiting for pod pod-configmaps-37289d72-f8a6-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:55:42.904: INFO: Pod pod-configmaps-37289d72-f8a6-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:55:42.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pnd8w" for this suite.
Dec  5 15:55:48.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:55:48.991: INFO: namespace: e2e-tests-configmap-pnd8w, resource: bindings, ignored listing per whitelist
Dec  5 15:55:48.993: INFO: namespace e2e-tests-configmap-pnd8w deletion completed in 6.085614837s

• [SLOW TEST:8.392 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:55:48.996: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 15:55:49.062: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3c0cfeca-f8a6-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-nngsf" to be "success or failure"
Dec  5 15:55:49.067: INFO: Pod "downwardapi-volume-3c0cfeca-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.577805ms
Dec  5 15:55:51.070: INFO: Pod "downwardapi-volume-3c0cfeca-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007959788s
STEP: Saw pod success
Dec  5 15:55:51.070: INFO: Pod "downwardapi-volume-3c0cfeca-f8a6-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:55:51.073: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-3c0cfeca-f8a6-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 15:55:51.092: INFO: Waiting for pod downwardapi-volume-3c0cfeca-f8a6-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:55:51.094: INFO: Pod downwardapi-volume-3c0cfeca-f8a6-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:55:51.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nngsf" for this suite.
Dec  5 15:55:57.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:55:57.149: INFO: namespace: e2e-tests-projected-nngsf, resource: bindings, ignored listing per whitelist
Dec  5 15:55:57.188: INFO: namespace e2e-tests-projected-nngsf deletion completed in 6.089619549s

• [SLOW TEST:8.192 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:55:57.188: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 15:55:59.816: INFO: Successfully updated pod "annotationupdate40f0e0d0-f8a6-11e8-a7f8-ceaf58ef2674"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:56:01.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9j9z5" for this suite.
Dec  5 15:56:23.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:56:23.904: INFO: namespace: e2e-tests-projected-9j9z5, resource: bindings, ignored listing per whitelist
Dec  5 15:56:23.921: INFO: namespace e2e-tests-projected-9j9z5 deletion completed in 22.083492976s

• [SLOW TEST:26.733 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:56:23.923: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-50dfab53-f8a6-11e8-a7f8-ceaf58ef2674
STEP: Creating configMap with name cm-test-opt-upd-50dfab97-f8a6-11e8-a7f8-ceaf58ef2674
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-50dfab53-f8a6-11e8-a7f8-ceaf58ef2674
STEP: Updating configmap cm-test-opt-upd-50dfab97-f8a6-11e8-a7f8-ceaf58ef2674
STEP: Creating configMap with name cm-test-opt-create-50dfabb2-f8a6-11e8-a7f8-ceaf58ef2674
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:57:58.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gw54b" for this suite.
Dec  5 15:58:20.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:58:20.530: INFO: namespace: e2e-tests-projected-gw54b, resource: bindings, ignored listing per whitelist
Dec  5 15:58:20.577: INFO: namespace e2e-tests-projected-gw54b deletion completed in 22.077537504s

• [SLOW TEST:116.654 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:58:20.579: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9667481b-f8a6-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 15:58:20.688: INFO: Waiting up to 5m0s for pod "pod-secrets-9667ee65-f8a6-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-secrets-snvhj" to be "success or failure"
Dec  5 15:58:20.693: INFO: Pod "pod-secrets-9667ee65-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.509732ms
Dec  5 15:58:22.696: INFO: Pod "pod-secrets-9667ee65-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007912504s
STEP: Saw pod success
Dec  5 15:58:22.696: INFO: Pod "pod-secrets-9667ee65-f8a6-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:58:22.698: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-secrets-9667ee65-f8a6-11e8-a7f8-ceaf58ef2674 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 15:58:22.719: INFO: Waiting for pod pod-secrets-9667ee65-f8a6-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:58:22.722: INFO: Pod pod-secrets-9667ee65-f8a6-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:58:22.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-snvhj" for this suite.
Dec  5 15:58:28.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:58:28.802: INFO: namespace: e2e-tests-secrets-snvhj, resource: bindings, ignored listing per whitelist
Dec  5 15:58:28.850: INFO: namespace e2e-tests-secrets-snvhj deletion completed in 6.125026647s

• [SLOW TEST:8.272 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:58:28.852: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 15:58:28.941: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9b585676-f8a6-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-4d2nv" to be "success or failure"
Dec  5 15:58:28.945: INFO: Pod "downwardapi-volume-9b585676-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 3.516714ms
Dec  5 15:58:30.948: INFO: Pod "downwardapi-volume-9b585676-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006805718s
STEP: Saw pod success
Dec  5 15:58:30.948: INFO: Pod "downwardapi-volume-9b585676-f8a6-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:58:30.950: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-9b585676-f8a6-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 15:58:30.976: INFO: Waiting for pod downwardapi-volume-9b585676-f8a6-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:58:30.978: INFO: Pod downwardapi-volume-9b585676-f8a6-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:58:30.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4d2nv" for this suite.
Dec  5 15:58:36.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:58:37.010: INFO: namespace: e2e-tests-downward-api-4d2nv, resource: bindings, ignored listing per whitelist
Dec  5 15:58:37.060: INFO: namespace e2e-tests-downward-api-4d2nv deletion completed in 6.080489955s

• [SLOW TEST:8.209 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:58:37.062: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 15:58:37.133: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a03aa71a-f8a6-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-85skl" to be "success or failure"
Dec  5 15:58:37.140: INFO: Pod "downwardapi-volume-a03aa71a-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.739133ms
Dec  5 15:58:39.144: INFO: Pod "downwardapi-volume-a03aa71a-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010309858s
STEP: Saw pod success
Dec  5 15:58:39.144: INFO: Pod "downwardapi-volume-a03aa71a-f8a6-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 15:58:39.146: INFO: Trying to get logs from node ip-10-0-12-134 pod downwardapi-volume-a03aa71a-f8a6-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 15:58:39.191: INFO: Waiting for pod downwardapi-volume-a03aa71a-f8a6-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 15:58:39.193: INFO: Pod downwardapi-volume-a03aa71a-f8a6-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:58:39.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-85skl" for this suite.
Dec  5 15:58:45.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:58:45.225: INFO: namespace: e2e-tests-downward-api-85skl, resource: bindings, ignored listing per whitelist
Dec  5 15:58:45.297: INFO: namespace e2e-tests-downward-api-85skl deletion completed in 6.100947268s

• [SLOW TEST:8.235 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:58:45.299: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-27dfm A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-27dfm;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-27dfm A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-27dfm;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-27dfm.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-27dfm.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-27dfm.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-27dfm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-27dfm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-27dfm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-27dfm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-27dfm.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-27dfm.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 80.46.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.46.80_udp@PTR;check="$$(dig +tcp +noall +answer +search 80.46.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.46.80_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-27dfm A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-27dfm;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-27dfm A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-27dfm;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-27dfm.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-27dfm.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-27dfm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-27dfm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-27dfm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-27dfm.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-27dfm.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 80.46.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.46.80_udp@PTR;check="$$(dig +tcp +noall +answer +search 80.46.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.46.80_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 15:58:47.587: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.600: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.634: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.639: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.681: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.698: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.702: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.705: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.708: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.712: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.715: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.718: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:47.738: INFO: Lookups using e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-27dfm jessie_tcp@dns-test-service.e2e-tests-dns-27dfm jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc]

Dec  5 15:58:52.743: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.746: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.762: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.765: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.788: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.791: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.795: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.798: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.801: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.804: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.808: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.811: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:52.842: INFO: Lookups using e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-27dfm jessie_tcp@dns-test-service.e2e-tests-dns-27dfm jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc]

Dec  5 15:58:57.743: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.747: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.764: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.768: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.788: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.791: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.794: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.797: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.801: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.804: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.809: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.819: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:58:57.838: INFO: Lookups using e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-27dfm jessie_tcp@dns-test-service.e2e-tests-dns-27dfm jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc]

Dec  5 15:59:02.743: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.747: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.774: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.778: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.811: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.820: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.829: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.838: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.844: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.850: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.857: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.862: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:02.900: INFO: Lookups using e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-27dfm jessie_tcp@dns-test-service.e2e-tests-dns-27dfm jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc]

Dec  5 15:59:07.748: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.755: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.788: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.794: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.830: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.835: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.842: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.846: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.850: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.856: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.863: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.874: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:07.900: INFO: Lookups using e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-27dfm jessie_tcp@dns-test-service.e2e-tests-dns-27dfm jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc]

Dec  5 15:59:12.743: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.747: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.765: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.768: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.791: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.794: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.797: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.801: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.805: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.808: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.811: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.815: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc from pod e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674: the server could not find the requested resource (get pods dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674)
Dec  5 15:59:12.861: INFO: Lookups using e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-27dfm jessie_tcp@dns-test-service.e2e-tests-dns-27dfm jessie_udp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@dns-test-service.e2e-tests-dns-27dfm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-27dfm.svc]

Dec  5 15:59:17.897: INFO: DNS probes using e2e-tests-dns-27dfm/dns-test-a535fd03-f8a6-11e8-a7f8-ceaf58ef2674 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:59:18.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-27dfm" for this suite.
Dec  5 15:59:24.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 15:59:24.077: INFO: namespace: e2e-tests-dns-27dfm, resource: bindings, ignored listing per whitelist
Dec  5 15:59:24.115: INFO: namespace e2e-tests-dns-27dfm deletion completed in 6.102396529s

• [SLOW TEST:38.816 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 15:59:24.117: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-f7nqb
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-f7nqb
STEP: Deleting pre-stop pod
Dec  5 15:59:35.231: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 15:59:35.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-f7nqb" for this suite.
Dec  5 16:00:13.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:00:13.327: INFO: namespace: e2e-tests-prestop-f7nqb, resource: bindings, ignored listing per whitelist
Dec  5 16:00:13.352: INFO: namespace e2e-tests-prestop-f7nqb deletion completed in 38.109785595s

• [SLOW TEST:49.236 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:00:13.353: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  5 16:00:13.423: INFO: namespace e2e-tests-kubectl-tt9tq
Dec  5 16:00:13.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-tt9tq'
Dec  5 16:00:13.879: INFO: stderr: ""
Dec  5 16:00:13.879: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 16:00:14.883: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 16:00:14.883: INFO: Found 0 / 1
Dec  5 16:00:15.883: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 16:00:15.883: INFO: Found 1 / 1
Dec  5 16:00:15.883: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 16:00:15.886: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 16:00:15.886: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 16:00:15.886: INFO: wait on redis-master startup in e2e-tests-kubectl-tt9tq 
Dec  5 16:00:15.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 logs redis-master-hgtxb redis-master --namespace=e2e-tests-kubectl-tt9tq'
Dec  5 16:00:16.006: INFO: stderr: ""
Dec  5 16:00:16.006: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Dec 16:00:14.749 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Dec 16:00:14.749 # Server started, Redis version 3.2.12\n1:M 05 Dec 16:00:14.749 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Dec 16:00:14.749 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  5 16:00:16.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-tt9tq'
Dec  5 16:00:16.145: INFO: stderr: ""
Dec  5 16:00:16.145: INFO: stdout: "service/rm2 exposed\n"
Dec  5 16:00:16.153: INFO: Service rm2 in namespace e2e-tests-kubectl-tt9tq found.
STEP: exposing service
Dec  5 16:00:18.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-tt9tq'
Dec  5 16:00:18.290: INFO: stderr: ""
Dec  5 16:00:18.290: INFO: stdout: "service/rm3 exposed\n"
Dec  5 16:00:18.297: INFO: Service rm3 in namespace e2e-tests-kubectl-tt9tq found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:00:20.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tt9tq" for this suite.
Dec  5 16:00:42.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:00:42.400: INFO: namespace: e2e-tests-kubectl-tt9tq, resource: bindings, ignored listing per whitelist
Dec  5 16:00:42.446: INFO: namespace e2e-tests-kubectl-tt9tq deletion completed in 22.118219163s

• [SLOW TEST:29.093 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:00:42.448: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 16:00:44.558: INFO: Waiting up to 5m0s for pod "client-envvars-ec2d986e-f8a6-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-pods-b5mdp" to be "success or failure"
Dec  5 16:00:44.565: INFO: Pod "client-envvars-ec2d986e-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.756426ms
Dec  5 16:00:46.569: INFO: Pod "client-envvars-ec2d986e-f8a6-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010124853s
STEP: Saw pod success
Dec  5 16:00:46.569: INFO: Pod "client-envvars-ec2d986e-f8a6-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:00:46.570: INFO: Trying to get logs from node ip-10-0-12-134 pod client-envvars-ec2d986e-f8a6-11e8-a7f8-ceaf58ef2674 container env3cont: <nil>
STEP: delete the pod
Dec  5 16:00:46.605: INFO: Waiting for pod client-envvars-ec2d986e-f8a6-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:00:46.609: INFO: Pod client-envvars-ec2d986e-f8a6-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:00:46.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-b5mdp" for this suite.
Dec  5 16:01:32.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:01:32.692: INFO: namespace: e2e-tests-pods-b5mdp, resource: bindings, ignored listing per whitelist
Dec  5 16:01:32.710: INFO: namespace e2e-tests-pods-b5mdp deletion completed in 46.098424621s

• [SLOW TEST:50.262 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:01:32.711: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:01:32.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-nb7gm" for this suite.
Dec  5 16:01:54.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:01:54.895: INFO: namespace: e2e-tests-kubelet-test-nb7gm, resource: bindings, ignored listing per whitelist
Dec  5 16:01:54.949: INFO: namespace e2e-tests-kubelet-test-nb7gm deletion completed in 22.123468368s

• [SLOW TEST:22.238 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:01:54.953: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 16:01:55.016: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:01:56.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-67bkp" for this suite.
Dec  5 16:02:02.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:02:02.264: INFO: namespace: e2e-tests-custom-resource-definition-67bkp, resource: bindings, ignored listing per whitelist
Dec  5 16:02:02.314: INFO: namespace e2e-tests-custom-resource-definition-67bkp deletion completed in 6.080681322s

• [SLOW TEST:7.361 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:02:02.316: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 16:02:02.435: INFO: Waiting up to 5m0s for pod "downward-api-1a994463-f8a7-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-tfb7p" to be "success or failure"
Dec  5 16:02:02.439: INFO: Pod "downward-api-1a994463-f8a7-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.222837ms
Dec  5 16:02:04.443: INFO: Pod "downward-api-1a994463-f8a7-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0073738s
STEP: Saw pod success
Dec  5 16:02:04.443: INFO: Pod "downward-api-1a994463-f8a7-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:02:04.445: INFO: Trying to get logs from node ip-10-0-12-134 pod downward-api-1a994463-f8a7-11e8-a7f8-ceaf58ef2674 container dapi-container: <nil>
STEP: delete the pod
Dec  5 16:02:04.463: INFO: Waiting for pod downward-api-1a994463-f8a7-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:02:04.477: INFO: Pod downward-api-1a994463-f8a7-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:02:04.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tfb7p" for this suite.
Dec  5 16:02:10.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:02:10.530: INFO: namespace: e2e-tests-downward-api-tfb7p, resource: bindings, ignored listing per whitelist
Dec  5 16:02:10.559: INFO: namespace e2e-tests-downward-api-tfb7p deletion completed in 6.079023009s

• [SLOW TEST:8.243 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:02:10.560: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 16:02:10.625: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:02:12.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-g2smj" for this suite.
Dec  5 16:03:02.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:03:02.876: INFO: namespace: e2e-tests-pods-g2smj, resource: bindings, ignored listing per whitelist
Dec  5 16:03:02.934: INFO: namespace e2e-tests-pods-g2smj deletion completed in 50.111699175s

• [SLOW TEST:52.374 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:03:02.936: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:04:03.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-44b6l" for this suite.
Dec  5 16:04:25.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:04:25.049: INFO: namespace: e2e-tests-container-probe-44b6l, resource: bindings, ignored listing per whitelist
Dec  5 16:04:25.095: INFO: namespace e2e-tests-container-probe-44b6l deletion completed in 22.079728561s

• [SLOW TEST:82.159 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:04:25.096: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 16:04:25.157: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:04:28.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-7mwlc" for this suite.
Dec  5 16:04:34.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:04:34.484: INFO: namespace: e2e-tests-init-container-7mwlc, resource: bindings, ignored listing per whitelist
Dec  5 16:04:34.489: INFO: namespace e2e-tests-init-container-7mwlc deletion completed in 6.083369545s

• [SLOW TEST:9.393 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:04:34.490: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-nndq
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 16:04:34.637: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-nndq" in namespace "e2e-tests-subpath-6jg8x" to be "success or failure"
Dec  5 16:04:34.644: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Pending", Reason="", readiness=false. Elapsed: 7.242866ms
Dec  5 16:04:36.651: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014266144s
Dec  5 16:04:38.655: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Running", Reason="", readiness=false. Elapsed: 4.017809692s
Dec  5 16:04:40.693: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Running", Reason="", readiness=false. Elapsed: 6.056158046s
Dec  5 16:04:42.696: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Running", Reason="", readiness=false. Elapsed: 8.059430166s
Dec  5 16:04:44.699: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Running", Reason="", readiness=false. Elapsed: 10.062657553s
Dec  5 16:04:46.703: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Running", Reason="", readiness=false. Elapsed: 12.065868394s
Dec  5 16:04:48.707: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Running", Reason="", readiness=false. Elapsed: 14.069727224s
Dec  5 16:04:50.710: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Running", Reason="", readiness=false. Elapsed: 16.073049841s
Dec  5 16:04:52.713: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Running", Reason="", readiness=false. Elapsed: 18.076252657s
Dec  5 16:04:54.716: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Running", Reason="", readiness=false. Elapsed: 20.079557249s
Dec  5 16:04:56.720: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Running", Reason="", readiness=false. Elapsed: 22.082918452s
Dec  5 16:04:58.728: INFO: Pod "pod-subpath-test-downwardapi-nndq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.090726797s
STEP: Saw pod success
Dec  5 16:04:58.728: INFO: Pod "pod-subpath-test-downwardapi-nndq" satisfied condition "success or failure"
Dec  5 16:04:58.730: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-subpath-test-downwardapi-nndq container test-container-subpath-downwardapi-nndq: <nil>
STEP: delete the pod
Dec  5 16:04:58.782: INFO: Waiting for pod pod-subpath-test-downwardapi-nndq to disappear
Dec  5 16:04:58.787: INFO: Pod pod-subpath-test-downwardapi-nndq no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-nndq
Dec  5 16:04:58.787: INFO: Deleting pod "pod-subpath-test-downwardapi-nndq" in namespace "e2e-tests-subpath-6jg8x"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:04:58.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6jg8x" for this suite.
Dec  5 16:05:04.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:05:04.888: INFO: namespace: e2e-tests-subpath-6jg8x, resource: bindings, ignored listing per whitelist
Dec  5 16:05:04.918: INFO: namespace e2e-tests-subpath-6jg8x deletion completed in 6.102535913s

• [SLOW TEST:30.428 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:05:04.919: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 16:05:04.989: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8768eb7c-f8a7-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-67gnq" to be "success or failure"
Dec  5 16:05:04.993: INFO: Pod "downwardapi-volume-8768eb7c-f8a7-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 3.167919ms
Dec  5 16:05:06.997: INFO: Pod "downwardapi-volume-8768eb7c-f8a7-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007276578s
STEP: Saw pod success
Dec  5 16:05:06.997: INFO: Pod "downwardapi-volume-8768eb7c-f8a7-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:05:06.999: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-8768eb7c-f8a7-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 16:05:07.037: INFO: Waiting for pod downwardapi-volume-8768eb7c-f8a7-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:05:07.041: INFO: Pod downwardapi-volume-8768eb7c-f8a7-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:05:07.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-67gnq" for this suite.
Dec  5 16:05:13.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:05:13.146: INFO: namespace: e2e-tests-projected-67gnq, resource: bindings, ignored listing per whitelist
Dec  5 16:05:13.153: INFO: namespace e2e-tests-projected-67gnq deletion completed in 6.108242604s

• [SLOW TEST:8.234 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:05:13.155: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8c53fd43-f8a7-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 16:05:13.308: INFO: Waiting up to 5m0s for pod "pod-secrets-8c5dc9e7-f8a7-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-secrets-bv5b2" to be "success or failure"
Dec  5 16:05:13.314: INFO: Pod "pod-secrets-8c5dc9e7-f8a7-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.306651ms
Dec  5 16:05:15.318: INFO: Pod "pod-secrets-8c5dc9e7-f8a7-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009325564s
STEP: Saw pod success
Dec  5 16:05:15.318: INFO: Pod "pod-secrets-8c5dc9e7-f8a7-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:05:15.321: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-secrets-8c5dc9e7-f8a7-11e8-a7f8-ceaf58ef2674 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 16:05:15.361: INFO: Waiting for pod pod-secrets-8c5dc9e7-f8a7-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:05:15.371: INFO: Pod pod-secrets-8c5dc9e7-f8a7-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:05:15.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bv5b2" for this suite.
Dec  5 16:05:21.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:05:21.482: INFO: namespace: e2e-tests-secrets-bv5b2, resource: bindings, ignored listing per whitelist
Dec  5 16:05:21.580: INFO: namespace e2e-tests-secrets-bv5b2 deletion completed in 6.130423047s
STEP: Destroying namespace "e2e-tests-secret-namespace-kzpl7" for this suite.
Dec  5 16:05:27.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:05:27.661: INFO: namespace: e2e-tests-secret-namespace-kzpl7, resource: bindings, ignored listing per whitelist
Dec  5 16:05:27.693: INFO: namespace e2e-tests-secret-namespace-kzpl7 deletion completed in 6.112732932s

• [SLOW TEST:14.538 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:05:27.695: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 16:05:27.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-7jlrg'
Dec  5 16:05:27.889: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 16:05:27.889: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec  5 16:05:27.918: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  5 16:05:27.928: INFO: scanned /root for discovery docs: <nil>
Dec  5 16:05:27.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-7jlrg'
Dec  5 16:05:43.765: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  5 16:05:43.765: INFO: stdout: "Created e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc\nScaling up e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  5 16:05:43.765: INFO: stdout: "Created e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc\nScaling up e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  5 16:05:43.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7jlrg'
Dec  5 16:05:43.860: INFO: stderr: ""
Dec  5 16:05:43.860: INFO: stdout: "e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc-rc75w "
Dec  5 16:05:43.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc-rc75w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7jlrg'
Dec  5 16:05:43.949: INFO: stderr: ""
Dec  5 16:05:43.949: INFO: stdout: "true"
Dec  5 16:05:43.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc-rc75w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7jlrg'
Dec  5 16:05:44.042: INFO: stderr: ""
Dec  5 16:05:44.042: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec  5 16:05:44.042: INFO: e2e-test-nginx-rc-c1bc6c1c26f7d3871e5a0e0b8df809bc-rc75w is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Dec  5 16:05:44.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7jlrg'
Dec  5 16:05:44.141: INFO: stderr: ""
Dec  5 16:05:44.141: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:05:44.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7jlrg" for this suite.
Dec  5 16:06:06.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:06:06.227: INFO: namespace: e2e-tests-kubectl-7jlrg, resource: bindings, ignored listing per whitelist
Dec  5 16:06:06.254: INFO: namespace e2e-tests-kubectl-7jlrg deletion completed in 22.107983624s

• [SLOW TEST:38.559 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:06:06.257: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-abf8b313-f8a7-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 16:06:06.336: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-abf96864-f8a7-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-v42wp" to be "success or failure"
Dec  5 16:06:06.342: INFO: Pod "pod-projected-secrets-abf96864-f8a7-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.400365ms
Dec  5 16:06:08.345: INFO: Pod "pod-projected-secrets-abf96864-f8a7-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00948915s
STEP: Saw pod success
Dec  5 16:06:08.345: INFO: Pod "pod-projected-secrets-abf96864-f8a7-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:06:08.348: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-secrets-abf96864-f8a7-11e8-a7f8-ceaf58ef2674 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 16:06:08.367: INFO: Waiting for pod pod-projected-secrets-abf96864-f8a7-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:06:08.371: INFO: Pod pod-projected-secrets-abf96864-f8a7-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:06:08.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v42wp" for this suite.
Dec  5 16:06:14.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:06:14.408: INFO: namespace: e2e-tests-projected-v42wp, resource: bindings, ignored listing per whitelist
Dec  5 16:06:14.454: INFO: namespace e2e-tests-projected-v42wp deletion completed in 6.08057958s

• [SLOW TEST:8.198 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:06:14.457: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  5 16:06:18.615: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 16:06:18.618: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 16:06:20.619: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 16:06:20.622: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 16:06:22.619: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 16:06:22.622: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 16:06:24.619: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 16:06:24.622: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:06:24.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-vx56f" for this suite.
Dec  5 16:06:46.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:06:46.704: INFO: namespace: e2e-tests-container-lifecycle-hook-vx56f, resource: bindings, ignored listing per whitelist
Dec  5 16:06:46.708: INFO: namespace e2e-tests-container-lifecycle-hook-vx56f deletion completed in 22.082801753s

• [SLOW TEST:32.251 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:06:46.710: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  5 16:06:48.798: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-c414a82b-f8a7-11e8-a7f8-ceaf58ef2674", GenerateName:"", Namespace:"e2e-tests-pods-mmgrw", SelfLink:"/api/v1/namespaces/e2e-tests-pods-mmgrw/pods/pod-submit-remove-c414a82b-f8a7-11e8-a7f8-ceaf58ef2674", UID:"c415851a-f8a7-11e8-ab6c-06b570ab0412", ResourceVersion:"60573", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679622806, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"771518087"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.0.105/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-rmfpl", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000d2dd40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rmfpl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001947dc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-40-84", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0020919e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001947e10)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001947e30)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001947e38), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001947e3c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679622806, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679622807, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679622807, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679622806, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.40.84", PodIP:"10.2.0.105", StartTime:(*v1.Time)(0xc000e90820), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000e90840), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd", ContainerID:"docker://606141fb7146001b3bc458c1f6b855afdcdfb58472f02c3eebe62f5f3e3c61ef"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:07:00.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mmgrw" for this suite.
Dec  5 16:07:06.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:07:06.601: INFO: namespace: e2e-tests-pods-mmgrw, resource: bindings, ignored listing per whitelist
Dec  5 16:07:06.612: INFO: namespace e2e-tests-pods-mmgrw deletion completed in 6.078912144s

• [SLOW TEST:19.903 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:07:06.614: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 16:07:06.687: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cff234aa-f8a7-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-bl29s" to be "success or failure"
Dec  5 16:07:06.696: INFO: Pod "downwardapi-volume-cff234aa-f8a7-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 9.484973ms
Dec  5 16:07:08.700: INFO: Pod "downwardapi-volume-cff234aa-f8a7-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012944147s
STEP: Saw pod success
Dec  5 16:07:08.700: INFO: Pod "downwardapi-volume-cff234aa-f8a7-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:07:08.702: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-cff234aa-f8a7-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 16:07:08.726: INFO: Waiting for pod downwardapi-volume-cff234aa-f8a7-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:07:08.728: INFO: Pod downwardapi-volume-cff234aa-f8a7-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:07:08.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bl29s" for this suite.
Dec  5 16:07:14.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:07:14.780: INFO: namespace: e2e-tests-projected-bl29s, resource: bindings, ignored listing per whitelist
Dec  5 16:07:14.814: INFO: namespace e2e-tests-projected-bl29s deletion completed in 6.082752299s

• [SLOW TEST:8.200 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:07:14.815: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-mtsv2
Dec  5 16:07:16.912: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-mtsv2
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 16:07:16.915: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:11:17.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mtsv2" for this suite.
Dec  5 16:11:23.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:11:23.467: INFO: namespace: e2e-tests-container-probe-mtsv2, resource: bindings, ignored listing per whitelist
Dec  5 16:11:23.518: INFO: namespace e2e-tests-container-probe-mtsv2 deletion completed in 6.08188923s

• [SLOW TEST:248.703 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:11:23.521: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 16:11:23.587: INFO: PodSpec: initContainers in spec.initContainers
Dec  5 16:12:09.129: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-69135eab-f8a8-11e8-a7f8-ceaf58ef2674", GenerateName:"", Namespace:"e2e-tests-init-container-q9k2f", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-q9k2f/pods/pod-init-69135eab-f8a8-11e8-a7f8-ceaf58ef2674", UID:"6913d0be-f8a8-11e8-ab6c-06b570ab0412", ResourceVersion:"61120", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679623083, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"587146850"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.0.108/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-g2xwn", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00249a240), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-g2xwn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-g2xwn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-g2xwn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001ec0718), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-40-84", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000926120), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001ec0830)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001ec0850)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001ec0858), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001ec085c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679623083, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679623083, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679623083, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679623083, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.40.84", PodIP:"10.2.0.108", StartTime:(*v1.Time)(0xc0031de120), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0013a81c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0013a82a0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://ed3154a9fde3e3174e2f75665dc6a87531baae12d8f4a9fb879a75b6535d05fb"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0031de160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0031de140), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:12:09.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-q9k2f" for this suite.
Dec  5 16:12:31.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:12:31.181: INFO: namespace: e2e-tests-init-container-q9k2f, resource: bindings, ignored listing per whitelist
Dec  5 16:12:31.215: INFO: namespace e2e-tests-init-container-q9k2f deletion completed in 22.082678495s

• [SLOW TEST:67.694 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:12:31.218: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-xzc9
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 16:12:31.302: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xzc9" in namespace "e2e-tests-subpath-5q7cq" to be "success or failure"
Dec  5 16:12:31.307: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.218026ms
Dec  5 16:12:33.310: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008668966s
Dec  5 16:12:35.366: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Running", Reason="", readiness=false. Elapsed: 4.064565707s
Dec  5 16:12:37.370: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Running", Reason="", readiness=false. Elapsed: 6.067818865s
Dec  5 16:12:39.373: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Running", Reason="", readiness=false. Elapsed: 8.071116793s
Dec  5 16:12:41.376: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Running", Reason="", readiness=false. Elapsed: 10.074506324s
Dec  5 16:12:43.380: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Running", Reason="", readiness=false. Elapsed: 12.077905084s
Dec  5 16:12:45.386: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Running", Reason="", readiness=false. Elapsed: 14.08379393s
Dec  5 16:12:47.389: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Running", Reason="", readiness=false. Elapsed: 16.087141198s
Dec  5 16:12:49.393: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Running", Reason="", readiness=false. Elapsed: 18.090753671s
Dec  5 16:12:51.396: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Running", Reason="", readiness=false. Elapsed: 20.094161853s
Dec  5 16:12:53.400: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Running", Reason="", readiness=false. Elapsed: 22.097865378s
Dec  5 16:12:55.404: INFO: Pod "pod-subpath-test-configmap-xzc9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.101873769s
STEP: Saw pod success
Dec  5 16:12:55.404: INFO: Pod "pod-subpath-test-configmap-xzc9" satisfied condition "success or failure"
Dec  5 16:12:55.406: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-subpath-test-configmap-xzc9 container test-container-subpath-configmap-xzc9: <nil>
STEP: delete the pod
Dec  5 16:12:55.428: INFO: Waiting for pod pod-subpath-test-configmap-xzc9 to disappear
Dec  5 16:12:55.432: INFO: Pod pod-subpath-test-configmap-xzc9 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xzc9
Dec  5 16:12:55.432: INFO: Deleting pod "pod-subpath-test-configmap-xzc9" in namespace "e2e-tests-subpath-5q7cq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:12:55.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5q7cq" for this suite.
Dec  5 16:13:01.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:13:01.534: INFO: namespace: e2e-tests-subpath-5q7cq, resource: bindings, ignored listing per whitelist
Dec  5 16:13:01.558: INFO: namespace e2e-tests-subpath-5q7cq deletion completed in 6.121929325s

• [SLOW TEST:30.340 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:13:01.560: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8t7r7
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec  5 16:13:01.661: INFO: Found 0 stateful pods, waiting for 3
Dec  5 16:13:11.665: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 16:13:11.665: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 16:13:11.665: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 16:13:11.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-8t7r7 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 16:13:11.853: INFO: stderr: ""
Dec  5 16:13:11.853: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 16:13:11.853: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  5 16:13:21.884: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  5 16:13:31.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-8t7r7 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 16:13:32.121: INFO: stderr: ""
Dec  5 16:13:32.121: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 16:13:32.121: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 16:13:52.138: INFO: Waiting for StatefulSet e2e-tests-statefulset-8t7r7/ss2 to complete update
STEP: Rolling back to a previous revision
Dec  5 16:14:02.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-8t7r7 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 16:14:02.360: INFO: stderr: ""
Dec  5 16:14:02.360: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 16:14:02.360: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 16:14:12.392: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  5 16:14:22.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 exec --namespace=e2e-tests-statefulset-8t7r7 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 16:14:22.590: INFO: stderr: ""
Dec  5 16:14:22.590: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 16:14:22.590: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 16:14:42.608: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8t7r7
Dec  5 16:14:42.610: INFO: Scaling statefulset ss2 to 0
Dec  5 16:15:02.628: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 16:15:02.630: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:15:02.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8t7r7" for this suite.
Dec  5 16:15:08.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:15:08.730: INFO: namespace: e2e-tests-statefulset-8t7r7, resource: bindings, ignored listing per whitelist
Dec  5 16:15:08.761: INFO: namespace e2e-tests-statefulset-8t7r7 deletion completed in 6.107551959s

• [SLOW TEST:127.201 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:15:08.764: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 16:15:08.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-j8wgr'
Dec  5 16:15:09.190: INFO: stderr: ""
Dec  5 16:15:09.190: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  5 16:15:14.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-j8wgr -o json'
Dec  5 16:15:14.345: INFO: stderr: ""
Dec  5 16:15:14.345: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.2.0.116/32\"\n        },\n        \"creationTimestamp\": \"2018-12-05T16:15:09Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-j8wgr\",\n        \"resourceVersion\": \"61800\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-j8wgr/pods/e2e-test-nginx-pod\",\n        \"uid\": \"ef88e5f2-f8a8-11e8-ab6c-06b570ab0412\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-v524j\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-40-84\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-v524j\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-v524j\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T16:15:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T16:15:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T16:15:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T16:15:09Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://c4c2fe8bb4c920b7b6d545f05e0921514290b95dca3c2e4a4d6d113b068c48bd\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-05T16:15:10Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.40.84\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.0.116\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-05T16:15:09Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  5 16:15:14.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 replace -f - --namespace=e2e-tests-kubectl-j8wgr'
Dec  5 16:15:14.564: INFO: stderr: ""
Dec  5 16:15:14.564: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Dec  5 16:15:14.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-j8wgr'
Dec  5 16:15:20.537: INFO: stderr: ""
Dec  5 16:15:20.537: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:15:20.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j8wgr" for this suite.
Dec  5 16:15:26.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:15:26.574: INFO: namespace: e2e-tests-kubectl-j8wgr, resource: bindings, ignored listing per whitelist
Dec  5 16:15:26.656: INFO: namespace e2e-tests-kubectl-j8wgr deletion completed in 6.113368069s

• [SLOW TEST:17.893 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:15:26.660: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-l7zpp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 16:15:26.741: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 16:15:48.836: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.0.117:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-l7zpp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 16:15:48.836: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 16:15:48.969: INFO: Found all expected endpoints: [netserver-0]
Dec  5 16:15:48.972: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.1.47:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-l7zpp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 16:15:48.972: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 16:15:49.064: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:15:49.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-l7zpp" for this suite.
Dec  5 16:16:11.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:16:11.134: INFO: namespace: e2e-tests-pod-network-test-l7zpp, resource: bindings, ignored listing per whitelist
Dec  5 16:16:11.155: INFO: namespace e2e-tests-pod-network-test-l7zpp deletion completed in 22.087822187s

• [SLOW TEST:44.495 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:16:11.157: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  5 16:16:11.249: INFO: Waiting up to 5m0s for pod "pod-148744de-f8a9-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-jkbrb" to be "success or failure"
Dec  5 16:16:11.256: INFO: Pod "pod-148744de-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 7.379422ms
Dec  5 16:16:13.260: INFO: Pod "pod-148744de-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010613082s
STEP: Saw pod success
Dec  5 16:16:13.260: INFO: Pod "pod-148744de-f8a9-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:16:13.262: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-148744de-f8a9-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:16:13.285: INFO: Waiting for pod pod-148744de-f8a9-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:16:13.287: INFO: Pod pod-148744de-f8a9-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:16:13.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jkbrb" for this suite.
Dec  5 16:16:19.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:16:19.362: INFO: namespace: e2e-tests-emptydir-jkbrb, resource: bindings, ignored listing per whitelist
Dec  5 16:16:19.373: INFO: namespace e2e-tests-emptydir-jkbrb deletion completed in 6.083446234s

• [SLOW TEST:8.216 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:16:19.375: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 16:16:19.439: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:16:23.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-vqj4j" for this suite.
Dec  5 16:16:45.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:16:45.202: INFO: namespace: e2e-tests-init-container-vqj4j, resource: bindings, ignored listing per whitelist
Dec  5 16:16:45.258: INFO: namespace e2e-tests-init-container-vqj4j deletion completed in 22.086577658s

• [SLOW TEST:25.884 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:16:45.259: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  5 16:16:45.459: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-v2sd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v2sd8/configmaps/e2e-watch-test-resource-version,UID:28e80018-f8a9-11e8-ab6c-06b570ab0412,ResourceVersion:62100,Generation:0,CreationTimestamp:2018-12-05 16:16:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 16:16:45.459: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-v2sd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v2sd8/configmaps/e2e-watch-test-resource-version,UID:28e80018-f8a9-11e8-ab6c-06b570ab0412,ResourceVersion:62101,Generation:0,CreationTimestamp:2018-12-05 16:16:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:16:45.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-v2sd8" for this suite.
Dec  5 16:16:51.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:16:51.550: INFO: namespace: e2e-tests-watch-v2sd8, resource: bindings, ignored listing per whitelist
Dec  5 16:16:51.565: INFO: namespace e2e-tests-watch-v2sd8 deletion completed in 6.102183345s

• [SLOW TEST:6.306 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:16:51.567: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2c99f4a6-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 16:16:51.637: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2c9a95f1-f8a9-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-7lnll" to be "success or failure"
Dec  5 16:16:51.641: INFO: Pod "pod-projected-configmaps-2c9a95f1-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038837ms
Dec  5 16:16:53.645: INFO: Pod "pod-projected-configmaps-2c9a95f1-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007962221s
STEP: Saw pod success
Dec  5 16:16:53.645: INFO: Pod "pod-projected-configmaps-2c9a95f1-f8a9-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:16:53.647: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-configmaps-2c9a95f1-f8a9-11e8-a7f8-ceaf58ef2674 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 16:16:53.665: INFO: Waiting for pod pod-projected-configmaps-2c9a95f1-f8a9-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:16:53.668: INFO: Pod pod-projected-configmaps-2c9a95f1-f8a9-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:16:53.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7lnll" for this suite.
Dec  5 16:16:59.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:16:59.730: INFO: namespace: e2e-tests-projected-7lnll, resource: bindings, ignored listing per whitelist
Dec  5 16:16:59.755: INFO: namespace e2e-tests-projected-7lnll deletion completed in 6.084240182s

• [SLOW TEST:8.189 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:16:59.757: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-317d8f82-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Creating configMap with name cm-test-opt-upd-317d8fc4-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-317d8f82-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Updating configmap cm-test-opt-upd-317d8fc4-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Creating configMap with name cm-test-opt-create-317d8fe4-f8a9-11e8-a7f8-ceaf58ef2674
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:17:03.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vh295" for this suite.
Dec  5 16:17:25.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:17:26.030: INFO: namespace: e2e-tests-configmap-vh295, resource: bindings, ignored listing per whitelist
Dec  5 16:17:26.065: INFO: namespace e2e-tests-configmap-vh295 deletion completed in 22.09230004s

• [SLOW TEST:26.308 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:17:26.068: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 16:17:26.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-nndg9'
Dec  5 16:17:26.238: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 16:17:26.238: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  5 16:17:26.246: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-t9l2q]
Dec  5 16:17:26.246: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-t9l2q" in namespace "e2e-tests-kubectl-nndg9" to be "running and ready"
Dec  5 16:17:26.261: INFO: Pod "e2e-test-nginx-rc-t9l2q": Phase="Pending", Reason="", readiness=false. Elapsed: 15.403131ms
Dec  5 16:17:28.265: INFO: Pod "e2e-test-nginx-rc-t9l2q": Phase="Running", Reason="", readiness=true. Elapsed: 2.018513173s
Dec  5 16:17:28.265: INFO: Pod "e2e-test-nginx-rc-t9l2q" satisfied condition "running and ready"
Dec  5 16:17:28.265: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-t9l2q]
Dec  5 16:17:28.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nndg9'
Dec  5 16:17:28.374: INFO: stderr: ""
Dec  5 16:17:28.374: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Dec  5 16:17:28.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nndg9'
Dec  5 16:17:28.470: INFO: stderr: ""
Dec  5 16:17:28.470: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:17:28.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nndg9" for this suite.
Dec  5 16:17:50.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:17:50.540: INFO: namespace: e2e-tests-kubectl-nndg9, resource: bindings, ignored listing per whitelist
Dec  5 16:17:50.559: INFO: namespace e2e-tests-kubectl-nndg9 deletion completed in 22.080017202s

• [SLOW TEST:24.492 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:17:50.561: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  5 16:17:50.634: INFO: Waiting up to 5m0s for pod "pod-4fc4eace-f8a9-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-gzqsz" to be "success or failure"
Dec  5 16:17:50.638: INFO: Pod "pod-4fc4eace-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.727903ms
Dec  5 16:17:52.642: INFO: Pod "pod-4fc4eace-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008080595s
STEP: Saw pod success
Dec  5 16:17:52.642: INFO: Pod "pod-4fc4eace-f8a9-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:17:52.644: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-4fc4eace-f8a9-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:17:52.660: INFO: Waiting for pod pod-4fc4eace-f8a9-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:17:52.663: INFO: Pod pod-4fc4eace-f8a9-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:17:52.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gzqsz" for this suite.
Dec  5 16:17:58.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:17:58.694: INFO: namespace: e2e-tests-emptydir-gzqsz, resource: bindings, ignored listing per whitelist
Dec  5 16:17:58.752: INFO: namespace e2e-tests-emptydir-gzqsz deletion completed in 6.086500665s

• [SLOW TEST:8.192 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:17:58.754: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  5 16:18:02.882: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:02.885: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 16:18:04.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:04.889: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 16:18:06.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:06.889: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 16:18:08.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:08.890: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 16:18:10.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:10.889: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 16:18:12.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:12.889: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 16:18:14.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:14.889: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 16:18:16.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:16.889: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 16:18:18.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:18.888: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 16:18:20.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:20.889: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 16:18:22.885: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 16:18:22.888: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:18:22.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-sp4bj" for this suite.
Dec  5 16:18:44.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:18:44.919: INFO: namespace: e2e-tests-container-lifecycle-hook-sp4bj, resource: bindings, ignored listing per whitelist
Dec  5 16:18:44.983: INFO: namespace e2e-tests-container-lifecycle-hook-sp4bj deletion completed in 22.090801031s

• [SLOW TEST:46.229 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:18:44.985: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec  5 16:18:45.061: INFO: Waiting up to 5m0s for pod "var-expansion-7035a8dc-f8a9-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-var-expansion-4nzdd" to be "success or failure"
Dec  5 16:18:45.067: INFO: Pod "var-expansion-7035a8dc-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.655024ms
Dec  5 16:18:47.070: INFO: Pod "var-expansion-7035a8dc-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009118226s
STEP: Saw pod success
Dec  5 16:18:47.070: INFO: Pod "var-expansion-7035a8dc-f8a9-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:18:47.072: INFO: Trying to get logs from node ip-10-0-40-84 pod var-expansion-7035a8dc-f8a9-11e8-a7f8-ceaf58ef2674 container dapi-container: <nil>
STEP: delete the pod
Dec  5 16:18:47.091: INFO: Waiting for pod var-expansion-7035a8dc-f8a9-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:18:47.095: INFO: Pod var-expansion-7035a8dc-f8a9-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:18:47.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4nzdd" for this suite.
Dec  5 16:18:53.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:18:53.127: INFO: namespace: e2e-tests-var-expansion-4nzdd, resource: bindings, ignored listing per whitelist
Dec  5 16:18:53.188: INFO: namespace e2e-tests-var-expansion-4nzdd deletion completed in 6.091055427s

• [SLOW TEST:8.204 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:18:53.190: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7519a337-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 16:18:53.285: INFO: Waiting up to 5m0s for pod "pod-configmaps-751a1e19-f8a9-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-configmap-jsgcc" to be "success or failure"
Dec  5 16:18:53.289: INFO: Pod "pod-configmaps-751a1e19-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.122832ms
Dec  5 16:18:55.293: INFO: Pod "pod-configmaps-751a1e19-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007810475s
STEP: Saw pod success
Dec  5 16:18:55.293: INFO: Pod "pod-configmaps-751a1e19-f8a9-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:18:55.295: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-configmaps-751a1e19-f8a9-11e8-a7f8-ceaf58ef2674 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 16:18:55.317: INFO: Waiting for pod pod-configmaps-751a1e19-f8a9-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:18:55.321: INFO: Pod pod-configmaps-751a1e19-f8a9-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:18:55.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jsgcc" for this suite.
Dec  5 16:19:01.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:19:01.414: INFO: namespace: e2e-tests-configmap-jsgcc, resource: bindings, ignored listing per whitelist
Dec  5 16:19:01.414: INFO: namespace e2e-tests-configmap-jsgcc deletion completed in 6.090744148s

• [SLOW TEST:8.224 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:19:01.415: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-7a011466-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Creating secret with name s-test-opt-upd-7a0114ae-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7a011466-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Updating secret s-test-opt-upd-7a0114ae-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Creating secret with name s-test-opt-create-7a0114ce-f8a9-11e8-a7f8-ceaf58ef2674
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:19:05.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sllrl" for this suite.
Dec  5 16:19:27.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:19:27.679: INFO: namespace: e2e-tests-projected-sllrl, resource: bindings, ignored listing per whitelist
Dec  5 16:19:27.690: INFO: namespace e2e-tests-projected-sllrl deletion completed in 22.082640302s

• [SLOW TEST:26.275 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:19:27.691: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 16:19:27.776: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:27.779: INFO: Number of nodes with available pods: 0
Dec  5 16:19:27.779: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:19:28.784: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:28.786: INFO: Number of nodes with available pods: 0
Dec  5 16:19:28.786: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:19:29.784: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:29.786: INFO: Number of nodes with available pods: 1
Dec  5 16:19:29.786: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:19:30.783: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:30.785: INFO: Number of nodes with available pods: 2
Dec  5 16:19:30.785: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  5 16:19:30.805: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:30.809: INFO: Number of nodes with available pods: 1
Dec  5 16:19:30.809: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:31.814: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:31.817: INFO: Number of nodes with available pods: 1
Dec  5 16:19:31.817: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:32.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:32.820: INFO: Number of nodes with available pods: 1
Dec  5 16:19:32.820: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:33.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:33.816: INFO: Number of nodes with available pods: 1
Dec  5 16:19:33.816: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:34.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:34.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:34.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:35.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:35.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:35.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:36.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:36.822: INFO: Number of nodes with available pods: 1
Dec  5 16:19:36.822: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:37.814: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:37.818: INFO: Number of nodes with available pods: 1
Dec  5 16:19:37.818: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:38.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:38.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:38.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:39.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:39.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:39.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:40.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:40.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:40.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:41.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:41.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:41.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:42.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:42.820: INFO: Number of nodes with available pods: 1
Dec  5 16:19:42.820: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:43.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:43.816: INFO: Number of nodes with available pods: 1
Dec  5 16:19:43.816: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:44.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:44.820: INFO: Number of nodes with available pods: 1
Dec  5 16:19:44.820: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:45.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:45.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:45.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:46.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:46.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:46.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:47.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:47.816: INFO: Number of nodes with available pods: 1
Dec  5 16:19:47.816: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:48.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:48.820: INFO: Number of nodes with available pods: 1
Dec  5 16:19:48.820: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:49.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:49.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:49.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:50.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:50.820: INFO: Number of nodes with available pods: 1
Dec  5 16:19:50.820: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:51.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:51.816: INFO: Number of nodes with available pods: 1
Dec  5 16:19:51.816: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:52.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:52.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:52.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:53.814: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:53.817: INFO: Number of nodes with available pods: 1
Dec  5 16:19:53.817: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:54.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:54.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:54.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:55.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:55.816: INFO: Number of nodes with available pods: 1
Dec  5 16:19:55.816: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:56.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:56.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:56.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:57.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:57.815: INFO: Number of nodes with available pods: 1
Dec  5 16:19:57.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:58.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:58.820: INFO: Number of nodes with available pods: 1
Dec  5 16:19:58.820: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:19:59.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:19:59.817: INFO: Number of nodes with available pods: 1
Dec  5 16:19:59.817: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:00.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:00.815: INFO: Number of nodes with available pods: 1
Dec  5 16:20:00.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:01.833: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:01.839: INFO: Number of nodes with available pods: 1
Dec  5 16:20:01.839: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:02.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:02.815: INFO: Number of nodes with available pods: 1
Dec  5 16:20:02.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:03.812: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:03.816: INFO: Number of nodes with available pods: 1
Dec  5 16:20:03.816: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:04.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:04.815: INFO: Number of nodes with available pods: 1
Dec  5 16:20:04.815: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:05.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:05.816: INFO: Number of nodes with available pods: 1
Dec  5 16:20:05.817: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:06.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:06.821: INFO: Number of nodes with available pods: 1
Dec  5 16:20:06.821: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:07.814: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:07.817: INFO: Number of nodes with available pods: 1
Dec  5 16:20:07.817: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:08.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:08.822: INFO: Number of nodes with available pods: 1
Dec  5 16:20:08.822: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:09.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:09.817: INFO: Number of nodes with available pods: 1
Dec  5 16:20:09.817: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:10.814: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:10.825: INFO: Number of nodes with available pods: 1
Dec  5 16:20:10.825: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:11.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:11.817: INFO: Number of nodes with available pods: 1
Dec  5 16:20:11.817: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:20:12.813: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:20:12.820: INFO: Number of nodes with available pods: 2
Dec  5 16:20:12.820: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-9z77b, will wait for the garbage collector to delete the pods
Dec  5 16:20:12.889: INFO: Deleting DaemonSet.extensions daemon-set took: 9.642941ms
Dec  5 16:20:12.989: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.307586ms
Dec  5 16:20:50.592: INFO: Number of nodes with available pods: 0
Dec  5 16:20:50.592: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 16:20:50.595: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9z77b/daemonsets","resourceVersion":"62781"},"items":null}

Dec  5 16:20:50.597: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9z77b/pods","resourceVersion":"62781"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:20:50.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9z77b" for this suite.
Dec  5 16:20:56.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:20:56.664: INFO: namespace: e2e-tests-daemonsets-9z77b, resource: bindings, ignored listing per whitelist
Dec  5 16:20:56.702: INFO: namespace e2e-tests-daemonsets-9z77b deletion completed in 6.096359671s

• [SLOW TEST:89.012 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:20:56.704: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-beb86940-f8a9-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 16:20:56.782: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-beb8f7a1-f8a9-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-wd8lc" to be "success or failure"
Dec  5 16:20:56.785: INFO: Pod "pod-projected-secrets-beb8f7a1-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.830126ms
Dec  5 16:20:58.788: INFO: Pod "pod-projected-secrets-beb8f7a1-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0061549s
STEP: Saw pod success
Dec  5 16:20:58.788: INFO: Pod "pod-projected-secrets-beb8f7a1-f8a9-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:20:58.790: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-secrets-beb8f7a1-f8a9-11e8-a7f8-ceaf58ef2674 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 16:20:58.808: INFO: Waiting for pod pod-projected-secrets-beb8f7a1-f8a9-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:20:58.812: INFO: Pod pod-projected-secrets-beb8f7a1-f8a9-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:20:58.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wd8lc" for this suite.
Dec  5 16:21:04.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:21:04.899: INFO: namespace: e2e-tests-projected-wd8lc, resource: bindings, ignored listing per whitelist
Dec  5 16:21:04.917: INFO: namespace e2e-tests-projected-wd8lc deletion completed in 6.10267765s

• [SLOW TEST:8.214 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:21:04.919: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 16:21:04.989: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c39cdfe7-f8a9-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-k5wtg" to be "success or failure"
Dec  5 16:21:05.030: INFO: Pod "downwardapi-volume-c39cdfe7-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 39.90739ms
Dec  5 16:21:07.033: INFO: Pod "downwardapi-volume-c39cdfe7-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043498665s
STEP: Saw pod success
Dec  5 16:21:07.033: INFO: Pod "downwardapi-volume-c39cdfe7-f8a9-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:21:07.035: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-c39cdfe7-f8a9-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 16:21:07.059: INFO: Waiting for pod downwardapi-volume-c39cdfe7-f8a9-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:21:07.062: INFO: Pod downwardapi-volume-c39cdfe7-f8a9-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:21:07.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k5wtg" for this suite.
Dec  5 16:21:13.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:21:13.136: INFO: namespace: e2e-tests-downward-api-k5wtg, resource: bindings, ignored listing per whitelist
Dec  5 16:21:13.155: INFO: namespace e2e-tests-downward-api-k5wtg deletion completed in 6.089980006s

• [SLOW TEST:8.236 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:21:13.157: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:21:13.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-2rpng" for this suite.
Dec  5 16:21:19.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:21:19.284: INFO: namespace: e2e-tests-services-2rpng, resource: bindings, ignored listing per whitelist
Dec  5 16:21:19.352: INFO: namespace e2e-tests-services-2rpng deletion completed in 6.097658143s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.195 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:21:19.354: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 16:21:19.461: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Dec  5 16:21:19.466: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7qgfd/daemonsets","resourceVersion":"62910"},"items":null}

Dec  5 16:21:19.468: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7qgfd/pods","resourceVersion":"62910"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:21:19.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7qgfd" for this suite.
Dec  5 16:21:25.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:21:25.529: INFO: namespace: e2e-tests-daemonsets-7qgfd, resource: bindings, ignored listing per whitelist
Dec  5 16:21:25.571: INFO: namespace e2e-tests-daemonsets-7qgfd deletion completed in 6.093256637s

S [SKIPPING] [6.218 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec  5 16:21:19.462: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:21:25.573: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 16:21:25.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-h2w2p'
Dec  5 16:21:25.741: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 16:21:25.741: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Dec  5 16:21:25.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-h2w2p'
Dec  5 16:21:25.842: INFO: stderr: ""
Dec  5 16:21:25.842: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:21:25.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h2w2p" for this suite.
Dec  5 16:21:31.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:21:31.889: INFO: namespace: e2e-tests-kubectl-h2w2p, resource: bindings, ignored listing per whitelist
Dec  5 16:21:31.935: INFO: namespace e2e-tests-kubectl-h2w2p deletion completed in 6.088741576s

• [SLOW TEST:6.362 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:21:31.936: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec  5 16:21:31.999: INFO: Waiting up to 5m0s for pod "client-containers-d3b6d686-f8a9-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-containers-c2pb6" to be "success or failure"
Dec  5 16:21:32.013: INFO: Pod "client-containers-d3b6d686-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 13.31703ms
Dec  5 16:21:34.017: INFO: Pod "client-containers-d3b6d686-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016980946s
Dec  5 16:21:36.020: INFO: Pod "client-containers-d3b6d686-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020210707s
STEP: Saw pod success
Dec  5 16:21:36.020: INFO: Pod "client-containers-d3b6d686-f8a9-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:21:36.022: INFO: Trying to get logs from node ip-10-0-40-84 pod client-containers-d3b6d686-f8a9-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:21:36.040: INFO: Waiting for pod client-containers-d3b6d686-f8a9-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:21:36.041: INFO: Pod client-containers-d3b6d686-f8a9-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:21:36.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-c2pb6" for this suite.
Dec  5 16:21:42.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:21:42.108: INFO: namespace: e2e-tests-containers-c2pb6, resource: bindings, ignored listing per whitelist
Dec  5 16:21:42.125: INFO: namespace e2e-tests-containers-c2pb6 deletion completed in 6.080064354s

• [SLOW TEST:10.190 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:21:42.128: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec  5 16:21:42.194: INFO: Waiting up to 5m0s for pod "var-expansion-d9ca52e7-f8a9-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-var-expansion-m99xj" to be "success or failure"
Dec  5 16:21:42.196: INFO: Pod "var-expansion-d9ca52e7-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.54295ms
Dec  5 16:21:44.200: INFO: Pod "var-expansion-d9ca52e7-f8a9-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006069882s
STEP: Saw pod success
Dec  5 16:21:44.200: INFO: Pod "var-expansion-d9ca52e7-f8a9-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:21:44.202: INFO: Trying to get logs from node ip-10-0-40-84 pod var-expansion-d9ca52e7-f8a9-11e8-a7f8-ceaf58ef2674 container dapi-container: <nil>
STEP: delete the pod
Dec  5 16:21:44.222: INFO: Waiting for pod var-expansion-d9ca52e7-f8a9-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:21:44.226: INFO: Pod var-expansion-d9ca52e7-f8a9-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:21:44.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-m99xj" for this suite.
Dec  5 16:21:50.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:21:50.326: INFO: namespace: e2e-tests-var-expansion-m99xj, resource: bindings, ignored listing per whitelist
Dec  5 16:21:50.355: INFO: namespace e2e-tests-var-expansion-m99xj deletion completed in 6.126317766s

• [SLOW TEST:8.228 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:21:50.357: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 16:21:53.002: INFO: Successfully updated pod "labelsupdatedeb9d946-f8a9-11e8-a7f8-ceaf58ef2674"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:21:57.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ffv8t" for this suite.
Dec  5 16:22:19.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:22:19.065: INFO: namespace: e2e-tests-projected-ffv8t, resource: bindings, ignored listing per whitelist
Dec  5 16:22:19.112: INFO: namespace e2e-tests-projected-ffv8t deletion completed in 22.078362729s

• [SLOW TEST:28.755 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:22:19.114: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-lxc7
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 16:22:19.200: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lxc7" in namespace "e2e-tests-subpath-2rj54" to be "success or failure"
Dec  5 16:22:19.205: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.989263ms
Dec  5 16:22:21.209: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00858916s
Dec  5 16:22:23.212: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Running", Reason="", readiness=false. Elapsed: 4.012054113s
Dec  5 16:22:25.216: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Running", Reason="", readiness=false. Elapsed: 6.015703512s
Dec  5 16:22:27.219: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Running", Reason="", readiness=false. Elapsed: 8.018878158s
Dec  5 16:22:29.222: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Running", Reason="", readiness=false. Elapsed: 10.021872261s
Dec  5 16:22:31.225: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Running", Reason="", readiness=false. Elapsed: 12.025043681s
Dec  5 16:22:33.230: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Running", Reason="", readiness=false. Elapsed: 14.0294625s
Dec  5 16:22:35.234: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Running", Reason="", readiness=false. Elapsed: 16.034092106s
Dec  5 16:22:37.238: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Running", Reason="", readiness=false. Elapsed: 18.037799143s
Dec  5 16:22:39.241: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Running", Reason="", readiness=false. Elapsed: 20.041158674s
Dec  5 16:22:41.245: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Running", Reason="", readiness=false. Elapsed: 22.045288201s
Dec  5 16:22:43.249: INFO: Pod "pod-subpath-test-configmap-lxc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.048405429s
STEP: Saw pod success
Dec  5 16:22:43.249: INFO: Pod "pod-subpath-test-configmap-lxc7" satisfied condition "success or failure"
Dec  5 16:22:43.250: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-subpath-test-configmap-lxc7 container test-container-subpath-configmap-lxc7: <nil>
STEP: delete the pod
Dec  5 16:22:43.270: INFO: Waiting for pod pod-subpath-test-configmap-lxc7 to disappear
Dec  5 16:22:43.273: INFO: Pod pod-subpath-test-configmap-lxc7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lxc7
Dec  5 16:22:43.273: INFO: Deleting pod "pod-subpath-test-configmap-lxc7" in namespace "e2e-tests-subpath-2rj54"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:22:43.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2rj54" for this suite.
Dec  5 16:22:49.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:22:49.354: INFO: namespace: e2e-tests-subpath-2rj54, resource: bindings, ignored listing per whitelist
Dec  5 16:22:49.364: INFO: namespace e2e-tests-subpath-2rj54 deletion completed in 6.086344856s

• [SLOW TEST:30.250 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:22:49.366: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  5 16:22:49.455: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-a,UID:01e20bd6-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63237,Generation:0,CreationTimestamp:2018-12-05 16:22:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 16:22:49.455: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-a,UID:01e20bd6-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63237,Generation:0,CreationTimestamp:2018-12-05 16:22:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  5 16:22:59.462: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-a,UID:01e20bd6-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63252,Generation:0,CreationTimestamp:2018-12-05 16:22:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  5 16:22:59.462: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-a,UID:01e20bd6-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63252,Generation:0,CreationTimestamp:2018-12-05 16:22:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  5 16:23:09.469: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-a,UID:01e20bd6-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63267,Generation:0,CreationTimestamp:2018-12-05 16:22:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 16:23:09.469: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-a,UID:01e20bd6-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63267,Generation:0,CreationTimestamp:2018-12-05 16:22:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  5 16:23:19.476: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-a,UID:01e20bd6-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63282,Generation:0,CreationTimestamp:2018-12-05 16:22:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 16:23:19.476: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-a,UID:01e20bd6-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63282,Generation:0,CreationTimestamp:2018-12-05 16:22:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  5 16:23:29.482: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-b,UID:19bd7628-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63297,Generation:0,CreationTimestamp:2018-12-05 16:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 16:23:29.482: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-b,UID:19bd7628-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63297,Generation:0,CreationTimestamp:2018-12-05 16:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  5 16:23:39.488: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-b,UID:19bd7628-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63312,Generation:0,CreationTimestamp:2018-12-05 16:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 16:23:39.488: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-x8twg,SelfLink:/api/v1/namespaces/e2e-tests-watch-x8twg/configmaps/e2e-watch-test-configmap-b,UID:19bd7628-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63312,Generation:0,CreationTimestamp:2018-12-05 16:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:23:49.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-x8twg" for this suite.
Dec  5 16:23:55.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:23:55.581: INFO: namespace: e2e-tests-watch-x8twg, resource: bindings, ignored listing per whitelist
Dec  5 16:23:55.585: INFO: namespace e2e-tests-watch-x8twg deletion completed in 6.092930987s

• [SLOW TEST:66.219 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:23:55.585: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1205 16:23:56.714109      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 16:23:56.714: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:23:56.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-98hs9" for this suite.
Dec  5 16:24:02.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:24:02.801: INFO: namespace: e2e-tests-gc-98hs9, resource: bindings, ignored listing per whitelist
Dec  5 16:24:02.815: INFO: namespace e2e-tests-gc-98hs9 deletion completed in 6.098687399s

• [SLOW TEST:7.230 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:24:02.817: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec  5 16:24:03.424: INFO: created pod pod-service-account-defaultsa
Dec  5 16:24:03.424: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  5 16:24:03.434: INFO: created pod pod-service-account-mountsa
Dec  5 16:24:03.434: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  5 16:24:03.449: INFO: created pod pod-service-account-nomountsa
Dec  5 16:24:03.449: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  5 16:24:03.476: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  5 16:24:03.476: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  5 16:24:03.496: INFO: created pod pod-service-account-mountsa-mountspec
Dec  5 16:24:03.496: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  5 16:24:03.516: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  5 16:24:03.516: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  5 16:24:03.532: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  5 16:24:03.532: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  5 16:24:03.563: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  5 16:24:03.563: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  5 16:24:03.571: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  5 16:24:03.571: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:24:03.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-j6cbs" for this suite.
Dec  5 16:24:09.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:24:09.670: INFO: namespace: e2e-tests-svcaccounts-j6cbs, resource: bindings, ignored listing per whitelist
Dec  5 16:24:09.679: INFO: namespace e2e-tests-svcaccounts-j6cbs deletion completed in 6.093817248s

• [SLOW TEST:6.863 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:24:09.681: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  5 16:24:12.278: INFO: Successfully updated pod "pod-update-31be006d-f8aa-11e8-a7f8-ceaf58ef2674"
STEP: verifying the updated pod is in kubernetes
Dec  5 16:24:12.282: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:24:12.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-szpms" for this suite.
Dec  5 16:24:34.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:24:34.321: INFO: namespace: e2e-tests-pods-szpms, resource: bindings, ignored listing per whitelist
Dec  5 16:24:34.368: INFO: namespace e2e-tests-pods-szpms deletion completed in 22.081526538s

• [SLOW TEST:24.687 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:24:34.370: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 16:24:34.443: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40754d9f-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-j5f4p" to be "success or failure"
Dec  5 16:24:34.448: INFO: Pod "downwardapi-volume-40754d9f-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.748967ms
Dec  5 16:24:36.451: INFO: Pod "downwardapi-volume-40754d9f-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008086006s
STEP: Saw pod success
Dec  5 16:24:36.451: INFO: Pod "downwardapi-volume-40754d9f-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:24:36.453: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-40754d9f-f8aa-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 16:24:36.474: INFO: Waiting for pod downwardapi-volume-40754d9f-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:24:36.477: INFO: Pod downwardapi-volume-40754d9f-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:24:36.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j5f4p" for this suite.
Dec  5 16:24:42.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:24:42.559: INFO: namespace: e2e-tests-downward-api-j5f4p, resource: bindings, ignored listing per whitelist
Dec  5 16:24:42.572: INFO: namespace e2e-tests-downward-api-j5f4p deletion completed in 6.093013463s

• [SLOW TEST:8.203 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:24:42.573: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec  5 16:24:42.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 cluster-info'
Dec  5 16:24:42.719: INFO: stderr: ""
Dec  5 16:24:42.719: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:24:42.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mtlbf" for this suite.
Dec  5 16:24:48.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:24:48.808: INFO: namespace: e2e-tests-kubectl-mtlbf, resource: bindings, ignored listing per whitelist
Dec  5 16:24:48.811: INFO: namespace e2e-tests-kubectl-mtlbf deletion completed in 6.089966842s

• [SLOW TEST:6.238 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:24:48.813: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  5 16:24:48.907: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 16:24:48.915: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 16:24:48.918: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-12-134 before test
Dec  5 16:24:48.925: INFO: calico-node-p6sb5 from kube-system started at 2018-12-05 05:33:47 +0000 UTC (2 container statuses recorded)
Dec  5 16:24:48.925: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 16:24:48.925: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 16:24:48.925: INFO: sonobuoy-e2e-job-4df755f956e944ee from heptio-sonobuoy started at 2018-12-05 15:21:37 +0000 UTC (2 container statuses recorded)
Dec  5 16:24:48.925: INFO: 	Container e2e ready: true, restart count 0
Dec  5 16:24:48.925: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 16:24:48.925: INFO: sonobuoy-systemd-logs-daemon-set-6778acf1ee8d4b8d-5rq4f from heptio-sonobuoy started at 2018-12-05 15:21:37 +0000 UTC (2 container statuses recorded)
Dec  5 16:24:48.925: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 16:24:48.925: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 16:24:48.925: INFO: kube-proxy-2hslj from kube-system started at 2018-12-05 05:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 16:24:48.927: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 16:24:48.927: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-40-84 before test
Dec  5 16:24:48.932: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-05 05:37:35 +0000 UTC (1 container statuses recorded)
Dec  5 16:24:48.933: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 16:24:48.933: INFO: calico-node-nkjpz from kube-system started at 2018-12-05 05:33:46 +0000 UTC (2 container statuses recorded)
Dec  5 16:24:48.933: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 16:24:48.933: INFO: 	Container install-cni ready: true, restart count 0
Dec  5 16:24:48.933: INFO: kube-proxy-gzgch from kube-system started at 2018-12-05 05:33:46 +0000 UTC (1 container statuses recorded)
Dec  5 16:24:48.933: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 16:24:48.933: INFO: sonobuoy-systemd-logs-daemon-set-6778acf1ee8d4b8d-8k8kp from heptio-sonobuoy started at 2018-12-05 15:21:37 +0000 UTC (2 container statuses recorded)
Dec  5 16:24:48.933: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 16:24:48.933: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156d7c74f1613333], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:24:49.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-b97jg" for this suite.
Dec  5 16:24:55.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:24:56.021: INFO: namespace: e2e-tests-sched-pred-b97jg, resource: bindings, ignored listing per whitelist
Dec  5 16:24:56.082: INFO: namespace e2e-tests-sched-pred-b97jg deletion completed in 6.10413826s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.269 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:24:56.084: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-kqcmg/secret-test-4d651e05-f8aa-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 16:24:56.150: INFO: Waiting up to 5m0s for pod "pod-configmaps-4d65a7c4-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-secrets-kqcmg" to be "success or failure"
Dec  5 16:24:56.154: INFO: Pod "pod-configmaps-4d65a7c4-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 3.655544ms
Dec  5 16:24:58.157: INFO: Pod "pod-configmaps-4d65a7c4-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007224527s
STEP: Saw pod success
Dec  5 16:24:58.158: INFO: Pod "pod-configmaps-4d65a7c4-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:24:58.160: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-configmaps-4d65a7c4-f8aa-11e8-a7f8-ceaf58ef2674 container env-test: <nil>
STEP: delete the pod
Dec  5 16:24:58.177: INFO: Waiting for pod pod-configmaps-4d65a7c4-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:24:58.180: INFO: Pod pod-configmaps-4d65a7c4-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:24:58.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kqcmg" for this suite.
Dec  5 16:25:04.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:25:04.239: INFO: namespace: e2e-tests-secrets-kqcmg, resource: bindings, ignored listing per whitelist
Dec  5 16:25:04.274: INFO: namespace e2e-tests-secrets-kqcmg deletion completed in 6.091530081s

• [SLOW TEST:8.191 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:25:04.276: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:25:06.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-gqrb4" for this suite.
Dec  5 16:25:52.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:25:52.520: INFO: namespace: e2e-tests-kubelet-test-gqrb4, resource: bindings, ignored listing per whitelist
Dec  5 16:25:52.523: INFO: namespace e2e-tests-kubelet-test-gqrb4 deletion completed in 46.108597418s

• [SLOW TEST:48.247 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:25:52.525: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  5 16:25:52.613: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6665v,SelfLink:/api/v1/namespaces/e2e-tests-watch-6665v/configmaps/e2e-watch-test-label-changed,UID:6f0c6001-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63781,Generation:0,CreationTimestamp:2018-12-05 16:25:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 16:25:52.613: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6665v,SelfLink:/api/v1/namespaces/e2e-tests-watch-6665v/configmaps/e2e-watch-test-label-changed,UID:6f0c6001-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63782,Generation:0,CreationTimestamp:2018-12-05 16:25:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  5 16:25:52.613: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6665v,SelfLink:/api/v1/namespaces/e2e-tests-watch-6665v/configmaps/e2e-watch-test-label-changed,UID:6f0c6001-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63783,Generation:0,CreationTimestamp:2018-12-05 16:25:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  5 16:26:02.635: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6665v,SelfLink:/api/v1/namespaces/e2e-tests-watch-6665v/configmaps/e2e-watch-test-label-changed,UID:6f0c6001-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63799,Generation:0,CreationTimestamp:2018-12-05 16:25:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 16:26:02.636: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6665v,SelfLink:/api/v1/namespaces/e2e-tests-watch-6665v/configmaps/e2e-watch-test-label-changed,UID:6f0c6001-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63800,Generation:0,CreationTimestamp:2018-12-05 16:25:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  5 16:26:02.636: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6665v,SelfLink:/api/v1/namespaces/e2e-tests-watch-6665v/configmaps/e2e-watch-test-label-changed,UID:6f0c6001-f8aa-11e8-ab6c-06b570ab0412,ResourceVersion:63801,Generation:0,CreationTimestamp:2018-12-05 16:25:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:26:02.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6665v" for this suite.
Dec  5 16:26:08.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:26:08.680: INFO: namespace: e2e-tests-watch-6665v, resource: bindings, ignored listing per whitelist
Dec  5 16:26:08.720: INFO: namespace e2e-tests-watch-6665v deletion completed in 6.081576446s

• [SLOW TEST:16.195 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:26:08.722: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  5 16:26:11.315: INFO: Successfully updated pod "pod-update-activedeadlineseconds-78b20280-f8aa-11e8-a7f8-ceaf58ef2674"
Dec  5 16:26:11.315: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-78b20280-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-pods-f8nzq" to be "terminated due to deadline exceeded"
Dec  5 16:26:11.319: INFO: Pod "pod-update-activedeadlineseconds-78b20280-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Running", Reason="", readiness=true. Elapsed: 3.262152ms
Dec  5 16:26:13.322: INFO: Pod "pod-update-activedeadlineseconds-78b20280-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Running", Reason="", readiness=true. Elapsed: 2.006669521s
Dec  5 16:26:15.372: INFO: Pod "pod-update-activedeadlineseconds-78b20280-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.056986466s
Dec  5 16:26:15.372: INFO: Pod "pod-update-activedeadlineseconds-78b20280-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:26:15.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f8nzq" for this suite.
Dec  5 16:26:21.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:26:21.466: INFO: namespace: e2e-tests-pods-f8nzq, resource: bindings, ignored listing per whitelist
Dec  5 16:26:21.487: INFO: namespace e2e-tests-pods-f8nzq deletion completed in 6.109492189s

• [SLOW TEST:12.766 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:26:21.488: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-804dca06-f8aa-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 16:26:21.560: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-804e4681-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-cbfhf" to be "success or failure"
Dec  5 16:26:21.564: INFO: Pod "pod-projected-secrets-804e4681-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 3.117126ms
Dec  5 16:26:23.567: INFO: Pod "pod-projected-secrets-804e4681-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006480299s
STEP: Saw pod success
Dec  5 16:26:23.567: INFO: Pod "pod-projected-secrets-804e4681-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:26:23.569: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-secrets-804e4681-f8aa-11e8-a7f8-ceaf58ef2674 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 16:26:23.588: INFO: Waiting for pod pod-projected-secrets-804e4681-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:26:23.592: INFO: Pod pod-projected-secrets-804e4681-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:26:23.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cbfhf" for this suite.
Dec  5 16:26:29.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:26:29.630: INFO: namespace: e2e-tests-projected-cbfhf, resource: bindings, ignored listing per whitelist
Dec  5 16:26:29.693: INFO: namespace e2e-tests-projected-cbfhf deletion completed in 6.099133727s

• [SLOW TEST:8.206 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:26:29.698: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  5 16:26:29.763: INFO: Waiting up to 5m0s for pod "pod-8531e572-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-67qpv" to be "success or failure"
Dec  5 16:26:29.772: INFO: Pod "pod-8531e572-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 8.620174ms
Dec  5 16:26:31.776: INFO: Pod "pod-8531e572-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012640625s
STEP: Saw pod success
Dec  5 16:26:31.776: INFO: Pod "pod-8531e572-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:26:31.778: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-8531e572-f8aa-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:26:31.806: INFO: Waiting for pod pod-8531e572-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:26:31.817: INFO: Pod pod-8531e572-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:26:31.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-67qpv" for this suite.
Dec  5 16:26:37.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:26:37.921: INFO: namespace: e2e-tests-emptydir-67qpv, resource: bindings, ignored listing per whitelist
Dec  5 16:26:37.924: INFO: namespace e2e-tests-emptydir-67qpv deletion completed in 6.097472072s

• [SLOW TEST:8.227 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:26:37.927: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:26:44.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-smf6r" for this suite.
Dec  5 16:26:50.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:26:50.158: INFO: namespace: e2e-tests-namespaces-smf6r, resource: bindings, ignored listing per whitelist
Dec  5 16:26:50.175: INFO: namespace e2e-tests-namespaces-smf6r deletion completed in 6.0813494s
STEP: Destroying namespace "e2e-tests-nsdeletetest-xmv57" for this suite.
Dec  5 16:26:50.179: INFO: Namespace e2e-tests-nsdeletetest-xmv57 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-grz5d" for this suite.
Dec  5 16:26:56.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:26:56.231: INFO: namespace: e2e-tests-nsdeletetest-grz5d, resource: bindings, ignored listing per whitelist
Dec  5 16:26:56.260: INFO: namespace e2e-tests-nsdeletetest-grz5d deletion completed in 6.080987365s

• [SLOW TEST:18.333 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:26:56.262: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-nkllj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nkllj to expose endpoints map[]
Dec  5 16:26:56.375: INFO: Get endpoints failed (8.607429ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec  5 16:26:57.378: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nkllj exposes endpoints map[] (1.011927338s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-nkllj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nkllj to expose endpoints map[pod1:[80]]
Dec  5 16:26:59.404: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nkllj exposes endpoints map[pod1:[80]] (2.019146728s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-nkllj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nkllj to expose endpoints map[pod1:[80] pod2:[80]]
Dec  5 16:27:01.450: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nkllj exposes endpoints map[pod2:[80] pod1:[80]] (2.03940081s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-nkllj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nkllj to expose endpoints map[pod2:[80]]
Dec  5 16:27:01.471: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nkllj exposes endpoints map[pod2:[80]] (13.673982ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-nkllj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nkllj to expose endpoints map[]
Dec  5 16:27:01.502: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nkllj exposes endpoints map[] (4.992729ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:27:01.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-nkllj" for this suite.
Dec  5 16:27:23.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:27:23.602: INFO: namespace: e2e-tests-services-nkllj, resource: bindings, ignored listing per whitelist
Dec  5 16:27:23.645: INFO: namespace e2e-tests-services-nkllj deletion completed in 22.096742648s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:27.383 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:27:23.646: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-v6l5f
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-v6l5f to expose endpoints map[]
Dec  5 16:27:23.741: INFO: Get endpoints failed (7.519574ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec  5 16:27:24.744: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-v6l5f exposes endpoints map[] (1.010451996s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-v6l5f
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-v6l5f to expose endpoints map[pod1:[100]]
Dec  5 16:27:26.777: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-v6l5f exposes endpoints map[pod1:[100]] (2.026070226s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-v6l5f
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-v6l5f to expose endpoints map[pod1:[100] pod2:[101]]
Dec  5 16:27:28.811: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-v6l5f exposes endpoints map[pod1:[100] pod2:[101]] (2.029976137s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-v6l5f
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-v6l5f to expose endpoints map[pod2:[101]]
Dec  5 16:27:28.858: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-v6l5f exposes endpoints map[pod2:[101]] (32.466558ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-v6l5f
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-v6l5f to expose endpoints map[]
Dec  5 16:27:28.898: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-v6l5f exposes endpoints map[] (16.116908ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:27:28.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-v6l5f" for this suite.
Dec  5 16:27:50.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:27:51.004: INFO: namespace: e2e-tests-services-v6l5f, resource: bindings, ignored listing per whitelist
Dec  5 16:27:51.022: INFO: namespace e2e-tests-services-v6l5f deletion completed in 22.09363162s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:27.376 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:27:51.026: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:27:55.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-f8nxw" for this suite.
Dec  5 16:28:01.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:28:01.174: INFO: namespace: e2e-tests-kubelet-test-f8nxw, resource: bindings, ignored listing per whitelist
Dec  5 16:28:01.246: INFO: namespace e2e-tests-kubelet-test-f8nxw deletion completed in 6.143564246s

• [SLOW TEST:10.220 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:28:01.247: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-bbe4c651-f8aa-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 16:28:01.544: INFO: Waiting up to 5m0s for pod "pod-secrets-bbe5a06c-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-secrets-s5lfs" to be "success or failure"
Dec  5 16:28:01.659: INFO: Pod "pod-secrets-bbe5a06c-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 114.212858ms
Dec  5 16:28:03.662: INFO: Pod "pod-secrets-bbe5a06c-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.117558186s
STEP: Saw pod success
Dec  5 16:28:03.662: INFO: Pod "pod-secrets-bbe5a06c-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:28:03.664: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-secrets-bbe5a06c-f8aa-11e8-a7f8-ceaf58ef2674 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 16:28:03.692: INFO: Waiting for pod pod-secrets-bbe5a06c-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:28:03.696: INFO: Pod pod-secrets-bbe5a06c-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:28:03.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-s5lfs" for this suite.
Dec  5 16:28:09.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:28:09.733: INFO: namespace: e2e-tests-secrets-s5lfs, resource: bindings, ignored listing per whitelist
Dec  5 16:28:09.780: INFO: namespace e2e-tests-secrets-s5lfs deletion completed in 6.082128166s

• [SLOW TEST:8.533 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:28:09.783: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec  5 16:28:09.902: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-9j8h7" to be "success or failure"
Dec  5 16:28:09.907: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.007098ms
Dec  5 16:28:11.911: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008503134s
STEP: Saw pod success
Dec  5 16:28:11.911: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  5 16:28:11.912: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  5 16:28:11.931: INFO: Waiting for pod pod-host-path-test to disappear
Dec  5 16:28:11.934: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:28:11.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-9j8h7" for this suite.
Dec  5 16:28:17.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:28:17.995: INFO: namespace: e2e-tests-hostpath-9j8h7, resource: bindings, ignored listing per whitelist
Dec  5 16:28:18.018: INFO: namespace e2e-tests-hostpath-9j8h7 deletion completed in 6.080957207s

• [SLOW TEST:8.236 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:28:18.020: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  5 16:28:18.097: INFO: Waiting up to 5m0s for pod "pod-c5c45384-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-kn4cc" to be "success or failure"
Dec  5 16:28:18.100: INFO: Pod "pod-c5c45384-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.947711ms
Dec  5 16:28:20.103: INFO: Pod "pod-c5c45384-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006770384s
STEP: Saw pod success
Dec  5 16:28:20.104: INFO: Pod "pod-c5c45384-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:28:20.106: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-c5c45384-f8aa-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:28:20.123: INFO: Waiting for pod pod-c5c45384-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:28:20.126: INFO: Pod pod-c5c45384-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:28:20.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kn4cc" for this suite.
Dec  5 16:28:26.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:28:26.209: INFO: namespace: e2e-tests-emptydir-kn4cc, resource: bindings, ignored listing per whitelist
Dec  5 16:28:26.228: INFO: namespace e2e-tests-emptydir-kn4cc deletion completed in 6.098940185s

• [SLOW TEST:8.208 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:28:26.231: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-knzq7 in namespace e2e-tests-proxy-8ppl6
I1205 16:28:26.312612      13 runners.go:184] Created replication controller with name: proxy-service-knzq7, namespace: e2e-tests-proxy-8ppl6, replica count: 1
I1205 16:28:27.363092      13 runners.go:184] proxy-service-knzq7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 16:28:28.363391      13 runners.go:184] proxy-service-knzq7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 16:28:29.363680      13 runners.go:184] proxy-service-knzq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 16:28:30.363936      13 runners.go:184] proxy-service-knzq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 16:28:31.364165      13 runners.go:184] proxy-service-knzq7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 16:28:32.364414      13 runners.go:184] proxy-service-knzq7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 16:28:32.367: INFO: setup took 6.075918688s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  5 16:28:32.386: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 17.807214ms)
Dec  5 16:28:32.399: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 31.779397ms)
Dec  5 16:28:32.401: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 33.669856ms)
Dec  5 16:28:32.403: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 34.756597ms)
Dec  5 16:28:32.403: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 34.818773ms)
Dec  5 16:28:32.404: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 36.766502ms)
Dec  5 16:28:32.404: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 35.943207ms)
Dec  5 16:28:32.404: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 36.125375ms)
Dec  5 16:28:32.405: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 36.70631ms)
Dec  5 16:28:32.412: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 43.869036ms)
Dec  5 16:28:32.413: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 44.590437ms)
Dec  5 16:28:32.413: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 44.165058ms)
Dec  5 16:28:32.413: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 45.582552ms)
Dec  5 16:28:32.415: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 46.800946ms)
Dec  5 16:28:32.415: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 47.090351ms)
Dec  5 16:28:32.415: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 47.580816ms)
Dec  5 16:28:32.431: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 15.437795ms)
Dec  5 16:28:32.431: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 15.408248ms)
Dec  5 16:28:32.432: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 15.952475ms)
Dec  5 16:28:32.432: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 15.433017ms)
Dec  5 16:28:32.434: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 18.364847ms)
Dec  5 16:28:32.435: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 19.12016ms)
Dec  5 16:28:32.436: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 20.077848ms)
Dec  5 16:28:32.436: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 19.870723ms)
Dec  5 16:28:32.437: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 20.147332ms)
Dec  5 16:28:32.437: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 20.161631ms)
Dec  5 16:28:32.437: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 20.688618ms)
Dec  5 16:28:32.437: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 21.110474ms)
Dec  5 16:28:32.438: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 21.737493ms)
Dec  5 16:28:32.438: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 21.082253ms)
Dec  5 16:28:32.438: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 21.790239ms)
Dec  5 16:28:32.438: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 22.515383ms)
Dec  5 16:28:32.453: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 14.604998ms)
Dec  5 16:28:32.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 15.090861ms)
Dec  5 16:28:32.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 15.899623ms)
Dec  5 16:28:32.455: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 15.946753ms)
Dec  5 16:28:32.458: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 18.622192ms)
Dec  5 16:28:32.458: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 18.736253ms)
Dec  5 16:28:32.458: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 19.39847ms)
Dec  5 16:28:32.458: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 18.682832ms)
Dec  5 16:28:32.459: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 20.41365ms)
Dec  5 16:28:32.459: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 19.307639ms)
Dec  5 16:28:32.459: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 19.840441ms)
Dec  5 16:28:32.459: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 19.999806ms)
Dec  5 16:28:32.459: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 20.068893ms)
Dec  5 16:28:32.460: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 20.701822ms)
Dec  5 16:28:32.460: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 20.43938ms)
Dec  5 16:28:32.460: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 21.291308ms)
Dec  5 16:28:32.473: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 12.544015ms)
Dec  5 16:28:32.479: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 17.122539ms)
Dec  5 16:28:32.483: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 22.516032ms)
Dec  5 16:28:32.483: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 22.535229ms)
Dec  5 16:28:32.483: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 22.757539ms)
Dec  5 16:28:32.484: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 22.595775ms)
Dec  5 16:28:32.484: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 23.113061ms)
Dec  5 16:28:32.485: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 22.974187ms)
Dec  5 16:28:32.486: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 24.795211ms)
Dec  5 16:28:32.486: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 25.137588ms)
Dec  5 16:28:32.487: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 25.603692ms)
Dec  5 16:28:32.500: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 38.651557ms)
Dec  5 16:28:32.500: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 38.776616ms)
Dec  5 16:28:32.501: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 40.035742ms)
Dec  5 16:28:32.501: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 39.932002ms)
Dec  5 16:28:32.506: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 45.599277ms)
Dec  5 16:28:32.520: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 13.851484ms)
Dec  5 16:28:32.530: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 23.689442ms)
Dec  5 16:28:32.531: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 24.152751ms)
Dec  5 16:28:32.537: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 29.896194ms)
Dec  5 16:28:32.539: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 31.100539ms)
Dec  5 16:28:32.539: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 31.607122ms)
Dec  5 16:28:32.540: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 32.325946ms)
Dec  5 16:28:32.543: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 35.355552ms)
Dec  5 16:28:32.543: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 35.614241ms)
Dec  5 16:28:32.543: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 36.052126ms)
Dec  5 16:28:32.544: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 36.409443ms)
Dec  5 16:28:32.547: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 39.85342ms)
Dec  5 16:28:32.548: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 40.913466ms)
Dec  5 16:28:32.549: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 41.92185ms)
Dec  5 16:28:32.550: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 42.939158ms)
Dec  5 16:28:32.550: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 42.458868ms)
Dec  5 16:28:32.568: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 17.92713ms)
Dec  5 16:28:32.569: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 18.674934ms)
Dec  5 16:28:32.579: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 27.900914ms)
Dec  5 16:28:32.579: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 27.797219ms)
Dec  5 16:28:32.579: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 28.014174ms)
Dec  5 16:28:32.582: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 29.831648ms)
Dec  5 16:28:32.582: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 31.317505ms)
Dec  5 16:28:32.582: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 30.81949ms)
Dec  5 16:28:32.583: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 31.384475ms)
Dec  5 16:28:32.583: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 31.482216ms)
Dec  5 16:28:32.583: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 31.814697ms)
Dec  5 16:28:32.583: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 32.159819ms)
Dec  5 16:28:32.589: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 37.992485ms)
Dec  5 16:28:32.589: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 37.660584ms)
Dec  5 16:28:32.589: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 38.254852ms)
Dec  5 16:28:32.590: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 37.825549ms)
Dec  5 16:28:32.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 19.18217ms)
Dec  5 16:28:32.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 19.310071ms)
Dec  5 16:28:32.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 19.163443ms)
Dec  5 16:28:32.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 20.078808ms)
Dec  5 16:28:32.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 20.482254ms)
Dec  5 16:28:32.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 19.328981ms)
Dec  5 16:28:32.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 20.113466ms)
Dec  5 16:28:32.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 20.046486ms)
Dec  5 16:28:32.610: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 20.000282ms)
Dec  5 16:28:32.611: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 20.423871ms)
Dec  5 16:28:32.611: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 20.548217ms)
Dec  5 16:28:32.611: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 21.418344ms)
Dec  5 16:28:32.612: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 22.009468ms)
Dec  5 16:28:32.612: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 21.447555ms)
Dec  5 16:28:32.612: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 22.086901ms)
Dec  5 16:28:32.612: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 22.482431ms)
Dec  5 16:28:32.631: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 18.76386ms)
Dec  5 16:28:32.635: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 22.411415ms)
Dec  5 16:28:32.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 29.332438ms)
Dec  5 16:28:32.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 29.655165ms)
Dec  5 16:28:32.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 29.399918ms)
Dec  5 16:28:32.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 29.582549ms)
Dec  5 16:28:32.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 30.673892ms)
Dec  5 16:28:32.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 30.035421ms)
Dec  5 16:28:32.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 30.679566ms)
Dec  5 16:28:32.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 30.616643ms)
Dec  5 16:28:32.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 33.655192ms)
Dec  5 16:28:32.648: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 34.60316ms)
Dec  5 16:28:32.648: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 35.278993ms)
Dec  5 16:28:32.648: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 35.851878ms)
Dec  5 16:28:32.648: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 34.99036ms)
Dec  5 16:28:32.649: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 35.319813ms)
Dec  5 16:28:32.666: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 17.231562ms)
Dec  5 16:28:32.666: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 16.314733ms)
Dec  5 16:28:32.666: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 17.349766ms)
Dec  5 16:28:32.669: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 20.10564ms)
Dec  5 16:28:32.670: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 21.122356ms)
Dec  5 16:28:32.670: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 20.814286ms)
Dec  5 16:28:32.670: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 20.546955ms)
Dec  5 16:28:32.670: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 21.478395ms)
Dec  5 16:28:32.671: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 21.495375ms)
Dec  5 16:28:32.671: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 21.644711ms)
Dec  5 16:28:32.672: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 22.33196ms)
Dec  5 16:28:32.673: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 22.868948ms)
Dec  5 16:28:32.673: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 23.425206ms)
Dec  5 16:28:32.673: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 23.688389ms)
Dec  5 16:28:32.673: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 23.430592ms)
Dec  5 16:28:32.673: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 24.495007ms)
Dec  5 16:28:32.692: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 18.225078ms)
Dec  5 16:28:32.693: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 18.873849ms)
Dec  5 16:28:32.693: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 18.947575ms)
Dec  5 16:28:32.693: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 19.509307ms)
Dec  5 16:28:32.693: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 19.893872ms)
Dec  5 16:28:32.702: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 27.919955ms)
Dec  5 16:28:32.702: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 27.68583ms)
Dec  5 16:28:32.702: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 28.367081ms)
Dec  5 16:28:32.705: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 30.599909ms)
Dec  5 16:28:32.710: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 36.618941ms)
Dec  5 16:28:32.711: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 35.780036ms)
Dec  5 16:28:32.711: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 36.613389ms)
Dec  5 16:28:32.711: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 36.661933ms)
Dec  5 16:28:32.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 40.022227ms)
Dec  5 16:28:32.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 40.479626ms)
Dec  5 16:28:32.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 40.563449ms)
Dec  5 16:28:32.740: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 23.337513ms)
Dec  5 16:28:32.743: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 27.3346ms)
Dec  5 16:28:32.743: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 27.144598ms)
Dec  5 16:28:32.743: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 27.866845ms)
Dec  5 16:28:32.744: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 27.050045ms)
Dec  5 16:28:32.746: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 30.163971ms)
Dec  5 16:28:32.747: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 30.613097ms)
Dec  5 16:28:32.747: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 31.083397ms)
Dec  5 16:28:32.747: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 31.553611ms)
Dec  5 16:28:32.748: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 31.284794ms)
Dec  5 16:28:32.751: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 34.870147ms)
Dec  5 16:28:32.752: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 36.386939ms)
Dec  5 16:28:32.752: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 35.756994ms)
Dec  5 16:28:32.753: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 36.65513ms)
Dec  5 16:28:32.753: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 37.289274ms)
Dec  5 16:28:32.756: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 40.287775ms)
Dec  5 16:28:32.770: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 13.798922ms)
Dec  5 16:28:32.771: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 14.63842ms)
Dec  5 16:28:32.773: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 15.975284ms)
Dec  5 16:28:32.773: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 16.163803ms)
Dec  5 16:28:32.775: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 17.387511ms)
Dec  5 16:28:32.775: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 18.09445ms)
Dec  5 16:28:32.775: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 18.0748ms)
Dec  5 16:28:32.775: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 17.991477ms)
Dec  5 16:28:32.775: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 18.734484ms)
Dec  5 16:28:32.776: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 19.151536ms)
Dec  5 16:28:32.776: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 19.699516ms)
Dec  5 16:28:32.777: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 19.663679ms)
Dec  5 16:28:32.777: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 19.617725ms)
Dec  5 16:28:32.777: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 20.644082ms)
Dec  5 16:28:32.778: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 20.996171ms)
Dec  5 16:28:32.778: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 20.074514ms)
Dec  5 16:28:32.796: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 18.257093ms)
Dec  5 16:28:32.797: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 19.224026ms)
Dec  5 16:28:32.798: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 19.89601ms)
Dec  5 16:28:32.799: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 21.083808ms)
Dec  5 16:28:32.800: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 21.764322ms)
Dec  5 16:28:32.800: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 21.341878ms)
Dec  5 16:28:32.800: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 21.803248ms)
Dec  5 16:28:32.801: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 22.721736ms)
Dec  5 16:28:32.801: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 22.631362ms)
Dec  5 16:28:32.802: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 23.149559ms)
Dec  5 16:28:32.802: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 23.85966ms)
Dec  5 16:28:32.802: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 23.910622ms)
Dec  5 16:28:32.802: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 24.207828ms)
Dec  5 16:28:32.802: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 23.568621ms)
Dec  5 16:28:32.802: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 24.032025ms)
Dec  5 16:28:32.802: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 23.791361ms)
Dec  5 16:28:32.819: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 16.857454ms)
Dec  5 16:28:32.820: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 17.188927ms)
Dec  5 16:28:32.824: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 21.076551ms)
Dec  5 16:28:32.825: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 21.331992ms)
Dec  5 16:28:32.825: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 22.014895ms)
Dec  5 16:28:32.825: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 22.370925ms)
Dec  5 16:28:32.825: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 21.690374ms)
Dec  5 16:28:32.826: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 22.788632ms)
Dec  5 16:28:32.829: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 25.379012ms)
Dec  5 16:28:32.829: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 25.466946ms)
Dec  5 16:28:32.833: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 29.79074ms)
Dec  5 16:28:32.834: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 30.388071ms)
Dec  5 16:28:32.834: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 29.763181ms)
Dec  5 16:28:32.834: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 31.457767ms)
Dec  5 16:28:32.835: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 30.825123ms)
Dec  5 16:28:32.835: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 31.35057ms)
Dec  5 16:28:32.851: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 15.939341ms)
Dec  5 16:28:32.852: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 15.619471ms)
Dec  5 16:28:32.856: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 19.52445ms)
Dec  5 16:28:32.862: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 27.186291ms)
Dec  5 16:28:32.862: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 26.28411ms)
Dec  5 16:28:32.862: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 26.395146ms)
Dec  5 16:28:32.863: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 27.097469ms)
Dec  5 16:28:32.863: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 26.706302ms)
Dec  5 16:28:32.863: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 27.09766ms)
Dec  5 16:28:32.863: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 26.376711ms)
Dec  5 16:28:32.863: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 27.669935ms)
Dec  5 16:28:32.863: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 27.437747ms)
Dec  5 16:28:32.864: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 27.846103ms)
Dec  5 16:28:32.864: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 28.035122ms)
Dec  5 16:28:32.864: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 28.143004ms)
Dec  5 16:28:32.864: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 27.837601ms)
Dec  5 16:28:32.892: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 26.797253ms)
Dec  5 16:28:32.892: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 28.554682ms)
Dec  5 16:28:32.893: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 28.505675ms)
Dec  5 16:28:32.893: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 29.247278ms)
Dec  5 16:28:32.895: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 30.166341ms)
Dec  5 16:28:32.895: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 30.551579ms)
Dec  5 16:28:32.896: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 30.92145ms)
Dec  5 16:28:32.896: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 31.43222ms)
Dec  5 16:28:32.899: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 34.842731ms)
Dec  5 16:28:32.899: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 34.913422ms)
Dec  5 16:28:32.900: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 35.426997ms)
Dec  5 16:28:32.907: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 42.241916ms)
Dec  5 16:28:32.907: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 41.934229ms)
Dec  5 16:28:32.907: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 42.406827ms)
Dec  5 16:28:32.913: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 49.353088ms)
Dec  5 16:28:32.914: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 48.535348ms)
Dec  5 16:28:32.932: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 17.380464ms)
Dec  5 16:28:32.932: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 17.932535ms)
Dec  5 16:28:32.932: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 18.808099ms)
Dec  5 16:28:32.933: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 19.171215ms)
Dec  5 16:28:32.935: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 21.073691ms)
Dec  5 16:28:32.937: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 23.24275ms)
Dec  5 16:28:32.937: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 23.133588ms)
Dec  5 16:28:32.941: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 27.112823ms)
Dec  5 16:28:32.941: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 26.623961ms)
Dec  5 16:28:32.941: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 26.652176ms)
Dec  5 16:28:32.942: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 27.502904ms)
Dec  5 16:28:32.942: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 27.199154ms)
Dec  5 16:28:32.944: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 29.982481ms)
Dec  5 16:28:32.949: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 33.759701ms)
Dec  5 16:28:32.949: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 34.374645ms)
Dec  5 16:28:32.949: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 34.205385ms)
Dec  5 16:28:32.965: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 16.146151ms)
Dec  5 16:28:32.966: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 16.505ms)
Dec  5 16:28:32.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 25.06859ms)
Dec  5 16:28:32.975: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 25.025651ms)
Dec  5 16:28:32.976: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 25.540116ms)
Dec  5 16:28:32.976: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 26.109603ms)
Dec  5 16:28:32.977: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 26.643227ms)
Dec  5 16:28:32.979: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 28.524537ms)
Dec  5 16:28:32.979: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 29.061443ms)
Dec  5 16:28:32.980: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 30.503759ms)
Dec  5 16:28:32.985: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 35.102514ms)
Dec  5 16:28:32.985: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 34.997837ms)
Dec  5 16:28:32.985: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 34.795878ms)
Dec  5 16:28:32.985: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 35.75332ms)
Dec  5 16:28:32.987: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 37.558973ms)
Dec  5 16:28:32.988: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 37.832159ms)
Dec  5 16:28:33.003: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 15.123152ms)
Dec  5 16:28:33.004: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 15.229702ms)
Dec  5 16:28:33.006: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 17.14442ms)
Dec  5 16:28:33.007: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 16.883765ms)
Dec  5 16:28:33.013: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 23.792561ms)
Dec  5 16:28:33.013: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 24.24778ms)
Dec  5 16:28:33.013: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 23.996193ms)
Dec  5 16:28:33.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 24.334725ms)
Dec  5 16:28:33.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 24.218163ms)
Dec  5 16:28:33.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 24.496579ms)
Dec  5 16:28:33.015: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 25.383082ms)
Dec  5 16:28:33.017: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 27.29379ms)
Dec  5 16:28:33.019: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 29.934593ms)
Dec  5 16:28:33.019: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 30.595431ms)
Dec  5 16:28:33.020: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 31.129908ms)
Dec  5 16:28:33.020: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 31.099394ms)
Dec  5 16:28:33.068: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname1/proxy/: tls baz (200; 47.587891ms)
Dec  5 16:28:33.069: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:162/proxy/: bar (200; 49.017738ms)
Dec  5 16:28:33.071: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:1080/proxy/... (200; 50.010178ms)
Dec  5 16:28:33.072: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:160/proxy/: foo (200; 51.318709ms)
Dec  5 16:28:33.072: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:1080/proxy/rewri... (200; 51.881261ms)
Dec  5 16:28:33.072: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:443/proxy/... (200; 51.813344ms)
Dec  5 16:28:33.073: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd/proxy/rewriteme"... (200; 52.332447ms)
Dec  5 16:28:33.073: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/proxy-service-knzq7-94rdd:160/proxy/: foo (200; 52.63728ms)
Dec  5 16:28:33.074: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:460/proxy/: tls baz (200; 52.541528ms)
Dec  5 16:28:33.074: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/https:proxy-service-knzq7-94rdd:462/proxy/: tls qux (200; 52.596237ms)
Dec  5 16:28:33.074: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/pods/http:proxy-service-knzq7-94rdd:162/proxy/: bar (200; 52.860148ms)
Dec  5 16:28:33.078: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname2/proxy/: bar (200; 56.976524ms)
Dec  5 16:28:33.079: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/https:proxy-service-knzq7:tlsportname2/proxy/: tls qux (200; 58.287093ms)
Dec  5 16:28:33.079: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname2/proxy/: bar (200; 57.763067ms)
Dec  5 16:28:33.079: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/http:proxy-service-knzq7:portname1/proxy/: foo (200; 58.815332ms)
Dec  5 16:28:33.079: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8ppl6/services/proxy-service-knzq7:portname1/proxy/: foo (200; 59.05869ms)
STEP: deleting ReplicationController proxy-service-knzq7 in namespace e2e-tests-proxy-8ppl6, will wait for the garbage collector to delete the pods
Dec  5 16:28:33.147: INFO: Deleting ReplicationController proxy-service-knzq7 took: 10.326693ms
Dec  5 16:28:33.247: INFO: Terminating ReplicationController proxy-service-knzq7 pods took: 100.245534ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:28:40.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8ppl6" for this suite.
Dec  5 16:28:46.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:28:47.074: INFO: namespace: e2e-tests-proxy-8ppl6, resource: bindings, ignored listing per whitelist
Dec  5 16:28:47.133: INFO: namespace e2e-tests-proxy-8ppl6 deletion completed in 6.583025726s

• [SLOW TEST:20.903 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:28:47.135: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d71d7f83-f8aa-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 16:28:47.207: INFO: Waiting up to 5m0s for pod "pod-configmaps-d71df8d7-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-configmap-75vft" to be "success or failure"
Dec  5 16:28:47.218: INFO: Pod "pod-configmaps-d71df8d7-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 11.294951ms
Dec  5 16:28:49.222: INFO: Pod "pod-configmaps-d71df8d7-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01479484s
STEP: Saw pod success
Dec  5 16:28:49.222: INFO: Pod "pod-configmaps-d71df8d7-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:28:49.224: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-configmaps-d71df8d7-f8aa-11e8-a7f8-ceaf58ef2674 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 16:28:49.241: INFO: Waiting for pod pod-configmaps-d71df8d7-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:28:49.244: INFO: Pod pod-configmaps-d71df8d7-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:28:49.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-75vft" for this suite.
Dec  5 16:28:55.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:28:55.349: INFO: namespace: e2e-tests-configmap-75vft, resource: bindings, ignored listing per whitelist
Dec  5 16:28:55.357: INFO: namespace e2e-tests-configmap-75vft deletion completed in 6.109778778s

• [SLOW TEST:8.222 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:28:55.360: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec  5 16:28:55.513: INFO: Waiting up to 5m0s for pod "client-containers-dc10ab7e-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-containers-rk57n" to be "success or failure"
Dec  5 16:28:55.527: INFO: Pod "client-containers-dc10ab7e-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 13.916807ms
Dec  5 16:28:57.531: INFO: Pod "client-containers-dc10ab7e-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018384079s
STEP: Saw pod success
Dec  5 16:28:57.532: INFO: Pod "client-containers-dc10ab7e-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:28:57.533: INFO: Trying to get logs from node ip-10-0-40-84 pod client-containers-dc10ab7e-f8aa-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:28:57.551: INFO: Waiting for pod client-containers-dc10ab7e-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:28:57.554: INFO: Pod client-containers-dc10ab7e-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:28:57.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rk57n" for this suite.
Dec  5 16:29:03.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:29:03.619: INFO: namespace: e2e-tests-containers-rk57n, resource: bindings, ignored listing per whitelist
Dec  5 16:29:03.643: INFO: namespace e2e-tests-containers-rk57n deletion completed in 6.086836787s

• [SLOW TEST:8.284 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:29:03.645: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  5 16:29:03.727: INFO: Waiting up to 5m0s for pod "pod-e0f6d276-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-jv9c4" to be "success or failure"
Dec  5 16:29:03.746: INFO: Pod "pod-e0f6d276-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 19.248749ms
Dec  5 16:29:05.750: INFO: Pod "pod-e0f6d276-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023205882s
STEP: Saw pod success
Dec  5 16:29:05.750: INFO: Pod "pod-e0f6d276-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:29:05.753: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-e0f6d276-f8aa-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:29:05.773: INFO: Waiting for pod pod-e0f6d276-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:29:05.776: INFO: Pod pod-e0f6d276-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:29:05.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jv9c4" for this suite.
Dec  5 16:29:11.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:29:11.826: INFO: namespace: e2e-tests-emptydir-jv9c4, resource: bindings, ignored listing per whitelist
Dec  5 16:29:11.878: INFO: namespace e2e-tests-emptydir-jv9c4 deletion completed in 6.099122746s

• [SLOW TEST:8.234 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:29:11.881: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 16:29:11.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-j2s4k'
Dec  5 16:29:12.220: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 16:29:12.220: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Dec  5 16:29:14.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-j2s4k'
Dec  5 16:29:14.334: INFO: stderr: ""
Dec  5 16:29:14.334: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:29:14.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j2s4k" for this suite.
Dec  5 16:29:36.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:29:36.385: INFO: namespace: e2e-tests-kubectl-j2s4k, resource: bindings, ignored listing per whitelist
Dec  5 16:29:36.432: INFO: namespace e2e-tests-kubectl-j2s4k deletion completed in 22.094640606s

• [SLOW TEST:24.551 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:29:36.434: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  5 16:29:36.508: INFO: Waiting up to 5m0s for pod "pod-f48085cb-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-pmrfd" to be "success or failure"
Dec  5 16:29:36.517: INFO: Pod "pod-f48085cb-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 8.637385ms
Dec  5 16:29:38.520: INFO: Pod "pod-f48085cb-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012183626s
STEP: Saw pod success
Dec  5 16:29:38.520: INFO: Pod "pod-f48085cb-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:29:38.522: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-f48085cb-f8aa-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:29:38.580: INFO: Waiting for pod pod-f48085cb-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:29:38.589: INFO: Pod pod-f48085cb-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:29:38.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pmrfd" for this suite.
Dec  5 16:29:44.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:29:44.653: INFO: namespace: e2e-tests-emptydir-pmrfd, resource: bindings, ignored listing per whitelist
Dec  5 16:29:44.703: INFO: namespace e2e-tests-emptydir-pmrfd deletion completed in 6.103849425s

• [SLOW TEST:8.269 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:29:44.705: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 16:29:44.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f96e0b53-f8aa-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-lrtfx" to be "success or failure"
Dec  5 16:29:44.780: INFO: Pod "downwardapi-volume-f96e0b53-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.505178ms
Dec  5 16:29:46.783: INFO: Pod "downwardapi-volume-f96e0b53-f8aa-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00892699s
STEP: Saw pod success
Dec  5 16:29:46.783: INFO: Pod "downwardapi-volume-f96e0b53-f8aa-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:29:46.786: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-f96e0b53-f8aa-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 16:29:46.804: INFO: Waiting for pod downwardapi-volume-f96e0b53-f8aa-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:29:46.808: INFO: Pod downwardapi-volume-f96e0b53-f8aa-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:29:46.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lrtfx" for this suite.
Dec  5 16:29:52.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:29:52.877: INFO: namespace: e2e-tests-projected-lrtfx, resource: bindings, ignored listing per whitelist
Dec  5 16:29:52.912: INFO: namespace e2e-tests-projected-lrtfx deletion completed in 6.101942593s

• [SLOW TEST:8.208 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:29:52.913: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-fe53aa08-f8aa-11e8-a7f8-ceaf58ef2674
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-fe53aa08-f8aa-11e8-a7f8-ceaf58ef2674
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:29:57.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7vwzh" for this suite.
Dec  5 16:30:19.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:30:19.138: INFO: namespace: e2e-tests-projected-7vwzh, resource: bindings, ignored listing per whitelist
Dec  5 16:30:19.149: INFO: namespace e2e-tests-projected-7vwzh deletion completed in 22.110759381s

• [SLOW TEST:26.236 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:30:19.151: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0df749c7-f8ab-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 16:30:19.235: INFO: Waiting up to 5m0s for pod "pod-secrets-0df7f53d-f8ab-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-secrets-rvkkb" to be "success or failure"
Dec  5 16:30:19.242: INFO: Pod "pod-secrets-0df7f53d-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.205804ms
Dec  5 16:30:21.247: INFO: Pod "pod-secrets-0df7f53d-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010994285s
STEP: Saw pod success
Dec  5 16:30:21.247: INFO: Pod "pod-secrets-0df7f53d-f8ab-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:30:21.249: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-secrets-0df7f53d-f8ab-11e8-a7f8-ceaf58ef2674 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 16:30:21.275: INFO: Waiting for pod pod-secrets-0df7f53d-f8ab-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:30:21.279: INFO: Pod pod-secrets-0df7f53d-f8ab-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:30:21.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rvkkb" for this suite.
Dec  5 16:30:27.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:30:27.325: INFO: namespace: e2e-tests-secrets-rvkkb, resource: bindings, ignored listing per whitelist
Dec  5 16:30:27.385: INFO: namespace e2e-tests-secrets-rvkkb deletion completed in 6.101596475s

• [SLOW TEST:8.235 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:30:27.388: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1205 16:30:57.988150      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 16:30:57.988: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:30:57.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-chc9l" for this suite.
Dec  5 16:31:04.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:31:04.021: INFO: namespace: e2e-tests-gc-chc9l, resource: bindings, ignored listing per whitelist
Dec  5 16:31:04.071: INFO: namespace e2e-tests-gc-chc9l deletion completed in 6.08153646s

• [SLOW TEST:36.684 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:31:04.074: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-52kx9/configmap-test-28be103a-f8ab-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 16:31:04.154: INFO: Waiting up to 5m0s for pod "pod-configmaps-28be9e76-f8ab-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-configmap-52kx9" to be "success or failure"
Dec  5 16:31:04.158: INFO: Pod "pod-configmaps-28be9e76-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.225233ms
Dec  5 16:31:06.161: INFO: Pod "pod-configmaps-28be9e76-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007452101s
STEP: Saw pod success
Dec  5 16:31:06.161: INFO: Pod "pod-configmaps-28be9e76-f8ab-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:31:06.163: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-configmaps-28be9e76-f8ab-11e8-a7f8-ceaf58ef2674 container env-test: <nil>
STEP: delete the pod
Dec  5 16:31:06.181: INFO: Waiting for pod pod-configmaps-28be9e76-f8ab-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:31:06.185: INFO: Pod pod-configmaps-28be9e76-f8ab-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:31:06.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-52kx9" for this suite.
Dec  5 16:31:12.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:31:12.253: INFO: namespace: e2e-tests-configmap-52kx9, resource: bindings, ignored listing per whitelist
Dec  5 16:31:12.270: INFO: namespace e2e-tests-configmap-52kx9 deletion completed in 6.082696937s

• [SLOW TEST:8.196 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:31:12.272: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 16:31:12.344: INFO: Waiting up to 5m0s for pod "downward-api-2da00ba7-f8ab-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-cklhp" to be "success or failure"
Dec  5 16:31:12.349: INFO: Pod "downward-api-2da00ba7-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.767572ms
Dec  5 16:31:14.353: INFO: Pod "downward-api-2da00ba7-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00938866s
STEP: Saw pod success
Dec  5 16:31:14.353: INFO: Pod "downward-api-2da00ba7-f8ab-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:31:14.355: INFO: Trying to get logs from node ip-10-0-40-84 pod downward-api-2da00ba7-f8ab-11e8-a7f8-ceaf58ef2674 container dapi-container: <nil>
STEP: delete the pod
Dec  5 16:31:14.374: INFO: Waiting for pod downward-api-2da00ba7-f8ab-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:31:14.377: INFO: Pod downward-api-2da00ba7-f8ab-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:31:14.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cklhp" for this suite.
Dec  5 16:31:20.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:31:20.472: INFO: namespace: e2e-tests-downward-api-cklhp, resource: bindings, ignored listing per whitelist
Dec  5 16:31:20.480: INFO: namespace e2e-tests-downward-api-cklhp deletion completed in 6.100594774s

• [SLOW TEST:8.209 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:31:20.482: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 16:31:20.568: INFO: Waiting up to 5m0s for pod "downwardapi-volume-328627d2-f8ab-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-649mr" to be "success or failure"
Dec  5 16:31:20.583: INFO: Pod "downwardapi-volume-328627d2-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 15.009179ms
Dec  5 16:31:22.587: INFO: Pod "downwardapi-volume-328627d2-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018724981s
STEP: Saw pod success
Dec  5 16:31:22.587: INFO: Pod "downwardapi-volume-328627d2-f8ab-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:31:22.595: INFO: Trying to get logs from node ip-10-0-12-134 pod downwardapi-volume-328627d2-f8ab-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 16:31:22.673: INFO: Waiting for pod downwardapi-volume-328627d2-f8ab-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:31:22.676: INFO: Pod downwardapi-volume-328627d2-f8ab-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:31:22.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-649mr" for this suite.
Dec  5 16:31:28.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:31:28.741: INFO: namespace: e2e-tests-projected-649mr, resource: bindings, ignored listing per whitelist
Dec  5 16:31:28.789: INFO: namespace e2e-tests-projected-649mr deletion completed in 6.106388762s

• [SLOW TEST:8.307 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:31:28.790: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-378328e6-f8ab-11e8-a7f8-ceaf58ef2674
STEP: Creating secret with name s-test-opt-upd-37832927-f8ab-11e8-a7f8-ceaf58ef2674
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-378328e6-f8ab-11e8-a7f8-ceaf58ef2674
STEP: Updating secret s-test-opt-upd-37832927-f8ab-11e8-a7f8-ceaf58ef2674
STEP: Creating secret with name s-test-opt-create-37832945-f8ab-11e8-a7f8-ceaf58ef2674
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:31:35.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6hbwj" for this suite.
Dec  5 16:31:57.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:31:57.051: INFO: namespace: e2e-tests-secrets-6hbwj, resource: bindings, ignored listing per whitelist
Dec  5 16:31:57.102: INFO: namespace e2e-tests-secrets-6hbwj deletion completed in 22.081135929s

• [SLOW TEST:28.312 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:31:57.103: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 16:31:57.201: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 16:31:57.218: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:31:57.224: INFO: Number of nodes with available pods: 0
Dec  5 16:31:57.224: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:31:58.228: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:31:58.231: INFO: Number of nodes with available pods: 1
Dec  5 16:31:58.231: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:31:59.233: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:31:59.235: INFO: Number of nodes with available pods: 2
Dec  5 16:31:59.235: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  5 16:31:59.264: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:31:59.264: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:31:59.268: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:00.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:00.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:00.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:01.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:01.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:01.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:02.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:02.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:02.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:03.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:03.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:03.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:04.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:04.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:04.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:05.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:05.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:05.278: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:06.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:06.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:06.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:07.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:07.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:07.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:08.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:08.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:08.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:09.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:09.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:09.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:10.273: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:10.273: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:10.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:11.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:11.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:11.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:12.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:12.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:12.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:13.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:13.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:13.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:14.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:14.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:14.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:15.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:15.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:15.278: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:16.271: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:16.271: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:16.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:17.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:17.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:17.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:18.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:18.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:18.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:19.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:19.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:19.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:20.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:20.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:20.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:21.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:21.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:21.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:22.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:22.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:22.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:23.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:23.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:23.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:24.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:24.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:24.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:25.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:25.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:25.277: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:26.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:26.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:26.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:27.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:27.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:27.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:28.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:28.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:28.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:29.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:29.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:29.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:30.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:30.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:30.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:31.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:31.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:31.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:32.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:32.272: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:32.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:32.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:33.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:33.272: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:33.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:33.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:34.271: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:34.271: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:34.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:34.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:35.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:35.272: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:35.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:35.283: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:36.273: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:36.274: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:36.274: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:36.276: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:37.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:37.272: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:37.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:37.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:38.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:38.272: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:38.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:38.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:39.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:39.273: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:39.273: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:39.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:40.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:40.272: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:40.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:40.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:41.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:41.272: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:41.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:41.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:42.272: INFO: Wrong image for pod: daemon-set-8gfgv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:42.272: INFO: Pod daemon-set-8gfgv is not available
Dec  5 16:32:42.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:42.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:43.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:43.272: INFO: Pod daemon-set-nlsvm is not available
Dec  5 16:32:43.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:44.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:44.272: INFO: Pod daemon-set-nlsvm is not available
Dec  5 16:32:44.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:45.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:45.277: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:46.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:46.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:47.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:47.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:48.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:48.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:49.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:49.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:50.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:50.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:51.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:51.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:52.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:52.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:53.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:53.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:54.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:54.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:55.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:55.277: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:56.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:56.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:57.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:57.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:58.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:58.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:32:59.274: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:32:59.276: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:00.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:00.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:01.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:01.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:02.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:02.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:03.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:03.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:04.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:04.282: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:05.271: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:05.277: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:06.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:06.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:07.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:07.277: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:08.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:08.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:09.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:09.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:10.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:10.276: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:11.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:11.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:12.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:12.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:13.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:13.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:14.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:14.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:15.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:15.276: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:16.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:16.272: INFO: Pod daemon-set-g8t75 is not available
Dec  5 16:33:16.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:17.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:17.272: INFO: Pod daemon-set-g8t75 is not available
Dec  5 16:33:17.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:18.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:18.272: INFO: Pod daemon-set-g8t75 is not available
Dec  5 16:33:18.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:19.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:19.272: INFO: Pod daemon-set-g8t75 is not available
Dec  5 16:33:19.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:20.272: INFO: Wrong image for pod: daemon-set-g8t75. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 16:33:20.272: INFO: Pod daemon-set-g8t75 is not available
Dec  5 16:33:20.274: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:21.272: INFO: Pod daemon-set-bkxf9 is not available
Dec  5 16:33:21.275: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  5 16:33:21.279: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:21.281: INFO: Number of nodes with available pods: 1
Dec  5 16:33:21.281: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:33:22.285: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:33:22.287: INFO: Number of nodes with available pods: 2
Dec  5 16:33:22.287: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-qx6xt, will wait for the garbage collector to delete the pods
Dec  5 16:33:22.358: INFO: Deleting DaemonSet.extensions daemon-set took: 8.48994ms
Dec  5 16:33:22.458: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.427592ms
Dec  5 16:33:32.961: INFO: Number of nodes with available pods: 0
Dec  5 16:33:32.961: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 16:33:32.963: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qx6xt/daemonsets","resourceVersion":"65308"},"items":null}

Dec  5 16:33:32.965: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qx6xt/pods","resourceVersion":"65308"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:33:32.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qx6xt" for this suite.
Dec  5 16:33:38.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:33:39.029: INFO: namespace: e2e-tests-daemonsets-qx6xt, resource: bindings, ignored listing per whitelist
Dec  5 16:33:39.063: INFO: namespace e2e-tests-daemonsets-qx6xt deletion completed in 6.089629526s

• [SLOW TEST:101.960 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:33:39.064: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  5 16:33:39.135: INFO: Waiting up to 5m0s for pod "pod-851ebf8d-f8ab-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-kbwv9" to be "success or failure"
Dec  5 16:33:39.137: INFO: Pod "pod-851ebf8d-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.196602ms
Dec  5 16:33:41.140: INFO: Pod "pod-851ebf8d-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005520416s
STEP: Saw pod success
Dec  5 16:33:41.140: INFO: Pod "pod-851ebf8d-f8ab-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:33:41.142: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-851ebf8d-f8ab-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:33:41.159: INFO: Waiting for pod pod-851ebf8d-f8ab-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:33:41.162: INFO: Pod pod-851ebf8d-f8ab-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:33:41.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kbwv9" for this suite.
Dec  5 16:33:47.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:33:47.223: INFO: namespace: e2e-tests-emptydir-kbwv9, resource: bindings, ignored listing per whitelist
Dec  5 16:33:47.246: INFO: namespace e2e-tests-emptydir-kbwv9 deletion completed in 6.080948591s

• [SLOW TEST:8.183 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:33:47.248: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1205 16:34:27.332535      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 16:34:27.332: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:34:27.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-khk9j" for this suite.
Dec  5 16:34:33.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:34:33.393: INFO: namespace: e2e-tests-gc-khk9j, resource: bindings, ignored listing per whitelist
Dec  5 16:34:33.424: INFO: namespace e2e-tests-gc-khk9j deletion completed in 6.088440957s

• [SLOW TEST:46.176 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:34:33.424: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec  5 16:34:33.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 --namespace=e2e-tests-kubectl-b8tx6 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  5 16:34:37.840: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  5 16:34:37.840: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:34:39.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b8tx6" for this suite.
Dec  5 16:34:53.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:34:53.871: INFO: namespace: e2e-tests-kubectl-b8tx6, resource: bindings, ignored listing per whitelist
Dec  5 16:34:53.941: INFO: namespace e2e-tests-kubectl-b8tx6 deletion completed in 14.093990017s

• [SLOW TEST:20.517 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:34:53.942: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  5 16:34:54.524: INFO: Waiting up to 5m0s for pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-n6gsd" in namespace "e2e-tests-svcaccounts-98mhg" to be "success or failure"
Dec  5 16:34:54.529: INFO: Pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-n6gsd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.504318ms
Dec  5 16:34:56.532: INFO: Pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-n6gsd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008595121s
Dec  5 16:34:58.537: INFO: Pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-n6gsd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013037405s
STEP: Saw pod success
Dec  5 16:34:58.537: INFO: Pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-n6gsd" satisfied condition "success or failure"
Dec  5 16:34:58.539: INFO: Trying to get logs from node ip-10-0-12-134 pod pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-n6gsd container token-test: <nil>
STEP: delete the pod
Dec  5 16:34:58.589: INFO: Waiting for pod pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-n6gsd to disappear
Dec  5 16:34:58.592: INFO: Pod pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-n6gsd no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  5 16:34:58.598: INFO: Waiting up to 5m0s for pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-dg2vl" in namespace "e2e-tests-svcaccounts-98mhg" to be "success or failure"
Dec  5 16:34:58.608: INFO: Pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-dg2vl": Phase="Pending", Reason="", readiness=false. Elapsed: 10.254466ms
Dec  5 16:35:00.612: INFO: Pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-dg2vl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013601034s
STEP: Saw pod success
Dec  5 16:35:00.612: INFO: Pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-dg2vl" satisfied condition "success or failure"
Dec  5 16:35:00.613: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-dg2vl container root-ca-test: <nil>
STEP: delete the pod
Dec  5 16:35:00.636: INFO: Waiting for pod pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-dg2vl to disappear
Dec  5 16:35:00.639: INFO: Pod pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-dg2vl no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  5 16:35:00.645: INFO: Waiting up to 5m0s for pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-pfk7w" in namespace "e2e-tests-svcaccounts-98mhg" to be "success or failure"
Dec  5 16:35:00.710: INFO: Pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-pfk7w": Phase="Pending", Reason="", readiness=false. Elapsed: 65.241258ms
Dec  5 16:35:02.715: INFO: Pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-pfk7w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.070015074s
STEP: Saw pod success
Dec  5 16:35:02.715: INFO: Pod "pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-pfk7w" satisfied condition "success or failure"
Dec  5 16:35:02.719: INFO: Trying to get logs from node ip-10-0-12-134 pod pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-pfk7w container namespace-test: <nil>
STEP: delete the pod
Dec  5 16:35:02.756: INFO: Waiting for pod pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-pfk7w to disappear
Dec  5 16:35:02.778: INFO: Pod pod-service-account-b20df0ea-f8ab-11e8-a7f8-ceaf58ef2674-pfk7w no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:35:02.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-98mhg" for this suite.
Dec  5 16:35:08.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:35:08.886: INFO: namespace: e2e-tests-svcaccounts-98mhg, resource: bindings, ignored listing per whitelist
Dec  5 16:35:08.919: INFO: namespace e2e-tests-svcaccounts-98mhg deletion completed in 6.135771934s

• [SLOW TEST:14.977 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:35:08.922: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec  5 16:35:09.006: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-292959027 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:35:09.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rfbhn" for this suite.
Dec  5 16:35:15.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:35:15.183: INFO: namespace: e2e-tests-kubectl-rfbhn, resource: bindings, ignored listing per whitelist
Dec  5 16:35:15.187: INFO: namespace e2e-tests-kubectl-rfbhn deletion completed in 6.092406612s

• [SLOW TEST:6.265 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:35:15.189: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  5 16:35:15.268: INFO: Waiting up to 5m0s for pod "pod-be6b389f-f8ab-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-l4558" to be "success or failure"
Dec  5 16:35:15.279: INFO: Pod "pod-be6b389f-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 10.534752ms
Dec  5 16:35:17.282: INFO: Pod "pod-be6b389f-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013989224s
STEP: Saw pod success
Dec  5 16:35:17.282: INFO: Pod "pod-be6b389f-f8ab-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:35:17.285: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-be6b389f-f8ab-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:35:17.307: INFO: Waiting for pod pod-be6b389f-f8ab-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:35:17.310: INFO: Pod pod-be6b389f-f8ab-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:35:17.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l4558" for this suite.
Dec  5 16:35:23.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:35:23.367: INFO: namespace: e2e-tests-emptydir-l4558, resource: bindings, ignored listing per whitelist
Dec  5 16:35:23.405: INFO: namespace e2e-tests-emptydir-l4558 deletion completed in 6.091601121s

• [SLOW TEST:8.216 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:35:23.407: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 16:35:23.480: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3507b1a-f8ab-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-r44w5" to be "success or failure"
Dec  5 16:35:23.483: INFO: Pod "downwardapi-volume-c3507b1a-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.596085ms
Dec  5 16:35:25.486: INFO: Pod "downwardapi-volume-c3507b1a-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005994317s
STEP: Saw pod success
Dec  5 16:35:25.486: INFO: Pod "downwardapi-volume-c3507b1a-f8ab-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:35:25.488: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-c3507b1a-f8ab-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 16:35:25.505: INFO: Waiting for pod downwardapi-volume-c3507b1a-f8ab-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:35:25.509: INFO: Pod downwardapi-volume-c3507b1a-f8ab-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:35:25.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r44w5" for this suite.
Dec  5 16:35:31.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:35:31.549: INFO: namespace: e2e-tests-projected-r44w5, resource: bindings, ignored listing per whitelist
Dec  5 16:35:31.608: INFO: namespace e2e-tests-projected-r44w5 deletion completed in 6.09505607s

• [SLOW TEST:8.202 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:35:31.610: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 16:35:31.739: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  5 16:35:36.743: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 16:35:36.743: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  5 16:35:38.746: INFO: Creating deployment "test-rollover-deployment"
Dec  5 16:35:38.758: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  5 16:35:40.765: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  5 16:35:40.770: INFO: Ensure that both replica sets have 1 created replica
Dec  5 16:35:40.776: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  5 16:35:40.783: INFO: Updating deployment test-rollover-deployment
Dec  5 16:35:40.783: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  5 16:35:42.793: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  5 16:35:42.801: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  5 16:35:42.810: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 16:35:42.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624542, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 16:35:44.822: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 16:35:44.823: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624542, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 16:35:46.823: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 16:35:46.823: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624542, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 16:35:48.818: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 16:35:48.818: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624542, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 16:35:50.822: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 16:35:50.822: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624542, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679624538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 16:35:52.828: INFO: 
Dec  5 16:35:52.828: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 16:35:52.837: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-96ngw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-96ngw/deployments/test-rollover-deployment,UID:cc6b429f-f8ab-11e8-ab6c-06b570ab0412,ResourceVersion:66024,Generation:2,CreationTimestamp:2018-12-05 16:35:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-05 16:35:38 +0000 UTC 2018-12-05 16:35:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-05 16:35:52 +0000 UTC 2018-12-05 16:35:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  5 16:35:52.840: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-96ngw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-96ngw/replicasets/test-rollover-deployment-6b7f9d6597,UID:cda21856-f8ab-11e8-ab6c-06b570ab0412,ResourceVersion:66015,Generation:2,CreationTimestamp:2018-12-05 16:35:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc6b429f-f8ab-11e8-ab6c-06b570ab0412 0xc0018fa097 0xc0018fa098}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  5 16:35:52.840: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  5 16:35:52.840: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-96ngw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-96ngw/replicasets/test-rollover-controller,UID:c83c5cf1-f8ab-11e8-ab6c-06b570ab0412,ResourceVersion:66023,Generation:2,CreationTimestamp:2018-12-05 16:35:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc6b429f-f8ab-11e8-ab6c-06b570ab0412 0xc001fa5bd7 0xc001fa5bd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 16:35:52.840: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-96ngw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-96ngw/replicasets/test-rollover-deployment-6586df867b,UID:cc6febac-f8ab-11e8-ab6c-06b570ab0412,ResourceVersion:65988,Generation:2,CreationTimestamp:2018-12-05 16:35:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc6b429f-f8ab-11e8-ab6c-06b570ab0412 0xc001fa5fa7 0xc001fa5fa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 16:35:52.844: INFO: Pod "test-rollover-deployment-6b7f9d6597-t7hhl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-t7hhl,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-96ngw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-96ngw/pods/test-rollover-deployment-6b7f9d6597-t7hhl,UID:cdac0d9c-f8ab-11e8-ab6c-06b570ab0412,ResourceVersion:65998,Generation:0,CreationTimestamp:2018-12-05 16:35:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.0.180/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 cda21856-f8ab-11e8-ab6c-06b570ab0412 0xc002798b47 0xc002798b48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rrhx2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rrhx2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rrhx2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002798bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002798bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:35:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:35:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:35:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:35:40 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:10.2.0.180,StartTime:2018-12-05 16:35:40 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-05 16:35:41 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://0d4315df755ef7a8a2812cacca8515afbd82040e7db8e12e8a0ee2d705b8704d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:35:52.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-96ngw" for this suite.
Dec  5 16:35:58.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:35:58.892: INFO: namespace: e2e-tests-deployment-96ngw, resource: bindings, ignored listing per whitelist
Dec  5 16:35:58.940: INFO: namespace e2e-tests-deployment-96ngw deletion completed in 6.092817346s

• [SLOW TEST:27.331 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:35:58.942: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  5 16:35:59.015: INFO: Waiting up to 5m0s for pod "pod-d87eb6c7-f8ab-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-p7f2d" to be "success or failure"
Dec  5 16:35:59.020: INFO: Pod "pod-d87eb6c7-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.881022ms
Dec  5 16:36:01.023: INFO: Pod "pod-d87eb6c7-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007587496s
STEP: Saw pod success
Dec  5 16:36:01.023: INFO: Pod "pod-d87eb6c7-f8ab-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:36:01.025: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-d87eb6c7-f8ab-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:36:01.052: INFO: Waiting for pod pod-d87eb6c7-f8ab-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:36:01.057: INFO: Pod pod-d87eb6c7-f8ab-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:36:01.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p7f2d" for this suite.
Dec  5 16:36:07.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:36:07.085: INFO: namespace: e2e-tests-emptydir-p7f2d, resource: bindings, ignored listing per whitelist
Dec  5 16:36:07.143: INFO: namespace e2e-tests-emptydir-p7f2d deletion completed in 6.082493896s

• [SLOW TEST:8.201 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:36:07.145: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  5 16:36:11.267: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:11.272: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 16:36:13.273: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:13.275: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 16:36:15.273: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:15.281: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 16:36:17.273: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:17.276: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 16:36:19.273: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:19.275: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 16:36:21.273: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:21.276: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 16:36:23.273: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:23.278: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 16:36:25.273: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:25.280: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 16:36:27.273: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:27.276: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 16:36:29.273: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:29.276: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 16:36:31.273: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 16:36:31.276: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:36:31.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-g2tff" for this suite.
Dec  5 16:36:53.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:36:53.358: INFO: namespace: e2e-tests-container-lifecycle-hook-g2tff, resource: bindings, ignored listing per whitelist
Dec  5 16:36:53.382: INFO: namespace e2e-tests-container-lifecycle-hook-g2tff deletion completed in 22.095863558s

• [SLOW TEST:46.237 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:36:53.383: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Dec  5 16:36:53.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-rr2xw'
Dec  5 16:36:53.638: INFO: stderr: ""
Dec  5 16:36:53.638: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec  5 16:36:54.644: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 16:36:54.644: INFO: Found 0 / 1
Dec  5 16:36:55.641: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 16:36:55.641: INFO: Found 1 / 1
Dec  5 16:36:55.641: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 16:36:55.644: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 16:36:55.644: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  5 16:36:55.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 logs redis-master-qrsvr redis-master --namespace=e2e-tests-kubectl-rr2xw'
Dec  5 16:36:55.741: INFO: stderr: ""
Dec  5 16:36:55.741: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Dec 16:36:54.435 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Dec 16:36:54.435 # Server started, Redis version 3.2.12\n1:M 05 Dec 16:36:54.435 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Dec 16:36:54.435 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  5 16:36:55.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 log redis-master-qrsvr redis-master --namespace=e2e-tests-kubectl-rr2xw --tail=1'
Dec  5 16:36:55.832: INFO: stderr: ""
Dec  5 16:36:55.832: INFO: stdout: "1:M 05 Dec 16:36:54.435 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  5 16:36:55.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 log redis-master-qrsvr redis-master --namespace=e2e-tests-kubectl-rr2xw --limit-bytes=1'
Dec  5 16:36:55.923: INFO: stderr: ""
Dec  5 16:36:55.923: INFO: stdout: " "
STEP: exposing timestamps
Dec  5 16:36:55.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 log redis-master-qrsvr redis-master --namespace=e2e-tests-kubectl-rr2xw --tail=1 --timestamps'
Dec  5 16:36:56.014: INFO: stderr: ""
Dec  5 16:36:56.014: INFO: stdout: "2018-12-05T16:36:54.435840081Z 1:M 05 Dec 16:36:54.435 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  5 16:36:58.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 log redis-master-qrsvr redis-master --namespace=e2e-tests-kubectl-rr2xw --since=1s'
Dec  5 16:36:58.602: INFO: stderr: ""
Dec  5 16:36:58.602: INFO: stdout: ""
Dec  5 16:36:58.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 log redis-master-qrsvr redis-master --namespace=e2e-tests-kubectl-rr2xw --since=24h'
Dec  5 16:36:58.701: INFO: stderr: ""
Dec  5 16:36:58.701: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Dec 16:36:54.435 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Dec 16:36:54.435 # Server started, Redis version 3.2.12\n1:M 05 Dec 16:36:54.435 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Dec 16:36:54.435 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Dec  5 16:36:58.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rr2xw'
Dec  5 16:36:58.779: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 16:36:58.779: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  5 16:36:58.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-rr2xw'
Dec  5 16:36:58.868: INFO: stderr: "No resources found.\n"
Dec  5 16:36:58.868: INFO: stdout: ""
Dec  5 16:36:58.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -l name=nginx --namespace=e2e-tests-kubectl-rr2xw -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 16:36:58.950: INFO: stderr: ""
Dec  5 16:36:58.951: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:36:58.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rr2xw" for this suite.
Dec  5 16:37:04.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:37:04.979: INFO: namespace: e2e-tests-kubectl-rr2xw, resource: bindings, ignored listing per whitelist
Dec  5 16:37:05.041: INFO: namespace e2e-tests-kubectl-rr2xw deletion completed in 6.087855745s

• [SLOW TEST:11.658 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:37:05.043: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  5 16:37:05.116: INFO: Waiting up to 5m0s for pod "pod-ffe4c112-f8ab-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-bg768" to be "success or failure"
Dec  5 16:37:05.124: INFO: Pod "pod-ffe4c112-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 7.754612ms
Dec  5 16:37:07.128: INFO: Pod "pod-ffe4c112-f8ab-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011307072s
STEP: Saw pod success
Dec  5 16:37:07.128: INFO: Pod "pod-ffe4c112-f8ab-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:37:07.129: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-ffe4c112-f8ab-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:37:07.149: INFO: Waiting for pod pod-ffe4c112-f8ab-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:37:07.153: INFO: Pod pod-ffe4c112-f8ab-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:37:07.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bg768" for this suite.
Dec  5 16:37:13.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:37:13.192: INFO: namespace: e2e-tests-emptydir-bg768, resource: bindings, ignored listing per whitelist
Dec  5 16:37:13.238: INFO: namespace e2e-tests-emptydir-bg768 deletion completed in 6.082916403s

• [SLOW TEST:8.195 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:37:13.240: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 16:37:13.317: INFO: Creating deployment "nginx-deployment"
Dec  5 16:37:13.322: INFO: Waiting for observed generation 1
Dec  5 16:37:15.329: INFO: Waiting for all required pods to come up
Dec  5 16:37:15.333: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  5 16:37:19.362: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  5 16:37:19.366: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  5 16:37:19.374: INFO: Updating deployment nginx-deployment
Dec  5 16:37:19.375: INFO: Waiting for observed generation 2
Dec  5 16:37:21.383: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  5 16:37:21.385: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  5 16:37:21.387: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  5 16:37:21.392: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  5 16:37:21.392: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  5 16:37:21.394: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  5 16:37:21.397: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  5 16:37:21.397: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  5 16:37:21.405: INFO: Updating deployment nginx-deployment
Dec  5 16:37:21.405: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  5 16:37:21.430: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  5 16:37:21.466: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 16:37:23.517: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ztmqh/deployments/nginx-deployment,UID:04c98dee-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66572,Generation:3,CreationTimestamp:2018-12-05 16:37:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2018-12-05 16:37:21 +0000 UTC 2018-12-05 16:37:21 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-05 16:37:21 +0000 UTC 2018-12-05 16:37:13 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  5 16:37:23.525: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ztmqh/replicasets/nginx-deployment-65bbdb5f8,UID:08663023-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66569,Generation:3,CreationTimestamp:2018-12-05 16:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 04c98dee-f8ac-11e8-ab6c-06b570ab0412 0xc0006847d7 0xc0006847d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 16:37:23.525: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  5 16:37:23.525: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ztmqh/replicasets/nginx-deployment-555b55d965,UID:04cb629c-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66555,Generation:3,CreationTimestamp:2018-12-05 16:37:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 04c98dee-f8ac-11e8-ab6c-06b570ab0412 0xc000684337 0xc000684338}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  5 16:37:23.543: INFO: Pod "nginx-deployment-555b55d965-297ct" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-297ct,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-297ct,UID:04d23c5c-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66417,Generation:0,CreationTimestamp:2018-12-05 16:37:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.0.185/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc000573207 0xc000573208}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000573380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005733c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:10.2.0.185,StartTime:2018-12-05 16:37:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 16:37:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://dae84b3e0a1e21b48e764979d06957b52df9a26ee97a391b24ca45e25ed43903}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.543: INFO: Pod "nginx-deployment-555b55d965-2zgcm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2zgcm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-2zgcm,UID:04d4bb8c-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66431,Generation:0,CreationTimestamp:2018-12-05 16:37:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.74/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc000573600 0xc000573601}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005738d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005739f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:10.2.1.74,StartTime:2018-12-05 16:37:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 16:37:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://bc3736eef42ec1b783cf148b07a948ade4efab69b4582fa55b375f9f177c268c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.543: INFO: Pod "nginx-deployment-555b55d965-6hvvs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6hvvs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-6hvvs,UID:099f5e6e-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66544,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc000573cb0 0xc000573cb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000573f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000318000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.543: INFO: Pod "nginx-deployment-555b55d965-8pmfx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8pmfx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-8pmfx,UID:09ade68c-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66621,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0003182a0 0xc0003182a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000318cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000318e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.544: INFO: Pod "nginx-deployment-555b55d965-8w2nq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8w2nq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-8w2nq,UID:04d545ed-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66415,Generation:0,CreationTimestamp:2018-12-05 16:37:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.0.186/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0003193e0 0xc0003193e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000319530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000319550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:10.2.0.186,StartTime:2018-12-05 16:37:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 16:37:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://f2ca81a88f8cb159e8c0d6a4d6871cc028546ee216cb4dc63c9df5c03ea4ddca}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.545: INFO: Pod "nginx-deployment-555b55d965-8zphm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8zphm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-8zphm,UID:09ad3d91-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66612,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc000319b40 0xc000319b41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000319fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000054140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.545: INFO: Pod "nginx-deployment-555b55d965-9ccv8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9ccv8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-9ccv8,UID:09ad97c3-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66623,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0000546f0 0xc0000546f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000054920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000054980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.545: INFO: Pod "nginx-deployment-555b55d965-dmqng" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dmqng,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-dmqng,UID:09a57985-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66574,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc000054b80 0xc000054b81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000054c40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000054c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.545: INFO: Pod "nginx-deployment-555b55d965-grtgm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-grtgm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-grtgm,UID:04ddcc36-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66393,Generation:0,CreationTimestamp:2018-12-05 16:37:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.71/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc000054df0 0xc000054df1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0000551d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0000551f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:10.2.1.71,StartTime:2018-12-05 16:37:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 16:37:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://9b7f4ad78e6a5b9ad8ed74586e1ad976466f1983cc506aee4fa70d83eb1fac4a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.545: INFO: Pod "nginx-deployment-555b55d965-jhwr9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jhwr9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-jhwr9,UID:09adabf7-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66593,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0000555c0 0xc0000555c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000055760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000055800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.545: INFO: Pod "nginx-deployment-555b55d965-kkpzt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kkpzt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-kkpzt,UID:099c9f42-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66546,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc000055940 0xc000055941}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000055a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000055ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.545: INFO: Pod "nginx-deployment-555b55d965-l7rpb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l7rpb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-l7rpb,UID:04dde29a-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66428,Generation:0,CreationTimestamp:2018-12-05 16:37:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.73/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc000055c60 0xc000055c61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000055f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0003b8300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:10.2.1.73,StartTime:2018-12-05 16:37:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 16:37:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://610bb2c20e203ef666e3c3364f709086bb7aae933c4e040cc979507395973a29}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.547: INFO: Pod "nginx-deployment-555b55d965-mjv5l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mjv5l,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-mjv5l,UID:04d20d19-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66385,Generation:0,CreationTimestamp:2018-12-05 16:37:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.70/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0003b89b0 0xc0003b89b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0003b8cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0003b8dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:10.2.1.70,StartTime:2018-12-05 16:37:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 16:37:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://6d306bea00704d0b780e29c250f3b78d2804fc02be76cc4568567693f25967c8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.548: INFO: Pod "nginx-deployment-555b55d965-r7t87" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-r7t87,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-r7t87,UID:09a4ffd6-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66610,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0003b9070 0xc0003b9071}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0003b91d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0003b9250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.548: INFO: Pod "nginx-deployment-555b55d965-swndt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-swndt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-swndt,UID:099f079e-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66596,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0003b9460 0xc0003b9461}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0003b94e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0003b9510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.548: INFO: Pod "nginx-deployment-555b55d965-vlfwt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vlfwt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-vlfwt,UID:04d59545-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66425,Generation:0,CreationTimestamp:2018-12-05 16:37:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.72/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0003b9630 0xc0003b9631}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0003b96e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0003b9710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:10.2.1.72,StartTime:2018-12-05 16:37:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 16:37:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://d0786c8e8bdbf49bf61915cf2a593ebbf2705d5aaaf6fd65e4f03745668783e1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.548: INFO: Pod "nginx-deployment-555b55d965-wql5j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wql5j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-wql5j,UID:09a591b1-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66611,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0003b9830 0xc0003b9831}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0003b98c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0003b98e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.548: INFO: Pod "nginx-deployment-555b55d965-x2gr5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-x2gr5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-x2gr5,UID:09acffa7-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66604,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0003b99d0 0xc0003b99d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00042e940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00042e970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.548: INFO: Pod "nginx-deployment-555b55d965-xrmcw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xrmcw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-xrmcw,UID:04d0cbe6-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66421,Generation:0,CreationTimestamp:2018-12-05 16:37:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.0.187/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc000696080 0xc000696081}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000696b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000696b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:13 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:10.2.0.187,StartTime:2018-12-05 16:37:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 16:37:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://5a21466ffb0412689eff4e820c6d3be80024e8d89ae54a6800b561291268d29d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.548: INFO: Pod "nginx-deployment-555b55d965-xx6w7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xx6w7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-555b55d965-xx6w7,UID:09a5a59c-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66619,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 04cb629c-f8ac-11e8-ab6c-06b570ab0412 0xc0006970b0 0xc0006970b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000697280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0006972b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.548: INFO: Pod "nginx-deployment-65bbdb5f8-4bs6d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4bs6d,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-4bs6d,UID:0868ab4d-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66606,Generation:0,CreationTimestamp:2018-12-05 16:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.0.190/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc000697820 0xc000697821}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0006978f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000697b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.549: INFO: Pod "nginx-deployment-65bbdb5f8-8wlwk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8wlwk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-8wlwk,UID:088b25d2-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66613,Generation:0,CreationTimestamp:2018-12-05 16:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.0.191/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc000697d90 0xc000697d91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027ac060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027ac1d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.549: INFO: Pod "nginx-deployment-65bbdb5f8-bk9k4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bk9k4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-bk9k4,UID:09bfed99-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66628,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc0027ac6a0 0xc0027ac6a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027aca00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027aca20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.549: INFO: Pod "nginx-deployment-65bbdb5f8-blhth" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-blhth,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-blhth,UID:09a0caeb-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66567,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc0027acaf0 0xc0027acaf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027acb70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027acb90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.549: INFO: Pod "nginx-deployment-65bbdb5f8-blnqq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-blnqq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-blnqq,UID:09a9bb6e-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66580,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc0027acc50 0xc0027acc51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027aceb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027aced0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.549: INFO: Pod "nginx-deployment-65bbdb5f8-cw69p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cw69p,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-cw69p,UID:09b10196-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66626,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc0027acfc0 0xc0027acfc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027ad040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027ad060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.550: INFO: Pod "nginx-deployment-65bbdb5f8-g7ktn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-g7ktn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-g7ktn,UID:09b175ec-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66618,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc0027ad130 0xc0027ad131}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027ad2e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027ad300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.550: INFO: Pod "nginx-deployment-65bbdb5f8-h658m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-h658m,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-h658m,UID:08889e92-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66500,Generation:0,CreationTimestamp:2018-12-05 16:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.76/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc0027ad3f0 0xc0027ad3f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027ad4a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027ad4c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:,StartTime:2018-12-05 16:37:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.551: INFO: Pod "nginx-deployment-65bbdb5f8-ngmtw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ngmtw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-ngmtw,UID:09b1be15-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66624,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc0027ad640 0xc0027ad641}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027ad7a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027ad7c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.551: INFO: Pod "nginx-deployment-65bbdb5f8-qqxzf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qqxzf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-qqxzf,UID:09a98f30-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66620,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc0027ad880 0xc0027ad881}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027ada70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027ada90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.551: INFO: Pod "nginx-deployment-65bbdb5f8-vggvs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vggvs,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-vggvs,UID:0871a42a-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66616,Generation:0,CreationTimestamp:2018-12-05 16:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.0.192/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc0003b2b40 0xc0003b2b41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0003b2d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0003b2e20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.40.84,PodIP:,StartTime:2018-12-05 16:37:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.551: INFO: Pod "nginx-deployment-65bbdb5f8-w2plt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-w2plt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-w2plt,UID:09b1d324-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66556,Generation:0,CreationTimestamp:2018-12-05 16:37:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc002ab79a0 0xc002ab79a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-40-84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ab7a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ab7b50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:21 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 16:37:23.554: INFO: Pod "nginx-deployment-65bbdb5f8-xchvq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xchvq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-ztmqh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ztmqh/pods/nginx-deployment-65bbdb5f8-xchvq,UID:087107e3-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:66629,Generation:0,CreationTimestamp:2018-12-05 16:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.1.75/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 08663023-f8ac-11e8-ab6c-06b570ab0412 0xc002ab7c20 0xc002ab7c21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xmtng {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xmtng,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xmtng true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-134,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ab7d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ab7d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 16:37:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.134,PodIP:10.2.1.75,StartTime:2018-12-05 16:37:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:37:23.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ztmqh" for this suite.
Dec  5 16:37:31.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:37:31.626: INFO: namespace: e2e-tests-deployment-ztmqh, resource: bindings, ignored listing per whitelist
Dec  5 16:37:31.675: INFO: namespace e2e-tests-deployment-ztmqh deletion completed in 8.118163918s

• [SLOW TEST:18.435 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:37:31.676: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0fc548c6-f8ac-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 16:37:31.756: INFO: Waiting up to 5m0s for pod "pod-secrets-0fc5d985-f8ac-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-secrets-v8kzm" to be "success or failure"
Dec  5 16:37:31.762: INFO: Pod "pod-secrets-0fc5d985-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 5.655963ms
Dec  5 16:37:33.765: INFO: Pod "pod-secrets-0fc5d985-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00870041s
Dec  5 16:37:35.768: INFO: Pod "pod-secrets-0fc5d985-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011696498s
Dec  5 16:37:37.771: INFO: Pod "pod-secrets-0fc5d985-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01512541s
Dec  5 16:37:39.775: INFO: Pod "pod-secrets-0fc5d985-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.018939078s
STEP: Saw pod success
Dec  5 16:37:39.775: INFO: Pod "pod-secrets-0fc5d985-f8ac-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:37:39.778: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-secrets-0fc5d985-f8ac-11e8-a7f8-ceaf58ef2674 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 16:37:39.803: INFO: Waiting for pod pod-secrets-0fc5d985-f8ac-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:37:39.805: INFO: Pod pod-secrets-0fc5d985-f8ac-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:37:39.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v8kzm" for this suite.
Dec  5 16:37:45.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:37:45.878: INFO: namespace: e2e-tests-secrets-v8kzm, resource: bindings, ignored listing per whitelist
Dec  5 16:37:45.917: INFO: namespace e2e-tests-secrets-v8kzm deletion completed in 6.109207446s

• [SLOW TEST:14.241 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:37:45.918: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  5 16:37:45.996: INFO: Pod name pod-release: Found 0 pods out of 1
Dec  5 16:37:50.999: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:37:51.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-trsq8" for this suite.
Dec  5 16:37:57.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:37:57.111: INFO: namespace: e2e-tests-replication-controller-trsq8, resource: bindings, ignored listing per whitelist
Dec  5 16:37:57.181: INFO: namespace e2e-tests-replication-controller-trsq8 deletion completed in 6.140110421s

• [SLOW TEST:11.263 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:37:57.181: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dz888
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec  5 16:37:57.275: INFO: Found 0 stateful pods, waiting for 3
Dec  5 16:38:07.278: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 16:38:07.279: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 16:38:07.279: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  5 16:38:07.310: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  5 16:38:17.371: INFO: Updating stateful set ss2
Dec  5 16:38:17.379: INFO: Waiting for Pod e2e-tests-statefulset-dz888/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  5 16:38:27.384: INFO: Waiting for Pod e2e-tests-statefulset-dz888/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec  5 16:38:37.542: INFO: Found 2 stateful pods, waiting for 3
Dec  5 16:38:47.546: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 16:38:47.546: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 16:38:47.546: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  5 16:38:47.570: INFO: Updating stateful set ss2
Dec  5 16:38:47.585: INFO: Waiting for Pod e2e-tests-statefulset-dz888/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  5 16:38:57.609: INFO: Updating stateful set ss2
Dec  5 16:38:57.630: INFO: Waiting for StatefulSet e2e-tests-statefulset-dz888/ss2 to complete update
Dec  5 16:38:57.630: INFO: Waiting for Pod e2e-tests-statefulset-dz888/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  5 16:39:07.636: INFO: Waiting for StatefulSet e2e-tests-statefulset-dz888/ss2 to complete update
Dec  5 16:39:07.636: INFO: Waiting for Pod e2e-tests-statefulset-dz888/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 16:39:18.201: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dz888
Dec  5 16:39:18.205: INFO: Scaling statefulset ss2 to 0
Dec  5 16:39:28.322: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 16:39:28.324: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:39:28.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dz888" for this suite.
Dec  5 16:39:34.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:39:34.380: INFO: namespace: e2e-tests-statefulset-dz888, resource: bindings, ignored listing per whitelist
Dec  5 16:39:34.443: INFO: namespace e2e-tests-statefulset-dz888 deletion completed in 6.098367169s

• [SLOW TEST:97.262 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:39:34.445: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 16:39:34.517: INFO: Waiting up to 5m0s for pod "downwardapi-volume-58f1ab32-f8ac-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-mkcbv" to be "success or failure"
Dec  5 16:39:34.522: INFO: Pod "downwardapi-volume-58f1ab32-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.9514ms
Dec  5 16:39:36.525: INFO: Pod "downwardapi-volume-58f1ab32-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008554858s
STEP: Saw pod success
Dec  5 16:39:36.526: INFO: Pod "downwardapi-volume-58f1ab32-f8ac-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:39:36.527: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-58f1ab32-f8ac-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 16:39:36.544: INFO: Waiting for pod downwardapi-volume-58f1ab32-f8ac-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:39:36.547: INFO: Pod downwardapi-volume-58f1ab32-f8ac-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:39:36.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mkcbv" for this suite.
Dec  5 16:39:42.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:39:42.622: INFO: namespace: e2e-tests-projected-mkcbv, resource: bindings, ignored listing per whitelist
Dec  5 16:39:42.628: INFO: namespace e2e-tests-projected-mkcbv deletion completed in 6.078864176s

• [SLOW TEST:8.183 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:39:42.631: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5dd20dd5-f8ac-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 16:39:42.703: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5dd2a031-f8ac-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-vp29l" to be "success or failure"
Dec  5 16:39:42.710: INFO: Pod "pod-projected-configmaps-5dd2a031-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 7.681535ms
Dec  5 16:39:44.714: INFO: Pod "pod-projected-configmaps-5dd2a031-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011142443s
STEP: Saw pod success
Dec  5 16:39:44.714: INFO: Pod "pod-projected-configmaps-5dd2a031-f8ac-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:39:44.716: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-configmaps-5dd2a031-f8ac-11e8-a7f8-ceaf58ef2674 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 16:39:44.735: INFO: Waiting for pod pod-projected-configmaps-5dd2a031-f8ac-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:39:44.737: INFO: Pod pod-projected-configmaps-5dd2a031-f8ac-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:39:44.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vp29l" for this suite.
Dec  5 16:39:50.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:39:50.768: INFO: namespace: e2e-tests-projected-vp29l, resource: bindings, ignored listing per whitelist
Dec  5 16:39:50.835: INFO: namespace e2e-tests-projected-vp29l deletion completed in 6.094766144s

• [SLOW TEST:8.204 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:39:50.837: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 16:39:50.934: INFO: Waiting up to 5m0s for pod "downward-api-62bab2cd-f8ac-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-gncwd" to be "success or failure"
Dec  5 16:39:50.939: INFO: Pod "downward-api-62bab2cd-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 4.571813ms
Dec  5 16:39:52.942: INFO: Pod "downward-api-62bab2cd-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008053028s
STEP: Saw pod success
Dec  5 16:39:52.942: INFO: Pod "downward-api-62bab2cd-f8ac-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:39:52.945: INFO: Trying to get logs from node ip-10-0-40-84 pod downward-api-62bab2cd-f8ac-11e8-a7f8-ceaf58ef2674 container dapi-container: <nil>
STEP: delete the pod
Dec  5 16:39:52.979: INFO: Waiting for pod downward-api-62bab2cd-f8ac-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:39:52.983: INFO: Pod downward-api-62bab2cd-f8ac-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:39:52.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gncwd" for this suite.
Dec  5 16:39:58.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:39:59.027: INFO: namespace: e2e-tests-downward-api-gncwd, resource: bindings, ignored listing per whitelist
Dec  5 16:39:59.066: INFO: namespace e2e-tests-downward-api-gncwd deletion completed in 6.081190391s

• [SLOW TEST:8.230 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:39:59.068: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-67a08f69-f8ac-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 16:39:59.155: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-67a134fc-f8ac-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-g48lt" to be "success or failure"
Dec  5 16:39:59.162: INFO: Pod "pod-projected-configmaps-67a134fc-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.362232ms
Dec  5 16:40:01.165: INFO: Pod "pod-projected-configmaps-67a134fc-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009644768s
STEP: Saw pod success
Dec  5 16:40:01.165: INFO: Pod "pod-projected-configmaps-67a134fc-f8ac-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:40:01.167: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-configmaps-67a134fc-f8ac-11e8-a7f8-ceaf58ef2674 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 16:40:01.200: INFO: Waiting for pod pod-projected-configmaps-67a134fc-f8ac-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:40:01.204: INFO: Pod pod-projected-configmaps-67a134fc-f8ac-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:40:01.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g48lt" for this suite.
Dec  5 16:40:07.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:40:07.245: INFO: namespace: e2e-tests-projected-g48lt, resource: bindings, ignored listing per whitelist
Dec  5 16:40:07.300: INFO: namespace e2e-tests-projected-g48lt deletion completed in 6.090803639s

• [SLOW TEST:8.232 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:40:07.301: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  5 16:40:07.373: INFO: Waiting up to 5m0s for pod "pod-6c87336d-f8ac-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-rfhnz" to be "success or failure"
Dec  5 16:40:07.380: INFO: Pod "pod-6c87336d-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 6.396508ms
Dec  5 16:40:09.383: INFO: Pod "pod-6c87336d-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009973481s
STEP: Saw pod success
Dec  5 16:40:09.383: INFO: Pod "pod-6c87336d-f8ac-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:40:09.385: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-6c87336d-f8ac-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:40:09.405: INFO: Waiting for pod pod-6c87336d-f8ac-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:40:09.408: INFO: Pod pod-6c87336d-f8ac-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:40:09.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rfhnz" for this suite.
Dec  5 16:40:15.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:40:15.517: INFO: namespace: e2e-tests-emptydir-rfhnz, resource: bindings, ignored listing per whitelist
Dec  5 16:40:15.534: INFO: namespace e2e-tests-emptydir-rfhnz deletion completed in 6.122634843s

• [SLOW TEST:8.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:40:15.535: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-716fff41-f8ac-11e8-a7f8-ceaf58ef2674
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:40:17.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9rsr5" for this suite.
Dec  5 16:40:45.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:40:45.708: INFO: namespace: e2e-tests-configmap-9rsr5, resource: bindings, ignored listing per whitelist
Dec  5 16:40:45.743: INFO: namespace e2e-tests-configmap-9rsr5 deletion completed in 28.08931322s

• [SLOW TEST:30.208 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:40:45.744: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  5 16:40:45.820: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kzgcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-kzgcx/configmaps/e2e-watch-test-watch-closed,UID:83711544-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:67667,Generation:0,CreationTimestamp:2018-12-05 16:40:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 16:40:45.820: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kzgcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-kzgcx/configmaps/e2e-watch-test-watch-closed,UID:83711544-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:67668,Generation:0,CreationTimestamp:2018-12-05 16:40:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  5 16:40:45.831: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kzgcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-kzgcx/configmaps/e2e-watch-test-watch-closed,UID:83711544-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:67669,Generation:0,CreationTimestamp:2018-12-05 16:40:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 16:40:45.831: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kzgcx,SelfLink:/api/v1/namespaces/e2e-tests-watch-kzgcx/configmaps/e2e-watch-test-watch-closed,UID:83711544-f8ac-11e8-ab6c-06b570ab0412,ResourceVersion:67670,Generation:0,CreationTimestamp:2018-12-05 16:40:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:40:45.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-kzgcx" for this suite.
Dec  5 16:40:51.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:40:51.905: INFO: namespace: e2e-tests-watch-kzgcx, resource: bindings, ignored listing per whitelist
Dec  5 16:40:51.918: INFO: namespace e2e-tests-watch-kzgcx deletion completed in 6.0848251s

• [SLOW TEST:6.175 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:40:51.921: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-871fb352-f8ac-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 16:40:52.005: INFO: Waiting up to 5m0s for pod "pod-configmaps-87205040-f8ac-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-configmap-w7dmf" to be "success or failure"
Dec  5 16:40:52.008: INFO: Pod "pod-configmaps-87205040-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 3.365267ms
Dec  5 16:40:54.012: INFO: Pod "pod-configmaps-87205040-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006910843s
STEP: Saw pod success
Dec  5 16:40:54.012: INFO: Pod "pod-configmaps-87205040-f8ac-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:40:54.014: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-configmaps-87205040-f8ac-11e8-a7f8-ceaf58ef2674 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 16:40:54.044: INFO: Waiting for pod pod-configmaps-87205040-f8ac-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:40:54.048: INFO: Pod pod-configmaps-87205040-f8ac-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:40:54.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-w7dmf" for this suite.
Dec  5 16:41:00.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:41:00.105: INFO: namespace: e2e-tests-configmap-w7dmf, resource: bindings, ignored listing per whitelist
Dec  5 16:41:00.143: INFO: namespace e2e-tests-configmap-w7dmf deletion completed in 6.091193319s

• [SLOW TEST:8.223 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:41:00.144: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 16:41:00.223: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  5 16:41:00.231: INFO: Number of nodes with available pods: 0
Dec  5 16:41:00.231: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  5 16:41:00.291: INFO: Number of nodes with available pods: 0
Dec  5 16:41:00.291: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:01.295: INFO: Number of nodes with available pods: 0
Dec  5 16:41:01.295: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:02.295: INFO: Number of nodes with available pods: 1
Dec  5 16:41:02.295: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  5 16:41:02.319: INFO: Number of nodes with available pods: 1
Dec  5 16:41:02.319: INFO: Number of running nodes: 0, number of available pods: 1
Dec  5 16:41:03.323: INFO: Number of nodes with available pods: 0
Dec  5 16:41:03.323: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  5 16:41:03.339: INFO: Number of nodes with available pods: 0
Dec  5 16:41:03.339: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:04.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:04.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:05.363: INFO: Number of nodes with available pods: 0
Dec  5 16:41:05.364: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:06.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:06.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:07.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:07.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:08.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:08.343: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:09.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:09.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:10.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:10.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:11.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:11.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:12.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:12.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:13.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:13.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:14.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:14.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:15.366: INFO: Number of nodes with available pods: 0
Dec  5 16:41:15.366: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:16.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:16.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:17.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:17.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:18.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:18.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:19.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:19.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:20.350: INFO: Number of nodes with available pods: 0
Dec  5 16:41:20.350: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:21.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:21.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:22.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:22.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:23.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:23.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:24.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:24.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:25.362: INFO: Number of nodes with available pods: 0
Dec  5 16:41:25.362: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:26.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:26.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:27.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:27.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:28.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:28.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:29.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:29.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:30.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:30.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:31.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:31.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:32.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:32.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:33.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:33.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:34.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:34.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:35.361: INFO: Number of nodes with available pods: 0
Dec  5 16:41:35.361: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:36.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:36.343: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:37.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:37.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:38.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:38.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:39.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:39.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:40.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:40.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:41.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:41.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:42.342: INFO: Number of nodes with available pods: 0
Dec  5 16:41:42.342: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:43.343: INFO: Number of nodes with available pods: 0
Dec  5 16:41:43.343: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:41:44.342: INFO: Number of nodes with available pods: 1
Dec  5 16:41:44.342: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-97lhw, will wait for the garbage collector to delete the pods
Dec  5 16:41:44.406: INFO: Deleting DaemonSet.extensions daemon-set took: 7.564318ms
Dec  5 16:41:44.507: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.318623ms
Dec  5 16:42:22.910: INFO: Number of nodes with available pods: 0
Dec  5 16:42:22.910: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 16:42:22.912: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-97lhw/daemonsets","resourceVersion":"67892"},"items":null}

Dec  5 16:42:22.913: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-97lhw/pods","resourceVersion":"67892"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:42:22.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-97lhw" for this suite.
Dec  5 16:42:28.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:42:28.999: INFO: namespace: e2e-tests-daemonsets-97lhw, resource: bindings, ignored listing per whitelist
Dec  5 16:42:29.024: INFO: namespace e2e-tests-daemonsets-97lhw deletion completed in 6.084933606s

• [SLOW TEST:88.880 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:42:29.026: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-kcgmv
Dec  5 16:42:31.116: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-kcgmv
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 16:42:31.118: INFO: Initial restart count of pod liveness-http is 0
Dec  5 16:42:47.147: INFO: Restart count of pod e2e-tests-container-probe-kcgmv/liveness-http is now 1 (16.02971152s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:42:47.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kcgmv" for this suite.
Dec  5 16:42:53.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:42:53.209: INFO: namespace: e2e-tests-container-probe-kcgmv, resource: bindings, ignored listing per whitelist
Dec  5 16:42:53.267: INFO: namespace e2e-tests-container-probe-kcgmv deletion completed in 6.100701364s

• [SLOW TEST:24.241 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:42:53.268: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-cf73d383-f8ac-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 16:42:53.367: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cf749416-f8ac-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-projected-qqwbg" to be "success or failure"
Dec  5 16:42:53.375: INFO: Pod "pod-projected-configmaps-cf749416-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 7.779025ms
Dec  5 16:42:55.379: INFO: Pod "pod-projected-configmaps-cf749416-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011371825s
STEP: Saw pod success
Dec  5 16:42:55.379: INFO: Pod "pod-projected-configmaps-cf749416-f8ac-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:42:55.383: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-projected-configmaps-cf749416-f8ac-11e8-a7f8-ceaf58ef2674 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 16:42:55.415: INFO: Waiting for pod pod-projected-configmaps-cf749416-f8ac-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:42:55.419: INFO: Pod pod-projected-configmaps-cf749416-f8ac-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:42:55.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qqwbg" for this suite.
Dec  5 16:43:01.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:43:01.453: INFO: namespace: e2e-tests-projected-qqwbg, resource: bindings, ignored listing per whitelist
Dec  5 16:43:01.540: INFO: namespace e2e-tests-projected-qqwbg deletion completed in 6.117381649s

• [SLOW TEST:8.272 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:43:01.543: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wlvj9
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-wlvj9
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-wlvj9
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-wlvj9
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-wlvj9
Dec  5 16:43:05.676: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wlvj9, name: ss-0, uid: d6cccf5a-f8ac-11e8-ab6c-06b570ab0412, status phase: Pending. Waiting for statefulset controller to delete.
Dec  5 16:43:06.249: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wlvj9, name: ss-0, uid: d6cccf5a-f8ac-11e8-ab6c-06b570ab0412, status phase: Failed. Waiting for statefulset controller to delete.
Dec  5 16:43:06.257: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wlvj9, name: ss-0, uid: d6cccf5a-f8ac-11e8-ab6c-06b570ab0412, status phase: Failed. Waiting for statefulset controller to delete.
Dec  5 16:43:06.262: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-wlvj9
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-wlvj9
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-wlvj9 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 16:43:10.314: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wlvj9
Dec  5 16:43:10.316: INFO: Scaling statefulset ss to 0
Dec  5 16:43:30.341: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 16:43:30.343: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:43:30.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wlvj9" for this suite.
Dec  5 16:43:36.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:43:36.417: INFO: namespace: e2e-tests-statefulset-wlvj9, resource: bindings, ignored listing per whitelist
Dec  5 16:43:36.444: INFO: namespace e2e-tests-statefulset-wlvj9 deletion completed in 6.084552371s

• [SLOW TEST:34.902 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:43:36.446: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1205 16:43:46.622895      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 16:43:46.622: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:43:46.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bkzfw" for this suite.
Dec  5 16:43:52.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:43:52.682: INFO: namespace: e2e-tests-gc-bkzfw, resource: bindings, ignored listing per whitelist
Dec  5 16:43:52.739: INFO: namespace e2e-tests-gc-bkzfw deletion completed in 6.114363457s

• [SLOW TEST:16.293 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:43:52.740: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec  5 16:43:52.821: INFO: Waiting up to 5m0s for pod "client-containers-f2e711c3-f8ac-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-containers-hv42w" to be "success or failure"
Dec  5 16:43:52.835: INFO: Pod "client-containers-f2e711c3-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 14.047722ms
Dec  5 16:43:54.840: INFO: Pod "client-containers-f2e711c3-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019382868s
STEP: Saw pod success
Dec  5 16:43:54.840: INFO: Pod "client-containers-f2e711c3-f8ac-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:43:54.842: INFO: Trying to get logs from node ip-10-0-40-84 pod client-containers-f2e711c3-f8ac-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:43:54.864: INFO: Waiting for pod client-containers-f2e711c3-f8ac-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:43:54.868: INFO: Pod client-containers-f2e711c3-f8ac-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:43:54.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-hv42w" for this suite.
Dec  5 16:44:00.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:44:00.919: INFO: namespace: e2e-tests-containers-hv42w, resource: bindings, ignored listing per whitelist
Dec  5 16:44:00.970: INFO: namespace e2e-tests-containers-hv42w deletion completed in 6.094275268s

• [SLOW TEST:8.230 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:44:00.971: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 16:44:01.043: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f7ce05c2-f8ac-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-downward-api-zhpkt" to be "success or failure"
Dec  5 16:44:01.052: INFO: Pod "downwardapi-volume-f7ce05c2-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 9.647062ms
Dec  5 16:44:03.056: INFO: Pod "downwardapi-volume-f7ce05c2-f8ac-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013032627s
STEP: Saw pod success
Dec  5 16:44:03.056: INFO: Pod "downwardapi-volume-f7ce05c2-f8ac-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:44:03.058: INFO: Trying to get logs from node ip-10-0-40-84 pod downwardapi-volume-f7ce05c2-f8ac-11e8-a7f8-ceaf58ef2674 container client-container: <nil>
STEP: delete the pod
Dec  5 16:44:03.079: INFO: Waiting for pod downwardapi-volume-f7ce05c2-f8ac-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:44:03.082: INFO: Pod downwardapi-volume-f7ce05c2-f8ac-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:44:03.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zhpkt" for this suite.
Dec  5 16:44:09.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:44:09.123: INFO: namespace: e2e-tests-downward-api-zhpkt, resource: bindings, ignored listing per whitelist
Dec  5 16:44:09.168: INFO: namespace e2e-tests-downward-api-zhpkt deletion completed in 6.083636692s

• [SLOW TEST:8.197 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:44:09.169: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Dec  5 16:44:09.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-9954h'
Dec  5 16:44:09.689: INFO: stderr: ""
Dec  5 16:44:09.689: INFO: stdout: "pod/pause created\n"
Dec  5 16:44:09.690: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  5 16:44:09.690: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-9954h" to be "running and ready"
Dec  5 16:44:09.701: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.549591ms
Dec  5 16:44:11.704: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.0148414s
Dec  5 16:44:11.704: INFO: Pod "pause" satisfied condition "running and ready"
Dec  5 16:44:11.704: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  5 16:44:11.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-9954h'
Dec  5 16:44:11.797: INFO: stderr: ""
Dec  5 16:44:11.797: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  5 16:44:11.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pod pause -L testing-label --namespace=e2e-tests-kubectl-9954h'
Dec  5 16:44:11.880: INFO: stderr: ""
Dec  5 16:44:11.880: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  5 16:44:11.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 label pods pause testing-label- --namespace=e2e-tests-kubectl-9954h'
Dec  5 16:44:11.970: INFO: stderr: ""
Dec  5 16:44:11.970: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  5 16:44:11.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pod pause -L testing-label --namespace=e2e-tests-kubectl-9954h'
Dec  5 16:44:12.051: INFO: stderr: ""
Dec  5 16:44:12.051: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Dec  5 16:44:12.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9954h'
Dec  5 16:44:12.146: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 16:44:12.146: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  5 16:44:12.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-9954h'
Dec  5 16:44:12.250: INFO: stderr: "No resources found.\n"
Dec  5 16:44:12.250: INFO: stdout: ""
Dec  5 16:44:12.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 get pods -l name=pause --namespace=e2e-tests-kubectl-9954h -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 16:44:12.336: INFO: stderr: ""
Dec  5 16:44:12.336: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:44:12.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9954h" for this suite.
Dec  5 16:44:18.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:44:18.387: INFO: namespace: e2e-tests-kubectl-9954h, resource: bindings, ignored listing per whitelist
Dec  5 16:44:18.436: INFO: namespace e2e-tests-kubectl-9954h deletion completed in 6.096494793s

• [SLOW TEST:9.267 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:44:18.438: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:44:20.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-8kmx5" for this suite.
Dec  5 16:45:02.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:45:02.579: INFO: namespace: e2e-tests-kubelet-test-8kmx5, resource: bindings, ignored listing per whitelist
Dec  5 16:45:02.638: INFO: namespace e2e-tests-kubelet-test-8kmx5 deletion completed in 42.095601638s

• [SLOW TEST:44.200 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:45:02.639: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-1c918938-f8ad-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume secrets
Dec  5 16:45:02.725: INFO: Waiting up to 5m0s for pod "pod-secrets-1c9232fc-f8ad-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-secrets-b795l" to be "success or failure"
Dec  5 16:45:02.734: INFO: Pod "pod-secrets-1c9232fc-f8ad-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 9.539185ms
Dec  5 16:45:04.738: INFO: Pod "pod-secrets-1c9232fc-f8ad-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012880544s
STEP: Saw pod success
Dec  5 16:45:04.738: INFO: Pod "pod-secrets-1c9232fc-f8ad-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:45:04.740: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-secrets-1c9232fc-f8ad-11e8-a7f8-ceaf58ef2674 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 16:45:04.760: INFO: Waiting for pod pod-secrets-1c9232fc-f8ad-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:45:04.762: INFO: Pod pod-secrets-1c9232fc-f8ad-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:45:04.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-b795l" for this suite.
Dec  5 16:45:10.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:45:10.857: INFO: namespace: e2e-tests-secrets-b795l, resource: bindings, ignored listing per whitelist
Dec  5 16:45:10.867: INFO: namespace e2e-tests-secrets-b795l deletion completed in 6.10157988s

• [SLOW TEST:8.228 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:45:10.868: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec  5 16:45:10.968: INFO: Waiting up to 5m0s for pod "client-containers-217a3783-f8ad-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-containers-6qwpr" to be "success or failure"
Dec  5 16:45:10.980: INFO: Pod "client-containers-217a3783-f8ad-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 11.231519ms
Dec  5 16:45:12.985: INFO: Pod "client-containers-217a3783-f8ad-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01670296s
STEP: Saw pod success
Dec  5 16:45:12.985: INFO: Pod "client-containers-217a3783-f8ad-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:45:12.987: INFO: Trying to get logs from node ip-10-0-40-84 pod client-containers-217a3783-f8ad-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:45:13.005: INFO: Waiting for pod client-containers-217a3783-f8ad-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:45:13.009: INFO: Pod client-containers-217a3783-f8ad-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:45:13.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6qwpr" for this suite.
Dec  5 16:45:19.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:45:19.051: INFO: namespace: e2e-tests-containers-6qwpr, resource: bindings, ignored listing per whitelist
Dec  5 16:45:19.117: INFO: namespace e2e-tests-containers-6qwpr deletion completed in 6.105719661s

• [SLOW TEST:8.250 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:45:19.119: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 16:45:19.211: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:45:19.214: INFO: Number of nodes with available pods: 0
Dec  5 16:45:19.214: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:45:20.218: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:45:20.220: INFO: Number of nodes with available pods: 0
Dec  5 16:45:20.220: INFO: Node ip-10-0-12-134 is running more than one daemon pod
Dec  5 16:45:21.218: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:45:21.221: INFO: Number of nodes with available pods: 2
Dec  5 16:45:21.221: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  5 16:45:21.247: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:45:21.261: INFO: Number of nodes with available pods: 1
Dec  5 16:45:21.261: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:45:22.265: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:45:22.267: INFO: Number of nodes with available pods: 1
Dec  5 16:45:22.267: INFO: Node ip-10-0-40-84 is running more than one daemon pod
Dec  5 16:45:23.265: INFO: DaemonSet pods can't tolerate node ip-10-0-11-227 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  5 16:45:23.267: INFO: Number of nodes with available pods: 2
Dec  5 16:45:23.268: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-vm2pg, will wait for the garbage collector to delete the pods
Dec  5 16:45:23.332: INFO: Deleting DaemonSet.extensions daemon-set took: 8.616961ms
Dec  5 16:45:23.432: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.264457ms
Dec  5 16:45:57.335: INFO: Number of nodes with available pods: 0
Dec  5 16:45:57.335: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 16:45:57.338: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vm2pg/daemonsets","resourceVersion":"68865"},"items":null}

Dec  5 16:45:57.340: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vm2pg/pods","resourceVersion":"68865"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:45:57.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vm2pg" for this suite.
Dec  5 16:46:03.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:46:03.394: INFO: namespace: e2e-tests-daemonsets-vm2pg, resource: bindings, ignored listing per whitelist
Dec  5 16:46:03.449: INFO: namespace e2e-tests-daemonsets-vm2pg deletion completed in 6.101006489s

• [SLOW TEST:44.330 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:46:03.451: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-hm4cz
Dec  5 16:46:05.541: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-hm4cz
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 16:46:05.544: INFO: Initial restart count of pod liveness-http is 0
Dec  5 16:46:17.568: INFO: Restart count of pod e2e-tests-container-probe-hm4cz/liveness-http is now 1 (12.023984225s elapsed)
Dec  5 16:46:39.605: INFO: Restart count of pod e2e-tests-container-probe-hm4cz/liveness-http is now 2 (34.061326575s elapsed)
Dec  5 16:46:59.642: INFO: Restart count of pod e2e-tests-container-probe-hm4cz/liveness-http is now 3 (54.097698992s elapsed)
Dec  5 16:47:19.681: INFO: Restart count of pod e2e-tests-container-probe-hm4cz/liveness-http is now 4 (1m14.136528182s elapsed)
Dec  5 16:48:25.826: INFO: Restart count of pod e2e-tests-container-probe-hm4cz/liveness-http is now 5 (2m20.28206625s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:48:25.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hm4cz" for this suite.
Dec  5 16:48:31.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:48:31.891: INFO: namespace: e2e-tests-container-probe-hm4cz, resource: bindings, ignored listing per whitelist
Dec  5 16:48:31.929: INFO: namespace e2e-tests-container-probe-hm4cz deletion completed in 6.085357447s

• [SLOW TEST:148.478 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:48:31.930: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 16:48:31.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-8ffls'
Dec  5 16:48:32.089: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 16:48:32.089: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Dec  5 16:48:36.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-8ffls'
Dec  5 16:48:36.204: INFO: stderr: ""
Dec  5 16:48:36.204: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:48:36.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8ffls" for this suite.
Dec  5 16:48:42.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:48:42.251: INFO: namespace: e2e-tests-kubectl-8ffls, resource: bindings, ignored listing per whitelist
Dec  5 16:48:42.311: INFO: namespace e2e-tests-kubectl-8ffls deletion completed in 6.100046853s

• [SLOW TEST:10.381 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:48:42.313: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-9f7fe675-f8ad-11e8-a7f8-ceaf58ef2674
STEP: Creating a pod to test consume configMaps
Dec  5 16:48:42.391: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f8076d8-f8ad-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-configmap-hrwrt" to be "success or failure"
Dec  5 16:48:42.400: INFO: Pod "pod-configmaps-9f8076d8-f8ad-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 9.290406ms
Dec  5 16:48:44.404: INFO: Pod "pod-configmaps-9f8076d8-f8ad-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012674954s
STEP: Saw pod success
Dec  5 16:48:44.404: INFO: Pod "pod-configmaps-9f8076d8-f8ad-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:48:44.406: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-configmaps-9f8076d8-f8ad-11e8-a7f8-ceaf58ef2674 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 16:48:44.423: INFO: Waiting for pod pod-configmaps-9f8076d8-f8ad-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:48:44.427: INFO: Pod pod-configmaps-9f8076d8-f8ad-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:48:44.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hrwrt" for this suite.
Dec  5 16:48:50.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:48:50.518: INFO: namespace: e2e-tests-configmap-hrwrt, resource: bindings, ignored listing per whitelist
Dec  5 16:48:50.520: INFO: namespace e2e-tests-configmap-hrwrt deletion completed in 6.088467823s

• [SLOW TEST:8.207 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:48:50.521: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  5 16:48:50.587: INFO: Waiting up to 5m0s for pod "pod-a46334b7-f8ad-11e8-a7f8-ceaf58ef2674" in namespace "e2e-tests-emptydir-h5qq5" to be "success or failure"
Dec  5 16:48:50.591: INFO: Pod "pod-a46334b7-f8ad-11e8-a7f8-ceaf58ef2674": Phase="Pending", Reason="", readiness=false. Elapsed: 3.682207ms
Dec  5 16:48:52.594: INFO: Pod "pod-a46334b7-f8ad-11e8-a7f8-ceaf58ef2674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007202557s
STEP: Saw pod success
Dec  5 16:48:52.594: INFO: Pod "pod-a46334b7-f8ad-11e8-a7f8-ceaf58ef2674" satisfied condition "success or failure"
Dec  5 16:48:52.596: INFO: Trying to get logs from node ip-10-0-40-84 pod pod-a46334b7-f8ad-11e8-a7f8-ceaf58ef2674 container test-container: <nil>
STEP: delete the pod
Dec  5 16:48:52.616: INFO: Waiting for pod pod-a46334b7-f8ad-11e8-a7f8-ceaf58ef2674 to disappear
Dec  5 16:48:52.619: INFO: Pod pod-a46334b7-f8ad-11e8-a7f8-ceaf58ef2674 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:48:52.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h5qq5" for this suite.
Dec  5 16:48:58.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:48:58.683: INFO: namespace: e2e-tests-emptydir-h5qq5, resource: bindings, ignored listing per whitelist
Dec  5 16:48:58.704: INFO: namespace e2e-tests-emptydir-h5qq5 deletion completed in 6.083565731s

• [SLOW TEST:8.183 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:48:58.706: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 16:48:58.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 version --client'
Dec  5 16:48:58.838: INFO: stderr: ""
Dec  5 16:48:58.838: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  5 16:48:58.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-zpbnj'
Dec  5 16:48:59.026: INFO: stderr: ""
Dec  5 16:48:59.026: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  5 16:48:59.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 create -f - --namespace=e2e-tests-kubectl-zpbnj'
Dec  5 16:48:59.213: INFO: stderr: ""
Dec  5 16:48:59.213: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 16:49:00.217: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 16:49:00.217: INFO: Found 0 / 1
Dec  5 16:49:01.217: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 16:49:01.217: INFO: Found 1 / 1
Dec  5 16:49:01.217: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 16:49:01.219: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 16:49:01.219: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 16:49:01.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 describe pod redis-master-6bfdd --namespace=e2e-tests-kubectl-zpbnj'
Dec  5 16:49:01.315: INFO: stderr: ""
Dec  5 16:49:01.315: INFO: stdout: "Name:               redis-master-6bfdd\nNamespace:          e2e-tests-kubectl-zpbnj\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-0-40-84/10.0.40.84\nStart Time:         Wed, 05 Dec 2018 16:48:59 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.2.0.234/32\nStatus:             Running\nIP:                 10.2.0.234\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://393f973fb4598409e91a0290b773c7d84ec3d60c7dd5d2a6c5469e79c4a4d16f\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 05 Dec 2018 16:48:59 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-kjwh4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-kjwh4:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-kjwh4\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  2s    default-scheduler       Successfully assigned e2e-tests-kubectl-zpbnj/redis-master-6bfdd to ip-10-0-40-84\n  Normal  Pulled     2s    kubelet, ip-10-0-40-84  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-10-0-40-84  Created container\n  Normal  Started    2s    kubelet, ip-10-0-40-84  Started container\n"
Dec  5 16:49:01.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 describe rc redis-master --namespace=e2e-tests-kubectl-zpbnj'
Dec  5 16:49:01.420: INFO: stderr: ""
Dec  5 16:49:01.421: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-zpbnj\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-6bfdd\n"
Dec  5 16:49:01.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 describe service redis-master --namespace=e2e-tests-kubectl-zpbnj'
Dec  5 16:49:01.513: INFO: stderr: ""
Dec  5 16:49:01.513: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-zpbnj\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.3.156.137\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.2.0.234:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  5 16:49:01.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 describe node ip-10-0-11-227'
Dec  5 16:49:01.624: INFO: stderr: ""
Dec  5 16:49:01.624: INFO: stdout: "Name:               ip-10-0-11-227\nRoles:              controller,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=ip-10-0-11-227\n                    node-role.kubernetes.io/controller=true\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.11.227/20\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 05 Dec 2018 05:33:51 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 05 Dec 2018 16:48:57 +0000   Wed, 05 Dec 2018 05:33:51 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 05 Dec 2018 16:48:57 +0000   Wed, 05 Dec 2018 05:33:51 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 05 Dec 2018 16:48:57 +0000   Wed, 05 Dec 2018 05:33:51 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 05 Dec 2018 16:48:57 +0000   Wed, 05 Dec 2018 05:34:22 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.11.227\n  Hostname:    ip-10-0-11-227\nCapacity:\n cpu:                1\n ephemeral-storage:  17897500Ki\n hugepages-2Mi:      0\n memory:             2041788Ki\n pods:               110\nAllocatable:\n cpu:                1\n ephemeral-storage:  16494335973\n hugepages-2Mi:      0\n memory:             1939388Ki\n pods:               110\nSystem Info:\n Machine ID:                 21992c8e8b734f18b8ef3e97eadead4b\n System UUID:                EC233E09-5D27-8C26-A382-1733592AB14A\n Boot ID:                    5e5cf77e-95d2-4b22-9a8c-b3e23b81e118\n Kernel Version:             4.14.81-coreos\n OS Image:                   Container Linux by CoreOS 1911.4.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.0\n Kube-Proxy Version:         v1.13.0\nPodCIDR:                     10.2.2.0/24\nNon-terminated Pods:         (12 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-6778acf1ee8d4b8d-69ltp    0 (0%)        0 (0%)      0 (0%)           0 (0%)         87m\n  kube-system                calico-node-vq49d                                          250m (25%)    0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                coredns-5f6984c766-lrpnt                                   100m (10%)    0 (0%)      70Mi (3%)        170Mi (8%)     11h\n  kube-system                coredns-5f6984c766-x6khv                                   100m (10%)    0 (0%)      70Mi (3%)        170Mi (8%)     11h\n  kube-system                kube-apiserver-f6f7m                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                kube-controller-manager-6b765d9bd4-gx6n9                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                kube-controller-manager-6b765d9bd4-z9vms                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                kube-proxy-mflsm                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                kube-scheduler-65b7f4789d-9pn46                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                kube-scheduler-65b7f4789d-wv4b7                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                pod-checkpointer-cbn9p                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                pod-checkpointer-cbn9p-ip-10-0-11-227                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                450m (45%)  0 (0%)\n  memory             140Mi (7%)  340Mi (17%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Dec  5 16:49:01.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-292959027 describe namespace e2e-tests-kubectl-zpbnj'
Dec  5 16:49:01.717: INFO: stderr: ""
Dec  5 16:49:01.717: INFO: stdout: "Name:         e2e-tests-kubectl-zpbnj\nLabels:       e2e-framework=kubectl\n              e2e-run=8644b6e4-f8a1-11e8-a7f8-ceaf58ef2674\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:49:01.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zpbnj" for this suite.
Dec  5 16:49:23.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:49:23.783: INFO: namespace: e2e-tests-kubectl-zpbnj, resource: bindings, ignored listing per whitelist
Dec  5 16:49:23.802: INFO: namespace e2e-tests-kubectl-zpbnj deletion completed in 22.082097217s

• [SLOW TEST:25.097 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 16:49:23.804: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4ldn9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 16:49:23.867: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 16:49:41.941: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.0.236:8080/dial?request=hostName&protocol=udp&host=10.2.1.99&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-4ldn9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 16:49:41.941: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 16:49:42.046: INFO: Waiting for endpoints: map[]
Dec  5 16:49:42.049: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.0.236:8080/dial?request=hostName&protocol=udp&host=10.2.0.235&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-4ldn9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 16:49:42.049: INFO: >>> kubeConfig: /tmp/kubeconfig-292959027
Dec  5 16:49:42.136: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 16:49:42.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4ldn9" for this suite.
Dec  5 16:50:04.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 16:50:04.205: INFO: namespace: e2e-tests-pod-network-test-4ldn9, resource: bindings, ignored listing per whitelist
Dec  5 16:50:04.274: INFO: namespace e2e-tests-pod-network-test-4ldn9 deletion completed in 22.134567871s

• [SLOW TEST:40.470 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSDec  5 16:50:04.276: INFO: Running AfterSuite actions on all nodes
Dec  5 16:50:04.277: INFO: Running AfterSuite actions on node 1
Dec  5 16:50:04.277: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5276.451 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h27m58.318522728s
Test Suite Passed
