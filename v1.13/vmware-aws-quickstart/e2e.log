I0227 01:56:14.555689      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-861261599
I0227 01:56:14.555853      15 e2e.go:224] Starting e2e run "dcb10cbd-3a32-11e9-8c03-2a4c52047ee8" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1551232573 - Will randomize all specs
Will run 201 of 1946 specs

Feb 27 01:56:15.160: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 01:56:15.164: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 27 01:56:15.175: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 27 01:56:15.198: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 27 01:56:15.198: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Feb 27 01:56:15.198: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 27 01:56:15.204: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'calico-etcd' (0 seconds elapsed)
Feb 27 01:56:15.204: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 27 01:56:15.204: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 27 01:56:15.204: INFO: e2e test version: v1.13.0
Feb 27 01:56:15.205: INFO: kube-apiserver version: v1.13.2
SSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:56:15.205: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
Feb 27 01:56:15.271: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 01:56:15.279: INFO: Waiting up to 5m0s for pod "downward-api-dda306fa-3a32-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-t6xd6" to be "success or failure"
Feb 27 01:56:15.294: INFO: Pod "downward-api-dda306fa-3a32-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.8692ms
Feb 27 01:56:17.296: INFO: Pod "downward-api-dda306fa-3a32-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017236927s
Feb 27 01:56:19.299: INFO: Pod "downward-api-dda306fa-3a32-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02014726s
Feb 27 01:56:21.301: INFO: Pod "downward-api-dda306fa-3a32-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022243373s
STEP: Saw pod success
Feb 27 01:56:21.301: INFO: Pod "downward-api-dda306fa-3a32-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 01:56:21.303: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod downward-api-dda306fa-3a32-11e9-8c03-2a4c52047ee8 container dapi-container: <nil>
STEP: delete the pod
Feb 27 01:56:21.327: INFO: Waiting for pod downward-api-dda306fa-3a32-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 01:56:21.332: INFO: Pod downward-api-dda306fa-3a32-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:56:21.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t6xd6" for this suite.
Feb 27 01:56:27.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:56:27.364: INFO: namespace: e2e-tests-downward-api-t6xd6, resource: bindings, ignored listing per whitelist
Feb 27 01:56:27.406: INFO: namespace e2e-tests-downward-api-t6xd6 deletion completed in 6.070219079s

• [SLOW TEST:12.200 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:56:27.406: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-e4e7b504-3a32-11e9-8c03-2a4c52047ee8
STEP: Creating secret with name s-test-opt-upd-e4e7b54d-3a32-11e9-8c03-2a4c52047ee8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e4e7b504-3a32-11e9-8c03-2a4c52047ee8
STEP: Updating secret s-test-opt-upd-e4e7b54d-3a32-11e9-8c03-2a4c52047ee8
STEP: Creating secret with name s-test-opt-create-e4e7b56b-3a32-11e9-8c03-2a4c52047ee8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:57:41.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n6nhc" for this suite.
Feb 27 01:58:03.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:58:03.888: INFO: namespace: e2e-tests-projected-n6nhc, resource: bindings, ignored listing per whitelist
Feb 27 01:58:03.888: INFO: namespace e2e-tests-projected-n6nhc deletion completed in 22.066653558s

• [SLOW TEST:96.482 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:58:03.888: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 01:58:03.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-2cqvr'
Feb 27 01:58:04.602: INFO: stderr: ""
Feb 27 01:58:04.602: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 27 01:58:14.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-2cqvr -o json'
Feb 27 01:58:14.800: INFO: stderr: ""
Feb 27 01:58:14.800: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-02-27T01:58:04Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-2cqvr\",\n        \"resourceVersion\": \"4608\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-2cqvr/pods/e2e-test-nginx-pod\",\n        \"uid\": \"1ec8e34d-3a33-11e9-8378-02ce1f9c2c90\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-wtbf7\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-30-134.us-west-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-wtbf7\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-wtbf7\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T01:58:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T01:58:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T01:58:09Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T01:58:04Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://152f3a87e149a53bc2a0423faa826b11f4f02fa5bc174808170f68a0cf58d570\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-27T01:58:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.30.134\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.48.197\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-27T01:58:04Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 27 01:58:14.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 replace -f - --namespace=e2e-tests-kubectl-2cqvr'
Feb 27 01:58:15.019: INFO: stderr: ""
Feb 27 01:58:15.019: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb 27 01:58:15.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-2cqvr'
Feb 27 01:58:16.965: INFO: stderr: ""
Feb 27 01:58:16.966: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:58:16.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2cqvr" for this suite.
Feb 27 01:58:22.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:58:22.994: INFO: namespace: e2e-tests-kubectl-2cqvr, resource: bindings, ignored listing per whitelist
Feb 27 01:58:23.053: INFO: namespace e2e-tests-kubectl-2cqvr deletion completed in 6.080865509s

• [SLOW TEST:19.165 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:58:23.054: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:58:23.118: INFO: Creating ReplicaSet my-hostname-basic-29d68ccb-3a33-11e9-8c03-2a4c52047ee8
Feb 27 01:58:23.136: INFO: Pod name my-hostname-basic-29d68ccb-3a33-11e9-8c03-2a4c52047ee8: Found 0 pods out of 1
Feb 27 01:58:28.140: INFO: Pod name my-hostname-basic-29d68ccb-3a33-11e9-8c03-2a4c52047ee8: Found 1 pods out of 1
Feb 27 01:58:28.140: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-29d68ccb-3a33-11e9-8c03-2a4c52047ee8" is running
Feb 27 01:58:28.142: INFO: Pod "my-hostname-basic-29d68ccb-3a33-11e9-8c03-2a4c52047ee8-n5mlf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:58:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:58:27 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:58:27 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:58:23 +0000 UTC Reason: Message:}])
Feb 27 01:58:28.142: INFO: Trying to dial the pod
Feb 27 01:58:33.150: INFO: Controller my-hostname-basic-29d68ccb-3a33-11e9-8c03-2a4c52047ee8: Got expected result from replica 1 [my-hostname-basic-29d68ccb-3a33-11e9-8c03-2a4c52047ee8-n5mlf]: "my-hostname-basic-29d68ccb-3a33-11e9-8c03-2a4c52047ee8-n5mlf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:58:33.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-v6wdq" for this suite.
Feb 27 01:58:39.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:58:39.206: INFO: namespace: e2e-tests-replicaset-v6wdq, resource: bindings, ignored listing per whitelist
Feb 27 01:58:39.224: INFO: namespace e2e-tests-replicaset-v6wdq deletion completed in 6.072036888s

• [SLOW TEST:16.170 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:58:39.224: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-6lzj
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 01:58:39.294: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6lzj" in namespace "e2e-tests-subpath-r622s" to be "success or failure"
Feb 27 01:58:39.296: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.389152ms
Feb 27 01:58:41.300: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006013555s
Feb 27 01:58:43.303: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Running", Reason="", readiness=false. Elapsed: 4.00900252s
Feb 27 01:58:45.306: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Running", Reason="", readiness=false. Elapsed: 6.012127304s
Feb 27 01:58:47.309: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Running", Reason="", readiness=false. Elapsed: 8.015102459s
Feb 27 01:58:49.312: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Running", Reason="", readiness=false. Elapsed: 10.018343605s
Feb 27 01:58:51.318: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Running", Reason="", readiness=false. Elapsed: 12.02455664s
Feb 27 01:58:53.321: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Running", Reason="", readiness=false. Elapsed: 14.027242309s
Feb 27 01:58:55.325: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Running", Reason="", readiness=false. Elapsed: 16.031466037s
Feb 27 01:58:57.328: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Running", Reason="", readiness=false. Elapsed: 18.034139572s
Feb 27 01:58:59.331: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Running", Reason="", readiness=false. Elapsed: 20.036993844s
Feb 27 01:59:01.334: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Running", Reason="", readiness=false. Elapsed: 22.040050797s
Feb 27 01:59:03.337: INFO: Pod "pod-subpath-test-configmap-6lzj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.043021554s
STEP: Saw pod success
Feb 27 01:59:03.337: INFO: Pod "pod-subpath-test-configmap-6lzj" satisfied condition "success or failure"
Feb 27 01:59:03.338: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-subpath-test-configmap-6lzj container test-container-subpath-configmap-6lzj: <nil>
STEP: delete the pod
Feb 27 01:59:03.352: INFO: Waiting for pod pod-subpath-test-configmap-6lzj to disappear
Feb 27 01:59:03.359: INFO: Pod pod-subpath-test-configmap-6lzj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6lzj
Feb 27 01:59:03.359: INFO: Deleting pod "pod-subpath-test-configmap-6lzj" in namespace "e2e-tests-subpath-r622s"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:59:03.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-r622s" for this suite.
Feb 27 01:59:09.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:59:09.393: INFO: namespace: e2e-tests-subpath-r622s, resource: bindings, ignored listing per whitelist
Feb 27 01:59:09.433: INFO: namespace e2e-tests-subpath-r622s deletion completed in 6.069085931s

• [SLOW TEST:30.209 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:59:09.434: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 27 01:59:09.497: INFO: Waiting up to 5m0s for pod "pod-457aaff5-3a33-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-vctzn" to be "success or failure"
Feb 27 01:59:09.500: INFO: Pod "pod-457aaff5-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.132506ms
Feb 27 01:59:11.504: INFO: Pod "pod-457aaff5-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006581079s
Feb 27 01:59:13.507: INFO: Pod "pod-457aaff5-3a33-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010400117s
STEP: Saw pod success
Feb 27 01:59:13.507: INFO: Pod "pod-457aaff5-3a33-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 01:59:13.509: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-457aaff5-3a33-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 01:59:13.525: INFO: Waiting for pod pod-457aaff5-3a33-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 01:59:13.527: INFO: Pod pod-457aaff5-3a33-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:59:13.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vctzn" for this suite.
Feb 27 01:59:19.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:59:19.595: INFO: namespace: e2e-tests-emptydir-vctzn, resource: bindings, ignored listing per whitelist
Feb 27 01:59:19.603: INFO: namespace e2e-tests-emptydir-vctzn deletion completed in 6.073479925s

• [SLOW TEST:10.170 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:59:19.603: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 27 01:59:19.671: INFO: Waiting up to 5m0s for pod "client-containers-4b8b36f7-3a33-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-containers-ccfdf" to be "success or failure"
Feb 27 01:59:19.676: INFO: Pod "client-containers-4b8b36f7-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.138813ms
Feb 27 01:59:21.679: INFO: Pod "client-containers-4b8b36f7-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008150419s
Feb 27 01:59:23.682: INFO: Pod "client-containers-4b8b36f7-3a33-11e9-8c03-2a4c52047ee8": Phase="Running", Reason="", readiness=true. Elapsed: 4.010852998s
Feb 27 01:59:25.685: INFO: Pod "client-containers-4b8b36f7-3a33-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014073318s
STEP: Saw pod success
Feb 27 01:59:25.685: INFO: Pod "client-containers-4b8b36f7-3a33-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 01:59:25.687: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod client-containers-4b8b36f7-3a33-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 01:59:25.702: INFO: Waiting for pod client-containers-4b8b36f7-3a33-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 01:59:25.710: INFO: Pod client-containers-4b8b36f7-3a33-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:59:25.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-ccfdf" for this suite.
Feb 27 01:59:31.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:59:31.744: INFO: namespace: e2e-tests-containers-ccfdf, resource: bindings, ignored listing per whitelist
Feb 27 01:59:31.786: INFO: namespace e2e-tests-containers-ccfdf deletion completed in 6.07411035s

• [SLOW TEST:12.183 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:59:31.786: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:59:31.859: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 27 01:59:31.865: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:31.868: INFO: Number of nodes with available pods: 0
Feb 27 01:59:31.868: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 01:59:32.872: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:32.874: INFO: Number of nodes with available pods: 0
Feb 27 01:59:32.874: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 01:59:33.871: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:33.873: INFO: Number of nodes with available pods: 0
Feb 27 01:59:33.873: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 01:59:34.871: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:34.873: INFO: Number of nodes with available pods: 1
Feb 27 01:59:34.873: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 01:59:35.872: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:35.874: INFO: Number of nodes with available pods: 1
Feb 27 01:59:35.874: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 01:59:36.871: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:36.874: INFO: Number of nodes with available pods: 2
Feb 27 01:59:36.874: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 27 01:59:36.891: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:36.891: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:36.894: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:37.898: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:37.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:37.901: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:38.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:38.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:38.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:39.899: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:39.899: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:39.902: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:40.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:40.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:40.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:41.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:41.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:41.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:42.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:42.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:42.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:43.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:43.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:43.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:44.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:44.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:44.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:45.898: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:45.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:45.901: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:46.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:46.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:46.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:47.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:47.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:47.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:48.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:48.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:48.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:49.898: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:49.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:49.901: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:50.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:50.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:50.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:51.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:51.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:51.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:52.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:52.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:52.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:53.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:53.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:53.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:54.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:54.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:54.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:55.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:55.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:55.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:56.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:56.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:56.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:57.898: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:57.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:57.901: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:58.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:58.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:58.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:59:59.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:59.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 01:59:59.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:00.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:00.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:00.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:01.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:01.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:01.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:02.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:02.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:02.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:03.898: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:03.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:03.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:04.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:04.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:04.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:05.898: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:05.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:05.901: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:06.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:06.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:06.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:07.898: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:07.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:07.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:08.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:08.897: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:08.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:08.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:09.898: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:09.898: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:09.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:09.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:10.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:10.897: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:10.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:10.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:11.901: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:11.901: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:11.901: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:11.903: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:12.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:12.897: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:12.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:12.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:13.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:13.897: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:13.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:13.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:14.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:14.897: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:14.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:14.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:15.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:15.897: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:15.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:15.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:16.898: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:16.898: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:16.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:16.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:17.905: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:17.905: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:17.905: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:17.911: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:18.897: INFO: Wrong image for pod: daemon-set-7qrcn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:18.897: INFO: Pod daemon-set-7qrcn is not available
Feb 27 02:00:18.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:18.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:19.898: INFO: Pod daemon-set-8h78k is not available
Feb 27 02:00:19.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:19.902: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:20.897: INFO: Pod daemon-set-8h78k is not available
Feb 27 02:00:20.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:20.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:21.897: INFO: Pod daemon-set-8h78k is not available
Feb 27 02:00:21.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:21.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:22.898: INFO: Pod daemon-set-8h78k is not available
Feb 27 02:00:22.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:22.902: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:23.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:23.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:24.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:24.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:25.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:25.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:26.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:26.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:27.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:27.901: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:28.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:28.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:29.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:29.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:30.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:30.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:31.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:31.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:32.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:32.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:33.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:33.901: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:34.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:34.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:35.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:35.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:36.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:36.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:37.899: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:37.902: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:38.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:38.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:39.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:39.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:40.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:40.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:41.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:41.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:42.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:42.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:43.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:43.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:44.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:44.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:45.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:45.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:46.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:46.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:47.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:47.901: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:48.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:48.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:49.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:49.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:50.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:50.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:51.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:51.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:52.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:52.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:53.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:53.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:54.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:54.897: INFO: Pod daemon-set-crzfm is not available
Feb 27 02:00:54.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:55.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:55.898: INFO: Pod daemon-set-crzfm is not available
Feb 27 02:00:55.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:56.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:56.897: INFO: Pod daemon-set-crzfm is not available
Feb 27 02:00:56.899: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:57.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:57.898: INFO: Pod daemon-set-crzfm is not available
Feb 27 02:00:57.901: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:58.897: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:58.897: INFO: Pod daemon-set-crzfm is not available
Feb 27 02:00:58.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:00:59.898: INFO: Wrong image for pod: daemon-set-crzfm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:00:59.898: INFO: Pod daemon-set-crzfm is not available
Feb 27 02:00:59.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:01:00.897: INFO: Pod daemon-set-228tm is not available
Feb 27 02:01:00.900: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 27 02:01:00.902: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:01:00.904: INFO: Number of nodes with available pods: 1
Feb 27 02:01:00.904: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:01:01.907: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:01:01.909: INFO: Number of nodes with available pods: 1
Feb 27 02:01:01.909: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:01:02.909: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:01:02.911: INFO: Number of nodes with available pods: 1
Feb 27 02:01:02.911: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:01:03.907: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:01:03.909: INFO: Number of nodes with available pods: 2
Feb 27 02:01:03.909: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-p9xt7, will wait for the garbage collector to delete the pods
Feb 27 02:01:03.975: INFO: Deleting DaemonSet.extensions daemon-set took: 4.206841ms
Feb 27 02:01:04.075: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.220682ms
Feb 27 02:01:10.277: INFO: Number of nodes with available pods: 0
Feb 27 02:01:10.277: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 02:01:10.279: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-p9xt7/daemonsets","resourceVersion":"5094"},"items":null}

Feb 27 02:01:10.281: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-p9xt7/pods","resourceVersion":"5094"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:01:10.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-p9xt7" for this suite.
Feb 27 02:01:16.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:01:16.356: INFO: namespace: e2e-tests-daemonsets-p9xt7, resource: bindings, ignored listing per whitelist
Feb 27 02:01:16.359: INFO: namespace e2e-tests-daemonsets-p9xt7 deletion completed in 6.070517632s

• [SLOW TEST:104.573 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:01:16.359: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-hcxq
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 02:01:16.430: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-hcxq" in namespace "e2e-tests-subpath-q76bb" to be "success or failure"
Feb 27 02:01:16.432: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.631908ms
Feb 27 02:01:18.435: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005362382s
Feb 27 02:01:20.438: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Running", Reason="", readiness=false. Elapsed: 4.008299547s
Feb 27 02:01:22.441: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Running", Reason="", readiness=false. Elapsed: 6.01118628s
Feb 27 02:01:24.447: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Running", Reason="", readiness=false. Elapsed: 8.017431345s
Feb 27 02:01:26.450: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Running", Reason="", readiness=false. Elapsed: 10.02030451s
Feb 27 02:01:28.453: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Running", Reason="", readiness=false. Elapsed: 12.02329032s
Feb 27 02:01:30.456: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Running", Reason="", readiness=false. Elapsed: 14.026485656s
Feb 27 02:01:32.459: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Running", Reason="", readiness=false. Elapsed: 16.029428015s
Feb 27 02:01:34.462: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Running", Reason="", readiness=false. Elapsed: 18.031911913s
Feb 27 02:01:36.465: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Running", Reason="", readiness=false. Elapsed: 20.035161414s
Feb 27 02:01:38.468: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Running", Reason="", readiness=false. Elapsed: 22.038532395s
Feb 27 02:01:40.472: INFO: Pod "pod-subpath-test-projected-hcxq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.042641034s
STEP: Saw pod success
Feb 27 02:01:40.472: INFO: Pod "pod-subpath-test-projected-hcxq" satisfied condition "success or failure"
Feb 27 02:01:40.474: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-subpath-test-projected-hcxq container test-container-subpath-projected-hcxq: <nil>
STEP: delete the pod
Feb 27 02:01:40.498: INFO: Waiting for pod pod-subpath-test-projected-hcxq to disappear
Feb 27 02:01:40.504: INFO: Pod pod-subpath-test-projected-hcxq no longer exists
STEP: Deleting pod pod-subpath-test-projected-hcxq
Feb 27 02:01:40.504: INFO: Deleting pod "pod-subpath-test-projected-hcxq" in namespace "e2e-tests-subpath-q76bb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:01:40.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-q76bb" for this suite.
Feb 27 02:01:46.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:01:46.549: INFO: namespace: e2e-tests-subpath-q76bb, resource: bindings, ignored listing per whitelist
Feb 27 02:01:46.576: INFO: namespace e2e-tests-subpath-q76bb deletion completed in 6.066967819s

• [SLOW TEST:30.216 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:01:46.576: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 27 02:01:46.642: INFO: Waiting up to 5m0s for pod "client-containers-a323fd6c-3a33-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-containers-n4gbx" to be "success or failure"
Feb 27 02:01:46.647: INFO: Pod "client-containers-a323fd6c-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.146248ms
Feb 27 02:01:48.650: INFO: Pod "client-containers-a323fd6c-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007321525s
Feb 27 02:01:50.652: INFO: Pod "client-containers-a323fd6c-3a33-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010011504s
STEP: Saw pod success
Feb 27 02:01:50.653: INFO: Pod "client-containers-a323fd6c-3a33-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:01:50.655: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod client-containers-a323fd6c-3a33-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 02:01:50.669: INFO: Waiting for pod client-containers-a323fd6c-3a33-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:01:50.676: INFO: Pod client-containers-a323fd6c-3a33-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:01:50.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-n4gbx" for this suite.
Feb 27 02:01:56.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:01:56.734: INFO: namespace: e2e-tests-containers-n4gbx, resource: bindings, ignored listing per whitelist
Feb 27 02:01:56.751: INFO: namespace e2e-tests-containers-n4gbx deletion completed in 6.073401279s

• [SLOW TEST:10.176 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:01:56.752: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 27 02:01:56.819: INFO: Waiting up to 5m0s for pod "pod-a935f769-3a33-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-vz2hs" to be "success or failure"
Feb 27 02:01:56.822: INFO: Pod "pod-a935f769-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.358611ms
Feb 27 02:01:58.825: INFO: Pod "pod-a935f769-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006448452s
Feb 27 02:02:00.828: INFO: Pod "pod-a935f769-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00935536s
Feb 27 02:02:02.831: INFO: Pod "pod-a935f769-3a33-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012418743s
STEP: Saw pod success
Feb 27 02:02:02.831: INFO: Pod "pod-a935f769-3a33-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:02:02.833: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-a935f769-3a33-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 02:02:02.845: INFO: Waiting for pod pod-a935f769-3a33-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:02:02.849: INFO: Pod pod-a935f769-3a33-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:02:02.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vz2hs" for this suite.
Feb 27 02:02:08.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:02:08.872: INFO: namespace: e2e-tests-emptydir-vz2hs, resource: bindings, ignored listing per whitelist
Feb 27 02:02:08.919: INFO: namespace e2e-tests-emptydir-vz2hs deletion completed in 6.065988761s

• [SLOW TEST:12.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:02:08.920: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 27 02:02:08.983: INFO: Waiting up to 5m0s for pod "pod-b075820a-3a33-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-zg4sf" to be "success or failure"
Feb 27 02:02:08.986: INFO: Pod "pod-b075820a-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.661802ms
Feb 27 02:02:10.989: INFO: Pod "pod-b075820a-3a33-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005597674s
Feb 27 02:02:12.992: INFO: Pod "pod-b075820a-3a33-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008369768s
STEP: Saw pod success
Feb 27 02:02:12.992: INFO: Pod "pod-b075820a-3a33-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:02:12.994: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-b075820a-3a33-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 02:02:13.008: INFO: Waiting for pod pod-b075820a-3a33-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:02:13.014: INFO: Pod pod-b075820a-3a33-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:02:13.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zg4sf" for this suite.
Feb 27 02:02:19.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:02:19.037: INFO: namespace: e2e-tests-emptydir-zg4sf, resource: bindings, ignored listing per whitelist
Feb 27 02:02:19.082: INFO: namespace e2e-tests-emptydir-zg4sf deletion completed in 6.0652797s

• [SLOW TEST:10.162 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:02:19.082: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-ckcnf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ckcnf to expose endpoints map[]
Feb 27 02:02:19.169: INFO: Get endpoints failed (10.669567ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 27 02:02:20.171: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ckcnf exposes endpoints map[] (1.012926016s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-ckcnf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ckcnf to expose endpoints map[pod1:[100]]
Feb 27 02:02:23.204: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ckcnf exposes endpoints map[pod1:[100]] (3.027897691s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-ckcnf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ckcnf to expose endpoints map[pod1:[100] pod2:[101]]
Feb 27 02:02:26.238: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ckcnf exposes endpoints map[pod1:[100] pod2:[101]] (3.029678404s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-ckcnf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ckcnf to expose endpoints map[pod2:[101]]
Feb 27 02:02:26.256: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ckcnf exposes endpoints map[pod2:[101]] (13.013811ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-ckcnf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ckcnf to expose endpoints map[]
Feb 27 02:02:27.268: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ckcnf exposes endpoints map[] (1.006123025s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:02:27.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ckcnf" for this suite.
Feb 27 02:02:49.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:02:49.341: INFO: namespace: e2e-tests-services-ckcnf, resource: bindings, ignored listing per whitelist
Feb 27 02:02:49.374: INFO: namespace e2e-tests-services-ckcnf deletion completed in 22.070239674s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:30.292 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:02:49.374: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 27 02:02:49.430: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 27 02:02:49.440: INFO: Waiting for terminating namespaces to be deleted...
Feb 27 02:02:49.441: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-12-40.us-west-2.compute.internal before test
Feb 27 02:02:49.445: INFO: kube-proxy-xm2xq from kube-system started at 2019-02-27 01:17:19 +0000 UTC (1 container statuses recorded)
Feb 27 02:02:49.445: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 02:02:49.445: INFO: calico-node-9nn2r from kube-system started at 2019-02-27 01:17:19 +0000 UTC (2 container statuses recorded)
Feb 27 02:02:49.445: INFO: 	Container calico-node ready: true, restart count 2
Feb 27 02:02:49.445: INFO: 	Container install-cni ready: true, restart count 0
Feb 27 02:02:49.445: INFO: sonobuoy-e2e-job-bcc306d9d27f4dc9 from heptio-sonobuoy started at 2019-02-27 01:55:41 +0000 UTC (2 container statuses recorded)
Feb 27 02:02:49.445: INFO: 	Container e2e ready: true, restart count 0
Feb 27 02:02:49.445: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 02:02:49.445: INFO: sonobuoy-systemd-logs-daemon-set-d41f01fb14fe49b8-gwcvp from heptio-sonobuoy started at 2019-02-27 01:55:41 +0000 UTC (2 container statuses recorded)
Feb 27 02:02:49.445: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 27 02:02:49.445: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 02:02:49.445: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-30-134.us-west-2.compute.internal before test
Feb 27 02:02:49.449: INFO: kube-proxy-wxzzd from kube-system started at 2019-02-27 01:17:20 +0000 UTC (1 container statuses recorded)
Feb 27 02:02:49.449: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 02:02:49.449: INFO: calico-node-wv2cm from kube-system started at 2019-02-27 01:17:20 +0000 UTC (2 container statuses recorded)
Feb 27 02:02:49.449: INFO: 	Container calico-node ready: true, restart count 1
Feb 27 02:02:49.450: INFO: 	Container install-cni ready: true, restart count 0
Feb 27 02:02:49.450: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-27 01:55:39 +0000 UTC (1 container statuses recorded)
Feb 27 02:02:49.450: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 27 02:02:49.450: INFO: sonobuoy-systemd-logs-daemon-set-d41f01fb14fe49b8-rs7fp from heptio-sonobuoy started at 2019-02-27 01:55:41 +0000 UTC (2 container statuses recorded)
Feb 27 02:02:49.450: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 27 02:02:49.450: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1587162abcaec871], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:02:50.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5tbsp" for this suite.
Feb 27 02:02:56.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:02:56.505: INFO: namespace: e2e-tests-sched-pred-5tbsp, resource: bindings, ignored listing per whitelist
Feb 27 02:02:56.545: INFO: namespace e2e-tests-sched-pred-5tbsp deletion completed in 6.076833233s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.171 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:02:56.545: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-wr6qr
Feb 27 02:03:00.606: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-wr6qr
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 02:03:00.607: INFO: Initial restart count of pod liveness-http is 0
Feb 27 02:03:22.650: INFO: Restart count of pod e2e-tests-container-probe-wr6qr/liveness-http is now 1 (22.043069471s elapsed)
Feb 27 02:03:40.676: INFO: Restart count of pod e2e-tests-container-probe-wr6qr/liveness-http is now 2 (40.06909298s elapsed)
Feb 27 02:04:00.705: INFO: Restart count of pod e2e-tests-container-probe-wr6qr/liveness-http is now 3 (1m0.09773017s elapsed)
Feb 27 02:04:20.737: INFO: Restart count of pod e2e-tests-container-probe-wr6qr/liveness-http is now 4 (1m20.129987762s elapsed)
Feb 27 02:04:40.765: INFO: Restart count of pod e2e-tests-container-probe-wr6qr/liveness-http is now 5 (1m40.158080632s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:04:40.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wr6qr" for this suite.
Feb 27 02:04:46.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:04:46.836: INFO: namespace: e2e-tests-container-probe-wr6qr, resource: bindings, ignored listing per whitelist
Feb 27 02:04:46.846: INFO: namespace e2e-tests-container-probe-wr6qr deletion completed in 6.065834963s

• [SLOW TEST:110.300 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:04:46.846: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 27 02:04:46.913: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:46.915: INFO: Number of nodes with available pods: 0
Feb 27 02:04:46.915: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:47.921: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:47.923: INFO: Number of nodes with available pods: 0
Feb 27 02:04:47.923: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:48.919: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:48.921: INFO: Number of nodes with available pods: 0
Feb 27 02:04:48.921: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:49.920: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:49.922: INFO: Number of nodes with available pods: 2
Feb 27 02:04:49.922: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 27 02:04:49.937: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:49.940: INFO: Number of nodes with available pods: 1
Feb 27 02:04:49.940: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:50.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:50.945: INFO: Number of nodes with available pods: 1
Feb 27 02:04:50.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:51.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:51.945: INFO: Number of nodes with available pods: 1
Feb 27 02:04:51.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:52.944: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:52.946: INFO: Number of nodes with available pods: 1
Feb 27 02:04:52.946: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:53.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:53.945: INFO: Number of nodes with available pods: 1
Feb 27 02:04:53.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:54.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:54.945: INFO: Number of nodes with available pods: 1
Feb 27 02:04:54.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:55.944: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:55.947: INFO: Number of nodes with available pods: 1
Feb 27 02:04:55.947: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:56.945: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:56.949: INFO: Number of nodes with available pods: 1
Feb 27 02:04:56.949: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:57.944: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:57.946: INFO: Number of nodes with available pods: 1
Feb 27 02:04:57.946: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:58.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:58.945: INFO: Number of nodes with available pods: 1
Feb 27 02:04:58.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:04:59.944: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:04:59.947: INFO: Number of nodes with available pods: 1
Feb 27 02:04:59.947: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:00.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:00.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:00.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:01.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:01.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:01.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:02.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:02.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:02.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:03.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:03.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:03.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:04.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:04.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:04.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:05.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:05.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:05.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:06.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:06.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:06.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:07.944: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:07.947: INFO: Number of nodes with available pods: 1
Feb 27 02:05:07.947: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:08.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:08.946: INFO: Number of nodes with available pods: 1
Feb 27 02:05:08.946: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:09.944: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:09.946: INFO: Number of nodes with available pods: 1
Feb 27 02:05:09.946: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:10.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:10.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:10.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:11.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:11.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:11.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:12.942: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:12.944: INFO: Number of nodes with available pods: 1
Feb 27 02:05:12.944: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:13.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:13.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:13.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:14.942: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:14.944: INFO: Number of nodes with available pods: 1
Feb 27 02:05:14.944: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:15.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:15.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:15.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:16.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:16.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:16.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:17.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:17.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:17.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:18.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:18.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:18.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:19.944: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:19.946: INFO: Number of nodes with available pods: 1
Feb 27 02:05:19.946: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:20.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:20.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:20.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:21.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:21.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:21.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:22.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:22.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:22.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:23.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:23.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:23.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:24.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:24.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:24.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:25.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:25.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:25.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:26.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:26.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:26.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:27.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:27.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:27.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:28.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:28.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:28.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:29.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:29.952: INFO: Number of nodes with available pods: 1
Feb 27 02:05:29.952: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:30.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:30.944: INFO: Number of nodes with available pods: 1
Feb 27 02:05:30.944: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:31.943: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:31.945: INFO: Number of nodes with available pods: 1
Feb 27 02:05:31.945: INFO: Node ip-10-0-30-134.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:05:32.942: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:05:32.945: INFO: Number of nodes with available pods: 2
Feb 27 02:05:32.945: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-wvhqd, will wait for the garbage collector to delete the pods
Feb 27 02:05:33.003: INFO: Deleting DaemonSet.extensions daemon-set took: 4.636849ms
Feb 27 02:05:33.104: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.23493ms
Feb 27 02:06:06.606: INFO: Number of nodes with available pods: 0
Feb 27 02:06:06.606: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 02:06:06.607: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-wvhqd/daemonsets","resourceVersion":"5839"},"items":null}

Feb 27 02:06:06.609: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-wvhqd/pods","resourceVersion":"5839"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:06:06.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-wvhqd" for this suite.
Feb 27 02:06:12.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:06:12.684: INFO: namespace: e2e-tests-daemonsets-wvhqd, resource: bindings, ignored listing per whitelist
Feb 27 02:06:12.692: INFO: namespace e2e-tests-daemonsets-wvhqd deletion completed in 6.07490959s

• [SLOW TEST:85.846 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:06:12.692: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-pg4v
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 02:06:12.764: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pg4v" in namespace "e2e-tests-subpath-7cwpl" to be "success or failure"
Feb 27 02:06:12.767: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Pending", Reason="", readiness=false. Elapsed: 3.354408ms
Feb 27 02:06:14.769: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005575881s
Feb 27 02:06:16.771: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Running", Reason="", readiness=false. Elapsed: 4.007834298s
Feb 27 02:06:18.774: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Running", Reason="", readiness=false. Elapsed: 6.010797101s
Feb 27 02:06:20.777: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Running", Reason="", readiness=false. Elapsed: 8.013829427s
Feb 27 02:06:22.781: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Running", Reason="", readiness=false. Elapsed: 10.017001212s
Feb 27 02:06:24.783: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Running", Reason="", readiness=false. Elapsed: 12.019602257s
Feb 27 02:06:26.786: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Running", Reason="", readiness=false. Elapsed: 14.022105834s
Feb 27 02:06:28.788: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Running", Reason="", readiness=false. Elapsed: 16.024659348s
Feb 27 02:06:30.791: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Running", Reason="", readiness=false. Elapsed: 18.027160466s
Feb 27 02:06:32.793: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Running", Reason="", readiness=false. Elapsed: 20.029592338s
Feb 27 02:06:34.796: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Running", Reason="", readiness=false. Elapsed: 22.032432653s
Feb 27 02:06:36.800: INFO: Pod "pod-subpath-test-configmap-pg4v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.036007187s
STEP: Saw pod success
Feb 27 02:06:36.800: INFO: Pod "pod-subpath-test-configmap-pg4v" satisfied condition "success or failure"
Feb 27 02:06:36.801: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-subpath-test-configmap-pg4v container test-container-subpath-configmap-pg4v: <nil>
STEP: delete the pod
Feb 27 02:06:36.816: INFO: Waiting for pod pod-subpath-test-configmap-pg4v to disappear
Feb 27 02:06:36.822: INFO: Pod pod-subpath-test-configmap-pg4v no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pg4v
Feb 27 02:06:36.822: INFO: Deleting pod "pod-subpath-test-configmap-pg4v" in namespace "e2e-tests-subpath-7cwpl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:06:36.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7cwpl" for this suite.
Feb 27 02:06:42.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:06:42.859: INFO: namespace: e2e-tests-subpath-7cwpl, resource: bindings, ignored listing per whitelist
Feb 27 02:06:42.895: INFO: namespace e2e-tests-subpath-7cwpl deletion completed in 6.068866143s

• [SLOW TEST:30.204 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:06:42.896: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-53c2a67a-3a34-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 02:06:42.961: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-53c30ba4-3a34-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-xmbt4" to be "success or failure"
Feb 27 02:06:42.964: INFO: Pod "pod-projected-configmaps-53c30ba4-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.745647ms
Feb 27 02:06:44.966: INFO: Pod "pod-projected-configmaps-53c30ba4-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00518717s
Feb 27 02:06:46.969: INFO: Pod "pod-projected-configmaps-53c30ba4-3a34-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007826206s
STEP: Saw pod success
Feb 27 02:06:46.969: INFO: Pod "pod-projected-configmaps-53c30ba4-3a34-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:06:46.971: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-projected-configmaps-53c30ba4-3a34-11e9-8c03-2a4c52047ee8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:06:46.987: INFO: Waiting for pod pod-projected-configmaps-53c30ba4-3a34-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:06:46.993: INFO: Pod pod-projected-configmaps-53c30ba4-3a34-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:06:46.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xmbt4" for this suite.
Feb 27 02:06:53.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:06:53.018: INFO: namespace: e2e-tests-projected-xmbt4, resource: bindings, ignored listing per whitelist
Feb 27 02:06:53.067: INFO: namespace e2e-tests-projected-xmbt4 deletion completed in 6.072363059s

• [SLOW TEST:10.171 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:06:53.068: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-59d63769-3a34-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 02:06:53.153: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-59d72aac-3a34-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-2628j" to be "success or failure"
Feb 27 02:06:53.157: INFO: Pod "pod-projected-configmaps-59d72aac-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.580061ms
Feb 27 02:06:55.159: INFO: Pod "pod-projected-configmaps-59d72aac-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006356036s
Feb 27 02:06:57.162: INFO: Pod "pod-projected-configmaps-59d72aac-3a34-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009251447s
STEP: Saw pod success
Feb 27 02:06:57.162: INFO: Pod "pod-projected-configmaps-59d72aac-3a34-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:06:57.164: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-projected-configmaps-59d72aac-3a34-11e9-8c03-2a4c52047ee8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:06:57.179: INFO: Waiting for pod pod-projected-configmaps-59d72aac-3a34-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:06:57.181: INFO: Pod pod-projected-configmaps-59d72aac-3a34-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:06:57.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2628j" for this suite.
Feb 27 02:07:03.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:07:03.224: INFO: namespace: e2e-tests-projected-2628j, resource: bindings, ignored listing per whitelist
Feb 27 02:07:03.255: INFO: namespace e2e-tests-projected-2628j deletion completed in 6.071113623s

• [SLOW TEST:10.187 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:07:03.255: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5fe6ba8e-3a34-11e9-8c03-2a4c52047ee8
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5fe6ba8e-3a34-11e9-8c03-2a4c52047ee8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:08:27.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fr5xc" for this suite.
Feb 27 02:08:49.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:08:49.761: INFO: namespace: e2e-tests-projected-fr5xc, resource: bindings, ignored listing per whitelist
Feb 27 02:08:49.795: INFO: namespace e2e-tests-projected-fr5xc deletion completed in 22.101766596s

• [SLOW TEST:106.540 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:08:49.796: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 27 02:08:49.904: INFO: Waiting up to 5m0s for pod "client-containers-9f6c4ec1-3a34-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-containers-h8llq" to be "success or failure"
Feb 27 02:08:49.907: INFO: Pod "client-containers-9f6c4ec1-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.591917ms
Feb 27 02:08:51.910: INFO: Pod "client-containers-9f6c4ec1-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005967412s
Feb 27 02:08:53.917: INFO: Pod "client-containers-9f6c4ec1-3a34-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013441978s
STEP: Saw pod success
Feb 27 02:08:53.917: INFO: Pod "client-containers-9f6c4ec1-3a34-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:08:53.920: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod client-containers-9f6c4ec1-3a34-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 02:08:53.944: INFO: Waiting for pod client-containers-9f6c4ec1-3a34-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:08:53.947: INFO: Pod client-containers-9f6c4ec1-3a34-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:08:53.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-h8llq" for this suite.
Feb 27 02:08:59.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:09:00.023: INFO: namespace: e2e-tests-containers-h8llq, resource: bindings, ignored listing per whitelist
Feb 27 02:09:00.040: INFO: namespace e2e-tests-containers-h8llq deletion completed in 6.091173214s

• [SLOW TEST:10.244 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:09:00.041: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-a5820c22-3a34-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 02:09:00.109: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a5830d8a-3a34-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-pzrxd" to be "success or failure"
Feb 27 02:09:00.112: INFO: Pod "pod-projected-configmaps-a5830d8a-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.765851ms
Feb 27 02:09:02.115: INFO: Pod "pod-projected-configmaps-a5830d8a-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005801272s
Feb 27 02:09:04.118: INFO: Pod "pod-projected-configmaps-a5830d8a-3a34-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008399734s
STEP: Saw pod success
Feb 27 02:09:04.118: INFO: Pod "pod-projected-configmaps-a5830d8a-3a34-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:09:04.120: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-projected-configmaps-a5830d8a-3a34-11e9-8c03-2a4c52047ee8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:09:04.135: INFO: Waiting for pod pod-projected-configmaps-a5830d8a-3a34-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:09:04.139: INFO: Pod pod-projected-configmaps-a5830d8a-3a34-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:09:04.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pzrxd" for this suite.
Feb 27 02:09:10.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:09:10.186: INFO: namespace: e2e-tests-projected-pzrxd, resource: bindings, ignored listing per whitelist
Feb 27 02:09:10.210: INFO: namespace e2e-tests-projected-pzrxd deletion completed in 6.068179361s

• [SLOW TEST:10.169 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:09:10.210: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-ab917cc5-3a34-11e9-8c03-2a4c52047ee8
STEP: Creating secret with name secret-projected-all-test-volume-ab917ca2-3a34-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 27 02:09:10.279: INFO: Waiting up to 5m0s for pod "projected-volume-ab917c5a-3a34-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-4g5sp" to be "success or failure"
Feb 27 02:09:10.282: INFO: Pod "projected-volume-ab917c5a-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.292731ms
Feb 27 02:09:12.285: INFO: Pod "projected-volume-ab917c5a-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005901858s
Feb 27 02:09:14.288: INFO: Pod "projected-volume-ab917c5a-3a34-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008914188s
STEP: Saw pod success
Feb 27 02:09:14.288: INFO: Pod "projected-volume-ab917c5a-3a34-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:09:14.290: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod projected-volume-ab917c5a-3a34-11e9-8c03-2a4c52047ee8 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 27 02:09:14.303: INFO: Waiting for pod projected-volume-ab917c5a-3a34-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:09:14.305: INFO: Pod projected-volume-ab917c5a-3a34-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:09:14.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4g5sp" for this suite.
Feb 27 02:09:20.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:09:20.365: INFO: namespace: e2e-tests-projected-4g5sp, resource: bindings, ignored listing per whitelist
Feb 27 02:09:20.385: INFO: namespace e2e-tests-projected-4g5sp deletion completed in 6.077528442s

• [SLOW TEST:10.175 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:09:20.385: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 02:09:20.453: INFO: Waiting up to 5m0s for pod "downward-api-b1a267c7-3a34-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-msszn" to be "success or failure"
Feb 27 02:09:20.461: INFO: Pod "downward-api-b1a267c7-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.867113ms
Feb 27 02:09:22.464: INFO: Pod "downward-api-b1a267c7-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009983126s
Feb 27 02:09:24.467: INFO: Pod "downward-api-b1a267c7-3a34-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013269426s
Feb 27 02:09:26.470: INFO: Pod "downward-api-b1a267c7-3a34-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01615077s
STEP: Saw pod success
Feb 27 02:09:26.470: INFO: Pod "downward-api-b1a267c7-3a34-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:09:26.471: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downward-api-b1a267c7-3a34-11e9-8c03-2a4c52047ee8 container dapi-container: <nil>
STEP: delete the pod
Feb 27 02:09:26.485: INFO: Waiting for pod downward-api-b1a267c7-3a34-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:09:26.492: INFO: Pod downward-api-b1a267c7-3a34-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:09:26.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-msszn" for this suite.
Feb 27 02:09:32.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:09:32.538: INFO: namespace: e2e-tests-downward-api-msszn, resource: bindings, ignored listing per whitelist
Feb 27 02:09:32.560: INFO: namespace e2e-tests-downward-api-msszn deletion completed in 6.065419746s

• [SLOW TEST:12.175 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:09:32.560: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:09:32.627: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 27 02:09:37.631: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 27 02:09:37.631: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 27 02:09:39.633: INFO: Creating deployment "test-rollover-deployment"
Feb 27 02:09:39.640: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 27 02:09:41.645: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 27 02:09:41.649: INFO: Ensure that both replica sets have 1 created replica
Feb 27 02:09:41.652: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 27 02:09:41.657: INFO: Updating deployment test-rollover-deployment
Feb 27 02:09:41.657: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 27 02:09:43.662: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 27 02:09:43.666: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 27 02:09:43.670: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:09:43.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830181, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:09:45.675: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:09:45.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830183, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:09:47.676: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:09:47.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830183, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:09:49.675: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:09:49.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830183, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:09:51.675: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:09:51.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830183, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:09:53.675: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:09:53.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830183, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830179, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:09:55.675: INFO: 
Feb 27 02:09:55.675: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 02:09:55.680: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-j25l2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j25l2/deployments/test-rollover-deployment,UID:bd12a6bf-3a34-11e9-8378-02ce1f9c2c90,ResourceVersion:6480,Generation:2,CreationTimestamp:2019-02-27 02:09:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-27 02:09:39 +0000 UTC 2019-02-27 02:09:39 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-27 02:09:53 +0000 UTC 2019-02-27 02:09:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 27 02:09:55.682: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-j25l2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j25l2/replicasets/test-rollover-deployment-6b7f9d6597,UID:be47941b-3a34-11e9-8378-02ce1f9c2c90,ResourceVersion:6471,Generation:2,CreationTimestamp:2019-02-27 02:09:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bd12a6bf-3a34-11e9-8378-02ce1f9c2c90 0xc0019aa627 0xc0019aa628}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 27 02:09:55.683: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 27 02:09:55.683: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-j25l2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j25l2/replicasets/test-rollover-controller,UID:b8e3e595-3a34-11e9-8378-02ce1f9c2c90,ResourceVersion:6479,Generation:2,CreationTimestamp:2019-02-27 02:09:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bd12a6bf-3a34-11e9-8378-02ce1f9c2c90 0xc0019aa49f 0xc0019aa4b0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 02:09:55.683: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-j25l2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j25l2/replicasets/test-rollover-deployment-6586df867b,UID:bd1537b5-3a34-11e9-8378-02ce1f9c2c90,ResourceVersion:6440,Generation:2,CreationTimestamp:2019-02-27 02:09:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bd12a6bf-3a34-11e9-8378-02ce1f9c2c90 0xc0019aa567 0xc0019aa568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 02:09:55.685: INFO: Pod "test-rollover-deployment-6b7f9d6597-29pht" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-29pht,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-j25l2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j25l2/pods/test-rollover-deployment-6b7f9d6597-29pht,UID:be4d2bd9-3a34-11e9-8378-02ce1f9c2c90,ResourceVersion:6454,Generation:0,CreationTimestamp:2019-02-27 02:09:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 be47941b-3a34-11e9-8378-02ce1f9c2c90 0xc0019ab137 0xc0019ab138}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-824jx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-824jx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-824jx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019ab1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019ab1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:09:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:09:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:09:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:09:41 +0000 UTC  }],Message:,Reason:,HostIP:10.0.30.134,PodIP:192.168.48.214,StartTime:2019-02-27 02:09:41 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-27 02:09:43 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://f6c6d403a0cf0eb55b1ef6cb47c7adac2818286843be78082a662c5fb36df070}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:09:55.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-j25l2" for this suite.
Feb 27 02:10:01.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:10:01.744: INFO: namespace: e2e-tests-deployment-j25l2, resource: bindings, ignored listing per whitelist
Feb 27 02:10:01.754: INFO: namespace e2e-tests-deployment-j25l2 deletion completed in 6.067057555s

• [SLOW TEST:29.195 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:10:01.755: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 02:10:01.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-hhqrw'
Feb 27 02:10:02.465: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 02:10:02.465: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb 27 02:10:04.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-hhqrw'
Feb 27 02:10:04.679: INFO: stderr: ""
Feb 27 02:10:04.679: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:10:04.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hhqrw" for this suite.
Feb 27 02:10:36.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:10:36.710: INFO: namespace: e2e-tests-kubectl-hhqrw, resource: bindings, ignored listing per whitelist
Feb 27 02:10:36.752: INFO: namespace e2e-tests-kubectl-hhqrw deletion completed in 32.069833139s

• [SLOW TEST:34.997 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:10:36.752: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb 27 02:10:36.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-rdll2'
Feb 27 02:10:36.968: INFO: stderr: ""
Feb 27 02:10:36.968: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 27 02:10:37.972: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:10:37.972: INFO: Found 0 / 1
Feb 27 02:10:38.971: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:10:38.971: INFO: Found 0 / 1
Feb 27 02:10:39.972: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:10:39.972: INFO: Found 1 / 1
Feb 27 02:10:39.972: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 27 02:10:39.974: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:10:39.974: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 27 02:10:39.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 logs redis-master-75x4b redis-master --namespace=e2e-tests-kubectl-rdll2'
Feb 27 02:10:40.057: INFO: stderr: ""
Feb 27 02:10:40.058: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Feb 02:10:38.534 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Feb 02:10:38.534 # Server started, Redis version 3.2.12\n1:M 27 Feb 02:10:38.534 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Feb 02:10:38.534 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 27 02:10:40.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 log redis-master-75x4b redis-master --namespace=e2e-tests-kubectl-rdll2 --tail=1'
Feb 27 02:10:40.138: INFO: stderr: ""
Feb 27 02:10:40.138: INFO: stdout: "1:M 27 Feb 02:10:38.534 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 27 02:10:40.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 log redis-master-75x4b redis-master --namespace=e2e-tests-kubectl-rdll2 --limit-bytes=1'
Feb 27 02:10:40.216: INFO: stderr: ""
Feb 27 02:10:40.216: INFO: stdout: " "
STEP: exposing timestamps
Feb 27 02:10:40.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 log redis-master-75x4b redis-master --namespace=e2e-tests-kubectl-rdll2 --tail=1 --timestamps'
Feb 27 02:10:40.296: INFO: stderr: ""
Feb 27 02:10:40.296: INFO: stdout: "2019-02-27T02:10:38.534571807Z 1:M 27 Feb 02:10:38.534 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 27 02:10:42.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 log redis-master-75x4b redis-master --namespace=e2e-tests-kubectl-rdll2 --since=1s'
Feb 27 02:10:42.880: INFO: stderr: ""
Feb 27 02:10:42.880: INFO: stdout: ""
Feb 27 02:10:42.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 log redis-master-75x4b redis-master --namespace=e2e-tests-kubectl-rdll2 --since=24h'
Feb 27 02:10:42.966: INFO: stderr: ""
Feb 27 02:10:42.966: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Feb 02:10:38.534 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Feb 02:10:38.534 # Server started, Redis version 3.2.12\n1:M 27 Feb 02:10:38.534 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Feb 02:10:38.534 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb 27 02:10:42.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rdll2'
Feb 27 02:10:43.039: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:10:43.039: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 27 02:10:43.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-rdll2'
Feb 27 02:10:43.126: INFO: stderr: "No resources found.\n"
Feb 27 02:10:43.126: INFO: stdout: ""
Feb 27 02:10:43.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -l name=nginx --namespace=e2e-tests-kubectl-rdll2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 02:10:43.196: INFO: stderr: ""
Feb 27 02:10:43.196: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:10:43.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rdll2" for this suite.
Feb 27 02:11:05.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:11:05.215: INFO: namespace: e2e-tests-kubectl-rdll2, resource: bindings, ignored listing per whitelist
Feb 27 02:11:05.307: INFO: namespace e2e-tests-kubectl-rdll2 deletion completed in 22.10834685s

• [SLOW TEST:28.555 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:11:05.307: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-9j2m2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9j2m2 to expose endpoints map[]
Feb 27 02:11:05.460: INFO: Get endpoints failed (38.507366ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 27 02:11:06.463: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9j2m2 exposes endpoints map[] (1.041494888s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-9j2m2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9j2m2 to expose endpoints map[pod1:[80]]
Feb 27 02:11:09.487: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9j2m2 exposes endpoints map[pod1:[80]] (3.01875966s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-9j2m2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9j2m2 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 27 02:11:12.518: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9j2m2 exposes endpoints map[pod1:[80] pod2:[80]] (3.026632138s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-9j2m2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9j2m2 to expose endpoints map[pod2:[80]]
Feb 27 02:11:12.539: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9j2m2 exposes endpoints map[pod2:[80]] (11.450682ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-9j2m2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9j2m2 to expose endpoints map[]
Feb 27 02:11:12.555: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9j2m2 exposes endpoints map[] (10.157529ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:11:12.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9j2m2" for this suite.
Feb 27 02:11:34.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:11:34.661: INFO: namespace: e2e-tests-services-9j2m2, resource: bindings, ignored listing per whitelist
Feb 27 02:11:34.669: INFO: namespace e2e-tests-services-9j2m2 deletion completed in 22.077197554s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.362 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:11:34.670: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 02:11:39.260: INFO: Successfully updated pod "annotationupdate01ad0102-3a35-11e9-8c03-2a4c52047ee8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:11:41.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4vqpc" for this suite.
Feb 27 02:12:03.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:12:03.336: INFO: namespace: e2e-tests-projected-4vqpc, resource: bindings, ignored listing per whitelist
Feb 27 02:12:03.379: INFO: namespace e2e-tests-projected-4vqpc deletion completed in 22.082711376s

• [SLOW TEST:28.710 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:12:03.379: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-12c901f3-3a35-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 02:12:03.446: INFO: Waiting up to 5m0s for pod "pod-secrets-12ca2039-3a35-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-secrets-9nqjg" to be "success or failure"
Feb 27 02:12:03.449: INFO: Pod "pod-secrets-12ca2039-3a35-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.038818ms
Feb 27 02:12:05.455: INFO: Pod "pod-secrets-12ca2039-3a35-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009356036s
Feb 27 02:12:07.458: INFO: Pod "pod-secrets-12ca2039-3a35-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01232352s
STEP: Saw pod success
Feb 27 02:12:07.458: INFO: Pod "pod-secrets-12ca2039-3a35-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:12:07.460: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-secrets-12ca2039-3a35-11e9-8c03-2a4c52047ee8 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:12:07.476: INFO: Waiting for pod pod-secrets-12ca2039-3a35-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:12:07.482: INFO: Pod pod-secrets-12ca2039-3a35-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:12:07.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9nqjg" for this suite.
Feb 27 02:12:13.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:12:13.531: INFO: namespace: e2e-tests-secrets-9nqjg, resource: bindings, ignored listing per whitelist
Feb 27 02:12:13.554: INFO: namespace e2e-tests-secrets-9nqjg deletion completed in 6.069139387s

• [SLOW TEST:10.174 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:12:13.554: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 02:12:13.613: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:12:17.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-2s7x7" for this suite.
Feb 27 02:12:23.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:12:23.172: INFO: namespace: e2e-tests-init-container-2s7x7, resource: bindings, ignored listing per whitelist
Feb 27 02:12:23.220: INFO: namespace e2e-tests-init-container-2s7x7 deletion completed in 6.071342604s

• [SLOW TEST:9.666 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:12:23.220: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:12:23.278: INFO: (0) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.527833ms)
Feb 27 02:12:23.281: INFO: (1) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.432238ms)
Feb 27 02:12:23.283: INFO: (2) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.574244ms)
Feb 27 02:12:23.286: INFO: (3) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.566042ms)
Feb 27 02:12:23.288: INFO: (4) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.430923ms)
Feb 27 02:12:23.291: INFO: (5) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.524885ms)
Feb 27 02:12:23.293: INFO: (6) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.470563ms)
Feb 27 02:12:23.296: INFO: (7) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.414007ms)
Feb 27 02:12:23.298: INFO: (8) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.255302ms)
Feb 27 02:12:23.300: INFO: (9) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.277558ms)
Feb 27 02:12:23.303: INFO: (10) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.322591ms)
Feb 27 02:12:23.305: INFO: (11) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.350604ms)
Feb 27 02:12:23.308: INFO: (12) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.323448ms)
Feb 27 02:12:23.310: INFO: (13) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.405123ms)
Feb 27 02:12:23.312: INFO: (14) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.456128ms)
Feb 27 02:12:23.315: INFO: (15) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.195202ms)
Feb 27 02:12:23.317: INFO: (16) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.307663ms)
Feb 27 02:12:23.319: INFO: (17) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.236796ms)
Feb 27 02:12:23.322: INFO: (18) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.482519ms)
Feb 27 02:12:23.324: INFO: (19) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.370836ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:12:23.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-bj75r" for this suite.
Feb 27 02:12:29.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:12:29.378: INFO: namespace: e2e-tests-proxy-bj75r, resource: bindings, ignored listing per whitelist
Feb 27 02:12:29.393: INFO: namespace e2e-tests-proxy-bj75r deletion completed in 6.066498133s

• [SLOW TEST:6.173 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:12:29.393: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-224a3626-3a35-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 02:12:29.459: INFO: Waiting up to 5m0s for pod "pod-configmaps-224b5763-3a35-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-configmap-8rljx" to be "success or failure"
Feb 27 02:12:29.462: INFO: Pod "pod-configmaps-224b5763-3a35-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.212114ms
Feb 27 02:12:31.465: INFO: Pod "pod-configmaps-224b5763-3a35-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006148531s
Feb 27 02:12:33.468: INFO: Pod "pod-configmaps-224b5763-3a35-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008974324s
STEP: Saw pod success
Feb 27 02:12:33.468: INFO: Pod "pod-configmaps-224b5763-3a35-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:12:33.470: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-configmaps-224b5763-3a35-11e9-8c03-2a4c52047ee8 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:12:33.483: INFO: Waiting for pod pod-configmaps-224b5763-3a35-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:12:33.486: INFO: Pod pod-configmaps-224b5763-3a35-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:12:33.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8rljx" for this suite.
Feb 27 02:12:39.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:12:39.507: INFO: namespace: e2e-tests-configmap-8rljx, resource: bindings, ignored listing per whitelist
Feb 27 02:12:39.554: INFO: namespace e2e-tests-configmap-8rljx deletion completed in 6.065378148s

• [SLOW TEST:10.161 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:12:39.555: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:12:39.619: INFO: Waiting up to 5m0s for pod "downwardapi-volume-28594e66-3a35-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-vvjn8" to be "success or failure"
Feb 27 02:12:39.621: INFO: Pod "downwardapi-volume-28594e66-3a35-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.160646ms
Feb 27 02:12:41.624: INFO: Pod "downwardapi-volume-28594e66-3a35-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004948431s
Feb 27 02:12:43.627: INFO: Pod "downwardapi-volume-28594e66-3a35-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00791746s
STEP: Saw pod success
Feb 27 02:12:43.627: INFO: Pod "downwardapi-volume-28594e66-3a35-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:12:43.629: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod downwardapi-volume-28594e66-3a35-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 02:12:43.642: INFO: Waiting for pod downwardapi-volume-28594e66-3a35-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:12:43.644: INFO: Pod downwardapi-volume-28594e66-3a35-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:12:43.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vvjn8" for this suite.
Feb 27 02:12:49.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:12:49.671: INFO: namespace: e2e-tests-downward-api-vvjn8, resource: bindings, ignored listing per whitelist
Feb 27 02:12:49.715: INFO: namespace e2e-tests-downward-api-vvjn8 deletion completed in 6.068434515s

• [SLOW TEST:10.160 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:12:49.715: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:12:49.793: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 27 02:12:49.810: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 27 02:12:54.813: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 27 02:12:54.813: INFO: Creating deployment "test-rolling-update-deployment"
Feb 27 02:12:54.816: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 27 02:12:54.823: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 27 02:12:56.828: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 27 02:12:56.830: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830374, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830374, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830374, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830374, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:12:58.832: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 02:12:58.838: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-hhshp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hhshp/deployments/test-rolling-update-deployment,UID:31689cff-3a35-11e9-8378-02ce1f9c2c90,ResourceVersion:7085,Generation:1,CreationTimestamp:2019-02-27 02:12:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-27 02:12:54 +0000 UTC 2019-02-27 02:12:54 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-27 02:12:56 +0000 UTC 2019-02-27 02:12:54 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 27 02:12:58.840: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-hhshp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hhshp/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:316b3f40-3a35-11e9-8378-02ce1f9c2c90,ResourceVersion:7076,Generation:1,CreationTimestamp:2019-02-27 02:12:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 31689cff-3a35-11e9-8378-02ce1f9c2c90 0xc001e578f7 0xc001e578f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 27 02:12:58.840: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 27 02:12:58.840: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-hhshp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hhshp/replicasets/test-rolling-update-controller,UID:2e6aa9cb-3a35-11e9-8378-02ce1f9c2c90,ResourceVersion:7084,Generation:2,CreationTimestamp:2019-02-27 02:12:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 31689cff-3a35-11e9-8378-02ce1f9c2c90 0xc001e5777f 0xc001e57790}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 02:12:58.842: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-65x5z" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-65x5z,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-hhshp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hhshp/pods/test-rolling-update-deployment-68b55d7bc6-65x5z,UID:316bb179-3a35-11e9-8378-02ce1f9c2c90,ResourceVersion:7075,Generation:0,CreationTimestamp:2019-02-27 02:12:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 316b3f40-3a35-11e9-8378-02ce1f9c2c90 0xc001ec29d7 0xc001ec29d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dqj77 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dqj77,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-dqj77 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ec2a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ec2a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:12:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:12:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:12:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:12:54 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.40,PodIP:192.168.161.20,StartTime:2019-02-27 02:12:54 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-27 02:12:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c839cf115351d18e767854baf26ec4af0fd6def5fb5d7a258be1f42ffd282e67}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:12:58.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-hhshp" for this suite.
Feb 27 02:13:04.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:13:04.877: INFO: namespace: e2e-tests-deployment-hhshp, resource: bindings, ignored listing per whitelist
Feb 27 02:13:04.915: INFO: namespace e2e-tests-deployment-hhshp deletion completed in 6.070195534s

• [SLOW TEST:15.200 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:13:04.915: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 27 02:13:04.980: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 27 02:13:09.984: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:13:10.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-csj5t" for this suite.
Feb 27 02:13:17.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:13:17.043: INFO: namespace: e2e-tests-replication-controller-csj5t, resource: bindings, ignored listing per whitelist
Feb 27 02:13:17.068: INFO: namespace e2e-tests-replication-controller-csj5t deletion completed in 6.070043955s

• [SLOW TEST:12.153 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:13:17.068: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 27 02:13:27.155: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:27.157: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:29.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:29.160: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:31.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:31.160: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:33.158: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:33.161: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:35.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:35.161: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:37.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:37.160: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:39.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:39.160: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:41.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:41.160: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:43.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:43.160: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:45.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:45.160: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:47.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:47.161: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:49.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:49.160: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 02:13:51.157: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 02:13:51.160: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:13:51.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-d2sxt" for this suite.
Feb 27 02:14:13.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:14:13.226: INFO: namespace: e2e-tests-container-lifecycle-hook-d2sxt, resource: bindings, ignored listing per whitelist
Feb 27 02:14:13.237: INFO: namespace e2e-tests-container-lifecycle-hook-d2sxt deletion completed in 22.068371336s

• [SLOW TEST:56.169 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:14:13.238: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 27 02:14:13.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 cluster-info'
Feb 27 02:14:13.369: INFO: stderr: ""
Feb 27 02:14:13.369: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:14:13.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-crqcj" for this suite.
Feb 27 02:14:19.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:14:19.437: INFO: namespace: e2e-tests-kubectl-crqcj, resource: bindings, ignored listing per whitelist
Feb 27 02:14:19.441: INFO: namespace e2e-tests-kubectl-crqcj deletion completed in 6.069269227s

• [SLOW TEST:6.204 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:14:19.442: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 27 02:14:24.519: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:14:25.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-2kxdl" for this suite.
Feb 27 02:14:47.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:14:47.600: INFO: namespace: e2e-tests-replicaset-2kxdl, resource: bindings, ignored listing per whitelist
Feb 27 02:14:47.607: INFO: namespace e2e-tests-replicaset-2kxdl deletion completed in 22.071393466s

• [SLOW TEST:28.165 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:14:47.607: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 27 02:14:47.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-qcffb'
Feb 27 02:14:47.847: INFO: stderr: ""
Feb 27 02:14:47.847: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 02:14:47.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qcffb'
Feb 27 02:14:47.934: INFO: stderr: ""
Feb 27 02:14:47.934: INFO: stdout: "update-demo-nautilus-ctff6 update-demo-nautilus-v4n4j "
Feb 27 02:14:47.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-ctff6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qcffb'
Feb 27 02:14:48.008: INFO: stderr: ""
Feb 27 02:14:48.008: INFO: stdout: ""
Feb 27 02:14:48.008: INFO: update-demo-nautilus-ctff6 is created but not running
Feb 27 02:14:53.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qcffb'
Feb 27 02:14:53.102: INFO: stderr: ""
Feb 27 02:14:53.102: INFO: stdout: "update-demo-nautilus-ctff6 update-demo-nautilus-v4n4j "
Feb 27 02:14:53.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-ctff6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qcffb'
Feb 27 02:14:53.172: INFO: stderr: ""
Feb 27 02:14:53.172: INFO: stdout: "true"
Feb 27 02:14:53.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-ctff6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qcffb'
Feb 27 02:14:53.241: INFO: stderr: ""
Feb 27 02:14:53.241: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 02:14:53.241: INFO: validating pod update-demo-nautilus-ctff6
Feb 27 02:14:53.244: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 02:14:53.245: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 02:14:53.245: INFO: update-demo-nautilus-ctff6 is verified up and running
Feb 27 02:14:53.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-v4n4j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qcffb'
Feb 27 02:14:53.316: INFO: stderr: ""
Feb 27 02:14:53.316: INFO: stdout: "true"
Feb 27 02:14:53.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-v4n4j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qcffb'
Feb 27 02:14:53.387: INFO: stderr: ""
Feb 27 02:14:53.387: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 02:14:53.387: INFO: validating pod update-demo-nautilus-v4n4j
Feb 27 02:14:53.390: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 02:14:53.390: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 02:14:53.390: INFO: update-demo-nautilus-v4n4j is verified up and running
STEP: using delete to clean up resources
Feb 27 02:14:53.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qcffb'
Feb 27 02:14:53.481: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:14:53.481: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 27 02:14:53.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-qcffb'
Feb 27 02:14:53.581: INFO: stderr: "No resources found.\n"
Feb 27 02:14:53.581: INFO: stdout: ""
Feb 27 02:14:53.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -l name=update-demo --namespace=e2e-tests-kubectl-qcffb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 02:14:53.654: INFO: stderr: ""
Feb 27 02:14:53.654: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:14:53.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qcffb" for this suite.
Feb 27 02:15:15.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:15:15.679: INFO: namespace: e2e-tests-kubectl-qcffb, resource: bindings, ignored listing per whitelist
Feb 27 02:15:15.725: INFO: namespace e2e-tests-kubectl-qcffb deletion completed in 22.067813604s

• [SLOW TEST:28.117 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:15:15.725: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-g8lfs
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 27 02:15:15.804: INFO: Found 0 stateful pods, waiting for 3
Feb 27 02:15:25.808: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:15:25.808: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:15:25.808: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 27 02:15:25.829: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 27 02:15:35.865: INFO: Updating stateful set ss2
Feb 27 02:15:35.870: INFO: Waiting for Pod e2e-tests-statefulset-g8lfs/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 27 02:15:45.957: INFO: Found 2 stateful pods, waiting for 3
Feb 27 02:15:55.960: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:15:55.960: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:15:55.960: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 27 02:15:55.979: INFO: Updating stateful set ss2
Feb 27 02:15:55.985: INFO: Waiting for Pod e2e-tests-statefulset-g8lfs/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 27 02:16:05.990: INFO: Waiting for Pod e2e-tests-statefulset-g8lfs/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 27 02:16:16.008: INFO: Updating stateful set ss2
Feb 27 02:16:16.019: INFO: Waiting for StatefulSet e2e-tests-statefulset-g8lfs/ss2 to complete update
Feb 27 02:16:16.019: INFO: Waiting for Pod e2e-tests-statefulset-g8lfs/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 02:16:26.024: INFO: Deleting all statefulset in ns e2e-tests-statefulset-g8lfs
Feb 27 02:16:26.026: INFO: Scaling statefulset ss2 to 0
Feb 27 02:16:56.038: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:16:56.040: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:16:56.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-g8lfs" for this suite.
Feb 27 02:17:02.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:17:02.136: INFO: namespace: e2e-tests-statefulset-g8lfs, resource: bindings, ignored listing per whitelist
Feb 27 02:17:02.140: INFO: namespace e2e-tests-statefulset-g8lfs deletion completed in 6.078096434s

• [SLOW TEST:106.415 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:17:02.141: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-krlk6/configmap-test-c4dcfbdc-3a35-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 02:17:02.212: INFO: Waiting up to 5m0s for pod "pod-configmaps-c4ddbba1-3a35-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-configmap-krlk6" to be "success or failure"
Feb 27 02:17:02.216: INFO: Pod "pod-configmaps-c4ddbba1-3a35-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.393604ms
Feb 27 02:17:04.219: INFO: Pod "pod-configmaps-c4ddbba1-3a35-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006441163s
Feb 27 02:17:06.222: INFO: Pod "pod-configmaps-c4ddbba1-3a35-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009313218s
STEP: Saw pod success
Feb 27 02:17:06.222: INFO: Pod "pod-configmaps-c4ddbba1-3a35-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:17:06.223: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-configmaps-c4ddbba1-3a35-11e9-8c03-2a4c52047ee8 container env-test: <nil>
STEP: delete the pod
Feb 27 02:17:06.237: INFO: Waiting for pod pod-configmaps-c4ddbba1-3a35-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:17:06.241: INFO: Pod pod-configmaps-c4ddbba1-3a35-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:17:06.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-krlk6" for this suite.
Feb 27 02:17:12.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:17:12.287: INFO: namespace: e2e-tests-configmap-krlk6, resource: bindings, ignored listing per whitelist
Feb 27 02:17:12.313: INFO: namespace e2e-tests-configmap-krlk6 deletion completed in 6.070047423s

• [SLOW TEST:10.173 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:17:12.313: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-bjrzg
Feb 27 02:17:16.383: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-bjrzg
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 02:17:16.385: INFO: Initial restart count of pod liveness-http is 0
Feb 27 02:17:36.417: INFO: Restart count of pod e2e-tests-container-probe-bjrzg/liveness-http is now 1 (20.032009006s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:17:36.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bjrzg" for this suite.
Feb 27 02:17:42.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:17:42.480: INFO: namespace: e2e-tests-container-probe-bjrzg, resource: bindings, ignored listing per whitelist
Feb 27 02:17:42.502: INFO: namespace e2e-tests-container-probe-bjrzg deletion completed in 6.068851916s

• [SLOW TEST:30.189 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:17:42.503: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 02:17:42.572: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:17:46.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-fbjmn" for this suite.
Feb 27 02:18:08.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:18:08.984: INFO: namespace: e2e-tests-init-container-fbjmn, resource: bindings, ignored listing per whitelist
Feb 27 02:18:09.010: INFO: namespace e2e-tests-init-container-fbjmn deletion completed in 22.068426288s

• [SLOW TEST:26.507 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:18:09.010: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:18:09.077: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ecb84acb-3a35-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-rgtsn" to be "success or failure"
Feb 27 02:18:09.080: INFO: Pod "downwardapi-volume-ecb84acb-3a35-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.641651ms
Feb 27 02:18:11.083: INFO: Pod "downwardapi-volume-ecb84acb-3a35-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0066217s
Feb 27 02:18:13.085: INFO: Pod "downwardapi-volume-ecb84acb-3a35-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008869833s
STEP: Saw pod success
Feb 27 02:18:13.086: INFO: Pod "downwardapi-volume-ecb84acb-3a35-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:18:13.087: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downwardapi-volume-ecb84acb-3a35-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 02:18:13.103: INFO: Waiting for pod downwardapi-volume-ecb84acb-3a35-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:18:13.112: INFO: Pod downwardapi-volume-ecb84acb-3a35-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:18:13.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rgtsn" for this suite.
Feb 27 02:18:19.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:18:19.150: INFO: namespace: e2e-tests-projected-rgtsn, resource: bindings, ignored listing per whitelist
Feb 27 02:18:19.195: INFO: namespace e2e-tests-projected-rgtsn deletion completed in 6.076012668s

• [SLOW TEST:10.186 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:18:19.198: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 27 02:18:27.305: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:27.307: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:18:29.307: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:29.310: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:18:31.307: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:31.310: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:18:33.307: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:33.310: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:18:35.307: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:35.310: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:18:37.307: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:37.310: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:18:39.307: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:39.310: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:18:41.307: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:41.310: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:18:43.307: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:43.310: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:18:45.307: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:45.311: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:18:47.307: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:18:47.310: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:18:47.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-vzf8r" for this suite.
Feb 27 02:19:09.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:19:09.380: INFO: namespace: e2e-tests-container-lifecycle-hook-vzf8r, resource: bindings, ignored listing per whitelist
Feb 27 02:19:09.380: INFO: namespace e2e-tests-container-lifecycle-hook-vzf8r deletion completed in 22.06776576s

• [SLOW TEST:50.183 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:19:09.381: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-10b39093-3a36-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 02:19:09.448: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-10b3e233-3a36-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-l2d2t" to be "success or failure"
Feb 27 02:19:09.452: INFO: Pod "pod-projected-secrets-10b3e233-3a36-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.825703ms
Feb 27 02:19:11.455: INFO: Pod "pod-projected-secrets-10b3e233-3a36-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007028099s
Feb 27 02:19:13.458: INFO: Pod "pod-projected-secrets-10b3e233-3a36-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009832233s
STEP: Saw pod success
Feb 27 02:19:13.458: INFO: Pod "pod-projected-secrets-10b3e233-3a36-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:19:13.460: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-projected-secrets-10b3e233-3a36-11e9-8c03-2a4c52047ee8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:19:13.477: INFO: Waiting for pod pod-projected-secrets-10b3e233-3a36-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:19:13.480: INFO: Pod pod-projected-secrets-10b3e233-3a36-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:19:13.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l2d2t" for this suite.
Feb 27 02:19:19.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:19:19.553: INFO: namespace: e2e-tests-projected-l2d2t, resource: bindings, ignored listing per whitelist
Feb 27 02:19:19.553: INFO: namespace e2e-tests-projected-l2d2t deletion completed in 6.070649742s

• [SLOW TEST:10.172 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:19:19.553: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-d5h6h
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 27 02:19:19.644: INFO: Found 0 stateful pods, waiting for 3
Feb 27 02:19:29.648: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:19:29.648: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:19:29.648: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:19:29.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-d5h6h ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:19:29.990: INFO: stderr: ""
Feb 27 02:19:29.990: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:19:29.990: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 27 02:19:40.020: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 27 02:19:50.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-d5h6h ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:19:50.325: INFO: stderr: ""
Feb 27 02:19:50.325: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:19:50.325: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:20:10.339: INFO: Waiting for StatefulSet e2e-tests-statefulset-d5h6h/ss2 to complete update
STEP: Rolling back to a previous revision
Feb 27 02:20:20.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-d5h6h ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:20:20.627: INFO: stderr: ""
Feb 27 02:20:20.627: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:20:20.627: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:20:30.652: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 27 02:20:40.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-d5h6h ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:20:40.947: INFO: stderr: ""
Feb 27 02:20:40.947: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:20:40.947: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:20:50.962: INFO: Waiting for StatefulSet e2e-tests-statefulset-d5h6h/ss2 to complete update
Feb 27 02:20:50.962: INFO: Waiting for Pod e2e-tests-statefulset-d5h6h/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 27 02:20:50.962: INFO: Waiting for Pod e2e-tests-statefulset-d5h6h/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 27 02:21:00.967: INFO: Waiting for StatefulSet e2e-tests-statefulset-d5h6h/ss2 to complete update
Feb 27 02:21:00.967: INFO: Waiting for Pod e2e-tests-statefulset-d5h6h/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 27 02:21:10.972: INFO: Waiting for StatefulSet e2e-tests-statefulset-d5h6h/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 02:21:20.967: INFO: Deleting all statefulset in ns e2e-tests-statefulset-d5h6h
Feb 27 02:21:20.969: INFO: Scaling statefulset ss2 to 0
Feb 27 02:21:40.980: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:21:40.982: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:21:40.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-d5h6h" for this suite.
Feb 27 02:21:47.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:21:47.032: INFO: namespace: e2e-tests-statefulset-d5h6h, resource: bindings, ignored listing per whitelist
Feb 27 02:21:47.074: INFO: namespace e2e-tests-statefulset-d5h6h deletion completed in 6.078816054s

• [SLOW TEST:147.520 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:21:47.074: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 27 02:21:47.146: INFO: Waiting up to 5m0s for pod "pod-6eb330b1-3a36-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-lv2kf" to be "success or failure"
Feb 27 02:21:47.148: INFO: Pod "pod-6eb330b1-3a36-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.546535ms
Feb 27 02:21:49.151: INFO: Pod "pod-6eb330b1-3a36-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005437248s
Feb 27 02:21:51.154: INFO: Pod "pod-6eb330b1-3a36-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008200919s
STEP: Saw pod success
Feb 27 02:21:51.154: INFO: Pod "pod-6eb330b1-3a36-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:21:51.156: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-6eb330b1-3a36-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 02:21:51.170: INFO: Waiting for pod pod-6eb330b1-3a36-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:21:51.173: INFO: Pod pod-6eb330b1-3a36-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:21:51.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lv2kf" for this suite.
Feb 27 02:21:57.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:21:57.194: INFO: namespace: e2e-tests-emptydir-lv2kf, resource: bindings, ignored listing per whitelist
Feb 27 02:21:57.243: INFO: namespace e2e-tests-emptydir-lv2kf deletion completed in 6.067413971s

• [SLOW TEST:10.169 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:21:57.243: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-74c12ec3-3a36-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 02:21:57.315: INFO: Waiting up to 5m0s for pod "pod-configmaps-74c247e7-3a36-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-configmap-9qljp" to be "success or failure"
Feb 27 02:21:57.319: INFO: Pod "pod-configmaps-74c247e7-3a36-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.319278ms
Feb 27 02:21:59.322: INFO: Pod "pod-configmaps-74c247e7-3a36-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006424339s
Feb 27 02:22:01.324: INFO: Pod "pod-configmaps-74c247e7-3a36-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009197601s
STEP: Saw pod success
Feb 27 02:22:01.325: INFO: Pod "pod-configmaps-74c247e7-3a36-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:22:01.326: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-configmaps-74c247e7-3a36-11e9-8c03-2a4c52047ee8 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:22:01.341: INFO: Waiting for pod pod-configmaps-74c247e7-3a36-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:22:01.347: INFO: Pod pod-configmaps-74c247e7-3a36-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:22:01.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9qljp" for this suite.
Feb 27 02:22:07.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:22:07.415: INFO: namespace: e2e-tests-configmap-9qljp, resource: bindings, ignored listing per whitelist
Feb 27 02:22:07.430: INFO: namespace e2e-tests-configmap-9qljp deletion completed in 6.079053419s

• [SLOW TEST:10.187 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:22:07.430: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7ad47582-3a36-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 02:22:07.497: INFO: Waiting up to 5m0s for pod "pod-secrets-7ad4d9cb-3a36-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-secrets-k56z6" to be "success or failure"
Feb 27 02:22:07.502: INFO: Pod "pod-secrets-7ad4d9cb-3a36-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.771825ms
Feb 27 02:22:09.505: INFO: Pod "pod-secrets-7ad4d9cb-3a36-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008673531s
Feb 27 02:22:11.508: INFO: Pod "pod-secrets-7ad4d9cb-3a36-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011669657s
STEP: Saw pod success
Feb 27 02:22:11.509: INFO: Pod "pod-secrets-7ad4d9cb-3a36-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:22:11.510: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-secrets-7ad4d9cb-3a36-11e9-8c03-2a4c52047ee8 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:22:11.525: INFO: Waiting for pod pod-secrets-7ad4d9cb-3a36-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:22:11.528: INFO: Pod pod-secrets-7ad4d9cb-3a36-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:22:11.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-k56z6" for this suite.
Feb 27 02:22:17.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:22:17.585: INFO: namespace: e2e-tests-secrets-k56z6, resource: bindings, ignored listing per whitelist
Feb 27 02:22:17.603: INFO: namespace e2e-tests-secrets-k56z6 deletion completed in 6.073354064s

• [SLOW TEST:10.173 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:22:17.604: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 27 02:22:17.694: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrl5z,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrl5z/configmaps/e2e-watch-test-label-changed,UID:80e50229-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:8975,Generation:0,CreationTimestamp:2019-02-27 02:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 02:22:17.694: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrl5z,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrl5z/configmaps/e2e-watch-test-label-changed,UID:80e50229-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:8976,Generation:0,CreationTimestamp:2019-02-27 02:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 27 02:22:17.694: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrl5z,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrl5z/configmaps/e2e-watch-test-label-changed,UID:80e50229-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:8977,Generation:0,CreationTimestamp:2019-02-27 02:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 27 02:22:27.724: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrl5z,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrl5z/configmaps/e2e-watch-test-label-changed,UID:80e50229-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:8993,Generation:0,CreationTimestamp:2019-02-27 02:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 02:22:27.724: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrl5z,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrl5z/configmaps/e2e-watch-test-label-changed,UID:80e50229-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:8994,Generation:0,CreationTimestamp:2019-02-27 02:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 27 02:22:27.724: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-nrl5z,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrl5z/configmaps/e2e-watch-test-label-changed,UID:80e50229-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:8995,Generation:0,CreationTimestamp:2019-02-27 02:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:22:27.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nrl5z" for this suite.
Feb 27 02:22:33.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:22:33.774: INFO: namespace: e2e-tests-watch-nrl5z, resource: bindings, ignored listing per whitelist
Feb 27 02:22:33.799: INFO: namespace e2e-tests-watch-nrl5z deletion completed in 6.068152901s

• [SLOW TEST:16.196 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:22:33.800: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:22:33.854: INFO: Creating deployment "test-recreate-deployment"
Feb 27 02:22:33.862: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 27 02:22:33.867: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 27 02:22:35.871: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 27 02:22:35.873: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830953, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830953, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830953, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686830953, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:22:37.877: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 27 02:22:37.884: INFO: Updating deployment test-recreate-deployment
Feb 27 02:22:37.884: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 02:22:38.001: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-sk4d5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sk4d5/deployments/test-recreate-deployment,UID:8a8b4d32-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:9058,Generation:2,CreationTimestamp:2019-02-27 02:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-27 02:22:37 +0000 UTC 2019-02-27 02:22:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-27 02:22:37 +0000 UTC 2019-02-27 02:22:33 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 27 02:22:38.004: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-sk4d5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sk4d5/replicasets/test-recreate-deployment-697fbf54bf,UID:8cf99d6e-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:9056,Generation:1,CreationTimestamp:2019-02-27 02:22:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 8a8b4d32-3a36-11e9-8378-02ce1f9c2c90 0xc000739ef7 0xc000739ef8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 02:22:38.004: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 27 02:22:38.005: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-sk4d5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sk4d5/replicasets/test-recreate-deployment-5dfdcc846d,UID:8a8d3deb-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:9046,Generation:2,CreationTimestamp:2019-02-27 02:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 8a8b4d32-3a36-11e9-8378-02ce1f9c2c90 0xc000739e47 0xc000739e48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 02:22:38.007: INFO: Pod "test-recreate-deployment-697fbf54bf-tmt5v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-tmt5v,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-sk4d5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-sk4d5/pods/test-recreate-deployment-697fbf54bf-tmt5v,UID:8cfabfb5-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:9057,Generation:0,CreationTimestamp:2019-02-27 02:22:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 8cf99d6e-3a36-11e9-8378-02ce1f9c2c90 0xc00187df47 0xc00187df48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-q8jlq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q8jlq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q8jlq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00187dfb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00187dfd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:22:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:22:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:22:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:22:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.30.134,PodIP:,StartTime:2019-02-27 02:22:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:22:38.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-sk4d5" for this suite.
Feb 27 02:22:44.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:22:44.058: INFO: namespace: e2e-tests-deployment-sk4d5, resource: bindings, ignored listing per whitelist
Feb 27 02:22:44.098: INFO: namespace e2e-tests-deployment-sk4d5 deletion completed in 6.086485967s

• [SLOW TEST:10.298 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:22:44.098: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 27 02:22:44.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 --namespace=e2e-tests-kubectl-tb9p2 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 27 02:22:47.737: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 27 02:22:47.737: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:22:49.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tb9p2" for this suite.
Feb 27 02:22:55.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:22:55.817: INFO: namespace: e2e-tests-kubectl-tb9p2, resource: bindings, ignored listing per whitelist
Feb 27 02:22:55.820: INFO: namespace e2e-tests-kubectl-tb9p2 deletion completed in 6.075644979s

• [SLOW TEST:11.722 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:22:55.820: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:22:55.887: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 27 02:23:00.890: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 27 02:23:00.890: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 02:23:00.903: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-nzghr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nzghr/deployments/test-cleanup-deployment,UID:9aa8f9ef-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:9165,Generation:1,CreationTimestamp:2019-02-27 02:23:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 27 02:23:00.908: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Feb 27 02:23:00.908: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 27 02:23:00.908: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-nzghr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nzghr/replicasets/test-cleanup-controller,UID:97ab462d-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:9166,Generation:1,CreationTimestamp:2019-02-27 02:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 9aa8f9ef-3a36-11e9-8378-02ce1f9c2c90 0xc000bb450f 0xc000bb4520}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 27 02:23:00.913: INFO: Pod "test-cleanup-controller-4whw9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-4whw9,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-nzghr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nzghr/pods/test-cleanup-controller-4whw9,UID:97ad5a73-3a36-11e9-8378-02ce1f9c2c90,ResourceVersion:9161,Generation:0,CreationTimestamp:2019-02-27 02:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 97ab462d-3a36-11e9-8378-02ce1f9c2c90 0xc000bb4acf 0xc000bb4ae0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9s5c4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9s5c4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9s5c4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000bb4b40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000bb4b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:22:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:22:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:22:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:22:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.30.134,PodIP:192.168.48.244,StartTime:2019-02-27 02:22:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 02:22:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://c0efc1163831c688f084c4a360561ba76a2ef5a329f84dea1d1b398571b4952b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:23:00.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-nzghr" for this suite.
Feb 27 02:23:06.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:23:06.968: INFO: namespace: e2e-tests-deployment-nzghr, resource: bindings, ignored listing per whitelist
Feb 27 02:23:07.011: INFO: namespace e2e-tests-deployment-nzghr deletion completed in 6.085578399s

• [SLOW TEST:11.191 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:23:07.012: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-9e58fb6f-3a36-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 02:23:07.093: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9e5a731e-3a36-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-t8dv7" to be "success or failure"
Feb 27 02:23:07.096: INFO: Pod "pod-projected-secrets-9e5a731e-3a36-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.164313ms
Feb 27 02:23:09.100: INFO: Pod "pod-projected-secrets-9e5a731e-3a36-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006935329s
Feb 27 02:23:11.103: INFO: Pod "pod-projected-secrets-9e5a731e-3a36-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009822479s
STEP: Saw pod success
Feb 27 02:23:11.103: INFO: Pod "pod-projected-secrets-9e5a731e-3a36-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:23:11.109: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-projected-secrets-9e5a731e-3a36-11e9-8c03-2a4c52047ee8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:23:11.134: INFO: Waiting for pod pod-projected-secrets-9e5a731e-3a36-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:23:11.137: INFO: Pod pod-projected-secrets-9e5a731e-3a36-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:23:11.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t8dv7" for this suite.
Feb 27 02:23:17.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:23:17.185: INFO: namespace: e2e-tests-projected-t8dv7, resource: bindings, ignored listing per whitelist
Feb 27 02:23:17.217: INFO: namespace e2e-tests-projected-t8dv7 deletion completed in 6.076929008s

• [SLOW TEST:10.205 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:23:17.218: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 02:23:17.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-2t87t'
Feb 27 02:23:17.351: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 02:23:17.351: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb 27 02:23:21.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-2t87t'
Feb 27 02:23:21.453: INFO: stderr: ""
Feb 27 02:23:21.453: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:23:21.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2t87t" for this suite.
Feb 27 02:23:43.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:23:43.481: INFO: namespace: e2e-tests-kubectl-2t87t, resource: bindings, ignored listing per whitelist
Feb 27 02:23:43.528: INFO: namespace e2e-tests-kubectl-2t87t deletion completed in 22.071247822s

• [SLOW TEST:26.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:23:43.529: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0227 02:24:23.616649      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 02:24:23.616: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:24:23.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-t7ndp" for this suite.
Feb 27 02:24:29.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:24:29.651: INFO: namespace: e2e-tests-gc-t7ndp, resource: bindings, ignored listing per whitelist
Feb 27 02:24:29.713: INFO: namespace e2e-tests-gc-t7ndp deletion completed in 6.094739074s

• [SLOW TEST:46.185 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:24:29.714: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-qsd9
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 02:24:29.839: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-qsd9" in namespace "e2e-tests-subpath-476dj" to be "success or failure"
Feb 27 02:24:29.854: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.55921ms
Feb 27 02:24:31.856: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017086565s
Feb 27 02:24:33.858: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 4.019301431s
Feb 27 02:24:35.861: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 6.022360621s
Feb 27 02:24:37.865: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 8.026260629s
Feb 27 02:24:39.871: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 10.031589193s
Feb 27 02:24:41.874: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 12.034573971s
Feb 27 02:24:43.877: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 14.037421881s
Feb 27 02:24:45.880: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 16.04058175s
Feb 27 02:24:47.883: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 18.043860819s
Feb 27 02:24:49.887: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 20.047473642s
Feb 27 02:24:51.889: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 22.050106208s
Feb 27 02:24:53.892: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Running", Reason="", readiness=false. Elapsed: 24.053022329s
Feb 27 02:24:55.895: INFO: Pod "pod-subpath-test-secret-qsd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.05569741s
STEP: Saw pod success
Feb 27 02:24:55.895: INFO: Pod "pod-subpath-test-secret-qsd9" satisfied condition "success or failure"
Feb 27 02:24:55.897: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-subpath-test-secret-qsd9 container test-container-subpath-secret-qsd9: <nil>
STEP: delete the pod
Feb 27 02:24:55.913: INFO: Waiting for pod pod-subpath-test-secret-qsd9 to disappear
Feb 27 02:24:55.921: INFO: Pod pod-subpath-test-secret-qsd9 no longer exists
STEP: Deleting pod pod-subpath-test-secret-qsd9
Feb 27 02:24:55.921: INFO: Deleting pod "pod-subpath-test-secret-qsd9" in namespace "e2e-tests-subpath-476dj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:24:55.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-476dj" for this suite.
Feb 27 02:25:01.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:25:01.963: INFO: namespace: e2e-tests-subpath-476dj, resource: bindings, ignored listing per whitelist
Feb 27 02:25:01.996: INFO: namespace e2e-tests-subpath-476dj deletion completed in 6.0713135s

• [SLOW TEST:32.282 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:25:01.997: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 27 02:25:02.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 api-versions'
Feb 27 02:25:02.145: INFO: stderr: ""
Feb 27 02:25:02.145: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:25:02.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2mh74" for this suite.
Feb 27 02:25:08.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:25:08.195: INFO: namespace: e2e-tests-kubectl-2mh74, resource: bindings, ignored listing per whitelist
Feb 27 02:25:08.215: INFO: namespace e2e-tests-kubectl-2mh74 deletion completed in 6.066263589s

• [SLOW TEST:6.218 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:25:08.215: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-5ktqv
I0227 02:25:08.267544      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-5ktqv, replica count: 1
I0227 02:25:09.318059      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 02:25:10.318313      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 02:25:11.318571      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 27 02:25:11.430: INFO: Created: latency-svc-87swz
Feb 27 02:25:11.445: INFO: Got endpoints: latency-svc-87swz [26.011662ms]
Feb 27 02:25:11.457: INFO: Created: latency-svc-5267t
Feb 27 02:25:11.465: INFO: Got endpoints: latency-svc-5267t [20.256857ms]
Feb 27 02:25:11.479: INFO: Created: latency-svc-jgxg4
Feb 27 02:25:11.485: INFO: Got endpoints: latency-svc-jgxg4 [39.478271ms]
Feb 27 02:25:11.491: INFO: Created: latency-svc-vdbc8
Feb 27 02:25:11.502: INFO: Got endpoints: latency-svc-vdbc8 [55.999206ms]
Feb 27 02:25:11.514: INFO: Created: latency-svc-bvtx8
Feb 27 02:25:11.528: INFO: Got endpoints: latency-svc-bvtx8 [82.548281ms]
Feb 27 02:25:11.532: INFO: Created: latency-svc-2cqw4
Feb 27 02:25:11.536: INFO: Got endpoints: latency-svc-2cqw4 [89.799831ms]
Feb 27 02:25:11.572: INFO: Created: latency-svc-m99gx
Feb 27 02:25:11.587: INFO: Got endpoints: latency-svc-m99gx [140.261294ms]
Feb 27 02:25:11.617: INFO: Created: latency-svc-5sgch
Feb 27 02:25:11.623: INFO: Got endpoints: latency-svc-5sgch [177.256788ms]
Feb 27 02:25:11.637: INFO: Created: latency-svc-845nt
Feb 27 02:25:11.640: INFO: Got endpoints: latency-svc-845nt [194.164569ms]
Feb 27 02:25:11.658: INFO: Created: latency-svc-pjdd4
Feb 27 02:25:11.680: INFO: Got endpoints: latency-svc-pjdd4 [233.259439ms]
Feb 27 02:25:11.741: INFO: Created: latency-svc-5r4zd
Feb 27 02:25:11.811: INFO: Got endpoints: latency-svc-5r4zd [364.876278ms]
Feb 27 02:25:11.828: INFO: Created: latency-svc-d68jp
Feb 27 02:25:11.837: INFO: Got endpoints: latency-svc-d68jp [390.084115ms]
Feb 27 02:25:11.846: INFO: Created: latency-svc-9sfhp
Feb 27 02:25:11.852: INFO: Got endpoints: latency-svc-9sfhp [405.615468ms]
Feb 27 02:25:11.863: INFO: Created: latency-svc-qrmrd
Feb 27 02:25:11.870: INFO: Got endpoints: latency-svc-qrmrd [423.415192ms]
Feb 27 02:25:11.878: INFO: Created: latency-svc-6l9bv
Feb 27 02:25:11.887: INFO: Got endpoints: latency-svc-6l9bv [439.998692ms]
Feb 27 02:25:11.893: INFO: Created: latency-svc-9r5xr
Feb 27 02:25:11.906: INFO: Got endpoints: latency-svc-9r5xr [458.733116ms]
Feb 27 02:25:11.931: INFO: Created: latency-svc-sd4ft
Feb 27 02:25:11.934: INFO: Got endpoints: latency-svc-sd4ft [468.132083ms]
Feb 27 02:25:11.952: INFO: Created: latency-svc-c527q
Feb 27 02:25:11.957: INFO: Got endpoints: latency-svc-c527q [471.938862ms]
Feb 27 02:25:11.993: INFO: Created: latency-svc-6zc7h
Feb 27 02:25:12.000: INFO: Got endpoints: latency-svc-6zc7h [498.584865ms]
Feb 27 02:25:12.017: INFO: Created: latency-svc-fs56b
Feb 27 02:25:12.018: INFO: Got endpoints: latency-svc-fs56b [490.297104ms]
Feb 27 02:25:12.064: INFO: Created: latency-svc-d9q7v
Feb 27 02:25:12.070: INFO: Got endpoints: latency-svc-d9q7v [534.244972ms]
Feb 27 02:25:12.087: INFO: Created: latency-svc-j4xwg
Feb 27 02:25:12.093: INFO: Got endpoints: latency-svc-j4xwg [505.526506ms]
Feb 27 02:25:12.104: INFO: Created: latency-svc-kdqqq
Feb 27 02:25:12.109: INFO: Got endpoints: latency-svc-kdqqq [486.094488ms]
Feb 27 02:25:12.120: INFO: Created: latency-svc-5z5fh
Feb 27 02:25:12.124: INFO: Got endpoints: latency-svc-5z5fh [483.921088ms]
Feb 27 02:25:12.145: INFO: Created: latency-svc-8sc4t
Feb 27 02:25:12.146: INFO: Got endpoints: latency-svc-8sc4t [466.861283ms]
Feb 27 02:25:12.183: INFO: Created: latency-svc-xwlsl
Feb 27 02:25:12.183: INFO: Created: latency-svc-p8spw
Feb 27 02:25:12.189: INFO: Got endpoints: latency-svc-p8spw [351.946675ms]
Feb 27 02:25:12.189: INFO: Got endpoints: latency-svc-xwlsl [377.313637ms]
Feb 27 02:25:12.207: INFO: Created: latency-svc-fkjzg
Feb 27 02:25:12.212: INFO: Got endpoints: latency-svc-fkjzg [359.061709ms]
Feb 27 02:25:12.234: INFO: Created: latency-svc-7tr66
Feb 27 02:25:12.238: INFO: Created: latency-svc-h8ph6
Feb 27 02:25:12.256: INFO: Got endpoints: latency-svc-7tr66 [385.8271ms]
Feb 27 02:25:12.262: INFO: Got endpoints: latency-svc-h8ph6 [374.674734ms]
Feb 27 02:25:12.278: INFO: Created: latency-svc-qpl8c
Feb 27 02:25:12.287: INFO: Got endpoints: latency-svc-qpl8c [381.31871ms]
Feb 27 02:25:12.313: INFO: Created: latency-svc-98jbp
Feb 27 02:25:12.321: INFO: Got endpoints: latency-svc-98jbp [387.353224ms]
Feb 27 02:25:12.339: INFO: Created: latency-svc-x9cvc
Feb 27 02:25:12.345: INFO: Got endpoints: latency-svc-x9cvc [387.962689ms]
Feb 27 02:25:12.351: INFO: Created: latency-svc-89fbd
Feb 27 02:25:12.356: INFO: Got endpoints: latency-svc-89fbd [355.857611ms]
Feb 27 02:25:12.369: INFO: Created: latency-svc-dttcc
Feb 27 02:25:12.376: INFO: Got endpoints: latency-svc-dttcc [357.289143ms]
Feb 27 02:25:12.420: INFO: Created: latency-svc-hkvvc
Feb 27 02:25:12.435: INFO: Got endpoints: latency-svc-hkvvc [364.547133ms]
Feb 27 02:25:12.440: INFO: Created: latency-svc-bvv7x
Feb 27 02:25:12.446: INFO: Got endpoints: latency-svc-bvv7x [352.924883ms]
Feb 27 02:25:12.459: INFO: Created: latency-svc-gd4mx
Feb 27 02:25:12.477: INFO: Got endpoints: latency-svc-gd4mx [368.045428ms]
Feb 27 02:25:12.492: INFO: Created: latency-svc-h5w67
Feb 27 02:25:12.502: INFO: Got endpoints: latency-svc-h5w67 [377.028241ms]
Feb 27 02:25:12.521: INFO: Created: latency-svc-v4rv2
Feb 27 02:25:12.534: INFO: Got endpoints: latency-svc-v4rv2 [387.245995ms]
Feb 27 02:25:12.537: INFO: Created: latency-svc-d66zh
Feb 27 02:25:12.554: INFO: Got endpoints: latency-svc-d66zh [364.65986ms]
Feb 27 02:25:12.559: INFO: Created: latency-svc-kprdq
Feb 27 02:25:12.569: INFO: Got endpoints: latency-svc-kprdq [379.944375ms]
Feb 27 02:25:12.587: INFO: Created: latency-svc-pmlfk
Feb 27 02:25:12.592: INFO: Got endpoints: latency-svc-pmlfk [379.920116ms]
Feb 27 02:25:12.607: INFO: Created: latency-svc-v79jt
Feb 27 02:25:12.613: INFO: Got endpoints: latency-svc-v79jt [356.760723ms]
Feb 27 02:25:12.629: INFO: Created: latency-svc-zfndr
Feb 27 02:25:12.632: INFO: Got endpoints: latency-svc-zfndr [370.025269ms]
Feb 27 02:25:12.654: INFO: Created: latency-svc-hfhhr
Feb 27 02:25:12.673: INFO: Got endpoints: latency-svc-hfhhr [386.127653ms]
Feb 27 02:25:12.688: INFO: Created: latency-svc-fdjqk
Feb 27 02:25:12.694: INFO: Got endpoints: latency-svc-fdjqk [372.509673ms]
Feb 27 02:25:12.699: INFO: Created: latency-svc-7qr8n
Feb 27 02:25:12.706: INFO: Got endpoints: latency-svc-7qr8n [360.915087ms]
Feb 27 02:25:12.717: INFO: Created: latency-svc-wptqd
Feb 27 02:25:12.731: INFO: Got endpoints: latency-svc-wptqd [374.801939ms]
Feb 27 02:25:12.739: INFO: Created: latency-svc-wvs89
Feb 27 02:25:12.757: INFO: Got endpoints: latency-svc-wvs89 [381.124218ms]
Feb 27 02:25:12.807: INFO: Created: latency-svc-gkrfg
Feb 27 02:25:12.815: INFO: Got endpoints: latency-svc-gkrfg [380.763582ms]
Feb 27 02:25:12.817: INFO: Created: latency-svc-qmnw4
Feb 27 02:25:12.823: INFO: Got endpoints: latency-svc-qmnw4 [377.053255ms]
Feb 27 02:25:12.839: INFO: Created: latency-svc-gp6qs
Feb 27 02:25:12.845: INFO: Got endpoints: latency-svc-gp6qs [367.216817ms]
Feb 27 02:25:12.868: INFO: Created: latency-svc-ntdkr
Feb 27 02:25:12.868: INFO: Got endpoints: latency-svc-ntdkr [366.6416ms]
Feb 27 02:25:12.886: INFO: Created: latency-svc-dbl2j
Feb 27 02:25:12.890: INFO: Got endpoints: latency-svc-dbl2j [356.096395ms]
Feb 27 02:25:12.932: INFO: Created: latency-svc-5mc2t
Feb 27 02:25:12.935: INFO: Got endpoints: latency-svc-5mc2t [380.936633ms]
Feb 27 02:25:12.958: INFO: Created: latency-svc-8k4kc
Feb 27 02:25:12.965: INFO: Got endpoints: latency-svc-8k4kc [396.512695ms]
Feb 27 02:25:12.972: INFO: Created: latency-svc-r4nb5
Feb 27 02:25:12.974: INFO: Got endpoints: latency-svc-r4nb5 [382.599553ms]
Feb 27 02:25:12.991: INFO: Created: latency-svc-jw6sx
Feb 27 02:25:12.997: INFO: Got endpoints: latency-svc-jw6sx [383.679762ms]
Feb 27 02:25:13.016: INFO: Created: latency-svc-gr98g
Feb 27 02:25:13.018: INFO: Got endpoints: latency-svc-gr98g [385.550046ms]
Feb 27 02:25:13.055: INFO: Created: latency-svc-gvv8n
Feb 27 02:25:13.061: INFO: Got endpoints: latency-svc-gvv8n [387.417301ms]
Feb 27 02:25:13.073: INFO: Created: latency-svc-7jf87
Feb 27 02:25:13.079: INFO: Got endpoints: latency-svc-7jf87 [385.155579ms]
Feb 27 02:25:13.093: INFO: Created: latency-svc-5x6h6
Feb 27 02:25:13.099: INFO: Got endpoints: latency-svc-5x6h6 [392.738885ms]
Feb 27 02:25:13.119: INFO: Created: latency-svc-jn2xk
Feb 27 02:25:13.138: INFO: Created: latency-svc-5b9fd
Feb 27 02:25:13.140: INFO: Got endpoints: latency-svc-jn2xk [408.862713ms]
Feb 27 02:25:13.171: INFO: Created: latency-svc-pbrvz
Feb 27 02:25:13.185: INFO: Got endpoints: latency-svc-5b9fd [428.24794ms]
Feb 27 02:25:13.198: INFO: Created: latency-svc-t8pvm
Feb 27 02:25:13.228: INFO: Created: latency-svc-knbmh
Feb 27 02:25:13.239: INFO: Got endpoints: latency-svc-pbrvz [423.21751ms]
Feb 27 02:25:13.262: INFO: Created: latency-svc-sjj6d
Feb 27 02:25:13.295: INFO: Got endpoints: latency-svc-t8pvm [471.412569ms]
Feb 27 02:25:13.298: INFO: Created: latency-svc-jqjdt
Feb 27 02:25:13.320: INFO: Created: latency-svc-9ftnq
Feb 27 02:25:13.339: INFO: Created: latency-svc-gm28j
Feb 27 02:25:13.346: INFO: Got endpoints: latency-svc-knbmh [500.526712ms]
Feb 27 02:25:13.354: INFO: Created: latency-svc-sqnnd
Feb 27 02:25:13.375: INFO: Created: latency-svc-vz7bg
Feb 27 02:25:13.384: INFO: Created: latency-svc-lnsh6
Feb 27 02:25:13.411: INFO: Got endpoints: latency-svc-sjj6d [543.158512ms]
Feb 27 02:25:13.431: INFO: Created: latency-svc-smb7v
Feb 27 02:25:13.435: INFO: Got endpoints: latency-svc-jqjdt [544.684442ms]
Feb 27 02:25:13.443: INFO: Created: latency-svc-pfrgm
Feb 27 02:25:13.470: INFO: Created: latency-svc-nw5ht
Feb 27 02:25:13.493: INFO: Got endpoints: latency-svc-9ftnq [558.209623ms]
Feb 27 02:25:13.495: INFO: Created: latency-svc-6bxj2
Feb 27 02:25:13.510: INFO: Created: latency-svc-9vzb6
Feb 27 02:25:13.544: INFO: Created: latency-svc-6h2v8
Feb 27 02:25:13.550: INFO: Got endpoints: latency-svc-gm28j [584.663373ms]
Feb 27 02:25:13.576: INFO: Created: latency-svc-wdq6z
Feb 27 02:25:13.680: INFO: Got endpoints: latency-svc-vz7bg [683.238884ms]
Feb 27 02:25:13.680: INFO: Got endpoints: latency-svc-sqnnd [705.833681ms]
Feb 27 02:25:13.706: INFO: Got endpoints: latency-svc-lnsh6 [688.26236ms]
Feb 27 02:25:13.713: INFO: Created: latency-svc-z66gx
Feb 27 02:25:13.730: INFO: Created: latency-svc-d5snp
Feb 27 02:25:13.740: INFO: Got endpoints: latency-svc-smb7v [678.89075ms]
Feb 27 02:25:13.746: INFO: Created: latency-svc-82pjd
Feb 27 02:25:13.776: INFO: Created: latency-svc-wbwpx
Feb 27 02:25:13.786: INFO: Got endpoints: latency-svc-pfrgm [706.192917ms]
Feb 27 02:25:13.804: INFO: Created: latency-svc-fzfl9
Feb 27 02:25:13.834: INFO: Created: latency-svc-jr9hm
Feb 27 02:25:13.839: INFO: Got endpoints: latency-svc-nw5ht [740.003513ms]
Feb 27 02:25:13.851: INFO: Created: latency-svc-rcls9
Feb 27 02:25:13.875: INFO: Created: latency-svc-nskrd
Feb 27 02:25:13.883: INFO: Created: latency-svc-phc9n
Feb 27 02:25:13.891: INFO: Got endpoints: latency-svc-6bxj2 [749.959018ms]
Feb 27 02:25:13.909: INFO: Created: latency-svc-84xm7
Feb 27 02:25:13.927: INFO: Created: latency-svc-9mrmb
Feb 27 02:25:13.949: INFO: Got endpoints: latency-svc-9vzb6 [763.641325ms]
Feb 27 02:25:13.959: INFO: Created: latency-svc-wgfgq
Feb 27 02:25:13.974: INFO: Created: latency-svc-mlgrf
Feb 27 02:25:13.984: INFO: Got endpoints: latency-svc-6h2v8 [744.893696ms]
Feb 27 02:25:14.000: INFO: Created: latency-svc-8tlcg
Feb 27 02:25:14.036: INFO: Got endpoints: latency-svc-wdq6z [740.865365ms]
Feb 27 02:25:14.076: INFO: Created: latency-svc-v5gzw
Feb 27 02:25:14.086: INFO: Got endpoints: latency-svc-z66gx [739.73178ms]
Feb 27 02:25:14.102: INFO: Created: latency-svc-kqwxp
Feb 27 02:25:14.134: INFO: Got endpoints: latency-svc-d5snp [722.461926ms]
Feb 27 02:25:14.153: INFO: Created: latency-svc-7wqzl
Feb 27 02:25:14.187: INFO: Got endpoints: latency-svc-82pjd [751.766594ms]
Feb 27 02:25:14.210: INFO: Created: latency-svc-tcctt
Feb 27 02:25:14.235: INFO: Got endpoints: latency-svc-wbwpx [741.939587ms]
Feb 27 02:25:14.262: INFO: Created: latency-svc-vhx2j
Feb 27 02:25:14.285: INFO: Got endpoints: latency-svc-fzfl9 [734.350484ms]
Feb 27 02:25:14.318: INFO: Created: latency-svc-57xm5
Feb 27 02:25:14.335: INFO: Got endpoints: latency-svc-jr9hm [654.929501ms]
Feb 27 02:25:14.354: INFO: Created: latency-svc-rnjt8
Feb 27 02:25:14.385: INFO: Got endpoints: latency-svc-rcls9 [704.816245ms]
Feb 27 02:25:14.402: INFO: Created: latency-svc-jgq6h
Feb 27 02:25:14.435: INFO: Got endpoints: latency-svc-nskrd [728.378205ms]
Feb 27 02:25:14.481: INFO: Created: latency-svc-m8xqn
Feb 27 02:25:14.491: INFO: Got endpoints: latency-svc-phc9n [751.144839ms]
Feb 27 02:25:14.504: INFO: Created: latency-svc-2djj9
Feb 27 02:25:14.534: INFO: Got endpoints: latency-svc-84xm7 [748.484977ms]
Feb 27 02:25:14.551: INFO: Created: latency-svc-f4pth
Feb 27 02:25:14.587: INFO: Got endpoints: latency-svc-9mrmb [748.01297ms]
Feb 27 02:25:14.603: INFO: Created: latency-svc-nx6f5
Feb 27 02:25:14.650: INFO: Got endpoints: latency-svc-wgfgq [759.107302ms]
Feb 27 02:25:14.673: INFO: Created: latency-svc-brq6v
Feb 27 02:25:14.684: INFO: Got endpoints: latency-svc-mlgrf [735.299919ms]
Feb 27 02:25:14.711: INFO: Created: latency-svc-776qs
Feb 27 02:25:14.734: INFO: Got endpoints: latency-svc-8tlcg [750.23396ms]
Feb 27 02:25:14.772: INFO: Created: latency-svc-mbwql
Feb 27 02:25:14.785: INFO: Got endpoints: latency-svc-v5gzw [749.459918ms]
Feb 27 02:25:14.799: INFO: Created: latency-svc-6ztdj
Feb 27 02:25:14.834: INFO: Got endpoints: latency-svc-kqwxp [748.830821ms]
Feb 27 02:25:14.853: INFO: Created: latency-svc-v7xps
Feb 27 02:25:14.885: INFO: Got endpoints: latency-svc-7wqzl [750.556979ms]
Feb 27 02:25:14.900: INFO: Created: latency-svc-4khxn
Feb 27 02:25:14.936: INFO: Got endpoints: latency-svc-tcctt [749.125291ms]
Feb 27 02:25:14.960: INFO: Created: latency-svc-qjqh5
Feb 27 02:25:15.008: INFO: Got endpoints: latency-svc-vhx2j [772.932315ms]
Feb 27 02:25:15.025: INFO: Created: latency-svc-hqqvj
Feb 27 02:25:15.035: INFO: Got endpoints: latency-svc-57xm5 [750.381431ms]
Feb 27 02:25:15.055: INFO: Created: latency-svc-vvll6
Feb 27 02:25:15.086: INFO: Got endpoints: latency-svc-rnjt8 [750.737376ms]
Feb 27 02:25:15.116: INFO: Created: latency-svc-7d48h
Feb 27 02:25:15.134: INFO: Got endpoints: latency-svc-jgq6h [749.207523ms]
Feb 27 02:25:15.152: INFO: Created: latency-svc-tvfkn
Feb 27 02:25:15.184: INFO: Got endpoints: latency-svc-m8xqn [749.483652ms]
Feb 27 02:25:15.204: INFO: Created: latency-svc-qtc2k
Feb 27 02:25:15.241: INFO: Got endpoints: latency-svc-2djj9 [749.79628ms]
Feb 27 02:25:15.264: INFO: Created: latency-svc-v2ttp
Feb 27 02:25:15.290: INFO: Got endpoints: latency-svc-f4pth [756.118503ms]
Feb 27 02:25:15.320: INFO: Created: latency-svc-7wxks
Feb 27 02:25:15.339: INFO: Got endpoints: latency-svc-nx6f5 [752.094379ms]
Feb 27 02:25:15.373: INFO: Created: latency-svc-wg6cq
Feb 27 02:25:15.404: INFO: Got endpoints: latency-svc-brq6v [753.967929ms]
Feb 27 02:25:15.431: INFO: Created: latency-svc-vxldh
Feb 27 02:25:15.438: INFO: Got endpoints: latency-svc-776qs [753.854956ms]
Feb 27 02:25:15.507: INFO: Created: latency-svc-zxvvj
Feb 27 02:25:15.522: INFO: Got endpoints: latency-svc-mbwql [787.74276ms]
Feb 27 02:25:15.540: INFO: Got endpoints: latency-svc-6ztdj [754.694299ms]
Feb 27 02:25:15.552: INFO: Created: latency-svc-jrcqv
Feb 27 02:25:15.565: INFO: Created: latency-svc-tjl42
Feb 27 02:25:15.594: INFO: Got endpoints: latency-svc-v7xps [759.746343ms]
Feb 27 02:25:15.610: INFO: Created: latency-svc-x7kfm
Feb 27 02:25:15.636: INFO: Got endpoints: latency-svc-4khxn [751.209414ms]
Feb 27 02:25:15.659: INFO: Created: latency-svc-lsk96
Feb 27 02:25:15.685: INFO: Got endpoints: latency-svc-qjqh5 [748.560437ms]
Feb 27 02:25:15.721: INFO: Created: latency-svc-mhktg
Feb 27 02:25:15.741: INFO: Got endpoints: latency-svc-hqqvj [733.315985ms]
Feb 27 02:25:15.764: INFO: Created: latency-svc-sf8mj
Feb 27 02:25:15.796: INFO: Got endpoints: latency-svc-vvll6 [760.143899ms]
Feb 27 02:25:15.842: INFO: Got endpoints: latency-svc-7d48h [755.447701ms]
Feb 27 02:25:15.843: INFO: Created: latency-svc-p9v6x
Feb 27 02:25:15.867: INFO: Created: latency-svc-4z8p8
Feb 27 02:25:15.885: INFO: Got endpoints: latency-svc-tvfkn [750.760989ms]
Feb 27 02:25:15.904: INFO: Created: latency-svc-zwm69
Feb 27 02:25:15.935: INFO: Got endpoints: latency-svc-qtc2k [750.945908ms]
Feb 27 02:25:15.972: INFO: Created: latency-svc-d659r
Feb 27 02:25:15.985: INFO: Got endpoints: latency-svc-v2ttp [744.015125ms]
Feb 27 02:25:16.003: INFO: Created: latency-svc-qpfrg
Feb 27 02:25:16.035: INFO: Got endpoints: latency-svc-7wxks [744.507774ms]
Feb 27 02:25:16.049: INFO: Created: latency-svc-cvz5z
Feb 27 02:25:16.087: INFO: Got endpoints: latency-svc-wg6cq [747.643631ms]
Feb 27 02:25:16.121: INFO: Created: latency-svc-2blg8
Feb 27 02:25:16.134: INFO: Got endpoints: latency-svc-vxldh [730.074154ms]
Feb 27 02:25:16.157: INFO: Created: latency-svc-gb5xt
Feb 27 02:25:16.197: INFO: Got endpoints: latency-svc-zxvvj [758.324383ms]
Feb 27 02:25:16.213: INFO: Created: latency-svc-z5dwz
Feb 27 02:25:16.234: INFO: Got endpoints: latency-svc-jrcqv [711.774102ms]
Feb 27 02:25:16.247: INFO: Created: latency-svc-nrkxn
Feb 27 02:25:16.284: INFO: Got endpoints: latency-svc-tjl42 [744.142054ms]
Feb 27 02:25:16.317: INFO: Created: latency-svc-jzchq
Feb 27 02:25:16.339: INFO: Got endpoints: latency-svc-x7kfm [745.030788ms]
Feb 27 02:25:16.356: INFO: Created: latency-svc-zxz8c
Feb 27 02:25:16.384: INFO: Got endpoints: latency-svc-lsk96 [748.018749ms]
Feb 27 02:25:16.404: INFO: Created: latency-svc-698zx
Feb 27 02:25:16.435: INFO: Got endpoints: latency-svc-mhktg [749.450887ms]
Feb 27 02:25:16.454: INFO: Created: latency-svc-crzm9
Feb 27 02:25:16.485: INFO: Got endpoints: latency-svc-sf8mj [743.466356ms]
Feb 27 02:25:16.502: INFO: Created: latency-svc-hzflf
Feb 27 02:25:16.542: INFO: Got endpoints: latency-svc-p9v6x [745.739725ms]
Feb 27 02:25:16.583: INFO: Created: latency-svc-9j4qd
Feb 27 02:25:16.585: INFO: Got endpoints: latency-svc-4z8p8 [742.567565ms]
Feb 27 02:25:16.605: INFO: Created: latency-svc-d7sct
Feb 27 02:25:16.636: INFO: Got endpoints: latency-svc-zwm69 [750.155803ms]
Feb 27 02:25:16.663: INFO: Created: latency-svc-qx28w
Feb 27 02:25:16.685: INFO: Got endpoints: latency-svc-d659r [750.045593ms]
Feb 27 02:25:16.704: INFO: Created: latency-svc-l2m2p
Feb 27 02:25:16.735: INFO: Got endpoints: latency-svc-qpfrg [749.281225ms]
Feb 27 02:25:16.751: INFO: Created: latency-svc-6nkb6
Feb 27 02:25:16.786: INFO: Got endpoints: latency-svc-cvz5z [750.921642ms]
Feb 27 02:25:16.886: INFO: Created: latency-svc-tt6mz
Feb 27 02:25:16.933: INFO: Got endpoints: latency-svc-gb5xt [799.069356ms]
Feb 27 02:25:16.934: INFO: Got endpoints: latency-svc-2blg8 [846.731058ms]
Feb 27 02:25:16.935: INFO: Got endpoints: latency-svc-z5dwz [738.140101ms]
Feb 27 02:25:16.954: INFO: Created: latency-svc-k2czf
Feb 27 02:25:16.979: INFO: Created: latency-svc-9f62h
Feb 27 02:25:16.985: INFO: Created: latency-svc-r9sgq
Feb 27 02:25:16.989: INFO: Got endpoints: latency-svc-nrkxn [754.572153ms]
Feb 27 02:25:17.020: INFO: Created: latency-svc-hrfmx
Feb 27 02:25:17.045: INFO: Got endpoints: latency-svc-jzchq [760.967922ms]
Feb 27 02:25:17.067: INFO: Created: latency-svc-88h2g
Feb 27 02:25:17.084: INFO: Got endpoints: latency-svc-zxz8c [744.697901ms]
Feb 27 02:25:17.108: INFO: Created: latency-svc-h56dt
Feb 27 02:25:17.134: INFO: Got endpoints: latency-svc-698zx [750.144811ms]
Feb 27 02:25:17.155: INFO: Created: latency-svc-vkpgh
Feb 27 02:25:17.185: INFO: Got endpoints: latency-svc-crzm9 [749.939508ms]
Feb 27 02:25:17.204: INFO: Created: latency-svc-knd4z
Feb 27 02:25:17.235: INFO: Got endpoints: latency-svc-hzflf [749.789119ms]
Feb 27 02:25:17.255: INFO: Created: latency-svc-dmlx2
Feb 27 02:25:17.286: INFO: Got endpoints: latency-svc-9j4qd [744.37564ms]
Feb 27 02:25:17.303: INFO: Created: latency-svc-crg8g
Feb 27 02:25:17.334: INFO: Got endpoints: latency-svc-d7sct [749.449448ms]
Feb 27 02:25:17.355: INFO: Created: latency-svc-cv8bm
Feb 27 02:25:17.384: INFO: Got endpoints: latency-svc-qx28w [748.55349ms]
Feb 27 02:25:17.414: INFO: Created: latency-svc-x5d5p
Feb 27 02:25:17.434: INFO: Got endpoints: latency-svc-l2m2p [748.878814ms]
Feb 27 02:25:17.451: INFO: Created: latency-svc-447m6
Feb 27 02:25:17.490: INFO: Got endpoints: latency-svc-6nkb6 [755.371508ms]
Feb 27 02:25:17.527: INFO: Created: latency-svc-g977s
Feb 27 02:25:17.536: INFO: Got endpoints: latency-svc-tt6mz [750.032083ms]
Feb 27 02:25:17.557: INFO: Created: latency-svc-d8sfx
Feb 27 02:25:17.585: INFO: Got endpoints: latency-svc-k2czf [650.910333ms]
Feb 27 02:25:17.604: INFO: Created: latency-svc-zld4l
Feb 27 02:25:17.637: INFO: Got endpoints: latency-svc-9f62h [702.321554ms]
Feb 27 02:25:17.666: INFO: Created: latency-svc-h6ht5
Feb 27 02:25:17.688: INFO: Got endpoints: latency-svc-r9sgq [754.932545ms]
Feb 27 02:25:17.733: INFO: Created: latency-svc-sbzmw
Feb 27 02:25:17.761: INFO: Got endpoints: latency-svc-hrfmx [771.232301ms]
Feb 27 02:25:17.788: INFO: Created: latency-svc-pcksh
Feb 27 02:25:17.794: INFO: Got endpoints: latency-svc-88h2g [748.548429ms]
Feb 27 02:25:17.809: INFO: Created: latency-svc-dgvqd
Feb 27 02:25:17.834: INFO: Got endpoints: latency-svc-h56dt [749.892955ms]
Feb 27 02:25:17.851: INFO: Created: latency-svc-xqjcm
Feb 27 02:25:17.888: INFO: Got endpoints: latency-svc-vkpgh [753.934875ms]
Feb 27 02:25:17.914: INFO: Created: latency-svc-zwwj8
Feb 27 02:25:17.937: INFO: Got endpoints: latency-svc-knd4z [752.006618ms]
Feb 27 02:25:17.957: INFO: Created: latency-svc-mth2q
Feb 27 02:25:17.985: INFO: Got endpoints: latency-svc-dmlx2 [750.049298ms]
Feb 27 02:25:18.013: INFO: Created: latency-svc-s9nrs
Feb 27 02:25:18.037: INFO: Got endpoints: latency-svc-crg8g [750.631442ms]
Feb 27 02:25:18.056: INFO: Created: latency-svc-cp5sk
Feb 27 02:25:18.086: INFO: Got endpoints: latency-svc-cv8bm [751.981341ms]
Feb 27 02:25:18.122: INFO: Created: latency-svc-7r7nv
Feb 27 02:25:18.137: INFO: Got endpoints: latency-svc-x5d5p [752.274493ms]
Feb 27 02:25:18.164: INFO: Created: latency-svc-cbp6p
Feb 27 02:25:18.188: INFO: Got endpoints: latency-svc-447m6 [753.806271ms]
Feb 27 02:25:18.207: INFO: Created: latency-svc-6247x
Feb 27 02:25:18.234: INFO: Got endpoints: latency-svc-g977s [743.661058ms]
Feb 27 02:25:18.251: INFO: Created: latency-svc-r28w4
Feb 27 02:25:18.287: INFO: Got endpoints: latency-svc-d8sfx [751.218973ms]
Feb 27 02:25:18.302: INFO: Created: latency-svc-jzsnd
Feb 27 02:25:18.347: INFO: Got endpoints: latency-svc-zld4l [762.268217ms]
Feb 27 02:25:18.363: INFO: Created: latency-svc-mfgnr
Feb 27 02:25:18.386: INFO: Got endpoints: latency-svc-h6ht5 [748.95388ms]
Feb 27 02:25:18.401: INFO: Created: latency-svc-px7sh
Feb 27 02:25:18.436: INFO: Got endpoints: latency-svc-sbzmw [747.720467ms]
Feb 27 02:25:18.465: INFO: Created: latency-svc-x5pt5
Feb 27 02:25:18.487: INFO: Got endpoints: latency-svc-pcksh [726.050146ms]
Feb 27 02:25:18.509: INFO: Created: latency-svc-5hnbw
Feb 27 02:25:18.538: INFO: Got endpoints: latency-svc-dgvqd [744.126936ms]
Feb 27 02:25:18.615: INFO: Got endpoints: latency-svc-xqjcm [780.802459ms]
Feb 27 02:25:18.621: INFO: Created: latency-svc-96jkg
Feb 27 02:25:18.637: INFO: Got endpoints: latency-svc-zwwj8 [748.755722ms]
Feb 27 02:25:18.655: INFO: Created: latency-svc-6w4hv
Feb 27 02:25:18.667: INFO: Created: latency-svc-6xrr6
Feb 27 02:25:18.685: INFO: Got endpoints: latency-svc-mth2q [747.893159ms]
Feb 27 02:25:18.705: INFO: Created: latency-svc-qlmd8
Feb 27 02:25:18.736: INFO: Got endpoints: latency-svc-s9nrs [750.848298ms]
Feb 27 02:25:18.757: INFO: Created: latency-svc-2v7gc
Feb 27 02:25:18.786: INFO: Got endpoints: latency-svc-cp5sk [748.579739ms]
Feb 27 02:25:18.802: INFO: Created: latency-svc-nwxqp
Feb 27 02:25:18.843: INFO: Got endpoints: latency-svc-7r7nv [756.728419ms]
Feb 27 02:25:18.865: INFO: Created: latency-svc-fm6nm
Feb 27 02:25:18.886: INFO: Got endpoints: latency-svc-cbp6p [749.043478ms]
Feb 27 02:25:18.913: INFO: Created: latency-svc-fjq7f
Feb 27 02:25:18.934: INFO: Got endpoints: latency-svc-6247x [746.20813ms]
Feb 27 02:25:18.982: INFO: Created: latency-svc-kcwcx
Feb 27 02:25:18.987: INFO: Got endpoints: latency-svc-r28w4 [752.553439ms]
Feb 27 02:25:19.004: INFO: Created: latency-svc-f6q68
Feb 27 02:25:19.037: INFO: Got endpoints: latency-svc-jzsnd [749.986122ms]
Feb 27 02:25:19.055: INFO: Created: latency-svc-gqf8c
Feb 27 02:25:19.085: INFO: Got endpoints: latency-svc-mfgnr [737.223467ms]
Feb 27 02:25:19.102: INFO: Created: latency-svc-grxm2
Feb 27 02:25:19.135: INFO: Got endpoints: latency-svc-px7sh [748.689701ms]
Feb 27 02:25:19.161: INFO: Created: latency-svc-d9wqq
Feb 27 02:25:19.198: INFO: Got endpoints: latency-svc-x5pt5 [761.713789ms]
Feb 27 02:25:19.213: INFO: Created: latency-svc-89bsc
Feb 27 02:25:19.235: INFO: Got endpoints: latency-svc-5hnbw [747.44096ms]
Feb 27 02:25:19.254: INFO: Created: latency-svc-hsbl4
Feb 27 02:25:19.285: INFO: Got endpoints: latency-svc-96jkg [746.859203ms]
Feb 27 02:25:19.336: INFO: Got endpoints: latency-svc-6w4hv [721.066438ms]
Feb 27 02:25:19.386: INFO: Got endpoints: latency-svc-6xrr6 [748.571232ms]
Feb 27 02:25:19.435: INFO: Got endpoints: latency-svc-qlmd8 [750.065284ms]
Feb 27 02:25:19.488: INFO: Got endpoints: latency-svc-2v7gc [751.87969ms]
Feb 27 02:25:19.535: INFO: Got endpoints: latency-svc-nwxqp [749.535481ms]
Feb 27 02:25:19.586: INFO: Got endpoints: latency-svc-fm6nm [742.324344ms]
Feb 27 02:25:19.635: INFO: Got endpoints: latency-svc-fjq7f [749.033141ms]
Feb 27 02:25:19.686: INFO: Got endpoints: latency-svc-kcwcx [751.366164ms]
Feb 27 02:25:19.736: INFO: Got endpoints: latency-svc-f6q68 [749.406607ms]
Feb 27 02:25:19.790: INFO: Got endpoints: latency-svc-gqf8c [752.488129ms]
Feb 27 02:25:19.836: INFO: Got endpoints: latency-svc-grxm2 [750.989238ms]
Feb 27 02:25:19.885: INFO: Got endpoints: latency-svc-d9wqq [749.612803ms]
Feb 27 02:25:19.939: INFO: Got endpoints: latency-svc-89bsc [740.097115ms]
Feb 27 02:25:19.985: INFO: Got endpoints: latency-svc-hsbl4 [749.99943ms]
Feb 27 02:25:19.985: INFO: Latencies: [20.256857ms 39.478271ms 55.999206ms 82.548281ms 89.799831ms 140.261294ms 177.256788ms 194.164569ms 233.259439ms 351.946675ms 352.924883ms 355.857611ms 356.096395ms 356.760723ms 357.289143ms 359.061709ms 360.915087ms 364.547133ms 364.65986ms 364.876278ms 366.6416ms 367.216817ms 368.045428ms 370.025269ms 372.509673ms 374.674734ms 374.801939ms 377.028241ms 377.053255ms 377.313637ms 379.920116ms 379.944375ms 380.763582ms 380.936633ms 381.124218ms 381.31871ms 382.599553ms 383.679762ms 385.155579ms 385.550046ms 385.8271ms 386.127653ms 387.245995ms 387.353224ms 387.417301ms 387.962689ms 390.084115ms 392.738885ms 396.512695ms 405.615468ms 408.862713ms 423.21751ms 423.415192ms 428.24794ms 439.998692ms 458.733116ms 466.861283ms 468.132083ms 471.412569ms 471.938862ms 483.921088ms 486.094488ms 490.297104ms 498.584865ms 500.526712ms 505.526506ms 534.244972ms 543.158512ms 544.684442ms 558.209623ms 584.663373ms 650.910333ms 654.929501ms 678.89075ms 683.238884ms 688.26236ms 702.321554ms 704.816245ms 705.833681ms 706.192917ms 711.774102ms 721.066438ms 722.461926ms 726.050146ms 728.378205ms 730.074154ms 733.315985ms 734.350484ms 735.299919ms 737.223467ms 738.140101ms 739.73178ms 740.003513ms 740.097115ms 740.865365ms 741.939587ms 742.324344ms 742.567565ms 743.466356ms 743.661058ms 744.015125ms 744.126936ms 744.142054ms 744.37564ms 744.507774ms 744.697901ms 744.893696ms 745.030788ms 745.739725ms 746.20813ms 746.859203ms 747.44096ms 747.643631ms 747.720467ms 747.893159ms 748.01297ms 748.018749ms 748.484977ms 748.548429ms 748.55349ms 748.560437ms 748.571232ms 748.579739ms 748.689701ms 748.755722ms 748.830821ms 748.878814ms 748.95388ms 749.033141ms 749.043478ms 749.125291ms 749.207523ms 749.281225ms 749.406607ms 749.449448ms 749.450887ms 749.459918ms 749.483652ms 749.535481ms 749.612803ms 749.789119ms 749.79628ms 749.892955ms 749.939508ms 749.959018ms 749.986122ms 749.99943ms 750.032083ms 750.045593ms 750.049298ms 750.065284ms 750.144811ms 750.155803ms 750.23396ms 750.381431ms 750.556979ms 750.631442ms 750.737376ms 750.760989ms 750.848298ms 750.921642ms 750.945908ms 750.989238ms 751.144839ms 751.209414ms 751.218973ms 751.366164ms 751.766594ms 751.87969ms 751.981341ms 752.006618ms 752.094379ms 752.274493ms 752.488129ms 752.553439ms 753.806271ms 753.854956ms 753.934875ms 753.967929ms 754.572153ms 754.694299ms 754.932545ms 755.371508ms 755.447701ms 756.118503ms 756.728419ms 758.324383ms 759.107302ms 759.746343ms 760.143899ms 760.967922ms 761.713789ms 762.268217ms 763.641325ms 771.232301ms 772.932315ms 780.802459ms 787.74276ms 799.069356ms 846.731058ms]
Feb 27 02:25:19.985: INFO: 50 %ile: 744.015125ms
Feb 27 02:25:19.985: INFO: 90 %ile: 754.694299ms
Feb 27 02:25:19.985: INFO: 99 %ile: 799.069356ms
Feb 27 02:25:19.985: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:25:19.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-5ktqv" for this suite.
Feb 27 02:25:40.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:25:40.072: INFO: namespace: e2e-tests-svc-latency-5ktqv, resource: bindings, ignored listing per whitelist
Feb 27 02:25:40.089: INFO: namespace e2e-tests-svc-latency-5ktqv deletion completed in 20.097388293s

• [SLOW TEST:31.874 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:25:40.089: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-pbkk2 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-pbkk2;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-pbkk2 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-pbkk2;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-pbkk2.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-pbkk2.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-pbkk2.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-pbkk2.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-pbkk2.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-pbkk2.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-pbkk2.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-pbkk2.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-pbkk2.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 223.158.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.158.223_udp@PTR;check="$$(dig +tcp +noall +answer +search 223.158.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.158.223_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-pbkk2 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-pbkk2;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-pbkk2 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-pbkk2.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-pbkk2.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-pbkk2.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-pbkk2.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-pbkk2.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-pbkk2.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-pbkk2.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-pbkk2.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 223.158.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.158.223_udp@PTR;check="$$(dig +tcp +noall +answer +search 223.158.109.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.109.158.223_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 27 02:25:56.206: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:25:56.208: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:25:56.262: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:25:56.264: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:25:56.267: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-pbkk2 from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:25:56.269: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2 from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:25:56.271: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:25:56.273: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:25:56.275: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:25:56.278: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:25:56.290: INFO: Lookups using e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-pbkk2 jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2 jessie_udp@dns-test-service.e2e-tests-dns-pbkk2.svc jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc]

Feb 27 02:26:01.294: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:01.296: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:01.324: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:01.326: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:01.329: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-pbkk2 from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:01.331: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2 from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:01.333: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:01.335: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:01.337: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:01.339: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:01.352: INFO: Lookups using e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-pbkk2 jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2 jessie_udp@dns-test-service.e2e-tests-dns-pbkk2.svc jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc]

Feb 27 02:26:06.295: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:06.298: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:06.327: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:06.329: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:06.331: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-pbkk2 from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:06.334: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2 from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:06.336: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:06.338: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:06.340: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:06.342: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:06.355: INFO: Lookups using e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-pbkk2 jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2 jessie_udp@dns-test-service.e2e-tests-dns-pbkk2.svc jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc]

Feb 27 02:26:11.294: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:11.297: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:11.325: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:11.327: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:11.329: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-pbkk2 from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:11.331: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2 from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:11.333: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:11.335: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:11.338: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:11.340: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc from pod e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8: the server could not find the requested resource (get pods dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8)
Feb 27 02:26:11.352: INFO: Lookups using e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-pbkk2 jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2 jessie_udp@dns-test-service.e2e-tests-dns-pbkk2.svc jessie_tcp@dns-test-service.e2e-tests-dns-pbkk2.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pbkk2.svc]

Feb 27 02:26:16.358: INFO: DNS probes using e2e-tests-dns-pbkk2/dns-test-f998d7e9-3a36-11e9-8c03-2a4c52047ee8 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:26:16.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-pbkk2" for this suite.
Feb 27 02:26:22.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:26:22.475: INFO: namespace: e2e-tests-dns-pbkk2, resource: bindings, ignored listing per whitelist
Feb 27 02:26:22.505: INFO: namespace e2e-tests-dns-pbkk2 deletion completed in 6.078833909s

• [SLOW TEST:42.416 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:26:22.505: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:26:22.565: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12dd1c18-3a37-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-pfwwx" to be "success or failure"
Feb 27 02:26:22.570: INFO: Pod "downwardapi-volume-12dd1c18-3a37-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.576472ms
Feb 27 02:26:24.573: INFO: Pod "downwardapi-volume-12dd1c18-3a37-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008087668s
Feb 27 02:26:26.576: INFO: Pod "downwardapi-volume-12dd1c18-3a37-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011103257s
STEP: Saw pod success
Feb 27 02:26:26.576: INFO: Pod "downwardapi-volume-12dd1c18-3a37-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:26:26.578: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downwardapi-volume-12dd1c18-3a37-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 02:26:26.594: INFO: Waiting for pod downwardapi-volume-12dd1c18-3a37-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:26:26.600: INFO: Pod downwardapi-volume-12dd1c18-3a37-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:26:26.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pfwwx" for this suite.
Feb 27 02:26:32.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:26:32.652: INFO: namespace: e2e-tests-downward-api-pfwwx, resource: bindings, ignored listing per whitelist
Feb 27 02:26:32.671: INFO: namespace e2e-tests-downward-api-pfwwx deletion completed in 6.068195824s

• [SLOW TEST:10.165 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:26:32.671: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:26:32.737: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18eccbb9-3a37-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-5sp7w" to be "success or failure"
Feb 27 02:26:32.741: INFO: Pod "downwardapi-volume-18eccbb9-3a37-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027503ms
Feb 27 02:26:34.744: INFO: Pod "downwardapi-volume-18eccbb9-3a37-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006864081s
Feb 27 02:26:36.746: INFO: Pod "downwardapi-volume-18eccbb9-3a37-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009697439s
STEP: Saw pod success
Feb 27 02:26:36.746: INFO: Pod "downwardapi-volume-18eccbb9-3a37-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:26:36.748: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod downwardapi-volume-18eccbb9-3a37-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 02:26:36.762: INFO: Waiting for pod downwardapi-volume-18eccbb9-3a37-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:26:36.763: INFO: Pod downwardapi-volume-18eccbb9-3a37-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:26:36.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5sp7w" for this suite.
Feb 27 02:26:42.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:26:42.809: INFO: namespace: e2e-tests-downward-api-5sp7w, resource: bindings, ignored listing per whitelist
Feb 27 02:26:42.835: INFO: namespace e2e-tests-downward-api-5sp7w deletion completed in 6.069212068s

• [SLOW TEST:10.164 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:26:42.835: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:26:42.890: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:26:47.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dcbvv" for this suite.
Feb 27 02:27:33.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:27:33.158: INFO: namespace: e2e-tests-pods-dcbvv, resource: bindings, ignored listing per whitelist
Feb 27 02:27:33.178: INFO: namespace e2e-tests-pods-dcbvv deletion completed in 46.088109993s

• [SLOW TEST:50.343 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:27:33.179: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 27 02:27:33.244: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-a,UID:3cfe0a35-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11267,Generation:0,CreationTimestamp:2019-02-27 02:27:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 02:27:33.244: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-a,UID:3cfe0a35-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11267,Generation:0,CreationTimestamp:2019-02-27 02:27:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 27 02:27:43.252: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-a,UID:3cfe0a35-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11282,Generation:0,CreationTimestamp:2019-02-27 02:27:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 27 02:27:43.252: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-a,UID:3cfe0a35-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11282,Generation:0,CreationTimestamp:2019-02-27 02:27:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 27 02:27:53.258: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-a,UID:3cfe0a35-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11297,Generation:0,CreationTimestamp:2019-02-27 02:27:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 02:27:53.258: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-a,UID:3cfe0a35-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11297,Generation:0,CreationTimestamp:2019-02-27 02:27:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 27 02:28:03.264: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-a,UID:3cfe0a35-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11312,Generation:0,CreationTimestamp:2019-02-27 02:27:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 02:28:03.264: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-a,UID:3cfe0a35-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11312,Generation:0,CreationTimestamp:2019-02-27 02:27:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 27 02:28:13.269: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-b,UID:54d91123-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11327,Generation:0,CreationTimestamp:2019-02-27 02:28:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 02:28:13.269: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-b,UID:54d91123-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11327,Generation:0,CreationTimestamp:2019-02-27 02:28:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 27 02:28:23.277: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-b,UID:54d91123-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11342,Generation:0,CreationTimestamp:2019-02-27 02:28:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 02:28:23.277: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-7ggqd,SelfLink:/api/v1/namespaces/e2e-tests-watch-7ggqd/configmaps/e2e-watch-test-configmap-b,UID:54d91123-3a37-11e9-8378-02ce1f9c2c90,ResourceVersion:11342,Generation:0,CreationTimestamp:2019-02-27 02:28:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:28:33.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-7ggqd" for this suite.
Feb 27 02:28:39.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:28:39.327: INFO: namespace: e2e-tests-watch-7ggqd, resource: bindings, ignored listing per whitelist
Feb 27 02:28:39.349: INFO: namespace e2e-tests-watch-7ggqd deletion completed in 6.068484104s

• [SLOW TEST:66.170 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:28:39.349: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 02:28:39.412: INFO: Waiting up to 5m0s for pod "downward-api-646e094c-3a37-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-lrbnc" to be "success or failure"
Feb 27 02:28:39.416: INFO: Pod "downward-api-646e094c-3a37-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.564528ms
Feb 27 02:28:41.418: INFO: Pod "downward-api-646e094c-3a37-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006202108s
Feb 27 02:28:43.421: INFO: Pod "downward-api-646e094c-3a37-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009300858s
STEP: Saw pod success
Feb 27 02:28:43.421: INFO: Pod "downward-api-646e094c-3a37-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:28:43.423: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod downward-api-646e094c-3a37-11e9-8c03-2a4c52047ee8 container dapi-container: <nil>
STEP: delete the pod
Feb 27 02:28:43.438: INFO: Waiting for pod downward-api-646e094c-3a37-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:28:43.444: INFO: Pod downward-api-646e094c-3a37-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:28:43.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lrbnc" for this suite.
Feb 27 02:28:49.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:28:49.510: INFO: namespace: e2e-tests-downward-api-lrbnc, resource: bindings, ignored listing per whitelist
Feb 27 02:28:49.522: INFO: namespace e2e-tests-downward-api-lrbnc deletion completed in 6.075539243s

• [SLOW TEST:10.173 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:28:49.523: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:28:54.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-tdjrf" for this suite.
Feb 27 02:29:16.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:29:16.666: INFO: namespace: e2e-tests-replication-controller-tdjrf, resource: bindings, ignored listing per whitelist
Feb 27 02:29:16.671: INFO: namespace e2e-tests-replication-controller-tdjrf deletion completed in 22.064710749s

• [SLOW TEST:27.148 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:29:16.671: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 27 02:29:16.743: INFO: Waiting up to 5m0s for pod "pod-7aae0a66-3a37-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-tgjhv" to be "success or failure"
Feb 27 02:29:16.746: INFO: Pod "pod-7aae0a66-3a37-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.675897ms
Feb 27 02:29:18.749: INFO: Pod "pod-7aae0a66-3a37-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005818292s
Feb 27 02:29:20.752: INFO: Pod "pod-7aae0a66-3a37-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008699329s
STEP: Saw pod success
Feb 27 02:29:20.752: INFO: Pod "pod-7aae0a66-3a37-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:29:20.754: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-7aae0a66-3a37-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 02:29:20.767: INFO: Waiting for pod pod-7aae0a66-3a37-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:29:20.769: INFO: Pod pod-7aae0a66-3a37-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:29:20.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tgjhv" for this suite.
Feb 27 02:29:26.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:29:26.805: INFO: namespace: e2e-tests-emptydir-tgjhv, resource: bindings, ignored listing per whitelist
Feb 27 02:29:26.849: INFO: namespace e2e-tests-emptydir-tgjhv deletion completed in 6.077504802s

• [SLOW TEST:10.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:29:26.849: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 02:29:31.434: INFO: Successfully updated pod "labelsupdate80bdc411-3a37-11e9-8c03-2a4c52047ee8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:29:33.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ksjsq" for this suite.
Feb 27 02:29:55.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:29:55.525: INFO: namespace: e2e-tests-downward-api-ksjsq, resource: bindings, ignored listing per whitelist
Feb 27 02:29:55.551: INFO: namespace e2e-tests-downward-api-ksjsq deletion completed in 22.09361917s

• [SLOW TEST:28.702 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:29:55.552: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zkcnb
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-zkcnb
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-zkcnb
Feb 27 02:29:55.636: INFO: Found 0 stateful pods, waiting for 1
Feb 27 02:30:05.640: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 27 02:30:05.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:30:05.912: INFO: stderr: ""
Feb 27 02:30:05.913: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:30:05.913: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:30:05.916: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 27 02:30:15.919: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:30:15.919: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:30:15.930: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:15.930: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:15.930: INFO: 
Feb 27 02:30:15.930: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 27 02:30:16.933: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996281045s
Feb 27 02:30:17.936: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992985649s
Feb 27 02:30:18.940: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989646671s
Feb 27 02:30:19.944: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986199516s
Feb 27 02:30:20.947: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98218052s
Feb 27 02:30:21.950: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.978763809s
Feb 27 02:30:22.954: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.975503939s
Feb 27 02:30:23.959: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.972221446s
Feb 27 02:30:24.963: INFO: Verifying statefulset ss doesn't scale past 3 for another 966.4228ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-zkcnb
Feb 27 02:30:25.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:30:26.264: INFO: stderr: ""
Feb 27 02:30:26.264: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:30:26.264: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:30:26.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:30:26.515: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 27 02:30:26.515: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:30:26.515: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:30:26.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:30:26.878: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 27 02:30:26.878: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:30:26.878: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:30:26.880: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:30:26.880: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:30:26.880: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 27 02:30:26.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:30:27.159: INFO: stderr: ""
Feb 27 02:30:27.159: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:30:27.160: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:30:27.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:30:27.414: INFO: stderr: ""
Feb 27 02:30:27.414: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:30:27.414: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:30:27.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:30:27.754: INFO: stderr: ""
Feb 27 02:30:27.754: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:30:27.755: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:30:27.755: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:30:27.763: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 27 02:30:37.769: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:30:37.769: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:30:37.769: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:30:37.785: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:37.785: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:37.785: INFO: ss-1  ip-10-0-12-40.us-west-2.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  }]
Feb 27 02:30:37.785: INFO: ss-2  ip-10-0-30-134.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  }]
Feb 27 02:30:37.785: INFO: 
Feb 27 02:30:37.785: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 27 02:30:38.788: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:38.788: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:38.789: INFO: ss-1  ip-10-0-12-40.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  }]
Feb 27 02:30:38.789: INFO: ss-2  ip-10-0-30-134.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  }]
Feb 27 02:30:38.789: INFO: 
Feb 27 02:30:38.789: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 27 02:30:39.793: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:39.793: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:39.793: INFO: ss-1  ip-10-0-12-40.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  }]
Feb 27 02:30:39.793: INFO: ss-2  ip-10-0-30-134.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:15 +0000 UTC  }]
Feb 27 02:30:39.793: INFO: 
Feb 27 02:30:39.793: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 27 02:30:40.796: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:40.796: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:40.796: INFO: 
Feb 27 02:30:40.796: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 27 02:30:41.799: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:41.799: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:41.799: INFO: 
Feb 27 02:30:41.799: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 27 02:30:42.802: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:42.802: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:42.802: INFO: 
Feb 27 02:30:42.802: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 27 02:30:43.805: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:43.805: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:43.805: INFO: 
Feb 27 02:30:43.805: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 27 02:30:44.808: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:44.808: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:44.808: INFO: 
Feb 27 02:30:44.808: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 27 02:30:45.812: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:45.812: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:45.812: INFO: 
Feb 27 02:30:45.812: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 27 02:30:46.815: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 27 02:30:46.815: INFO: ss-0  ip-10-0-30-134.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:30:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:29:55 +0000 UTC  }]
Feb 27 02:30:46.815: INFO: 
Feb 27 02:30:46.815: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-zkcnb
Feb 27 02:30:47.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:30:47.915: INFO: rc: 1
Feb 27 02:30:47.915: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001853bc0 exit status 1 <nil> <nil> true [0xc000972458 0xc000972490 0xc0009724a8] [0xc000972458 0xc000972490 0xc0009724a8] [0xc000972488 0xc0009724a0] [0x92f8e0 0x92f8e0] 0xc0019af860 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb 27 02:30:57.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:30:57.978: INFO: rc: 1
Feb 27 02:30:57.978: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0009964e0 exit status 1 <nil> <nil> true [0xc000b5bc20 0xc000b5bca8 0xc000b5bcf0] [0xc000b5bc20 0xc000b5bca8 0xc000b5bcf0] [0xc000b5bc50 0xc000b5bcd8] [0x92f8e0 0x92f8e0] 0xc0020ae5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:31:07.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:31:08.042: INFO: rc: 1
Feb 27 02:31:08.043: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000a22000 exit status 1 <nil> <nil> true [0xc0009724b0 0xc0009724d8 0xc000972518] [0xc0009724b0 0xc0009724d8 0xc000972518] [0xc0009724d0 0xc000972510] [0x92f8e0 0x92f8e0] 0xc0019afb60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:31:18.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:31:18.106: INFO: rc: 1
Feb 27 02:31:18.107: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000996900 exit status 1 <nil> <nil> true [0xc000b5bcf8 0xc000b5bd78 0xc000b5bdd8] [0xc000b5bcf8 0xc000b5bd78 0xc000b5bdd8] [0xc000b5bd60 0xc000b5bd98] [0x92f8e0 0x92f8e0] 0xc0020aec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:31:28.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:31:28.171: INFO: rc: 1
Feb 27 02:31:28.171: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000996cc0 exit status 1 <nil> <nil> true [0xc000b5bdf8 0xc000b5be88 0xc000b5bed8] [0xc000b5bdf8 0xc000b5be88 0xc000b5bed8] [0xc000b5be80 0xc000b5beb8] [0x92f8e0 0x92f8e0] 0xc0020af260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:31:38.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:31:38.236: INFO: rc: 1
Feb 27 02:31:38.236: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0009971d0 exit status 1 <nil> <nil> true [0xc000b5bf00 0xc000b5bf58 0xc000b5bf88] [0xc000b5bf00 0xc000b5bf58 0xc000b5bf88] [0xc000b5bf40 0xc000b5bf80] [0x92f8e0 0x92f8e0] 0xc0020af620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:31:48.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:31:48.300: INFO: rc: 1
Feb 27 02:31:48.300: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000997560 exit status 1 <nil> <nil> true [0xc000b5bf98 0xc0004e4138 0xc0004e42f0] [0xc000b5bf98 0xc0004e4138 0xc0004e42f0] [0xc000b5bfd8 0xc0004e41b8] [0x92f8e0 0x92f8e0] 0xc0020afb60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:31:58.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:31:58.364: INFO: rc: 1
Feb 27 02:31:58.364: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000997920 exit status 1 <nil> <nil> true [0xc0004e4760 0xc0004e4ac8 0xc0004e4b78] [0xc0004e4760 0xc0004e4ac8 0xc0004e4b78] [0xc0004e4a78 0xc0004e4b10] [0x92f8e0 0x92f8e0] 0xc00211c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:32:08.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:32:08.431: INFO: rc: 1
Feb 27 02:32:08.431: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000997fb0 exit status 1 <nil> <nil> true [0xc0004e4bc8 0xc0004e4de8 0xc0004e5020] [0xc0004e4bc8 0xc0004e4de8 0xc0004e5020] [0xc0004e4d78 0xc0004e4fb8] [0x92f8e0 0x92f8e0] 0xc00211c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:32:18.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:32:18.498: INFO: rc: 1
Feb 27 02:32:18.499: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000a223f0 exit status 1 <nil> <nil> true [0xc000972520 0xc000972560 0xc000972578] [0xc000972520 0xc000972560 0xc000972578] [0xc000972548 0xc000972570] [0x92f8e0 0x92f8e0] 0xc0019afe60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:32:28.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:32:28.563: INFO: rc: 1
Feb 27 02:32:28.563: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000996420 exit status 1 <nil> <nil> true [0xc000b5a0a0 0xc000b5a218 0xc000b5a480] [0xc000b5a0a0 0xc000b5a218 0xc000b5a480] [0xc000b5a1b8 0xc000b5a470] [0x92f8e0 0x92f8e0] 0xc0020ae240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:32:38.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:32:38.628: INFO: rc: 1
Feb 27 02:32:38.628: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000996870 exit status 1 <nil> <nil> true [0xc000b5a4c0 0xc000b5a898 0xc000b5aa38] [0xc000b5a4c0 0xc000b5a898 0xc000b5aa38] [0xc000b5a6b0 0xc000b5a9c8] [0x92f8e0 0x92f8e0] 0xc0020ae5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:32:48.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:32:48.694: INFO: rc: 1
Feb 27 02:32:48.694: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018523c0 exit status 1 <nil> <nil> true [0xc0004e4138 0xc0004e42f0 0xc0004e4a78] [0xc0004e4138 0xc0004e42f0 0xc0004e4a78] [0xc0004e41b8 0xc0004e4a70] [0x92f8e0 0x92f8e0] 0xc001a4a3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:32:58.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:32:58.757: INFO: rc: 1
Feb 27 02:32:58.757: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001852780 exit status 1 <nil> <nil> true [0xc0004e4ac8 0xc0004e4b78 0xc0004e4d78] [0xc0004e4ac8 0xc0004e4b78 0xc0004e4d78] [0xc0004e4b10 0xc0004e4d18] [0x92f8e0 0x92f8e0] 0xc001a4a720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:33:08.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:33:08.822: INFO: rc: 1
Feb 27 02:33:08.822: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001852b70 exit status 1 <nil> <nil> true [0xc0004e4de8 0xc0004e5020 0xc0004e51a8] [0xc0004e4de8 0xc0004e5020 0xc0004e51a8] [0xc0004e4fb8 0xc0004e5100] [0x92f8e0 0x92f8e0] 0xc001a4aa20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:33:18.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:33:18.886: INFO: rc: 1
Feb 27 02:33:18.886: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018530e0 exit status 1 <nil> <nil> true [0xc0004e55e8 0xc0004e5760 0xc0004e5898] [0xc0004e55e8 0xc0004e5760 0xc0004e5898] [0xc0004e56d8 0xc0004e5800] [0x92f8e0 0x92f8e0] 0xc001a4ad20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:33:28.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:33:28.949: INFO: rc: 1
Feb 27 02:33:28.949: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001853530 exit status 1 <nil> <nil> true [0xc0004e5930 0xc0004e5ad8 0xc0004e5b08] [0xc0004e5930 0xc0004e5ad8 0xc0004e5b08] [0xc0004e5a60 0xc0004e5ae8] [0x92f8e0 0x92f8e0] 0xc001a4b020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:33:38.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:33:39.017: INFO: rc: 1
Feb 27 02:33:39.017: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001853ad0 exit status 1 <nil> <nil> true [0xc0004e5bd8 0xc0004e5cc8 0xc0004e5ce8] [0xc0004e5bd8 0xc0004e5cc8 0xc0004e5ce8] [0xc0004e5cb0 0xc0004e5ce0] [0x92f8e0 0x92f8e0] 0xc001a4b380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:33:49.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:33:49.080: INFO: rc: 1
Feb 27 02:33:49.080: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000996c90 exit status 1 <nil> <nil> true [0xc000b5aa88 0xc000b5ac70 0xc000b5ada0] [0xc000b5aa88 0xc000b5ac70 0xc000b5ada0] [0xc000b5ac10 0xc000b5ad18] [0x92f8e0 0x92f8e0] 0xc0020aec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:33:59.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:33:59.148: INFO: rc: 1
Feb 27 02:33:59.148: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000997200 exit status 1 <nil> <nil> true [0xc000b5ae30 0xc000b5af00 0xc000b5aff0] [0xc000b5ae30 0xc000b5af00 0xc000b5aff0] [0xc000b5aeb8 0xc000b5af50] [0x92f8e0 0x92f8e0] 0xc0020af260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:34:09.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:34:09.216: INFO: rc: 1
Feb 27 02:34:09.216: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0009975f0 exit status 1 <nil> <nil> true [0xc000b5b000 0xc000b5b1d0 0xc000b5b4c8] [0xc000b5b000 0xc000b5b1d0 0xc000b5b4c8] [0xc000b5b078 0xc000b5b390] [0x92f8e0 0x92f8e0] 0xc0020af620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:34:19.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:34:19.281: INFO: rc: 1
Feb 27 02:34:19.281: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000997b30 exit status 1 <nil> <nil> true [0xc000b5b548 0xc000b5b570 0xc000b5b6a0] [0xc000b5b548 0xc000b5b570 0xc000b5b6a0] [0xc000b5b558 0xc000b5b618] [0x92f8e0 0x92f8e0] 0xc0020afb60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:34:29.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:34:29.357: INFO: rc: 1
Feb 27 02:34:29.357: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001853e90 exit status 1 <nil> <nil> true [0xc0004e5d18 0xc0004e5d50 0xc0004e5da8] [0xc0004e5d18 0xc0004e5d50 0xc0004e5da8] [0xc0004e5d48 0xc0004e5da0] [0x92f8e0 0x92f8e0] 0xc001a4b980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:34:39.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:34:39.421: INFO: rc: 1
Feb 27 02:34:39.421: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000996450 exit status 1 <nil> <nil> true [0xc000b5a040 0xc000b5a1b8 0xc000b5a470] [0xc000b5a040 0xc000b5a1b8 0xc000b5a470] [0xc000b5a0e0 0xc000b5a2d8] [0x92f8e0 0x92f8e0] 0xc0020ae240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:34:49.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:34:49.494: INFO: rc: 1
Feb 27 02:34:49.494: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018523f0 exit status 1 <nil> <nil> true [0xc0004e4138 0xc0004e42f0 0xc0004e4a78] [0xc0004e4138 0xc0004e42f0 0xc0004e4a78] [0xc0004e41b8 0xc0004e4a70] [0x92f8e0 0x92f8e0] 0xc001a4a3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:34:59.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:34:59.560: INFO: rc: 1
Feb 27 02:34:59.560: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018527e0 exit status 1 <nil> <nil> true [0xc0004e4ac8 0xc0004e4b78 0xc0004e4d78] [0xc0004e4ac8 0xc0004e4b78 0xc0004e4d78] [0xc0004e4b10 0xc0004e4d18] [0x92f8e0 0x92f8e0] 0xc001a4a720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:35:09.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:35:09.627: INFO: rc: 1
Feb 27 02:35:09.628: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000996900 exit status 1 <nil> <nil> true [0xc000b5a480 0xc000b5a6b0 0xc000b5a9c8] [0xc000b5a480 0xc000b5a6b0 0xc000b5a9c8] [0xc000b5a538 0xc000b5a8e8] [0x92f8e0 0x92f8e0] 0xc0020ae5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:35:19.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:35:19.699: INFO: rc: 1
Feb 27 02:35:19.699: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001852bd0 exit status 1 <nil> <nil> true [0xc0004e4de8 0xc0004e5020 0xc0004e51a8] [0xc0004e4de8 0xc0004e5020 0xc0004e51a8] [0xc0004e4fb8 0xc0004e5100] [0x92f8e0 0x92f8e0] 0xc001a4aa20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:35:29.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:35:29.763: INFO: rc: 1
Feb 27 02:35:29.763: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000996d20 exit status 1 <nil> <nil> true [0xc000b5aa38 0xc000b5ac10 0xc000b5ad18] [0xc000b5aa38 0xc000b5ac10 0xc000b5ad18] [0xc000b5ab98 0xc000b5aca8] [0x92f8e0 0x92f8e0] 0xc0020aec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:35:39.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:35:39.828: INFO: rc: 1
Feb 27 02:35:39.828: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001853140 exit status 1 <nil> <nil> true [0xc0004e55e8 0xc0004e5760 0xc0004e5898] [0xc0004e55e8 0xc0004e5760 0xc0004e5898] [0xc0004e56d8 0xc0004e5800] [0x92f8e0 0x92f8e0] 0xc001a4ad20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 27 02:35:49.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-zkcnb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:35:49.894: INFO: rc: 1
Feb 27 02:35:49.894: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Feb 27 02:35:49.894: INFO: Scaling statefulset ss to 0
Feb 27 02:35:49.901: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 02:35:49.904: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zkcnb
Feb 27 02:35:49.906: INFO: Scaling statefulset ss to 0
Feb 27 02:35:49.915: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:35:49.917: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:35:49.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zkcnb" for this suite.
Feb 27 02:35:55.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:35:55.974: INFO: namespace: e2e-tests-statefulset-zkcnb, resource: bindings, ignored listing per whitelist
Feb 27 02:35:56.014: INFO: namespace e2e-tests-statefulset-zkcnb deletion completed in 6.076508287s

• [SLOW TEST:360.462 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:35:56.016: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:36:56.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mh7h7" for this suite.
Feb 27 02:37:18.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:37:18.112: INFO: namespace: e2e-tests-container-probe-mh7h7, resource: bindings, ignored listing per whitelist
Feb 27 02:37:18.152: INFO: namespace e2e-tests-container-probe-mh7h7 deletion completed in 22.067811097s

• [SLOW TEST:82.137 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:37:18.153: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 27 02:37:18.230: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-l7nh6,SelfLink:/api/v1/namespaces/e2e-tests-watch-l7nh6/configmaps/e2e-watch-test-resource-version,UID:99a8e42a-3a38-11e9-8378-02ce1f9c2c90,ResourceVersion:12411,Generation:0,CreationTimestamp:2019-02-27 02:37:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 02:37:18.230: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-l7nh6,SelfLink:/api/v1/namespaces/e2e-tests-watch-l7nh6/configmaps/e2e-watch-test-resource-version,UID:99a8e42a-3a38-11e9-8378-02ce1f9c2c90,ResourceVersion:12412,Generation:0,CreationTimestamp:2019-02-27 02:37:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:37:18.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-l7nh6" for this suite.
Feb 27 02:37:24.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:37:24.298: INFO: namespace: e2e-tests-watch-l7nh6, resource: bindings, ignored listing per whitelist
Feb 27 02:37:24.301: INFO: namespace e2e-tests-watch-l7nh6 deletion completed in 6.068763021s

• [SLOW TEST:6.148 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:37:24.302: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:37:28.402: INFO: Waiting up to 5m0s for pod "client-envvars-9fbb139d-3a38-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-pods-nn5sq" to be "success or failure"
Feb 27 02:37:28.410: INFO: Pod "client-envvars-9fbb139d-3a38-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.511787ms
Feb 27 02:37:30.413: INFO: Pod "client-envvars-9fbb139d-3a38-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011445513s
Feb 27 02:37:32.416: INFO: Pod "client-envvars-9fbb139d-3a38-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014430756s
STEP: Saw pod success
Feb 27 02:37:32.416: INFO: Pod "client-envvars-9fbb139d-3a38-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:37:32.418: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod client-envvars-9fbb139d-3a38-11e9-8c03-2a4c52047ee8 container env3cont: <nil>
STEP: delete the pod
Feb 27 02:37:32.436: INFO: Waiting for pod client-envvars-9fbb139d-3a38-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:37:32.439: INFO: Pod client-envvars-9fbb139d-3a38-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:37:32.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nn5sq" for this suite.
Feb 27 02:38:10.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:38:10.458: INFO: namespace: e2e-tests-pods-nn5sq, resource: bindings, ignored listing per whitelist
Feb 27 02:38:10.507: INFO: namespace e2e-tests-pods-nn5sq deletion completed in 38.065466028s

• [SLOW TEST:46.206 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:38:10.508: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 27 02:38:10.563: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-861261599 proxy --unix-socket=/tmp/kubectl-proxy-unix487085554/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:38:10.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n7pmv" for this suite.
Feb 27 02:38:16.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:38:16.667: INFO: namespace: e2e-tests-kubectl-n7pmv, resource: bindings, ignored listing per whitelist
Feb 27 02:38:16.684: INFO: namespace e2e-tests-kubectl-n7pmv deletion completed in 6.065525183s

• [SLOW TEST:6.176 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:38:16.684: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:38:16.784: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"bc8e5020-3a38-11e9-8378-02ce1f9c2c90", Controller:(*bool)(0xc001a46b2e), BlockOwnerDeletion:(*bool)(0xc001a46b2f)}}
Feb 27 02:38:16.809: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"bc8c7783-3a38-11e9-8378-02ce1f9c2c90", Controller:(*bool)(0xc000bb815e), BlockOwnerDeletion:(*bool)(0xc000bb815f)}}
Feb 27 02:38:16.814: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"bc8cd7e5-3a38-11e9-8378-02ce1f9c2c90", Controller:(*bool)(0xc001a46d1e), BlockOwnerDeletion:(*bool)(0xc001a46d1f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:38:21.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-j8grb" for this suite.
Feb 27 02:38:27.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:38:27.907: INFO: namespace: e2e-tests-gc-j8grb, resource: bindings, ignored listing per whitelist
Feb 27 02:38:27.949: INFO: namespace e2e-tests-gc-j8grb deletion completed in 6.115985042s

• [SLOW TEST:11.265 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:38:27.949: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 27 02:38:28.039: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hf228,SelfLink:/api/v1/namespaces/e2e-tests-watch-hf228/configmaps/e2e-watch-test-watch-closed,UID:c346e2f0-3a38-11e9-8378-02ce1f9c2c90,ResourceVersion:12614,Generation:0,CreationTimestamp:2019-02-27 02:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 02:38:28.039: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hf228,SelfLink:/api/v1/namespaces/e2e-tests-watch-hf228/configmaps/e2e-watch-test-watch-closed,UID:c346e2f0-3a38-11e9-8378-02ce1f9c2c90,ResourceVersion:12615,Generation:0,CreationTimestamp:2019-02-27 02:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 27 02:38:28.048: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hf228,SelfLink:/api/v1/namespaces/e2e-tests-watch-hf228/configmaps/e2e-watch-test-watch-closed,UID:c346e2f0-3a38-11e9-8378-02ce1f9c2c90,ResourceVersion:12616,Generation:0,CreationTimestamp:2019-02-27 02:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 02:38:28.048: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hf228,SelfLink:/api/v1/namespaces/e2e-tests-watch-hf228/configmaps/e2e-watch-test-watch-closed,UID:c346e2f0-3a38-11e9-8378-02ce1f9c2c90,ResourceVersion:12617,Generation:0,CreationTimestamp:2019-02-27 02:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:38:28.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-hf228" for this suite.
Feb 27 02:38:34.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:38:34.112: INFO: namespace: e2e-tests-watch-hf228, resource: bindings, ignored listing per whitelist
Feb 27 02:38:34.118: INFO: namespace e2e-tests-watch-hf228 deletion completed in 6.067215489s

• [SLOW TEST:6.169 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:38:34.118: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:38:34.175: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6ef0ffb-3a38-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-tqz24" to be "success or failure"
Feb 27 02:38:34.178: INFO: Pod "downwardapi-volume-c6ef0ffb-3a38-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.789259ms
Feb 27 02:38:36.181: INFO: Pod "downwardapi-volume-c6ef0ffb-3a38-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005987087s
Feb 27 02:38:38.184: INFO: Pod "downwardapi-volume-c6ef0ffb-3a38-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008809882s
STEP: Saw pod success
Feb 27 02:38:38.184: INFO: Pod "downwardapi-volume-c6ef0ffb-3a38-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:38:38.186: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downwardapi-volume-c6ef0ffb-3a38-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 02:38:38.204: INFO: Waiting for pod downwardapi-volume-c6ef0ffb-3a38-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:38:38.206: INFO: Pod downwardapi-volume-c6ef0ffb-3a38-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:38:38.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tqz24" for this suite.
Feb 27 02:38:44.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:38:44.236: INFO: namespace: e2e-tests-downward-api-tqz24, resource: bindings, ignored listing per whitelist
Feb 27 02:38:44.276: INFO: namespace e2e-tests-downward-api-tqz24 deletion completed in 6.067585684s

• [SLOW TEST:10.158 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:38:44.276: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 27 02:38:44.373: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:38:44.375: INFO: Number of nodes with available pods: 0
Feb 27 02:38:44.375: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:38:45.411: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:38:45.417: INFO: Number of nodes with available pods: 0
Feb 27 02:38:45.417: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:38:46.379: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:38:46.381: INFO: Number of nodes with available pods: 0
Feb 27 02:38:46.381: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:38:47.378: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:38:47.380: INFO: Number of nodes with available pods: 2
Feb 27 02:38:47.380: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 27 02:38:47.392: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:38:47.402: INFO: Number of nodes with available pods: 1
Feb 27 02:38:47.402: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:38:48.405: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:38:48.412: INFO: Number of nodes with available pods: 1
Feb 27 02:38:48.412: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:38:49.405: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:38:49.407: INFO: Number of nodes with available pods: 1
Feb 27 02:38:49.407: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 02:38:50.405: INFO: DaemonSet pods can't tolerate node ip-10-0-28-244.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:38:50.407: INFO: Number of nodes with available pods: 2
Feb 27 02:38:50.407: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-4gnzs, will wait for the garbage collector to delete the pods
Feb 27 02:38:50.467: INFO: Deleting DaemonSet.extensions daemon-set took: 4.724724ms
Feb 27 02:38:50.567: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.208877ms
Feb 27 02:39:29.569: INFO: Number of nodes with available pods: 0
Feb 27 02:39:29.569: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 02:39:29.571: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4gnzs/daemonsets","resourceVersion":"12787"},"items":null}

Feb 27 02:39:29.573: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4gnzs/pods","resourceVersion":"12787"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:39:29.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4gnzs" for this suite.
Feb 27 02:39:35.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:39:35.662: INFO: namespace: e2e-tests-daemonsets-4gnzs, resource: bindings, ignored listing per whitelist
Feb 27 02:39:35.663: INFO: namespace e2e-tests-daemonsets-4gnzs deletion completed in 6.080571128s

• [SLOW TEST:51.387 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:39:35.664: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 27 02:39:35.728: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-861261599 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:39:35.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mvr9r" for this suite.
Feb 27 02:39:41.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:39:41.871: INFO: namespace: e2e-tests-kubectl-mvr9r, resource: bindings, ignored listing per whitelist
Feb 27 02:39:41.879: INFO: namespace e2e-tests-kubectl-mvr9r deletion completed in 6.086899125s

• [SLOW TEST:6.215 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:39:41.880: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:40:08.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-xvqn5" for this suite.
Feb 27 02:40:14.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:40:14.172: INFO: namespace: e2e-tests-container-runtime-xvqn5, resource: bindings, ignored listing per whitelist
Feb 27 02:40:14.175: INFO: namespace e2e-tests-container-runtime-xvqn5 deletion completed in 6.071884719s

• [SLOW TEST:32.296 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:40:14.176: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-02931615-3a39-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 02:40:14.231: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-02936a96-3a39-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-s65w2" to be "success or failure"
Feb 27 02:40:14.243: INFO: Pod "pod-projected-secrets-02936a96-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.901391ms
Feb 27 02:40:16.245: INFO: Pod "pod-projected-secrets-02936a96-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01432178s
Feb 27 02:40:18.248: INFO: Pod "pod-projected-secrets-02936a96-3a39-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017168614s
STEP: Saw pod success
Feb 27 02:40:18.248: INFO: Pod "pod-projected-secrets-02936a96-3a39-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:40:18.250: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-projected-secrets-02936a96-3a39-11e9-8c03-2a4c52047ee8 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:40:18.266: INFO: Waiting for pod pod-projected-secrets-02936a96-3a39-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:40:18.274: INFO: Pod pod-projected-secrets-02936a96-3a39-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:40:18.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s65w2" for this suite.
Feb 27 02:40:24.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:40:24.315: INFO: namespace: e2e-tests-projected-s65w2, resource: bindings, ignored listing per whitelist
Feb 27 02:40:24.348: INFO: namespace e2e-tests-projected-s65w2 deletion completed in 6.070122017s

• [SLOW TEST:10.173 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:40:24.348: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-08a39ab8-3a39-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 02:40:24.406: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-08a3f2ca-3a39-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-ff828" to be "success or failure"
Feb 27 02:40:24.409: INFO: Pod "pod-projected-configmaps-08a3f2ca-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.524314ms
Feb 27 02:40:26.412: INFO: Pod "pod-projected-configmaps-08a3f2ca-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00550582s
Feb 27 02:40:28.415: INFO: Pod "pod-projected-configmaps-08a3f2ca-3a39-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00866428s
STEP: Saw pod success
Feb 27 02:40:28.415: INFO: Pod "pod-projected-configmaps-08a3f2ca-3a39-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:40:28.417: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-projected-configmaps-08a3f2ca-3a39-11e9-8c03-2a4c52047ee8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:40:28.431: INFO: Waiting for pod pod-projected-configmaps-08a3f2ca-3a39-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:40:28.439: INFO: Pod pod-projected-configmaps-08a3f2ca-3a39-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:40:28.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ff828" for this suite.
Feb 27 02:40:34.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:40:34.490: INFO: namespace: e2e-tests-projected-ff828, resource: bindings, ignored listing per whitelist
Feb 27 02:40:34.514: INFO: namespace e2e-tests-projected-ff828 deletion completed in 6.071623908s

• [SLOW TEST:10.165 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:40:34.514: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 27 02:40:34.592: INFO: Waiting up to 5m0s for pod "var-expansion-0eb4ccd4-3a39-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-var-expansion-rcbdk" to be "success or failure"
Feb 27 02:40:34.603: INFO: Pod "var-expansion-0eb4ccd4-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.21043ms
Feb 27 02:40:36.614: INFO: Pod "var-expansion-0eb4ccd4-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021784571s
Feb 27 02:40:38.617: INFO: Pod "var-expansion-0eb4ccd4-3a39-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024765688s
STEP: Saw pod success
Feb 27 02:40:38.617: INFO: Pod "var-expansion-0eb4ccd4-3a39-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:40:38.619: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod var-expansion-0eb4ccd4-3a39-11e9-8c03-2a4c52047ee8 container dapi-container: <nil>
STEP: delete the pod
Feb 27 02:40:38.633: INFO: Waiting for pod var-expansion-0eb4ccd4-3a39-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:40:38.635: INFO: Pod var-expansion-0eb4ccd4-3a39-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:40:38.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-rcbdk" for this suite.
Feb 27 02:40:44.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:40:44.690: INFO: namespace: e2e-tests-var-expansion-rcbdk, resource: bindings, ignored listing per whitelist
Feb 27 02:40:44.717: INFO: namespace e2e-tests-var-expansion-rcbdk deletion completed in 6.079780808s

• [SLOW TEST:10.203 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:40:44.718: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 27 02:40:44.774: INFO: Waiting up to 5m0s for pod "client-containers-14c7cd5c-3a39-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-containers-jsn6p" to be "success or failure"
Feb 27 02:40:44.778: INFO: Pod "client-containers-14c7cd5c-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.267539ms
Feb 27 02:40:46.781: INFO: Pod "client-containers-14c7cd5c-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007252598s
Feb 27 02:40:48.783: INFO: Pod "client-containers-14c7cd5c-3a39-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009343193s
STEP: Saw pod success
Feb 27 02:40:48.783: INFO: Pod "client-containers-14c7cd5c-3a39-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:40:48.785: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod client-containers-14c7cd5c-3a39-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 02:40:48.801: INFO: Waiting for pod client-containers-14c7cd5c-3a39-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:40:48.803: INFO: Pod client-containers-14c7cd5c-3a39-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:40:48.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-jsn6p" for this suite.
Feb 27 02:40:54.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:40:54.867: INFO: namespace: e2e-tests-containers-jsn6p, resource: bindings, ignored listing per whitelist
Feb 27 02:40:54.880: INFO: namespace e2e-tests-containers-jsn6p deletion completed in 6.072999198s

• [SLOW TEST:10.163 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:40:54.881: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 27 02:40:54.937: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 27 02:40:54.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:40:55.640: INFO: stderr: ""
Feb 27 02:40:55.640: INFO: stdout: "service/redis-slave created\n"
Feb 27 02:40:55.640: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 27 02:40:55.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:40:55.825: INFO: stderr: ""
Feb 27 02:40:55.825: INFO: stdout: "service/redis-master created\n"
Feb 27 02:40:55.825: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 27 02:40:55.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:40:56.020: INFO: stderr: ""
Feb 27 02:40:56.020: INFO: stdout: "service/frontend created\n"
Feb 27 02:40:56.020: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 27 02:40:56.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:40:56.213: INFO: stderr: ""
Feb 27 02:40:56.213: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 27 02:40:56.213: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 27 02:40:56.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:40:56.399: INFO: stderr: ""
Feb 27 02:40:56.399: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 27 02:40:56.399: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 27 02:40:56.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:40:56.598: INFO: stderr: ""
Feb 27 02:40:56.598: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 27 02:40:56.598: INFO: Waiting for all frontend pods to be Running.
Feb 27 02:41:21.650: INFO: Waiting for frontend to serve content.
Feb 27 02:41:21.661: INFO: Trying to add a new entry to the guestbook.
Feb 27 02:41:21.671: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 27 02:41:21.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:41:21.782: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:41:21.782: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 02:41:21.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:41:21.891: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:41:21.891: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 02:41:21.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:41:22.003: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:41:22.003: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 02:41:22.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:41:22.114: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:41:22.114: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 02:41:22.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:41:22.243: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:41:22.243: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 02:41:22.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lwcx8'
Feb 27 02:41:22.412: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:41:22.412: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:41:22.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lwcx8" for this suite.
Feb 27 02:42:00.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:42:00.473: INFO: namespace: e2e-tests-kubectl-lwcx8, resource: bindings, ignored listing per whitelist
Feb 27 02:42:00.492: INFO: namespace e2e-tests-kubectl-lwcx8 deletion completed in 38.077020307s

• [SLOW TEST:65.611 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:42:00.492: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-41f3838a-3a39-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 02:42:00.565: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-41f4a430-3a39-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-zgnqq" to be "success or failure"
Feb 27 02:42:00.569: INFO: Pod "pod-projected-secrets-41f4a430-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.2674ms
Feb 27 02:42:02.571: INFO: Pod "pod-projected-secrets-41f4a430-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006056246s
Feb 27 02:42:04.580: INFO: Pod "pod-projected-secrets-41f4a430-3a39-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014501548s
STEP: Saw pod success
Feb 27 02:42:04.580: INFO: Pod "pod-projected-secrets-41f4a430-3a39-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:42:04.582: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-projected-secrets-41f4a430-3a39-11e9-8c03-2a4c52047ee8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:42:04.599: INFO: Waiting for pod pod-projected-secrets-41f4a430-3a39-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:42:04.601: INFO: Pod pod-projected-secrets-41f4a430-3a39-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:42:04.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zgnqq" for this suite.
Feb 27 02:42:10.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:42:10.620: INFO: namespace: e2e-tests-projected-zgnqq, resource: bindings, ignored listing per whitelist
Feb 27 02:42:10.679: INFO: namespace e2e-tests-projected-zgnqq deletion completed in 6.075475854s

• [SLOW TEST:10.187 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:42:10.679: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:42:16.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-h6ml5" for this suite.
Feb 27 02:42:22.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:42:22.885: INFO: namespace: e2e-tests-namespaces-h6ml5, resource: bindings, ignored listing per whitelist
Feb 27 02:42:22.918: INFO: namespace e2e-tests-namespaces-h6ml5 deletion completed in 6.067622311s
STEP: Destroying namespace "e2e-tests-nsdeletetest-sm56r" for this suite.
Feb 27 02:42:22.919: INFO: Namespace e2e-tests-nsdeletetest-sm56r was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-4jr8b" for this suite.
Feb 27 02:42:28.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:42:28.982: INFO: namespace: e2e-tests-nsdeletetest-4jr8b, resource: bindings, ignored listing per whitelist
Feb 27 02:42:28.988: INFO: namespace e2e-tests-nsdeletetest-4jr8b deletion completed in 6.068952092s

• [SLOW TEST:18.309 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:42:28.988: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:42:29.056: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52ef573a-3a39-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-9vd6s" to be "success or failure"
Feb 27 02:42:29.059: INFO: Pod "downwardapi-volume-52ef573a-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.053818ms
Feb 27 02:42:31.061: INFO: Pod "downwardapi-volume-52ef573a-3a39-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00583845s
Feb 27 02:42:33.064: INFO: Pod "downwardapi-volume-52ef573a-3a39-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008650526s
STEP: Saw pod success
Feb 27 02:42:33.064: INFO: Pod "downwardapi-volume-52ef573a-3a39-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:42:33.066: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod downwardapi-volume-52ef573a-3a39-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 02:42:33.093: INFO: Waiting for pod downwardapi-volume-52ef573a-3a39-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:42:33.095: INFO: Pod downwardapi-volume-52ef573a-3a39-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:42:33.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9vd6s" for this suite.
Feb 27 02:42:39.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:42:39.139: INFO: namespace: e2e-tests-projected-9vd6s, resource: bindings, ignored listing per whitelist
Feb 27 02:42:39.175: INFO: namespace e2e-tests-projected-9vd6s deletion completed in 6.077083136s

• [SLOW TEST:10.186 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:42:39.175: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 27 02:42:43.245: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-590111c6-3a39-11e9-8c03-2a4c52047ee8,GenerateName:,Namespace:e2e-tests-events-28zhg,SelfLink:/api/v1/namespaces/e2e-tests-events-28zhg/pods/send-events-590111c6-3a39-11e9-8c03-2a4c52047ee8,UID:59012be8-3a39-11e9-8378-02ce1f9c2c90,ResourceVersion:13550,Generation:0,CreationTimestamp:2019-02-27 02:42:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 230004679,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7z9pd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7z9pd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-7z9pd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001274e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001274ed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:42:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:42:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:42:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:42:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.40,PodIP:192.168.161.60,StartTime:2019-02-27 02:42:39 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-27 02:42:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://dbff26e6d8d0240c29dd996dfe951335c015f9aac708598a46e31183137de0fa}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 27 02:42:45.249: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 27 02:42:47.253: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:42:47.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-28zhg" for this suite.
Feb 27 02:43:25.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:43:25.343: INFO: namespace: e2e-tests-events-28zhg, resource: bindings, ignored listing per whitelist
Feb 27 02:43:25.370: INFO: namespace e2e-tests-events-28zhg deletion completed in 38.109008308s

• [SLOW TEST:46.195 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:43:25.370: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-rs5hk
Feb 27 02:43:29.505: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-rs5hk
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 02:43:29.507: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:47:29.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rs5hk" for this suite.
Feb 27 02:47:35.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:47:35.974: INFO: namespace: e2e-tests-container-probe-rs5hk, resource: bindings, ignored listing per whitelist
Feb 27 02:47:36.008: INFO: namespace e2e-tests-container-probe-rs5hk deletion completed in 6.088409672s

• [SLOW TEST:250.638 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:47:36.009: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 27 02:47:36.081: INFO: Waiting up to 5m0s for pod "pod-09f04717-3a3a-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-pbh6z" to be "success or failure"
Feb 27 02:47:36.084: INFO: Pod "pod-09f04717-3a3a-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.753353ms
Feb 27 02:47:38.087: INFO: Pod "pod-09f04717-3a3a-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005805741s
Feb 27 02:47:40.090: INFO: Pod "pod-09f04717-3a3a-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008731113s
STEP: Saw pod success
Feb 27 02:47:40.090: INFO: Pod "pod-09f04717-3a3a-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:47:40.092: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-09f04717-3a3a-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 02:47:40.109: INFO: Waiting for pod pod-09f04717-3a3a-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:47:40.115: INFO: Pod pod-09f04717-3a3a-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:47:40.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pbh6z" for this suite.
Feb 27 02:47:46.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:47:46.135: INFO: namespace: e2e-tests-emptydir-pbh6z, resource: bindings, ignored listing per whitelist
Feb 27 02:47:46.184: INFO: namespace e2e-tests-emptydir-pbh6z deletion completed in 6.066464591s

• [SLOW TEST:10.175 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:47:46.185: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 27 02:47:46.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-md5l2'
Feb 27 02:47:46.412: INFO: stderr: ""
Feb 27 02:47:46.412: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 27 02:47:47.416: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:47:47.416: INFO: Found 0 / 1
Feb 27 02:47:48.415: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:47:48.415: INFO: Found 0 / 1
Feb 27 02:47:49.415: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:47:49.415: INFO: Found 1 / 1
Feb 27 02:47:49.415: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 27 02:47:49.417: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:47:49.417: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 27 02:47:49.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 patch pod redis-master-b6nrd --namespace=e2e-tests-kubectl-md5l2 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 27 02:47:49.502: INFO: stderr: ""
Feb 27 02:47:49.503: INFO: stdout: "pod/redis-master-b6nrd patched\n"
STEP: checking annotations
Feb 27 02:47:49.507: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:47:49.507: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:47:49.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-md5l2" for this suite.
Feb 27 02:48:11.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:48:11.525: INFO: namespace: e2e-tests-kubectl-md5l2, resource: bindings, ignored listing per whitelist
Feb 27 02:48:11.576: INFO: namespace e2e-tests-kubectl-md5l2 deletion completed in 22.066065807s

• [SLOW TEST:25.391 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:48:11.576: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:48:11.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ptmzc" for this suite.
Feb 27 02:48:17.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:48:17.679: INFO: namespace: e2e-tests-services-ptmzc, resource: bindings, ignored listing per whitelist
Feb 27 02:48:17.761: INFO: namespace e2e-tests-services-ptmzc deletion completed in 6.125183033s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.184 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:48:17.761: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 27 02:48:25.861: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:48:25.865: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 02:48:27.865: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:48:27.869: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 02:48:29.865: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:48:29.872: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 02:48:31.865: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:48:31.868: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:48:31.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-f2qp5" for this suite.
Feb 27 02:48:53.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:48:53.934: INFO: namespace: e2e-tests-container-lifecycle-hook-f2qp5, resource: bindings, ignored listing per whitelist
Feb 27 02:48:53.937: INFO: namespace e2e-tests-container-lifecycle-hook-f2qp5 deletion completed in 22.066927518s

• [SLOW TEST:36.176 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:48:53.938: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:48:54.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-zxswr" for this suite.
Feb 27 02:49:00.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:49:00.087: INFO: namespace: e2e-tests-kubelet-test-zxswr, resource: bindings, ignored listing per whitelist
Feb 27 02:49:00.119: INFO: namespace e2e-tests-kubelet-test-zxswr deletion completed in 6.07097879s

• [SLOW TEST:6.181 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:49:00.119: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-d7pkh
Feb 27 02:49:04.194: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-d7pkh
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 02:49:04.196: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:53:04.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-d7pkh" for this suite.
Feb 27 02:53:10.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:53:10.616: INFO: namespace: e2e-tests-container-probe-d7pkh, resource: bindings, ignored listing per whitelist
Feb 27 02:53:10.618: INFO: namespace e2e-tests-container-probe-d7pkh deletion completed in 6.076400594s

• [SLOW TEST:250.499 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:53:10.619: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-7f9sb
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 02:53:10.677: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 02:53:34.737: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.48.211 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7f9sb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 02:53:34.737: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 02:53:35.910: INFO: Found all expected endpoints: [netserver-0]
Feb 27 02:53:35.913: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.161.63 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7f9sb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 02:53:35.913: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 02:53:37.156: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:53:37.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-7f9sb" for this suite.
Feb 27 02:53:59.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:53:59.198: INFO: namespace: e2e-tests-pod-network-test-7f9sb, resource: bindings, ignored listing per whitelist
Feb 27 02:53:59.238: INFO: namespace e2e-tests-pod-network-test-7f9sb deletion completed in 22.078628314s

• [SLOW TEST:48.619 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:53:59.238: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 27 02:54:03.353: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:54:27.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-6hdc2" for this suite.
Feb 27 02:54:33.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:54:33.453: INFO: namespace: e2e-tests-namespaces-6hdc2, resource: bindings, ignored listing per whitelist
Feb 27 02:54:33.483: INFO: namespace e2e-tests-namespaces-6hdc2 deletion completed in 6.070889626s
STEP: Destroying namespace "e2e-tests-nsdeletetest-zvtgg" for this suite.
Feb 27 02:54:33.485: INFO: Namespace e2e-tests-nsdeletetest-zvtgg was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-tvnwr" for this suite.
Feb 27 02:54:39.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:54:39.522: INFO: namespace: e2e-tests-nsdeletetest-tvnwr, resource: bindings, ignored listing per whitelist
Feb 27 02:54:39.552: INFO: namespace e2e-tests-nsdeletetest-tvnwr deletion completed in 6.066899144s

• [SLOW TEST:40.313 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:54:39.552: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-06626c35-3a3b-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 02:54:39.621: INFO: Waiting up to 5m0s for pod "pod-secrets-06635f34-3a3b-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-secrets-vlpw5" to be "success or failure"
Feb 27 02:54:39.623: INFO: Pod "pod-secrets-06635f34-3a3b-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.796566ms
Feb 27 02:54:41.626: INFO: Pod "pod-secrets-06635f34-3a3b-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005627604s
Feb 27 02:54:43.629: INFO: Pod "pod-secrets-06635f34-3a3b-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008357196s
STEP: Saw pod success
Feb 27 02:54:43.629: INFO: Pod "pod-secrets-06635f34-3a3b-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 02:54:43.631: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-secrets-06635f34-3a3b-11e9-8c03-2a4c52047ee8 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:54:43.648: INFO: Waiting for pod pod-secrets-06635f34-3a3b-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 02:54:43.650: INFO: Pod pod-secrets-06635f34-3a3b-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:54:43.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vlpw5" for this suite.
Feb 27 02:54:49.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:54:49.710: INFO: namespace: e2e-tests-secrets-vlpw5, resource: bindings, ignored listing per whitelist
Feb 27 02:54:49.723: INFO: namespace e2e-tests-secrets-vlpw5 deletion completed in 6.070107517s

• [SLOW TEST:10.171 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:54:49.723: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 02:54:49.798: INFO: PodSpec: initContainers in spec.initContainers
Feb 27 02:55:36.826: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-0c74f07a-3a3b-11e9-8c03-2a4c52047ee8", GenerateName:"", Namespace:"e2e-tests-init-container-6q7hw", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-6q7hw/pods/pod-init-0c74f07a-3a3b-11e9-8c03-2a4c52047ee8", UID:"0c7510e3-3a3b-11e9-8378-02ce1f9c2c90", ResourceVersion:"15010", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686832889, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"798265506"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-8499x", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00158a900), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8499x", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8499x", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8499x", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001d48928), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-30-134.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001b54b40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001d489a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001d489c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001d489c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001d489cc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832889, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832889, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832889, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832889, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.30.134", PodIP:"192.168.48.214", StartTime:(*v1.Time)(0xc0014cfcc0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001b4f9d0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001b4fab0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://af4ef9d19230dc0fbced8f248f54aa689377e0bc7d8fa735c209d31cebf128e6"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0014cfd20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0014cfd00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:55:36.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6q7hw" for this suite.
Feb 27 02:55:58.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:55:58.846: INFO: namespace: e2e-tests-init-container-6q7hw, resource: bindings, ignored listing per whitelist
Feb 27 02:55:58.899: INFO: namespace e2e-tests-init-container-6q7hw deletion completed in 22.069639353s

• [SLOW TEST:69.176 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:55:58.900: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-hk98h
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-hk98h
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-hk98h
Feb 27 02:55:58.993: INFO: Found 0 stateful pods, waiting for 1
Feb 27 02:56:08.997: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 27 02:56:08.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:56:09.251: INFO: stderr: ""
Feb 27 02:56:09.251: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:56:09.251: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:56:09.254: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 27 02:56:19.259: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:56:19.259: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:56:19.273: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998766s
Feb 27 02:56:20.276: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996994412s
Feb 27 02:56:21.279: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993626701s
Feb 27 02:56:22.283: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990483618s
Feb 27 02:56:23.286: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.987053911s
Feb 27 02:56:24.289: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.984160135s
Feb 27 02:56:25.293: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.980975323s
Feb 27 02:56:26.296: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.97734396s
Feb 27 02:56:27.299: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.974240471s
Feb 27 02:56:28.302: INFO: Verifying statefulset ss doesn't scale past 1 for another 970.995693ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-hk98h
Feb 27 02:56:29.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:56:29.586: INFO: stderr: ""
Feb 27 02:56:29.586: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:56:29.586: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:56:29.589: INFO: Found 1 stateful pods, waiting for 3
Feb 27 02:56:39.592: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:56:39.592: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:56:39.592: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 27 02:56:39.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:56:39.867: INFO: stderr: ""
Feb 27 02:56:39.867: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:56:39.867: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:56:39.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:56:40.231: INFO: stderr: ""
Feb 27 02:56:40.231: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:56:40.231: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:56:40.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:56:40.514: INFO: stderr: ""
Feb 27 02:56:40.514: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:56:40.514: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:56:40.514: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:56:40.517: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 27 02:56:50.522: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:56:50.522: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:56:50.522: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:56:50.532: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999052s
Feb 27 02:56:51.535: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99591896s
Feb 27 02:56:52.539: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992345822s
Feb 27 02:56:53.542: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988750994s
Feb 27 02:56:54.546: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985422081s
Feb 27 02:56:55.549: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.981852751s
Feb 27 02:56:56.552: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977957853s
Feb 27 02:56:57.555: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.975088372s
Feb 27 02:56:58.559: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.971935402s
Feb 27 02:56:59.565: INFO: Verifying statefulset ss doesn't scale past 3 for another 968.736924ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-hk98h
Feb 27 02:57:00.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:57:00.835: INFO: stderr: ""
Feb 27 02:57:00.835: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:57:00.835: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:57:00.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:57:01.216: INFO: stderr: ""
Feb 27 02:57:01.217: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:57:01.217: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:57:01.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:57:01.336: INFO: rc: 126
Feb 27 02:57:01.337: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil> cannot exec in a stopped state: unknown
 command terminated with exit code 126
 [] <nil> 0xc0009eeba0 exit status 126 <nil> <nil> true [0xc001f48360 0xc001f48378 0xc001f48390] [0xc001f48360 0xc001f48378 0xc001f48390] [0xc001f48370 0xc001f48388] [0x92f8e0 0x92f8e0] 0xc001476f00 <nil>}:
Command stdout:
cannot exec in a stopped state: unknown

stderr:
command terminated with exit code 126

error:
exit status 126

Feb 27 02:57:11.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:57:11.401: INFO: rc: 1
Feb 27 02:57:11.401: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006eb530 exit status 1 <nil> <nil> true [0xc0020e4778 0xc0020e4790 0xc0020e47a8] [0xc0020e4778 0xc0020e4790 0xc0020e47a8] [0xc0020e4788 0xc0020e47a0] [0x92f8e0 0x92f8e0] 0xc00150dda0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:57:21.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:57:21.465: INFO: rc: 1
Feb 27 02:57:21.465: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0009ef050 exit status 1 <nil> <nil> true [0xc001f48398 0xc001f483b0 0xc001f483c8] [0xc001f48398 0xc001f483b0 0xc001f483c8] [0xc001f483a8 0xc001f483c0] [0x92f8e0 0x92f8e0] 0xc001477260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:57:31.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:57:31.536: INFO: rc: 1
Feb 27 02:57:31.536: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006eb8c0 exit status 1 <nil> <nil> true [0xc0020e47b0 0xc0020e47c8 0xc0020e47e0] [0xc0020e47b0 0xc0020e47c8 0xc0020e47e0] [0xc0020e47c0 0xc0020e47d8] [0x92f8e0 0x92f8e0] 0xc000caa120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:57:41.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:57:41.603: INFO: rc: 1
Feb 27 02:57:41.603: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006ebec0 exit status 1 <nil> <nil> true [0xc0020e47e8 0xc0020e4800 0xc0020e4818] [0xc0020e47e8 0xc0020e4800 0xc0020e4818] [0xc0020e47f8 0xc0020e4810] [0x92f8e0 0x92f8e0] 0xc000caa480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:57:51.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:57:51.666: INFO: rc: 1
Feb 27 02:57:51.666: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce0420 exit status 1 <nil> <nil> true [0xc0020e4820 0xc0020e4838 0xc0020e4850] [0xc0020e4820 0xc0020e4838 0xc0020e4850] [0xc0020e4830 0xc0020e4848] [0x92f8e0 0x92f8e0] 0xc000caa780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:58:01.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:58:01.730: INFO: rc: 1
Feb 27 02:58:01.730: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce0810 exit status 1 <nil> <nil> true [0xc0020e4858 0xc0020e4870 0xc0020e4888] [0xc0020e4858 0xc0020e4870 0xc0020e4888] [0xc0020e4868 0xc0020e4880] [0x92f8e0 0x92f8e0] 0xc000caaae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:58:11.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:58:11.799: INFO: rc: 1
Feb 27 02:58:11.799: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce0bd0 exit status 1 <nil> <nil> true [0xc0020e4890 0xc0020e48a8 0xc0020e48c8] [0xc0020e4890 0xc0020e48a8 0xc0020e48c8] [0xc0020e48a0 0xc0020e48c0] [0x92f8e0 0x92f8e0] 0xc000caaf00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:58:21.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:58:21.863: INFO: rc: 1
Feb 27 02:58:21.863: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c74600 exit status 1 <nil> <nil> true [0xc0020e4050 0xc0020e40b8 0xc0020e40f0] [0xc0020e4050 0xc0020e40b8 0xc0020e40f0] [0xc0020e4090 0xc0020e40e0] [0x92f8e0 0x92f8e0] 0xc001a34240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:58:31.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:58:31.929: INFO: rc: 1
Feb 27 02:58:31.929: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006ea5a0 exit status 1 <nil> <nil> true [0xc001f48000 0xc001f48018 0xc001f48040] [0xc001f48000 0xc001f48018 0xc001f48040] [0xc001f48010 0xc001f48028] [0x92f8e0 0x92f8e0] 0xc00150c1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:58:41.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:58:41.998: INFO: rc: 1
Feb 27 02:58:41.998: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c74a20 exit status 1 <nil> <nil> true [0xc0020e4118 0xc0020e4158 0xc0020e41a8] [0xc0020e4118 0xc0020e4158 0xc0020e41a8] [0xc0020e4148 0xc0020e4198] [0x92f8e0 0x92f8e0] 0xc001a345a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:58:51.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:58:52.065: INFO: rc: 1
Feb 27 02:58:52.065: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006ea960 exit status 1 <nil> <nil> true [0xc001f48048 0xc001f48060 0xc001f48078] [0xc001f48048 0xc001f48060 0xc001f48078] [0xc001f48058 0xc001f48070] [0x92f8e0 0x92f8e0] 0xc00150c780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:59:02.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:59:02.129: INFO: rc: 1
Feb 27 02:59:02.129: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006eafc0 exit status 1 <nil> <nil> true [0xc001f48080 0xc001f48098 0xc001f480b0] [0xc001f48080 0xc001f48098 0xc001f480b0] [0xc001f48090 0xc001f480a8] [0x92f8e0 0x92f8e0] 0xc00150cd80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:59:12.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:59:12.190: INFO: rc: 1
Feb 27 02:59:12.190: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006eb410 exit status 1 <nil> <nil> true [0xc001f480b8 0xc001f480d0 0xc001f480e8] [0xc001f480b8 0xc001f480d0 0xc001f480e8] [0xc001f480c8 0xc001f480e0] [0x92f8e0 0x92f8e0] 0xc00150d3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:59:22.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:59:22.253: INFO: rc: 1
Feb 27 02:59:22.253: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006eb7d0 exit status 1 <nil> <nil> true [0xc001f480f0 0xc001f48108 0xc001f48120] [0xc001f480f0 0xc001f48108 0xc001f48120] [0xc001f48100 0xc001f48118] [0x92f8e0 0x92f8e0] 0xc0019580c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:59:32.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:59:32.316: INFO: rc: 1
Feb 27 02:59:32.317: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c74e70 exit status 1 <nil> <nil> true [0xc0020e41b8 0xc0020e4200 0xc0020e4260] [0xc0020e41b8 0xc0020e4200 0xc0020e4260] [0xc0020e41f0 0xc0020e4250] [0x92f8e0 0x92f8e0] 0xc001a349c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:59:42.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:59:42.379: INFO: rc: 1
Feb 27 02:59:42.379: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006ebe00 exit status 1 <nil> <nil> true [0xc001f48128 0xc001f48140 0xc001f48158] [0xc001f48128 0xc001f48140 0xc001f48158] [0xc001f48138 0xc001f48150] [0x92f8e0 0x92f8e0] 0xc001958660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 02:59:52.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:59:52.444: INFO: rc: 1
Feb 27 02:59:52.444: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c75200 exit status 1 <nil> <nil> true [0xc0020e4278 0xc0020e42b0 0xc0020e42f8] [0xc0020e4278 0xc0020e42b0 0xc0020e42f8] [0xc0020e42a0 0xc0020e42e0] [0x92f8e0 0x92f8e0] 0xc001a34d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:00:02.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:00:02.510: INFO: rc: 1
Feb 27 03:00:02.510: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001392240 exit status 1 <nil> <nil> true [0xc001f48160 0xc001f48178 0xc001f48190] [0xc001f48160 0xc001f48178 0xc001f48190] [0xc001f48170 0xc001f48188] [0x92f8e0 0x92f8e0] 0xc001958ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:00:12.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:00:12.574: INFO: rc: 1
Feb 27 03:00:12.574: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001392660 exit status 1 <nil> <nil> true [0xc001f48198 0xc001f481b0 0xc001f481c8] [0xc001f48198 0xc001f481b0 0xc001f481c8] [0xc001f481a8 0xc001f481c0] [0x92f8e0 0x92f8e0] 0xc001958ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:00:22.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:00:22.656: INFO: rc: 1
Feb 27 03:00:22.656: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c75560 exit status 1 <nil> <nil> true [0xc0020e4320 0xc0020e4398 0xc0020e43d0] [0xc0020e4320 0xc0020e4398 0xc0020e43d0] [0xc0020e4368 0xc0020e43c0] [0x92f8e0 0x92f8e0] 0xc001a35020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:00:32.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:00:32.720: INFO: rc: 1
Feb 27 03:00:32.720: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006ea5d0 exit status 1 <nil> <nil> true [0xc0020e4040 0xc0020e4090 0xc0020e40e0] [0xc0020e4040 0xc0020e4090 0xc0020e40e0] [0xc0020e4068 0xc0020e40c8] [0x92f8e0 0x92f8e0] 0xc00150c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:00:42.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:00:42.798: INFO: rc: 1
Feb 27 03:00:42.798: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006ea9c0 exit status 1 <nil> <nil> true [0xc0020e40f0 0xc0020e4148 0xc0020e4198] [0xc0020e40f0 0xc0020e4148 0xc0020e4198] [0xc0020e4128 0xc0020e4188] [0x92f8e0 0x92f8e0] 0xc00150ca80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:00:52.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:00:52.861: INFO: rc: 1
Feb 27 03:00:52.861: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c74630 exit status 1 <nil> <nil> true [0xc001f48000 0xc001f48018 0xc001f48040] [0xc001f48000 0xc001f48018 0xc001f48040] [0xc001f48010 0xc001f48028] [0x92f8e0 0x92f8e0] 0xc001a340c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:01:02.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:01:02.924: INFO: rc: 1
Feb 27 03:01:02.924: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c749f0 exit status 1 <nil> <nil> true [0xc001f48048 0xc001f48060 0xc001f48078] [0xc001f48048 0xc001f48060 0xc001f48078] [0xc001f48058 0xc001f48070] [0x92f8e0 0x92f8e0] 0xc001a34420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:01:12.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:01:12.988: INFO: rc: 1
Feb 27 03:01:12.988: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006eb0e0 exit status 1 <nil> <nil> true [0xc0020e41a8 0xc0020e41f0 0xc0020e4250] [0xc0020e41a8 0xc0020e41f0 0xc0020e4250] [0xc0020e41d0 0xc0020e4230] [0x92f8e0 0x92f8e0] 0xc00150d080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:01:22.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:01:23.055: INFO: rc: 1
Feb 27 03:01:23.055: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006eb530 exit status 1 <nil> <nil> true [0xc0020e4260 0xc0020e42a0 0xc0020e42e0] [0xc0020e4260 0xc0020e42a0 0xc0020e42e0] [0xc0020e4288 0xc0020e42d0] [0x92f8e0 0x92f8e0] 0xc00150d980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:01:33.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:01:33.123: INFO: rc: 1
Feb 27 03:01:33.123: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006eb8f0 exit status 1 <nil> <nil> true [0xc0020e42f8 0xc0020e4438 0xc0020e4480] [0xc0020e42f8 0xc0020e4438 0xc0020e4480] [0xc0020e4408 0xc0020e4470] [0x92f8e0 0x92f8e0] 0xc0019583c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:01:43.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:01:43.190: INFO: rc: 1
Feb 27 03:01:43.190: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c74e40 exit status 1 <nil> <nil> true [0xc001f48080 0xc001f48098 0xc001f480b0] [0xc001f48080 0xc001f48098 0xc001f480b0] [0xc001f48090 0xc001f480a8] [0x92f8e0 0x92f8e0] 0xc001a34840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:01:53.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:01:53.253: INFO: rc: 1
Feb 27 03:01:53.253: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c75590 exit status 1 <nil> <nil> true [0xc001f480b8 0xc001f480d0 0xc001f480e8] [0xc001f480b8 0xc001f480d0 0xc001f480e8] [0xc001f480c8 0xc001f480e0] [0x92f8e0 0x92f8e0] 0xc001a34ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 27 03:02:03.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 exec --namespace=e2e-tests-statefulset-hk98h ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 03:02:03.320: INFO: rc: 1
Feb 27 03:02:03.320: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb 27 03:02:03.320: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 03:02:03.327: INFO: Deleting all statefulset in ns e2e-tests-statefulset-hk98h
Feb 27 03:02:03.329: INFO: Scaling statefulset ss to 0
Feb 27 03:02:03.335: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 03:02:03.337: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:02:03.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-hk98h" for this suite.
Feb 27 03:02:09.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:02:09.393: INFO: namespace: e2e-tests-statefulset-hk98h, resource: bindings, ignored listing per whitelist
Feb 27 03:02:09.418: INFO: namespace e2e-tests-statefulset-hk98h deletion completed in 6.067465299s

• [SLOW TEST:370.518 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:02:09.418: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 03:02:09.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-khk85'
Feb 27 03:02:10.122: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 03:02:10.122: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 27 03:02:10.143: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-hwk8g]
Feb 27 03:02:10.143: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-hwk8g" in namespace "e2e-tests-kubectl-khk85" to be "running and ready"
Feb 27 03:02:10.158: INFO: Pod "e2e-test-nginx-rc-hwk8g": Phase="Pending", Reason="", readiness=false. Elapsed: 14.976531ms
Feb 27 03:02:12.160: INFO: Pod "e2e-test-nginx-rc-hwk8g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017747897s
Feb 27 03:02:14.163: INFO: Pod "e2e-test-nginx-rc-hwk8g": Phase="Running", Reason="", readiness=true. Elapsed: 4.02048101s
Feb 27 03:02:14.163: INFO: Pod "e2e-test-nginx-rc-hwk8g" satisfied condition "running and ready"
Feb 27 03:02:14.163: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-hwk8g]
Feb 27 03:02:14.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-khk85'
Feb 27 03:02:14.254: INFO: stderr: ""
Feb 27 03:02:14.254: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb 27 03:02:14.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-khk85'
Feb 27 03:02:14.330: INFO: stderr: ""
Feb 27 03:02:14.330: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:02:14.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-khk85" for this suite.
Feb 27 03:02:36.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:02:36.354: INFO: namespace: e2e-tests-kubectl-khk85, resource: bindings, ignored listing per whitelist
Feb 27 03:02:36.410: INFO: namespace e2e-tests-kubectl-khk85 deletion completed in 22.076275523s

• [SLOW TEST:26.992 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:02:36.410: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 27 03:02:36.498: INFO: Waiting up to 5m0s for pod "pod-22a0c81c-3a3c-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-jlkkd" to be "success or failure"
Feb 27 03:02:36.504: INFO: Pod "pod-22a0c81c-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.683297ms
Feb 27 03:02:38.507: INFO: Pod "pod-22a0c81c-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008633607s
Feb 27 03:02:40.510: INFO: Pod "pod-22a0c81c-3a3c-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011737535s
STEP: Saw pod success
Feb 27 03:02:40.510: INFO: Pod "pod-22a0c81c-3a3c-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:02:40.512: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-22a0c81c-3a3c-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 03:02:40.527: INFO: Waiting for pod pod-22a0c81c-3a3c-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:02:40.530: INFO: Pod pod-22a0c81c-3a3c-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:02:40.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jlkkd" for this suite.
Feb 27 03:02:46.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:02:46.575: INFO: namespace: e2e-tests-emptydir-jlkkd, resource: bindings, ignored listing per whitelist
Feb 27 03:02:46.598: INFO: namespace e2e-tests-emptydir-jlkkd deletion completed in 6.065612362s

• [SLOW TEST:10.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:02:46.598: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:02:50.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-wxth8" for this suite.
Feb 27 03:02:56.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:02:56.737: INFO: namespace: e2e-tests-kubelet-test-wxth8, resource: bindings, ignored listing per whitelist
Feb 27 03:02:56.755: INFO: namespace e2e-tests-kubelet-test-wxth8 deletion completed in 6.082571775s

• [SLOW TEST:10.156 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:02:56.755: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 27 03:02:57.317: INFO: Waiting up to 5m0s for pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-mglwx" in namespace "e2e-tests-svcaccounts-b8sk9" to be "success or failure"
Feb 27 03:02:57.320: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-mglwx": Phase="Pending", Reason="", readiness=false. Elapsed: 3.014399ms
Feb 27 03:02:59.323: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-mglwx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005703423s
Feb 27 03:03:01.326: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-mglwx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008608999s
STEP: Saw pod success
Feb 27 03:03:01.326: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-mglwx" satisfied condition "success or failure"
Feb 27 03:03:01.328: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-mglwx container token-test: <nil>
STEP: delete the pod
Feb 27 03:03:01.345: INFO: Waiting for pod pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-mglwx to disappear
Feb 27 03:03:01.348: INFO: Pod pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-mglwx no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 27 03:03:01.353: INFO: Waiting up to 5m0s for pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-sw626" in namespace "e2e-tests-svcaccounts-b8sk9" to be "success or failure"
Feb 27 03:03:01.359: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-sw626": Phase="Pending", Reason="", readiness=false. Elapsed: 6.930801ms
Feb 27 03:03:03.363: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-sw626": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009962453s
Feb 27 03:03:05.366: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-sw626": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013719493s
STEP: Saw pod success
Feb 27 03:03:05.366: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-sw626" satisfied condition "success or failure"
Feb 27 03:03:05.369: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-sw626 container root-ca-test: <nil>
STEP: delete the pod
Feb 27 03:03:05.424: INFO: Waiting for pod pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-sw626 to disappear
Feb 27 03:03:05.426: INFO: Pod pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-sw626 no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 27 03:03:05.435: INFO: Waiting up to 5m0s for pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-nsv6v" in namespace "e2e-tests-svcaccounts-b8sk9" to be "success or failure"
Feb 27 03:03:05.447: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-nsv6v": Phase="Pending", Reason="", readiness=false. Elapsed: 11.845335ms
Feb 27 03:03:07.450: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-nsv6v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014690907s
Feb 27 03:03:09.453: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-nsv6v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017676953s
STEP: Saw pod success
Feb 27 03:03:09.453: INFO: Pod "pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-nsv6v" satisfied condition "success or failure"
Feb 27 03:03:09.454: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-nsv6v container namespace-test: <nil>
STEP: delete the pod
Feb 27 03:03:09.470: INFO: Waiting for pod pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-nsv6v to disappear
Feb 27 03:03:09.475: INFO: Pod pod-service-account-2f09bc22-3a3c-11e9-8c03-2a4c52047ee8-nsv6v no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:03:09.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-b8sk9" for this suite.
Feb 27 03:03:15.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:03:15.505: INFO: namespace: e2e-tests-svcaccounts-b8sk9, resource: bindings, ignored listing per whitelist
Feb 27 03:03:15.587: INFO: namespace e2e-tests-svcaccounts-b8sk9 deletion completed in 6.108565733s

• [SLOW TEST:18.832 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:03:15.588: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:03:15.664: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39f9591e-3a3c-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-zdhxx" to be "success or failure"
Feb 27 03:03:15.668: INFO: Pod "downwardapi-volume-39f9591e-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.1373ms
Feb 27 03:03:17.671: INFO: Pod "downwardapi-volume-39f9591e-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007403327s
Feb 27 03:03:19.674: INFO: Pod "downwardapi-volume-39f9591e-3a3c-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009752659s
STEP: Saw pod success
Feb 27 03:03:19.674: INFO: Pod "downwardapi-volume-39f9591e-3a3c-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:03:19.675: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod downwardapi-volume-39f9591e-3a3c-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:03:19.690: INFO: Waiting for pod downwardapi-volume-39f9591e-3a3c-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:03:19.692: INFO: Pod downwardapi-volume-39f9591e-3a3c-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:03:19.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zdhxx" for this suite.
Feb 27 03:03:25.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:03:25.746: INFO: namespace: e2e-tests-projected-zdhxx, resource: bindings, ignored listing per whitelist
Feb 27 03:03:25.763: INFO: namespace e2e-tests-projected-zdhxx deletion completed in 6.067915087s

• [SLOW TEST:10.176 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:03:25.763: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-40074b46-3a3c-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 03:03:25.829: INFO: Waiting up to 5m0s for pod "pod-configmaps-40085bab-3a3c-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-configmap-nt5qq" to be "success or failure"
Feb 27 03:03:25.831: INFO: Pod "pod-configmaps-40085bab-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.61672ms
Feb 27 03:03:27.835: INFO: Pod "pod-configmaps-40085bab-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005862838s
Feb 27 03:03:29.839: INFO: Pod "pod-configmaps-40085bab-3a3c-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009822833s
STEP: Saw pod success
Feb 27 03:03:29.839: INFO: Pod "pod-configmaps-40085bab-3a3c-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:03:29.841: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-configmaps-40085bab-3a3c-11e9-8c03-2a4c52047ee8 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 03:03:29.861: INFO: Waiting for pod pod-configmaps-40085bab-3a3c-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:03:29.864: INFO: Pod pod-configmaps-40085bab-3a3c-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:03:29.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nt5qq" for this suite.
Feb 27 03:03:35.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:03:35.932: INFO: namespace: e2e-tests-configmap-nt5qq, resource: bindings, ignored listing per whitelist
Feb 27 03:03:35.936: INFO: namespace e2e-tests-configmap-nt5qq deletion completed in 6.067893895s

• [SLOW TEST:10.172 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:03:35.936: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:03:36.009: INFO: Waiting up to 5m0s for pod "downwardapi-volume-461918f9-3a3c-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-79drm" to be "success or failure"
Feb 27 03:03:36.012: INFO: Pod "downwardapi-volume-461918f9-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.337187ms
Feb 27 03:03:38.016: INFO: Pod "downwardapi-volume-461918f9-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006445341s
Feb 27 03:03:40.019: INFO: Pod "downwardapi-volume-461918f9-3a3c-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009456195s
STEP: Saw pod success
Feb 27 03:03:40.019: INFO: Pod "downwardapi-volume-461918f9-3a3c-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:03:40.021: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod downwardapi-volume-461918f9-3a3c-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:03:40.037: INFO: Waiting for pod downwardapi-volume-461918f9-3a3c-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:03:40.045: INFO: Pod downwardapi-volume-461918f9-3a3c-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:03:40.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-79drm" for this suite.
Feb 27 03:03:46.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:03:46.100: INFO: namespace: e2e-tests-downward-api-79drm, resource: bindings, ignored listing per whitelist
Feb 27 03:03:46.126: INFO: namespace e2e-tests-downward-api-79drm deletion completed in 6.07884222s

• [SLOW TEST:10.190 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:03:46.127: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-xbhh
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 03:03:46.198: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-xbhh" in namespace "e2e-tests-subpath-m98qj" to be "success or failure"
Feb 27 03:03:46.201: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Pending", Reason="", readiness=false. Elapsed: 3.510182ms
Feb 27 03:03:48.204: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006319482s
Feb 27 03:03:50.207: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Running", Reason="", readiness=false. Elapsed: 4.009415041s
Feb 27 03:03:52.210: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Running", Reason="", readiness=false. Elapsed: 6.012311825s
Feb 27 03:03:54.213: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Running", Reason="", readiness=false. Elapsed: 8.015196779s
Feb 27 03:03:56.216: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Running", Reason="", readiness=false. Elapsed: 10.01823674s
Feb 27 03:03:58.219: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Running", Reason="", readiness=false. Elapsed: 12.021195792s
Feb 27 03:04:00.222: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Running", Reason="", readiness=false. Elapsed: 14.023909812s
Feb 27 03:04:02.225: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Running", Reason="", readiness=false. Elapsed: 16.026947411s
Feb 27 03:04:04.228: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Running", Reason="", readiness=false. Elapsed: 18.030198352s
Feb 27 03:04:06.232: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Running", Reason="", readiness=false. Elapsed: 20.034327332s
Feb 27 03:04:08.235: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Running", Reason="", readiness=false. Elapsed: 22.037444394s
Feb 27 03:04:10.239: INFO: Pod "pod-subpath-test-downwardapi-xbhh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.040605935s
STEP: Saw pod success
Feb 27 03:04:10.239: INFO: Pod "pod-subpath-test-downwardapi-xbhh" satisfied condition "success or failure"
Feb 27 03:04:10.240: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-subpath-test-downwardapi-xbhh container test-container-subpath-downwardapi-xbhh: <nil>
STEP: delete the pod
Feb 27 03:04:10.256: INFO: Waiting for pod pod-subpath-test-downwardapi-xbhh to disappear
Feb 27 03:04:10.262: INFO: Pod pod-subpath-test-downwardapi-xbhh no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-xbhh
Feb 27 03:04:10.262: INFO: Deleting pod "pod-subpath-test-downwardapi-xbhh" in namespace "e2e-tests-subpath-m98qj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:04:10.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-m98qj" for this suite.
Feb 27 03:04:16.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:04:16.284: INFO: namespace: e2e-tests-subpath-m98qj, resource: bindings, ignored listing per whitelist
Feb 27 03:04:16.335: INFO: namespace e2e-tests-subpath-m98qj deletion completed in 6.06898294s

• [SLOW TEST:30.208 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:04:16.335: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-vpgkr
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-vpgkr
STEP: Deleting pre-stop pod
Feb 27 03:04:29.434: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:04:29.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-vpgkr" for this suite.
Feb 27 03:05:07.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:05:07.510: INFO: namespace: e2e-tests-prestop-vpgkr, resource: bindings, ignored listing per whitelist
Feb 27 03:05:07.515: INFO: namespace e2e-tests-prestop-vpgkr deletion completed in 38.072000533s

• [SLOW TEST:51.179 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:05:07.515: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 27 03:05:15.603: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-c29lh PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:05:15.604: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:05:15.814: INFO: Exec stderr: ""
Feb 27 03:05:15.814: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-c29lh PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:05:15.814: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:05:16.079: INFO: Exec stderr: ""
Feb 27 03:05:16.079: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-c29lh PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:05:16.080: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:05:16.352: INFO: Exec stderr: ""
Feb 27 03:05:16.353: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-c29lh PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:05:16.353: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:05:16.621: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 27 03:05:16.621: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-c29lh PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:05:16.621: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:05:16.909: INFO: Exec stderr: ""
Feb 27 03:05:16.909: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-c29lh PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:05:16.909: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:05:17.173: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 27 03:05:17.173: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-c29lh PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:05:17.173: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:05:17.361: INFO: Exec stderr: ""
Feb 27 03:05:17.361: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-c29lh PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:05:17.361: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:05:17.649: INFO: Exec stderr: ""
Feb 27 03:05:17.649: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-c29lh PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:05:17.649: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:05:17.898: INFO: Exec stderr: ""
Feb 27 03:05:17.899: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-c29lh PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:05:17.899: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:05:18.183: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:05:18.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-c29lh" for this suite.
Feb 27 03:06:00.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:06:00.231: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-c29lh, resource: bindings, ignored listing per whitelist
Feb 27 03:06:00.258: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-c29lh deletion completed in 42.072647169s

• [SLOW TEST:52.743 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:06:00.259: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-9c1f17d0-3a3c-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 03:06:00.335: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9c201f20-3a3c-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-9rp28" to be "success or failure"
Feb 27 03:06:00.338: INFO: Pod "pod-projected-configmaps-9c201f20-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.518232ms
Feb 27 03:06:02.341: INFO: Pod "pod-projected-configmaps-9c201f20-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006277723s
Feb 27 03:06:04.343: INFO: Pod "pod-projected-configmaps-9c201f20-3a3c-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008514639s
STEP: Saw pod success
Feb 27 03:06:04.343: INFO: Pod "pod-projected-configmaps-9c201f20-3a3c-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:06:04.345: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-projected-configmaps-9c201f20-3a3c-11e9-8c03-2a4c52047ee8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 03:06:04.360: INFO: Waiting for pod pod-projected-configmaps-9c201f20-3a3c-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:06:04.365: INFO: Pod pod-projected-configmaps-9c201f20-3a3c-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:06:04.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9rp28" for this suite.
Feb 27 03:06:10.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:06:10.429: INFO: namespace: e2e-tests-projected-9rp28, resource: bindings, ignored listing per whitelist
Feb 27 03:06:10.434: INFO: namespace e2e-tests-projected-9rp28 deletion completed in 6.065782854s

• [SLOW TEST:10.175 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:06:10.434: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:06:10.498: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a22e3d31-3a3c-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-nzh8j" to be "success or failure"
Feb 27 03:06:10.501: INFO: Pod "downwardapi-volume-a22e3d31-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.920654ms
Feb 27 03:06:12.503: INFO: Pod "downwardapi-volume-a22e3d31-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005213058s
Feb 27 03:06:14.507: INFO: Pod "downwardapi-volume-a22e3d31-3a3c-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009030157s
STEP: Saw pod success
Feb 27 03:06:14.507: INFO: Pod "downwardapi-volume-a22e3d31-3a3c-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:06:14.509: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downwardapi-volume-a22e3d31-3a3c-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:06:14.524: INFO: Waiting for pod downwardapi-volume-a22e3d31-3a3c-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:06:14.531: INFO: Pod downwardapi-volume-a22e3d31-3a3c-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:06:14.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nzh8j" for this suite.
Feb 27 03:06:20.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:06:20.579: INFO: namespace: e2e-tests-projected-nzh8j, resource: bindings, ignored listing per whitelist
Feb 27 03:06:20.610: INFO: namespace e2e-tests-projected-nzh8j deletion completed in 6.068084815s

• [SLOW TEST:10.176 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:06:20.610: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a8405600-3a3c-11e9-8c03-2a4c52047ee8
STEP: Creating secret with name s-test-opt-upd-a8405644-3a3c-11e9-8c03-2a4c52047ee8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a8405600-3a3c-11e9-8c03-2a4c52047ee8
STEP: Updating secret s-test-opt-upd-a8405644-3a3c-11e9-8c03-2a4c52047ee8
STEP: Creating secret with name s-test-opt-create-a8405662-3a3c-11e9-8c03-2a4c52047ee8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:06:26.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zmbrm" for this suite.
Feb 27 03:06:48.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:06:48.789: INFO: namespace: e2e-tests-secrets-zmbrm, resource: bindings, ignored listing per whitelist
Feb 27 03:06:48.839: INFO: namespace e2e-tests-secrets-zmbrm deletion completed in 22.083083536s

• [SLOW TEST:28.228 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:06:48.839: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:06:48.903: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b91300e2-3a3c-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-7vkwz" to be "success or failure"
Feb 27 03:06:48.916: INFO: Pod "downwardapi-volume-b91300e2-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.396782ms
Feb 27 03:06:50.919: INFO: Pod "downwardapi-volume-b91300e2-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015211382s
Feb 27 03:06:52.922: INFO: Pod "downwardapi-volume-b91300e2-3a3c-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018110593s
STEP: Saw pod success
Feb 27 03:06:52.922: INFO: Pod "downwardapi-volume-b91300e2-3a3c-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:06:52.923: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downwardapi-volume-b91300e2-3a3c-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:06:52.936: INFO: Waiting for pod downwardapi-volume-b91300e2-3a3c-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:06:52.939: INFO: Pod downwardapi-volume-b91300e2-3a3c-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:06:52.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7vkwz" for this suite.
Feb 27 03:06:58.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:06:58.963: INFO: namespace: e2e-tests-downward-api-7vkwz, resource: bindings, ignored listing per whitelist
Feb 27 03:06:59.010: INFO: namespace e2e-tests-downward-api-7vkwz deletion completed in 6.067975828s

• [SLOW TEST:10.171 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:06:59.010: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 27 03:07:03.081: INFO: Pod pod-hostip-bf2249b6-3a3c-11e9-8c03-2a4c52047ee8 has hostIP: 10.0.30.134
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:07:03.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qgjqd" for this suite.
Feb 27 03:07:25.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:07:25.108: INFO: namespace: e2e-tests-pods-qgjqd, resource: bindings, ignored listing per whitelist
Feb 27 03:07:25.162: INFO: namespace e2e-tests-pods-qgjqd deletion completed in 22.078143065s

• [SLOW TEST:26.152 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:07:25.162: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 03:07:25.248: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb 27 03:07:25.253: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-p7qbb/daemonsets","resourceVersion":"16787"},"items":null}

Feb 27 03:07:25.255: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-p7qbb/pods","resourceVersion":"16787"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:07:25.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-p7qbb" for this suite.
Feb 27 03:07:31.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:07:31.319: INFO: namespace: e2e-tests-daemonsets-p7qbb, resource: bindings, ignored listing per whitelist
Feb 27 03:07:31.336: INFO: namespace e2e-tests-daemonsets-p7qbb deletion completed in 6.067040397s

S [SKIPPING] [6.174 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 27 03:07:25.248: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:07:31.336: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 27 03:07:31.387: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 27 03:07:31.391: INFO: Waiting for terminating namespaces to be deleted...
Feb 27 03:07:31.393: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-12-40.us-west-2.compute.internal before test
Feb 27 03:07:31.397: INFO: calico-node-9nn2r from kube-system started at 2019-02-27 01:17:19 +0000 UTC (2 container statuses recorded)
Feb 27 03:07:31.397: INFO: 	Container calico-node ready: true, restart count 2
Feb 27 03:07:31.397: INFO: 	Container install-cni ready: true, restart count 0
Feb 27 03:07:31.397: INFO: sonobuoy-e2e-job-bcc306d9d27f4dc9 from heptio-sonobuoy started at 2019-02-27 01:55:41 +0000 UTC (2 container statuses recorded)
Feb 27 03:07:31.397: INFO: 	Container e2e ready: true, restart count 0
Feb 27 03:07:31.397: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 03:07:31.397: INFO: kube-proxy-xm2xq from kube-system started at 2019-02-27 01:17:19 +0000 UTC (1 container statuses recorded)
Feb 27 03:07:31.397: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 03:07:31.398: INFO: sonobuoy-systemd-logs-daemon-set-d41f01fb14fe49b8-gwcvp from heptio-sonobuoy started at 2019-02-27 01:55:41 +0000 UTC (2 container statuses recorded)
Feb 27 03:07:31.398: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 03:07:31.398: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 03:07:31.398: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-30-134.us-west-2.compute.internal before test
Feb 27 03:07:31.403: INFO: calico-node-wv2cm from kube-system started at 2019-02-27 01:17:20 +0000 UTC (2 container statuses recorded)
Feb 27 03:07:31.403: INFO: 	Container calico-node ready: true, restart count 1
Feb 27 03:07:31.403: INFO: 	Container install-cni ready: true, restart count 0
Feb 27 03:07:31.403: INFO: sonobuoy-systemd-logs-daemon-set-d41f01fb14fe49b8-rs7fp from heptio-sonobuoy started at 2019-02-27 01:55:41 +0000 UTC (2 container statuses recorded)
Feb 27 03:07:31.403: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 03:07:31.403: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 03:07:31.403: INFO: kube-proxy-wxzzd from kube-system started at 2019-02-27 01:17:20 +0000 UTC (1 container statuses recorded)
Feb 27 03:07:31.404: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 03:07:31.404: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-27 01:55:39 +0000 UTC (1 container statuses recorded)
Feb 27 03:07:31.404: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-10-0-12-40.us-west-2.compute.internal
STEP: verifying the node has the label node ip-10-0-30-134.us-west-2.compute.internal
Feb 27 03:07:31.435: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-30-134.us-west-2.compute.internal
Feb 27 03:07:31.435: INFO: Pod sonobuoy-e2e-job-bcc306d9d27f4dc9 requesting resource cpu=0m on Node ip-10-0-12-40.us-west-2.compute.internal
Feb 27 03:07:31.435: INFO: Pod sonobuoy-systemd-logs-daemon-set-d41f01fb14fe49b8-gwcvp requesting resource cpu=0m on Node ip-10-0-12-40.us-west-2.compute.internal
Feb 27 03:07:31.435: INFO: Pod sonobuoy-systemd-logs-daemon-set-d41f01fb14fe49b8-rs7fp requesting resource cpu=0m on Node ip-10-0-30-134.us-west-2.compute.internal
Feb 27 03:07:31.435: INFO: Pod calico-node-9nn2r requesting resource cpu=250m on Node ip-10-0-12-40.us-west-2.compute.internal
Feb 27 03:07:31.435: INFO: Pod calico-node-wv2cm requesting resource cpu=250m on Node ip-10-0-30-134.us-west-2.compute.internal
Feb 27 03:07:31.435: INFO: Pod kube-proxy-wxzzd requesting resource cpu=0m on Node ip-10-0-30-134.us-west-2.compute.internal
Feb 27 03:07:31.435: INFO: Pod kube-proxy-xm2xq requesting resource cpu=0m on Node ip-10-0-12-40.us-west-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d26d990e-3a3c-11e9-8c03-2a4c52047ee8.158719b294ca09c9], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kcr4f/filler-pod-d26d990e-3a3c-11e9-8c03-2a4c52047ee8 to ip-10-0-12-40.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d26d990e-3a3c-11e9-8c03-2a4c52047ee8.158719b2ddc23693], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d26d990e-3a3c-11e9-8c03-2a4c52047ee8.158719b2e2fb33bd], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d26d990e-3a3c-11e9-8c03-2a4c52047ee8.158719b2f781d11e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d26e58b3-3a3c-11e9-8c03-2a4c52047ee8.158719b2956b44fc], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kcr4f/filler-pod-d26e58b3-3a3c-11e9-8c03-2a4c52047ee8 to ip-10-0-30-134.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d26e58b3-3a3c-11e9-8c03-2a4c52047ee8.158719b2dacfb1b6], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d26e58b3-3a3c-11e9-8c03-2a4c52047ee8.158719b2e0d9ff58], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d26e58b3-3a3c-11e9-8c03-2a4c52047ee8.158719b2f6f3d328], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158719b3851829dd], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-0-12-40.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-30-134.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:07:36.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-kcr4f" for this suite.
Feb 27 03:07:42.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:07:42.577: INFO: namespace: e2e-tests-sched-pred-kcr4f, resource: bindings, ignored listing per whitelist
Feb 27 03:07:42.580: INFO: namespace e2e-tests-sched-pred-kcr4f deletion completed in 6.069008565s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.244 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:07:42.581: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0227 03:07:52.719647      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 03:07:52.719: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:07:52.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xns8m" for this suite.
Feb 27 03:07:58.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:07:58.753: INFO: namespace: e2e-tests-gc-xns8m, resource: bindings, ignored listing per whitelist
Feb 27 03:07:58.790: INFO: namespace e2e-tests-gc-xns8m deletion completed in 6.068672678s

• [SLOW TEST:16.209 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:07:58.790: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 03:07:58.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-6wwk5'
Feb 27 03:07:58.928: INFO: stderr: ""
Feb 27 03:07:58.928: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb 27 03:07:58.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6wwk5'
Feb 27 03:08:02.027: INFO: stderr: ""
Feb 27 03:08:02.027: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:08:02.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6wwk5" for this suite.
Feb 27 03:08:08.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:08:08.056: INFO: namespace: e2e-tests-kubectl-6wwk5, resource: bindings, ignored listing per whitelist
Feb 27 03:08:08.104: INFO: namespace e2e-tests-kubectl-6wwk5 deletion completed in 6.070516115s

• [SLOW TEST:9.313 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:08:08.104: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0227 03:08:18.172295      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 03:08:18.172: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:08:18.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-d6j7f" for this suite.
Feb 27 03:08:24.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:08:24.203: INFO: namespace: e2e-tests-gc-d6j7f, resource: bindings, ignored listing per whitelist
Feb 27 03:08:24.240: INFO: namespace e2e-tests-gc-d6j7f deletion completed in 6.065850517s

• [SLOW TEST:16.136 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:08:24.240: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-2g66q/configmap-test-f1ee7a7d-3a3c-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 03:08:24.296: INFO: Waiting up to 5m0s for pod "pod-configmaps-f1eed892-3a3c-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-configmap-2g66q" to be "success or failure"
Feb 27 03:08:24.299: INFO: Pod "pod-configmaps-f1eed892-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.587296ms
Feb 27 03:08:26.302: INFO: Pod "pod-configmaps-f1eed892-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006098203s
Feb 27 03:08:28.305: INFO: Pod "pod-configmaps-f1eed892-3a3c-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009334481s
STEP: Saw pod success
Feb 27 03:08:28.305: INFO: Pod "pod-configmaps-f1eed892-3a3c-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:08:28.307: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-configmaps-f1eed892-3a3c-11e9-8c03-2a4c52047ee8 container env-test: <nil>
STEP: delete the pod
Feb 27 03:08:28.328: INFO: Waiting for pod pod-configmaps-f1eed892-3a3c-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:08:28.333: INFO: Pod pod-configmaps-f1eed892-3a3c-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:08:28.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2g66q" for this suite.
Feb 27 03:08:34.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:08:34.395: INFO: namespace: e2e-tests-configmap-2g66q, resource: bindings, ignored listing per whitelist
Feb 27 03:08:34.410: INFO: namespace e2e-tests-configmap-2g66q deletion completed in 6.074712124s

• [SLOW TEST:10.170 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:08:34.410: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:08:34.476: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f7ff8c1e-3a3c-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-wsbxh" to be "success or failure"
Feb 27 03:08:34.485: INFO: Pod "downwardapi-volume-f7ff8c1e-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.116472ms
Feb 27 03:08:36.488: INFO: Pod "downwardapi-volume-f7ff8c1e-3a3c-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011983684s
Feb 27 03:08:38.491: INFO: Pod "downwardapi-volume-f7ff8c1e-3a3c-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014936935s
STEP: Saw pod success
Feb 27 03:08:38.491: INFO: Pod "downwardapi-volume-f7ff8c1e-3a3c-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:08:38.493: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downwardapi-volume-f7ff8c1e-3a3c-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:08:38.510: INFO: Waiting for pod downwardapi-volume-f7ff8c1e-3a3c-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:08:38.515: INFO: Pod downwardapi-volume-f7ff8c1e-3a3c-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:08:38.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wsbxh" for this suite.
Feb 27 03:08:44.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:08:44.538: INFO: namespace: e2e-tests-projected-wsbxh, resource: bindings, ignored listing per whitelist
Feb 27 03:08:44.611: INFO: namespace e2e-tests-projected-wsbxh deletion completed in 6.091456092s

• [SLOW TEST:10.200 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:08:44.611: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 03:08:44.674: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:08:45.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-7lqnc" for this suite.
Feb 27 03:08:51.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:08:51.787: INFO: namespace: e2e-tests-custom-resource-definition-7lqnc, resource: bindings, ignored listing per whitelist
Feb 27 03:08:51.787: INFO: namespace e2e-tests-custom-resource-definition-7lqnc deletion completed in 6.067620693s

• [SLOW TEST:7.176 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:08:51.787: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:08:55.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-7xznx" for this suite.
Feb 27 03:09:01.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:09:01.935: INFO: namespace: e2e-tests-emptydir-wrapper-7xznx, resource: bindings, ignored listing per whitelist
Feb 27 03:09:01.946: INFO: namespace e2e-tests-emptydir-wrapper-7xznx deletion completed in 6.067197575s

• [SLOW TEST:10.159 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:09:01.946: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0869abf6-3a3d-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 03:09:02.053: INFO: Waiting up to 5m0s for pod "pod-secrets-08700647-3a3d-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-secrets-297xb" to be "success or failure"
Feb 27 03:09:02.056: INFO: Pod "pod-secrets-08700647-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.646142ms
Feb 27 03:09:04.059: INFO: Pod "pod-secrets-08700647-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005489954s
Feb 27 03:09:06.061: INFO: Pod "pod-secrets-08700647-3a3d-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008328216s
STEP: Saw pod success
Feb 27 03:09:06.062: INFO: Pod "pod-secrets-08700647-3a3d-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:09:06.063: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-secrets-08700647-3a3d-11e9-8c03-2a4c52047ee8 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 03:09:06.079: INFO: Waiting for pod pod-secrets-08700647-3a3d-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:09:06.084: INFO: Pod pod-secrets-08700647-3a3d-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:09:06.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-297xb" for this suite.
Feb 27 03:09:12.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:09:12.122: INFO: namespace: e2e-tests-secrets-297xb, resource: bindings, ignored listing per whitelist
Feb 27 03:09:12.155: INFO: namespace e2e-tests-secrets-297xb deletion completed in 6.068269146s
STEP: Destroying namespace "e2e-tests-secret-namespace-jp68m" for this suite.
Feb 27 03:09:18.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:09:18.222: INFO: namespace: e2e-tests-secret-namespace-jp68m, resource: bindings, ignored listing per whitelist
Feb 27 03:09:18.226: INFO: namespace e2e-tests-secret-namespace-jp68m deletion completed in 6.070652252s

• [SLOW TEST:16.280 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:09:18.226: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 03:09:18.291: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:09:22.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xcpr9" for this suite.
Feb 27 03:09:28.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:09:28.492: INFO: namespace: e2e-tests-init-container-xcpr9, resource: bindings, ignored listing per whitelist
Feb 27 03:09:28.523: INFO: namespace e2e-tests-init-container-xcpr9 deletion completed in 6.069553904s

• [SLOW TEST:10.297 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:09:28.523: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0227 03:09:34.601042      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 03:09:34.601: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:09:34.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jv8hm" for this suite.
Feb 27 03:09:40.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:09:40.670: INFO: namespace: e2e-tests-gc-jv8hm, resource: bindings, ignored listing per whitelist
Feb 27 03:09:40.675: INFO: namespace e2e-tests-gc-jv8hm deletion completed in 6.072064782s

• [SLOW TEST:12.152 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:09:40.675: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1f7e3b9d-3a3d-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 03:09:40.737: INFO: Waiting up to 5m0s for pod "pod-secrets-1f7eb5d9-3a3d-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-secrets-nmvxc" to be "success or failure"
Feb 27 03:09:40.743: INFO: Pod "pod-secrets-1f7eb5d9-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.157876ms
Feb 27 03:09:42.746: INFO: Pod "pod-secrets-1f7eb5d9-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008154636s
Feb 27 03:09:44.749: INFO: Pod "pod-secrets-1f7eb5d9-3a3d-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011263585s
STEP: Saw pod success
Feb 27 03:09:44.749: INFO: Pod "pod-secrets-1f7eb5d9-3a3d-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:09:44.751: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-secrets-1f7eb5d9-3a3d-11e9-8c03-2a4c52047ee8 container secret-env-test: <nil>
STEP: delete the pod
Feb 27 03:09:44.769: INFO: Waiting for pod pod-secrets-1f7eb5d9-3a3d-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:09:44.775: INFO: Pod pod-secrets-1f7eb5d9-3a3d-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:09:44.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nmvxc" for this suite.
Feb 27 03:09:50.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:09:50.821: INFO: namespace: e2e-tests-secrets-nmvxc, resource: bindings, ignored listing per whitelist
Feb 27 03:09:50.857: INFO: namespace e2e-tests-secrets-nmvxc deletion completed in 6.079890192s

• [SLOW TEST:10.182 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:09:50.858: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 27 03:09:50.912: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 27 03:09:50.921: INFO: Waiting for terminating namespaces to be deleted...
Feb 27 03:09:50.923: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-12-40.us-west-2.compute.internal before test
Feb 27 03:09:50.927: INFO: calico-node-9nn2r from kube-system started at 2019-02-27 01:17:19 +0000 UTC (2 container statuses recorded)
Feb 27 03:09:50.927: INFO: 	Container calico-node ready: true, restart count 2
Feb 27 03:09:50.927: INFO: 	Container install-cni ready: true, restart count 0
Feb 27 03:09:50.927: INFO: sonobuoy-e2e-job-bcc306d9d27f4dc9 from heptio-sonobuoy started at 2019-02-27 01:55:41 +0000 UTC (2 container statuses recorded)
Feb 27 03:09:50.927: INFO: 	Container e2e ready: true, restart count 0
Feb 27 03:09:50.927: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 03:09:50.927: INFO: kube-proxy-xm2xq from kube-system started at 2019-02-27 01:17:19 +0000 UTC (1 container statuses recorded)
Feb 27 03:09:50.927: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 03:09:50.927: INFO: sonobuoy-systemd-logs-daemon-set-d41f01fb14fe49b8-gwcvp from heptio-sonobuoy started at 2019-02-27 01:55:41 +0000 UTC (2 container statuses recorded)
Feb 27 03:09:50.927: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 03:09:50.927: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 03:09:50.927: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-30-134.us-west-2.compute.internal before test
Feb 27 03:09:50.931: INFO: kube-proxy-wxzzd from kube-system started at 2019-02-27 01:17:20 +0000 UTC (1 container statuses recorded)
Feb 27 03:09:50.931: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 03:09:50.931: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-27 01:55:39 +0000 UTC (1 container statuses recorded)
Feb 27 03:09:50.931: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 27 03:09:50.931: INFO: calico-node-wv2cm from kube-system started at 2019-02-27 01:17:20 +0000 UTC (2 container statuses recorded)
Feb 27 03:09:50.931: INFO: 	Container calico-node ready: true, restart count 1
Feb 27 03:09:50.931: INFO: 	Container install-cni ready: true, restart count 0
Feb 27 03:09:50.931: INFO: sonobuoy-systemd-logs-daemon-set-d41f01fb14fe49b8-rs7fp from heptio-sonobuoy started at 2019-02-27 01:55:41 +0000 UTC (2 container statuses recorded)
Feb 27 03:09:50.931: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 03:09:50.931: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-27f8f144-3a3d-11e9-8c03-2a4c52047ee8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-27f8f144-3a3d-11e9-8c03-2a4c52047ee8 off the node ip-10-0-30-134.us-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-27f8f144-3a3d-11e9-8c03-2a4c52047ee8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:09:58.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-wh4zr" for this suite.
Feb 27 03:10:08.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:10:09.052: INFO: namespace: e2e-tests-sched-pred-wh4zr, resource: bindings, ignored listing per whitelist
Feb 27 03:10:09.052: INFO: namespace e2e-tests-sched-pred-wh4zr deletion completed in 10.065518614s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:18.194 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:10:09.052: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-30696dea-3a3d-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 03:10:09.130: INFO: Waiting up to 5m0s for pod "pod-configmaps-306ab50b-3a3d-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-configmap-m68w5" to be "success or failure"
Feb 27 03:10:09.133: INFO: Pod "pod-configmaps-306ab50b-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.768129ms
Feb 27 03:10:11.136: INFO: Pod "pod-configmaps-306ab50b-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006265324s
Feb 27 03:10:13.139: INFO: Pod "pod-configmaps-306ab50b-3a3d-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009206278s
STEP: Saw pod success
Feb 27 03:10:13.139: INFO: Pod "pod-configmaps-306ab50b-3a3d-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:10:13.141: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-configmaps-306ab50b-3a3d-11e9-8c03-2a4c52047ee8 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 03:10:13.156: INFO: Waiting for pod pod-configmaps-306ab50b-3a3d-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:10:13.161: INFO: Pod pod-configmaps-306ab50b-3a3d-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:10:13.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m68w5" for this suite.
Feb 27 03:10:19.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:10:19.228: INFO: namespace: e2e-tests-configmap-m68w5, resource: bindings, ignored listing per whitelist
Feb 27 03:10:19.231: INFO: namespace e2e-tests-configmap-m68w5 deletion completed in 6.06724459s

• [SLOW TEST:10.178 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:10:19.231: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-367ac951-3a3d-11e9-8c03-2a4c52047ee8
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-367ac951-3a3d-11e9-8c03-2a4c52047ee8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:11:25.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-78bvq" for this suite.
Feb 27 03:11:47.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:11:47.672: INFO: namespace: e2e-tests-configmap-78bvq, resource: bindings, ignored listing per whitelist
Feb 27 03:11:47.678: INFO: namespace e2e-tests-configmap-78bvq deletion completed in 22.088805749s

• [SLOW TEST:88.446 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:11:47.678: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6b36bec5-3a3d-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 03:11:47.782: INFO: Waiting up to 5m0s for pod "pod-secrets-6b37ddd1-3a3d-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-secrets-kssrs" to be "success or failure"
Feb 27 03:11:47.789: INFO: Pod "pod-secrets-6b37ddd1-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.278519ms
Feb 27 03:11:49.793: INFO: Pod "pod-secrets-6b37ddd1-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01123204s
Feb 27 03:11:51.804: INFO: Pod "pod-secrets-6b37ddd1-3a3d-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022313651s
STEP: Saw pod success
Feb 27 03:11:51.804: INFO: Pod "pod-secrets-6b37ddd1-3a3d-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:11:51.806: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-secrets-6b37ddd1-3a3d-11e9-8c03-2a4c52047ee8 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 03:11:51.825: INFO: Waiting for pod pod-secrets-6b37ddd1-3a3d-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:11:51.827: INFO: Pod pod-secrets-6b37ddd1-3a3d-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:11:51.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kssrs" for this suite.
Feb 27 03:11:57.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:11:57.911: INFO: namespace: e2e-tests-secrets-kssrs, resource: bindings, ignored listing per whitelist
Feb 27 03:11:57.938: INFO: namespace e2e-tests-secrets-kssrs deletion completed in 6.108768126s

• [SLOW TEST:10.260 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:11:57.938: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 27 03:12:02.541: INFO: Successfully updated pod "pod-update-7152355b-3a3d-11e9-8c03-2a4c52047ee8"
STEP: verifying the updated pod is in kubernetes
Feb 27 03:12:02.546: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:12:02.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-j2cnv" for this suite.
Feb 27 03:12:24.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:12:24.620: INFO: namespace: e2e-tests-pods-j2cnv, resource: bindings, ignored listing per whitelist
Feb 27 03:12:24.649: INFO: namespace e2e-tests-pods-j2cnv deletion completed in 22.10047246s

• [SLOW TEST:26.711 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:12:24.649: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 27 03:12:24.716: INFO: Waiting up to 5m0s for pod "pod-813b657a-3a3d-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-wnshk" to be "success or failure"
Feb 27 03:12:24.719: INFO: Pod "pod-813b657a-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.736794ms
Feb 27 03:12:26.722: INFO: Pod "pod-813b657a-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005457065s
Feb 27 03:12:28.724: INFO: Pod "pod-813b657a-3a3d-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007736416s
STEP: Saw pod success
Feb 27 03:12:28.724: INFO: Pod "pod-813b657a-3a3d-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:12:28.726: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-813b657a-3a3d-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 03:12:28.739: INFO: Waiting for pod pod-813b657a-3a3d-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:12:28.742: INFO: Pod pod-813b657a-3a3d-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:12:28.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wnshk" for this suite.
Feb 27 03:12:34.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:12:34.803: INFO: namespace: e2e-tests-emptydir-wnshk, resource: bindings, ignored listing per whitelist
Feb 27 03:12:34.812: INFO: namespace e2e-tests-emptydir-wnshk deletion completed in 6.067689558s

• [SLOW TEST:10.163 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:12:34.813: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-m6rjg
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-m6rjg
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-m6rjg
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-m6rjg
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-m6rjg
Feb 27 03:12:38.905: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-m6rjg, name: ss-0, uid: 8993bbd2-3a3d-11e9-8378-02ce1f9c2c90, status phase: Pending. Waiting for statefulset controller to delete.
Feb 27 03:12:39.294: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-m6rjg, name: ss-0, uid: 8993bbd2-3a3d-11e9-8378-02ce1f9c2c90, status phase: Failed. Waiting for statefulset controller to delete.
Feb 27 03:12:39.303: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-m6rjg, name: ss-0, uid: 8993bbd2-3a3d-11e9-8378-02ce1f9c2c90, status phase: Failed. Waiting for statefulset controller to delete.
Feb 27 03:12:39.306: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-m6rjg
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-m6rjg
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-m6rjg and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 03:12:43.337: INFO: Deleting all statefulset in ns e2e-tests-statefulset-m6rjg
Feb 27 03:12:43.339: INFO: Scaling statefulset ss to 0
Feb 27 03:12:53.351: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 03:12:53.353: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:12:53.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-m6rjg" for this suite.
Feb 27 03:12:59.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:12:59.392: INFO: namespace: e2e-tests-statefulset-m6rjg, resource: bindings, ignored listing per whitelist
Feb 27 03:12:59.439: INFO: namespace e2e-tests-statefulset-m6rjg deletion completed in 6.068489364s

• [SLOW TEST:24.627 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:12:59.440: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 03:12:59.503: INFO: (0) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.480333ms)
Feb 27 03:12:59.505: INFO: (1) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.442511ms)
Feb 27 03:12:59.508: INFO: (2) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.450223ms)
Feb 27 03:12:59.510: INFO: (3) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.267926ms)
Feb 27 03:12:59.513: INFO: (4) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.522017ms)
Feb 27 03:12:59.515: INFO: (5) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.445075ms)
Feb 27 03:12:59.518: INFO: (6) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.396249ms)
Feb 27 03:12:59.520: INFO: (7) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.441123ms)
Feb 27 03:12:59.523: INFO: (8) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.423258ms)
Feb 27 03:12:59.526: INFO: (9) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.716018ms)
Feb 27 03:12:59.529: INFO: (10) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.496224ms)
Feb 27 03:12:59.531: INFO: (11) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.176302ms)
Feb 27 03:12:59.534: INFO: (12) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.491473ms)
Feb 27 03:12:59.536: INFO: (13) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.303377ms)
Feb 27 03:12:59.539: INFO: (14) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.672131ms)
Feb 27 03:12:59.541: INFO: (15) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.473862ms)
Feb 27 03:12:59.543: INFO: (16) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.275575ms)
Feb 27 03:12:59.546: INFO: (17) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.305232ms)
Feb 27 03:12:59.548: INFO: (18) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.380189ms)
Feb 27 03:12:59.551: INFO: (19) /api/v1/nodes/ip-10-0-12-40.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.351927ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:12:59.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-pj78l" for this suite.
Feb 27 03:13:05.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:13:05.619: INFO: namespace: e2e-tests-proxy-pj78l, resource: bindings, ignored listing per whitelist
Feb 27 03:13:05.637: INFO: namespace e2e-tests-proxy-pj78l deletion completed in 6.083802474s

• [SLOW TEST:6.197 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:13:05.638: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 27 03:13:05.700: INFO: Waiting up to 5m0s for pod "pod-99a90baf-3a3d-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-fnnk8" to be "success or failure"
Feb 27 03:13:05.704: INFO: Pod "pod-99a90baf-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.314153ms
Feb 27 03:13:07.706: INFO: Pod "pod-99a90baf-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006038369s
Feb 27 03:13:09.709: INFO: Pod "pod-99a90baf-3a3d-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008319482s
STEP: Saw pod success
Feb 27 03:13:09.709: INFO: Pod "pod-99a90baf-3a3d-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:13:09.711: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-99a90baf-3a3d-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 03:13:09.736: INFO: Waiting for pod pod-99a90baf-3a3d-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:13:09.739: INFO: Pod pod-99a90baf-3a3d-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:13:09.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fnnk8" for this suite.
Feb 27 03:13:15.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:13:15.801: INFO: namespace: e2e-tests-emptydir-fnnk8, resource: bindings, ignored listing per whitelist
Feb 27 03:13:15.813: INFO: namespace e2e-tests-emptydir-fnnk8 deletion completed in 6.070272841s

• [SLOW TEST:10.175 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:13:15.813: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-tlhs4 in namespace e2e-tests-proxy-8jl4b
I0227 03:13:15.897010      15 runners.go:184] Created replication controller with name: proxy-service-tlhs4, namespace: e2e-tests-proxy-8jl4b, replica count: 1
I0227 03:13:16.947662      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 03:13:17.947915      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 03:13:18.948388      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 03:13:19.948623      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 03:13:20.948849      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 03:13:21.949068      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 03:13:22.949336      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 03:13:23.949829      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 03:13:24.950060      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 03:13:25.950283      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 03:13:26.950509      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 03:13:27.950731      15 runners.go:184] proxy-service-tlhs4 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 27 03:13:27.953: INFO: setup took 12.079732867s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 27 03:13:27.961: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 7.281357ms)
Feb 27 03:13:27.961: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 7.512237ms)
Feb 27 03:13:27.975: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 21.121782ms)
Feb 27 03:13:27.975: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 21.817816ms)
Feb 27 03:13:27.981: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 26.799179ms)
Feb 27 03:13:27.981: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 26.850564ms)
Feb 27 03:13:27.981: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 27.363959ms)
Feb 27 03:13:27.981: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 27.367932ms)
Feb 27 03:13:27.981: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 28.41308ms)
Feb 27 03:13:27.982: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 28.70645ms)
Feb 27 03:13:27.982: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 28.391337ms)
Feb 27 03:13:27.984: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 29.411347ms)
Feb 27 03:13:27.984: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 29.829364ms)
Feb 27 03:13:27.984: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 30.560816ms)
Feb 27 03:13:27.984: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 30.433665ms)
Feb 27 03:13:27.989: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 35.332412ms)
Feb 27 03:13:27.995: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 5.16756ms)
Feb 27 03:13:27.998: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 7.812515ms)
Feb 27 03:13:27.998: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 7.981851ms)
Feb 27 03:13:27.998: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 8.231992ms)
Feb 27 03:13:27.999: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 9.080872ms)
Feb 27 03:13:28.006: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 16.101068ms)
Feb 27 03:13:28.006: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 16.323346ms)
Feb 27 03:13:28.007: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 16.777207ms)
Feb 27 03:13:28.007: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 16.940737ms)
Feb 27 03:13:28.008: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 17.930164ms)
Feb 27 03:13:28.009: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 18.679576ms)
Feb 27 03:13:28.010: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 19.926764ms)
Feb 27 03:13:28.010: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 20.401016ms)
Feb 27 03:13:28.010: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 19.936168ms)
Feb 27 03:13:28.011: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 20.750201ms)
Feb 27 03:13:28.011: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 21.008824ms)
Feb 27 03:13:28.022: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 9.662394ms)
Feb 27 03:13:28.022: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 10.54162ms)
Feb 27 03:13:28.023: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 10.961576ms)
Feb 27 03:13:28.023: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 10.622313ms)
Feb 27 03:13:28.023: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 11.54873ms)
Feb 27 03:13:28.024: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 12.645933ms)
Feb 27 03:13:28.024: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 12.20426ms)
Feb 27 03:13:28.025: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 12.339316ms)
Feb 27 03:13:28.025: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 12.195298ms)
Feb 27 03:13:28.025: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 12.550685ms)
Feb 27 03:13:28.025: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 12.96559ms)
Feb 27 03:13:28.025: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 13.225175ms)
Feb 27 03:13:28.026: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 13.365936ms)
Feb 27 03:13:28.026: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 13.929598ms)
Feb 27 03:13:28.026: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 14.644267ms)
Feb 27 03:13:28.027: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 14.235321ms)
Feb 27 03:13:28.035: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 7.165002ms)
Feb 27 03:13:28.035: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 7.521643ms)
Feb 27 03:13:28.036: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 7.500747ms)
Feb 27 03:13:28.036: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 7.994837ms)
Feb 27 03:13:28.036: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 7.762375ms)
Feb 27 03:13:28.036: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 9.273092ms)
Feb 27 03:13:28.036: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 9.233333ms)
Feb 27 03:13:28.037: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 8.847317ms)
Feb 27 03:13:28.037: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 9.267763ms)
Feb 27 03:13:28.037: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 9.608982ms)
Feb 27 03:13:28.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 13.441678ms)
Feb 27 03:13:28.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 13.012909ms)
Feb 27 03:13:28.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 14.043774ms)
Feb 27 03:13:28.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 13.958214ms)
Feb 27 03:13:28.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 13.203352ms)
Feb 27 03:13:28.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 14.728378ms)
Feb 27 03:13:28.054: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 11.61393ms)
Feb 27 03:13:28.054: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 11.748193ms)
Feb 27 03:13:28.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 12.495556ms)
Feb 27 03:13:28.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 12.963898ms)
Feb 27 03:13:28.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 12.442007ms)
Feb 27 03:13:28.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 12.565822ms)
Feb 27 03:13:28.055: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 12.496167ms)
Feb 27 03:13:28.056: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 13.253167ms)
Feb 27 03:13:28.056: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 13.022569ms)
Feb 27 03:13:28.056: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 13.318074ms)
Feb 27 03:13:28.057: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 13.890584ms)
Feb 27 03:13:28.057: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 14.441781ms)
Feb 27 03:13:28.057: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 14.974856ms)
Feb 27 03:13:28.057: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 15.145505ms)
Feb 27 03:13:28.058: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 14.648252ms)
Feb 27 03:13:28.058: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 15.04617ms)
Feb 27 03:13:28.065: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 5.774799ms)
Feb 27 03:13:28.066: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 8.003751ms)
Feb 27 03:13:28.068: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 9.188427ms)
Feb 27 03:13:28.068: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 9.48002ms)
Feb 27 03:13:28.068: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 9.911096ms)
Feb 27 03:13:28.068: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 9.508105ms)
Feb 27 03:13:28.068: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 10.232887ms)
Feb 27 03:13:28.069: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 10.163837ms)
Feb 27 03:13:28.069: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 10.131318ms)
Feb 27 03:13:28.069: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 10.861467ms)
Feb 27 03:13:28.072: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 14.351115ms)
Feb 27 03:13:28.073: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 13.94648ms)
Feb 27 03:13:28.073: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 14.754103ms)
Feb 27 03:13:28.073: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 14.248736ms)
Feb 27 03:13:28.073: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 14.600396ms)
Feb 27 03:13:28.074: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 15.470953ms)
Feb 27 03:13:28.083: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 8.916394ms)
Feb 27 03:13:28.083: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 9.194564ms)
Feb 27 03:13:28.084: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 10.064135ms)
Feb 27 03:13:28.084: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 10.64273ms)
Feb 27 03:13:28.085: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 10.884869ms)
Feb 27 03:13:28.085: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 10.921692ms)
Feb 27 03:13:28.085: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 11.534441ms)
Feb 27 03:13:28.085: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 11.493569ms)
Feb 27 03:13:28.086: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 12.246096ms)
Feb 27 03:13:28.086: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 12.323257ms)
Feb 27 03:13:28.087: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 12.842889ms)
Feb 27 03:13:28.087: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 13.493645ms)
Feb 27 03:13:28.088: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 13.662793ms)
Feb 27 03:13:28.088: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 14.090863ms)
Feb 27 03:13:28.088: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 13.986037ms)
Feb 27 03:13:28.089: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 15.066869ms)
Feb 27 03:13:28.098: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 8.447989ms)
Feb 27 03:13:28.098: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 8.666006ms)
Feb 27 03:13:28.098: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 9.287213ms)
Feb 27 03:13:28.099: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 9.566986ms)
Feb 27 03:13:28.100: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 10.324979ms)
Feb 27 03:13:28.101: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 11.289604ms)
Feb 27 03:13:28.101: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 10.574928ms)
Feb 27 03:13:28.101: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 10.836783ms)
Feb 27 03:13:28.101: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 10.777969ms)
Feb 27 03:13:28.101: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 11.54478ms)
Feb 27 03:13:28.102: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 13.298265ms)
Feb 27 03:13:28.103: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 13.232406ms)
Feb 27 03:13:28.104: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 14.00608ms)
Feb 27 03:13:28.104: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 13.579106ms)
Feb 27 03:13:28.104: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 14.174497ms)
Feb 27 03:13:28.104: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 14.024984ms)
Feb 27 03:13:28.108: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 4.060088ms)
Feb 27 03:13:28.109: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 5.107957ms)
Feb 27 03:13:28.114: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 9.352704ms)
Feb 27 03:13:28.114: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 9.795056ms)
Feb 27 03:13:28.115: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 10.086759ms)
Feb 27 03:13:28.115: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 10.873395ms)
Feb 27 03:13:28.115: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 10.440429ms)
Feb 27 03:13:28.115: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 10.422802ms)
Feb 27 03:13:28.115: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 10.754051ms)
Feb 27 03:13:28.116: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 10.945305ms)
Feb 27 03:13:28.117: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 12.181778ms)
Feb 27 03:13:28.118: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 13.575796ms)
Feb 27 03:13:28.119: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 14.579502ms)
Feb 27 03:13:28.120: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 14.644541ms)
Feb 27 03:13:28.120: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 15.6554ms)
Feb 27 03:13:28.121: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 16.256341ms)
Feb 27 03:13:28.127: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 6.486244ms)
Feb 27 03:13:28.129: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 8.090503ms)
Feb 27 03:13:28.130: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 9.07636ms)
Feb 27 03:13:28.131: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 9.69755ms)
Feb 27 03:13:28.131: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 10.242235ms)
Feb 27 03:13:28.132: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 11.272815ms)
Feb 27 03:13:28.132: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 10.918366ms)
Feb 27 03:13:28.132: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 11.588329ms)
Feb 27 03:13:28.132: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 11.46818ms)
Feb 27 03:13:28.132: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 11.543686ms)
Feb 27 03:13:28.134: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 12.859461ms)
Feb 27 03:13:28.135: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 13.843288ms)
Feb 27 03:13:28.135: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 14.483198ms)
Feb 27 03:13:28.135: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 14.101291ms)
Feb 27 03:13:28.136: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 14.283795ms)
Feb 27 03:13:28.136: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 14.73291ms)
Feb 27 03:13:28.143: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 6.711613ms)
Feb 27 03:13:28.145: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 8.386231ms)
Feb 27 03:13:28.145: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 8.997054ms)
Feb 27 03:13:28.147: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 10.450349ms)
Feb 27 03:13:28.147: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 10.742668ms)
Feb 27 03:13:28.147: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 11.317777ms)
Feb 27 03:13:28.147: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 11.091759ms)
Feb 27 03:13:28.149: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 12.306964ms)
Feb 27 03:13:28.149: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 12.572612ms)
Feb 27 03:13:28.149: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 13.439346ms)
Feb 27 03:13:28.150: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 13.237994ms)
Feb 27 03:13:28.150: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 13.50636ms)
Feb 27 03:13:28.150: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 13.122626ms)
Feb 27 03:13:28.150: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 13.773462ms)
Feb 27 03:13:28.150: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 13.683605ms)
Feb 27 03:13:28.150: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 13.858698ms)
Feb 27 03:13:28.161: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 9.4389ms)
Feb 27 03:13:28.161: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 10.36532ms)
Feb 27 03:13:28.162: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 10.9026ms)
Feb 27 03:13:28.162: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 11.078117ms)
Feb 27 03:13:28.163: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 11.675601ms)
Feb 27 03:13:28.163: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 11.637583ms)
Feb 27 03:13:28.163: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 11.881655ms)
Feb 27 03:13:28.164: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 13.139904ms)
Feb 27 03:13:28.164: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 12.99735ms)
Feb 27 03:13:28.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 13.904423ms)
Feb 27 03:13:28.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 13.203872ms)
Feb 27 03:13:28.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 13.847537ms)
Feb 27 03:13:28.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 13.052065ms)
Feb 27 03:13:28.166: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 15.227734ms)
Feb 27 03:13:28.166: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 15.710235ms)
Feb 27 03:13:28.167: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 15.208125ms)
Feb 27 03:13:28.176: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 8.152204ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 11.820295ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 12.366166ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 12.753663ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 12.212363ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 12.310532ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 12.980562ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 12.455062ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 12.21244ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 12.72093ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 12.053097ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 12.91703ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 13.077712ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 12.383135ms)
Feb 27 03:13:28.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 13.314432ms)
Feb 27 03:13:28.181: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 14.056956ms)
Feb 27 03:13:28.184: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 2.63165ms)
Feb 27 03:13:28.191: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 10.203409ms)
Feb 27 03:13:28.192: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 10.471151ms)
Feb 27 03:13:28.193: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 10.531629ms)
Feb 27 03:13:28.193: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 11.13684ms)
Feb 27 03:13:28.193: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 12.046194ms)
Feb 27 03:13:28.194: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 11.616917ms)
Feb 27 03:13:28.195: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 13.492814ms)
Feb 27 03:13:28.196: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 14.147208ms)
Feb 27 03:13:28.196: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 14.771379ms)
Feb 27 03:13:28.196: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 14.413099ms)
Feb 27 03:13:28.197: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 15.450812ms)
Feb 27 03:13:28.197: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 15.185678ms)
Feb 27 03:13:28.197: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 15.221349ms)
Feb 27 03:13:28.198: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 15.884022ms)
Feb 27 03:13:28.198: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 15.68874ms)
Feb 27 03:13:28.207: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 8.847352ms)
Feb 27 03:13:28.208: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 10.645797ms)
Feb 27 03:13:28.209: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 10.819197ms)
Feb 27 03:13:28.213: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 15.343457ms)
Feb 27 03:13:28.213: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 15.016827ms)
Feb 27 03:13:28.214: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 15.582815ms)
Feb 27 03:13:28.214: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 15.502409ms)
Feb 27 03:13:28.214: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 15.478307ms)
Feb 27 03:13:28.214: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 15.890095ms)
Feb 27 03:13:28.214: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 16.051469ms)
Feb 27 03:13:28.217: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 18.828715ms)
Feb 27 03:13:28.220: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 21.303995ms)
Feb 27 03:13:28.220: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 21.479033ms)
Feb 27 03:13:28.220: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 21.988187ms)
Feb 27 03:13:28.220: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 22.094314ms)
Feb 27 03:13:28.221: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 22.990721ms)
Feb 27 03:13:28.228: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 6.347152ms)
Feb 27 03:13:28.229: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 7.673291ms)
Feb 27 03:13:28.230: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 8.459643ms)
Feb 27 03:13:28.230: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 8.972896ms)
Feb 27 03:13:28.230: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 9.153927ms)
Feb 27 03:13:28.231: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 9.255922ms)
Feb 27 03:13:28.232: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 9.554502ms)
Feb 27 03:13:28.232: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 9.974927ms)
Feb 27 03:13:28.233: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 11.521335ms)
Feb 27 03:13:28.234: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 11.842605ms)
Feb 27 03:13:28.236: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 14.65284ms)
Feb 27 03:13:28.239: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 16.936226ms)
Feb 27 03:13:28.239: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 17.578642ms)
Feb 27 03:13:28.239: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 17.660672ms)
Feb 27 03:13:28.239: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 17.515457ms)
Feb 27 03:13:28.243: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 21.112219ms)
Feb 27 03:13:28.253: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 10.519891ms)
Feb 27 03:13:28.254: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 10.241001ms)
Feb 27 03:13:28.254: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 11.757346ms)
Feb 27 03:13:28.255: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 11.525547ms)
Feb 27 03:13:28.255: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 11.909931ms)
Feb 27 03:13:28.256: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 13.53345ms)
Feb 27 03:13:28.257: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 13.659276ms)
Feb 27 03:13:28.257: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 13.823435ms)
Feb 27 03:13:28.259: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 16.027997ms)
Feb 27 03:13:28.259: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 16.016494ms)
Feb 27 03:13:28.259: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 16.305978ms)
Feb 27 03:13:28.260: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 16.494394ms)
Feb 27 03:13:28.260: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 16.421212ms)
Feb 27 03:13:28.260: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 16.209967ms)
Feb 27 03:13:28.260: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 16.736501ms)
Feb 27 03:13:28.260: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 16.382503ms)
Feb 27 03:13:28.269: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 8.745409ms)
Feb 27 03:13:28.270: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 9.19942ms)
Feb 27 03:13:28.271: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 10.91341ms)
Feb 27 03:13:28.271: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 10.407375ms)
Feb 27 03:13:28.271: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 10.99523ms)
Feb 27 03:13:28.272: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 11.32119ms)
Feb 27 03:13:28.273: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 12.624696ms)
Feb 27 03:13:28.273: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 12.348556ms)
Feb 27 03:13:28.273: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 12.468841ms)
Feb 27 03:13:28.273: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 13.038317ms)
Feb 27 03:13:28.274: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 14.022809ms)
Feb 27 03:13:28.274: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 13.659919ms)
Feb 27 03:13:28.274: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 13.7728ms)
Feb 27 03:13:28.275: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 14.777955ms)
Feb 27 03:13:28.275: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 14.293265ms)
Feb 27 03:13:28.276: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 16.130596ms)
Feb 27 03:13:28.286: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 8.883244ms)
Feb 27 03:13:28.286: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 9.72574ms)
Feb 27 03:13:28.286: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 9.916645ms)
Feb 27 03:13:28.287: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 10.412082ms)
Feb 27 03:13:28.287: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 9.543604ms)
Feb 27 03:13:28.288: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 11.322465ms)
Feb 27 03:13:28.288: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 10.932765ms)
Feb 27 03:13:28.288: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 11.545775ms)
Feb 27 03:13:28.290: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 13.404237ms)
Feb 27 03:13:28.291: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 14.042317ms)
Feb 27 03:13:28.291: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 14.012286ms)
Feb 27 03:13:28.291: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 14.178271ms)
Feb 27 03:13:28.291: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 14.721408ms)
Feb 27 03:13:28.291: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 15.190892ms)
Feb 27 03:13:28.292: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 15.014765ms)
Feb 27 03:13:28.297: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 19.868959ms)
Feb 27 03:13:28.303: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:1080/proxy/rewri... (200; 5.109965ms)
Feb 27 03:13:28.303: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:1080/proxy/... (200; 5.07571ms)
Feb 27 03:13:28.309: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 11.23698ms)
Feb 27 03:13:28.309: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname1/proxy/: foo (200; 12.779125ms)
Feb 27 03:13:28.310: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:443/proxy/... (200; 11.68827ms)
Feb 27 03:13:28.310: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 10.762468ms)
Feb 27 03:13:28.310: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9/proxy/rewriteme"... (200; 11.606987ms)
Feb 27 03:13:28.310: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:460/proxy/: tls baz (200; 11.745374ms)
Feb 27 03:13:28.310: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/proxy-service-tlhs4-bv5b9:160/proxy/: foo (200; 11.377229ms)
Feb 27 03:13:28.310: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/http:proxy-service-tlhs4-bv5b9:162/proxy/: bar (200; 11.347344ms)
Feb 27 03:13:28.310: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/pods/https:proxy-service-tlhs4-bv5b9:462/proxy/: tls qux (200; 11.296636ms)
Feb 27 03:13:28.311: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname2/proxy/: bar (200; 12.308724ms)
Feb 27 03:13:28.316: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname1/proxy/: tls baz (200; 17.038083ms)
Feb 27 03:13:28.316: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/proxy-service-tlhs4:portname1/proxy/: foo (200; 17.341188ms)
Feb 27 03:13:28.316: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/https:proxy-service-tlhs4:tlsportname2/proxy/: tls qux (200; 17.943997ms)
Feb 27 03:13:28.316: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8jl4b/services/http:proxy-service-tlhs4:portname2/proxy/: bar (200; 17.86905ms)
STEP: deleting ReplicationController proxy-service-tlhs4 in namespace e2e-tests-proxy-8jl4b, will wait for the garbage collector to delete the pods
Feb 27 03:13:28.375: INFO: Deleting ReplicationController proxy-service-tlhs4 took: 6.692961ms
Feb 27 03:13:28.475: INFO: Terminating ReplicationController proxy-service-tlhs4 pods took: 100.247391ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:13:30.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8jl4b" for this suite.
Feb 27 03:13:36.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:13:36.213: INFO: namespace: e2e-tests-proxy-8jl4b, resource: bindings, ignored listing per whitelist
Feb 27 03:13:36.252: INFO: namespace e2e-tests-proxy-8jl4b deletion completed in 6.071772016s

• [SLOW TEST:20.438 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:13:36.252: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 03:13:36.310: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:13:40.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-r7hbz" for this suite.
Feb 27 03:14:22.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:14:22.373: INFO: namespace: e2e-tests-pods-r7hbz, resource: bindings, ignored listing per whitelist
Feb 27 03:14:22.407: INFO: namespace e2e-tests-pods-r7hbz deletion completed in 42.06666747s

• [SLOW TEST:46.155 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:14:22.407: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-jjmkn/secret-test-c76d893e-3a3d-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 03:14:22.492: INFO: Waiting up to 5m0s for pod "pod-configmaps-c76deafc-3a3d-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-secrets-jjmkn" to be "success or failure"
Feb 27 03:14:22.494: INFO: Pod "pod-configmaps-c76deafc-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.879945ms
Feb 27 03:14:24.496: INFO: Pod "pod-configmaps-c76deafc-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004360913s
Feb 27 03:14:26.499: INFO: Pod "pod-configmaps-c76deafc-3a3d-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006567889s
STEP: Saw pod success
Feb 27 03:14:26.499: INFO: Pod "pod-configmaps-c76deafc-3a3d-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:14:26.500: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-configmaps-c76deafc-3a3d-11e9-8c03-2a4c52047ee8 container env-test: <nil>
STEP: delete the pod
Feb 27 03:14:26.518: INFO: Waiting for pod pod-configmaps-c76deafc-3a3d-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:14:26.525: INFO: Pod pod-configmaps-c76deafc-3a3d-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:14:26.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jjmkn" for this suite.
Feb 27 03:14:32.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:14:32.580: INFO: namespace: e2e-tests-secrets-jjmkn, resource: bindings, ignored listing per whitelist
Feb 27 03:14:32.597: INFO: namespace e2e-tests-secrets-jjmkn deletion completed in 6.069487959s

• [SLOW TEST:10.190 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:14:32.598: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-xtxxc.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-xtxxc.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xtxxc.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-xtxxc.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-xtxxc.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xtxxc.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 27 03:14:36.718: INFO: DNS probes using e2e-tests-dns-xtxxc/dns-test-cd7e6494-3a3d-11e9-8c03-2a4c52047ee8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:14:36.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-xtxxc" for this suite.
Feb 27 03:14:42.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:14:42.782: INFO: namespace: e2e-tests-dns-xtxxc, resource: bindings, ignored listing per whitelist
Feb 27 03:14:42.907: INFO: namespace e2e-tests-dns-xtxxc deletion completed in 6.171701405s

• [SLOW TEST:10.309 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:14:42.907: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 27 03:14:42.973: INFO: Waiting up to 5m0s for pod "pod-d3a38cab-3a3d-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-h7ps7" to be "success or failure"
Feb 27 03:14:42.976: INFO: Pod "pod-d3a38cab-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.844537ms
Feb 27 03:14:44.978: INFO: Pod "pod-d3a38cab-3a3d-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005494528s
Feb 27 03:14:46.981: INFO: Pod "pod-d3a38cab-3a3d-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008287465s
STEP: Saw pod success
Feb 27 03:14:46.981: INFO: Pod "pod-d3a38cab-3a3d-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:14:46.983: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-d3a38cab-3a3d-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 03:14:46.998: INFO: Waiting for pod pod-d3a38cab-3a3d-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:14:46.999: INFO: Pod pod-d3a38cab-3a3d-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:14:46.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h7ps7" for this suite.
Feb 27 03:14:53.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:14:53.043: INFO: namespace: e2e-tests-emptydir-h7ps7, resource: bindings, ignored listing per whitelist
Feb 27 03:14:53.068: INFO: namespace e2e-tests-emptydir-h7ps7 deletion completed in 6.066258468s

• [SLOW TEST:10.161 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:14:53.068: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-7js7k
Feb 27 03:14:57.148: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-7js7k
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 03:14:57.149: INFO: Initial restart count of pod liveness-exec is 0
Feb 27 03:15:45.225: INFO: Restart count of pod e2e-tests-container-probe-7js7k/liveness-exec is now 1 (48.075099033s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:15:45.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-7js7k" for this suite.
Feb 27 03:15:51.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:15:51.269: INFO: namespace: e2e-tests-container-probe-7js7k, resource: bindings, ignored listing per whitelist
Feb 27 03:15:51.311: INFO: namespace e2e-tests-container-probe-7js7k deletion completed in 6.075221469s

• [SLOW TEST:58.242 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:15:51.311: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-pmpsk
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 03:15:51.366: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 03:16:15.421: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.48.193:8080/dial?request=hostName&protocol=udp&host=192.168.48.255&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-pmpsk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:16:15.421: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:16:15.621: INFO: Waiting for endpoints: map[]
Feb 27 03:16:15.624: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.48.193:8080/dial?request=hostName&protocol=udp&host=192.168.161.32&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-pmpsk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:16:15.624: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:16:15.935: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:16:15.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-pmpsk" for this suite.
Feb 27 03:16:37.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:16:37.985: INFO: namespace: e2e-tests-pod-network-test-pmpsk, resource: bindings, ignored listing per whitelist
Feb 27 03:16:38.010: INFO: namespace e2e-tests-pod-network-test-pmpsk deletion completed in 22.067505551s

• [SLOW TEST:46.698 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:16:38.010: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:16:38.089: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18419ed9-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-t8qkt" to be "success or failure"
Feb 27 03:16:38.092: INFO: Pod "downwardapi-volume-18419ed9-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.847387ms
Feb 27 03:16:40.095: INFO: Pod "downwardapi-volume-18419ed9-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005867187s
Feb 27 03:16:42.098: INFO: Pod "downwardapi-volume-18419ed9-3a3e-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008894668s
STEP: Saw pod success
Feb 27 03:16:42.098: INFO: Pod "downwardapi-volume-18419ed9-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:16:42.100: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downwardapi-volume-18419ed9-3a3e-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:16:42.113: INFO: Waiting for pod downwardapi-volume-18419ed9-3a3e-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:16:42.116: INFO: Pod downwardapi-volume-18419ed9-3a3e-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:16:42.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t8qkt" for this suite.
Feb 27 03:16:48.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:16:48.183: INFO: namespace: e2e-tests-projected-t8qkt, resource: bindings, ignored listing per whitelist
Feb 27 03:16:48.193: INFO: namespace e2e-tests-projected-t8qkt deletion completed in 6.067782159s

• [SLOW TEST:10.183 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:16:48.193: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 27 03:16:48.776: INFO: created pod pod-service-account-defaultsa
Feb 27 03:16:48.776: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 27 03:16:48.780: INFO: created pod pod-service-account-mountsa
Feb 27 03:16:48.780: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 27 03:16:48.788: INFO: created pod pod-service-account-nomountsa
Feb 27 03:16:48.788: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 27 03:16:48.794: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 27 03:16:48.794: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 27 03:16:48.804: INFO: created pod pod-service-account-mountsa-mountspec
Feb 27 03:16:48.804: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 27 03:16:48.812: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 27 03:16:48.812: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 27 03:16:48.828: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 27 03:16:48.828: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 27 03:16:48.838: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 27 03:16:48.838: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 27 03:16:48.847: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 27 03:16:48.847: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:16:48.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-wlvqb" for this suite.
Feb 27 03:16:54.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:16:54.931: INFO: namespace: e2e-tests-svcaccounts-wlvqb, resource: bindings, ignored listing per whitelist
Feb 27 03:16:54.937: INFO: namespace e2e-tests-svcaccounts-wlvqb deletion completed in 6.083168566s

• [SLOW TEST:6.744 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:16:54.938: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 03:16:54.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 version --client'
Feb 27 03:16:55.048: INFO: stderr: ""
Feb 27 03:16:55.048: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 27 03:16:55.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-rxgr8'
Feb 27 03:16:55.754: INFO: stderr: ""
Feb 27 03:16:55.754: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 27 03:16:55.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-rxgr8'
Feb 27 03:16:55.922: INFO: stderr: ""
Feb 27 03:16:55.922: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 27 03:16:56.925: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 03:16:56.925: INFO: Found 0 / 1
Feb 27 03:16:57.926: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 03:16:57.926: INFO: Found 1 / 1
Feb 27 03:16:57.926: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 27 03:16:57.928: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 03:16:57.928: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 27 03:16:57.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 describe pod redis-master-hsgd9 --namespace=e2e-tests-kubectl-rxgr8'
Feb 27 03:16:58.014: INFO: stderr: ""
Feb 27 03:16:58.014: INFO: stdout: "Name:               redis-master-hsgd9\nNamespace:          e2e-tests-kubectl-rxgr8\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-0-30-134.us-west-2.compute.internal/10.0.30.134\nStart Time:         Wed, 27 Feb 2019 03:16:55 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 192.168.48.200\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://71a21abf772f33b840ab9eadaaf0904fbba7d0c79476058d2381c0bb94ae26b9\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 27 Feb 2019 03:16:57 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-8vp6q (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-8vp6q:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-8vp6q\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                Message\n  ----    ------     ----  ----                                                -------\n  Normal  Scheduled  3s    default-scheduler                                   Successfully assigned e2e-tests-kubectl-rxgr8/redis-master-hsgd9 to ip-10-0-30-134.us-west-2.compute.internal\n  Normal  Pulled     2s    kubelet, ip-10-0-30-134.us-west-2.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-10-0-30-134.us-west-2.compute.internal  Created container\n  Normal  Started    1s    kubelet, ip-10-0-30-134.us-west-2.compute.internal  Started container\n"
Feb 27 03:16:58.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 describe rc redis-master --namespace=e2e-tests-kubectl-rxgr8'
Feb 27 03:16:58.106: INFO: stderr: ""
Feb 27 03:16:58.106: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-rxgr8\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-hsgd9\n"
Feb 27 03:16:58.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 describe service redis-master --namespace=e2e-tests-kubectl-rxgr8'
Feb 27 03:16:58.188: INFO: stderr: ""
Feb 27 03:16:58.188: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-rxgr8\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.98.156.156\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.48.200:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 27 03:16:58.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 describe node ip-10-0-12-40.us-west-2.compute.internal'
Feb 27 03:16:58.289: INFO: stderr: ""
Feb 27 03:16:58.289: INFO: stdout: "Name:               ip-10-0-12-40.us-west-2.compute.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=m4.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-west-2\n                    failure-domain.beta.kubernetes.io/zone=us-west-2a\n                    kubernetes.io/hostname=ip-10-0-12-40.us-west-2.compute.internal\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 27 Feb 2019 01:17:19 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 27 Feb 2019 03:16:58 +0000   Wed, 27 Feb 2019 01:17:19 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 27 Feb 2019 03:16:58 +0000   Wed, 27 Feb 2019 01:17:19 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 27 Feb 2019 03:16:58 +0000   Wed, 27 Feb 2019 01:17:19 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 27 Feb 2019 03:16:58 +0000   Wed, 27 Feb 2019 01:17:49 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.0.12.40\n  InternalDNS:  ip-10-0-12-40.us-west-2.compute.internal\n  Hostname:     ip-10-0-12-40.us-west-2.compute.internal\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           40593612Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      8166956Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           37411072758\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      8064556Ki\n pods:                        110\nSystem Info:\n Machine ID:                 eb8fb8775cd748ad9a3ca7572169e19c\n System UUID:                EC241616-9B0F-5952-EB12-EFC37470C5CD\n Boot ID:                    cf1fb5a3-f16a-4f76-a638-9317de0ae7e3\n Kernel Version:             4.15.0-1031-aws\n OS Image:                   Ubuntu 18.04.1 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.1\n Kubelet Version:            v1.13.2\n Kube-Proxy Version:         v1.13.2\nProviderID:                  aws:///us-west-2a/i-0baadf3aca8317538\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-e2e-job-bcc306d9d27f4dc9                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-d41f01fb14fe49b8-gwcvp    0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                calico-node-9nn2r                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         119m\n  kube-system                kube-proxy-xm2xq                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         119m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         250m (12%)  0 (0%)\n  memory                      0 (0%)      0 (0%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Feb 27 03:16:58.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 describe namespace e2e-tests-kubectl-rxgr8'
Feb 27 03:16:58.368: INFO: stderr: ""
Feb 27 03:16:58.368: INFO: stdout: "Name:         e2e-tests-kubectl-rxgr8\nLabels:       e2e-framework=kubectl\n              e2e-run=dcb10cbd-3a32-11e9-8c03-2a4c52047ee8\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:16:58.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rxgr8" for this suite.
Feb 27 03:17:20.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:17:20.419: INFO: namespace: e2e-tests-kubectl-rxgr8, resource: bindings, ignored listing per whitelist
Feb 27 03:17:20.439: INFO: namespace e2e-tests-kubectl-rxgr8 deletion completed in 22.067253834s

• [SLOW TEST:25.501 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:17:20.439: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 27 03:17:20.504: INFO: Waiting up to 5m0s for pod "pod-31892c38-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-6vshm" to be "success or failure"
Feb 27 03:17:20.511: INFO: Pod "pod-31892c38-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.243843ms
Feb 27 03:17:22.514: INFO: Pod "pod-31892c38-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009954525s
Feb 27 03:17:24.517: INFO: Pod "pod-31892c38-3a3e-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013061757s
STEP: Saw pod success
Feb 27 03:17:24.517: INFO: Pod "pod-31892c38-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:17:24.519: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-31892c38-3a3e-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 03:17:24.533: INFO: Waiting for pod pod-31892c38-3a3e-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:17:24.536: INFO: Pod pod-31892c38-3a3e-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:17:24.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6vshm" for this suite.
Feb 27 03:17:30.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:17:30.602: INFO: namespace: e2e-tests-emptydir-6vshm, resource: bindings, ignored listing per whitelist
Feb 27 03:17:30.607: INFO: namespace e2e-tests-emptydir-6vshm deletion completed in 6.068332422s

• [SLOW TEST:10.168 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:17:30.607: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 03:17:30.661: INFO: Waiting up to 5m0s for pod "downward-api-37979a67-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-98gdj" to be "success or failure"
Feb 27 03:17:30.665: INFO: Pod "downward-api-37979a67-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.969089ms
Feb 27 03:17:32.668: INFO: Pod "downward-api-37979a67-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00677559s
Feb 27 03:17:34.671: INFO: Pod "downward-api-37979a67-3a3e-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009702503s
STEP: Saw pod success
Feb 27 03:17:34.671: INFO: Pod "downward-api-37979a67-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:17:34.674: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downward-api-37979a67-3a3e-11e9-8c03-2a4c52047ee8 container dapi-container: <nil>
STEP: delete the pod
Feb 27 03:17:34.688: INFO: Waiting for pod downward-api-37979a67-3a3e-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:17:34.695: INFO: Pod downward-api-37979a67-3a3e-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:17:34.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-98gdj" for this suite.
Feb 27 03:17:40.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:17:40.717: INFO: namespace: e2e-tests-downward-api-98gdj, resource: bindings, ignored listing per whitelist
Feb 27 03:17:40.772: INFO: namespace e2e-tests-downward-api-98gdj deletion completed in 6.073543069s

• [SLOW TEST:10.165 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:17:40.772: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:17:40.839: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3da7a369-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-8tgl7" to be "success or failure"
Feb 27 03:17:40.844: INFO: Pod "downwardapi-volume-3da7a369-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.788925ms
Feb 27 03:17:42.847: INFO: Pod "downwardapi-volume-3da7a369-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007300297s
Feb 27 03:17:44.849: INFO: Pod "downwardapi-volume-3da7a369-3a3e-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009476639s
STEP: Saw pod success
Feb 27 03:17:44.849: INFO: Pod "downwardapi-volume-3da7a369-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:17:44.851: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod downwardapi-volume-3da7a369-3a3e-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:17:44.865: INFO: Waiting for pod downwardapi-volume-3da7a369-3a3e-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:17:44.871: INFO: Pod downwardapi-volume-3da7a369-3a3e-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:17:44.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8tgl7" for this suite.
Feb 27 03:17:50.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:17:50.922: INFO: namespace: e2e-tests-downward-api-8tgl7, resource: bindings, ignored listing per whitelist
Feb 27 03:17:50.944: INFO: namespace e2e-tests-downward-api-8tgl7 deletion completed in 6.0699611s

• [SLOW TEST:10.171 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:17:50.944: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 27 03:17:51.172: INFO: Pod name wrapped-volume-race-43d00820-3a3e-11e9-8c03-2a4c52047ee8: Found 0 pods out of 5
Feb 27 03:17:56.177: INFO: Pod name wrapped-volume-race-43d00820-3a3e-11e9-8c03-2a4c52047ee8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-43d00820-3a3e-11e9-8c03-2a4c52047ee8 in namespace e2e-tests-emptydir-wrapper-kz7n5, will wait for the garbage collector to delete the pods
Feb 27 03:18:08.250: INFO: Deleting ReplicationController wrapped-volume-race-43d00820-3a3e-11e9-8c03-2a4c52047ee8 took: 6.489364ms
Feb 27 03:18:08.350: INFO: Terminating ReplicationController wrapped-volume-race-43d00820-3a3e-11e9-8c03-2a4c52047ee8 pods took: 100.227875ms
STEP: Creating RC which spawns configmap-volume pods
Feb 27 03:18:49.567: INFO: Pod name wrapped-volume-race-669dcf2f-3a3e-11e9-8c03-2a4c52047ee8: Found 0 pods out of 5
Feb 27 03:18:54.573: INFO: Pod name wrapped-volume-race-669dcf2f-3a3e-11e9-8c03-2a4c52047ee8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-669dcf2f-3a3e-11e9-8c03-2a4c52047ee8 in namespace e2e-tests-emptydir-wrapper-kz7n5, will wait for the garbage collector to delete the pods
Feb 27 03:19:08.651: INFO: Deleting ReplicationController wrapped-volume-race-669dcf2f-3a3e-11e9-8c03-2a4c52047ee8 took: 5.033517ms
Feb 27 03:19:08.751: INFO: Terminating ReplicationController wrapped-volume-race-669dcf2f-3a3e-11e9-8c03-2a4c52047ee8 pods took: 100.229969ms
STEP: Creating RC which spawns configmap-volume pods
Feb 27 03:19:49.968: INFO: Pod name wrapped-volume-race-8a9e3357-3a3e-11e9-8c03-2a4c52047ee8: Found 0 pods out of 5
Feb 27 03:19:54.973: INFO: Pod name wrapped-volume-race-8a9e3357-3a3e-11e9-8c03-2a4c52047ee8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8a9e3357-3a3e-11e9-8c03-2a4c52047ee8 in namespace e2e-tests-emptydir-wrapper-kz7n5, will wait for the garbage collector to delete the pods
Feb 27 03:20:09.049: INFO: Deleting ReplicationController wrapped-volume-race-8a9e3357-3a3e-11e9-8c03-2a4c52047ee8 took: 6.461017ms
Feb 27 03:20:09.251: INFO: Terminating ReplicationController wrapped-volume-race-8a9e3357-3a3e-11e9-8c03-2a4c52047ee8 pods took: 202.608933ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:20:49.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-kz7n5" for this suite.
Feb 27 03:20:57.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:20:57.937: INFO: namespace: e2e-tests-emptydir-wrapper-kz7n5, resource: bindings, ignored listing per whitelist
Feb 27 03:20:57.944: INFO: namespace e2e-tests-emptydir-wrapper-kz7n5 deletion completed in 8.106766899s

• [SLOW TEST:187.000 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:20:57.944: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:20:58.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7bc4q" for this suite.
Feb 27 03:21:20.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:21:20.094: INFO: namespace: e2e-tests-pods-7bc4q, resource: bindings, ignored listing per whitelist
Feb 27 03:21:20.116: INFO: namespace e2e-tests-pods-7bc4q deletion completed in 22.074444158s

• [SLOW TEST:22.173 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:21:20.117: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 27 03:21:20.203: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-247ps" to be "success or failure"
Feb 27 03:21:20.206: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.262832ms
Feb 27 03:21:22.208: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004769967s
Feb 27 03:21:24.211: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007765835s
STEP: Saw pod success
Feb 27 03:21:24.211: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 27 03:21:24.213: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 27 03:21:24.233: INFO: Waiting for pod pod-host-path-test to disappear
Feb 27 03:21:24.240: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:21:24.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-247ps" for this suite.
Feb 27 03:21:30.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:21:30.303: INFO: namespace: e2e-tests-hostpath-247ps, resource: bindings, ignored listing per whitelist
Feb 27 03:21:30.327: INFO: namespace e2e-tests-hostpath-247ps deletion completed in 6.084845629s

• [SLOW TEST:10.210 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:21:30.328: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c67aa284-3a3e-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 03:21:30.395: INFO: Waiting up to 5m0s for pod "pod-secrets-c67bee5d-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-secrets-6cxxk" to be "success or failure"
Feb 27 03:21:30.398: INFO: Pod "pod-secrets-c67bee5d-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.552239ms
Feb 27 03:21:32.400: INFO: Pod "pod-secrets-c67bee5d-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005360773s
Feb 27 03:21:34.403: INFO: Pod "pod-secrets-c67bee5d-3a3e-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007967042s
STEP: Saw pod success
Feb 27 03:21:34.403: INFO: Pod "pod-secrets-c67bee5d-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:21:34.405: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-secrets-c67bee5d-3a3e-11e9-8c03-2a4c52047ee8 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 03:21:34.423: INFO: Waiting for pod pod-secrets-c67bee5d-3a3e-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:21:34.429: INFO: Pod pod-secrets-c67bee5d-3a3e-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:21:34.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6cxxk" for this suite.
Feb 27 03:21:40.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:21:40.475: INFO: namespace: e2e-tests-secrets-6cxxk, resource: bindings, ignored listing per whitelist
Feb 27 03:21:40.502: INFO: namespace e2e-tests-secrets-6cxxk deletion completed in 6.070086678s

• [SLOW TEST:10.174 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:21:40.503: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 27 03:21:45.082: INFO: Successfully updated pod "pod-update-activedeadlineseconds-cc8b6dfd-3a3e-11e9-8c03-2a4c52047ee8"
Feb 27 03:21:45.082: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-cc8b6dfd-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-pods-bm9mb" to be "terminated due to deadline exceeded"
Feb 27 03:21:45.084: INFO: Pod "pod-update-activedeadlineseconds-cc8b6dfd-3a3e-11e9-8c03-2a4c52047ee8": Phase="Running", Reason="", readiness=true. Elapsed: 2.350296ms
Feb 27 03:21:47.087: INFO: Pod "pod-update-activedeadlineseconds-cc8b6dfd-3a3e-11e9-8c03-2a4c52047ee8": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.005115778s
Feb 27 03:21:47.087: INFO: Pod "pod-update-activedeadlineseconds-cc8b6dfd-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:21:47.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bm9mb" for this suite.
Feb 27 03:21:53.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:21:53.177: INFO: namespace: e2e-tests-pods-bm9mb, resource: bindings, ignored listing per whitelist
Feb 27 03:21:53.179: INFO: namespace e2e-tests-pods-bm9mb deletion completed in 6.089347421s

• [SLOW TEST:12.677 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:21:53.179: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-d41a429e-3a3e-11e9-8c03-2a4c52047ee8
STEP: Creating configMap with name cm-test-opt-upd-d41a42e1-3a3e-11e9-8c03-2a4c52047ee8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d41a429e-3a3e-11e9-8c03-2a4c52047ee8
STEP: Updating configmap cm-test-opt-upd-d41a42e1-3a3e-11e9-8c03-2a4c52047ee8
STEP: Creating configMap with name cm-test-opt-create-d41a42fb-3a3e-11e9-8c03-2a4c52047ee8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:22:01.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k7z9z" for this suite.
Feb 27 03:22:23.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:22:23.390: INFO: namespace: e2e-tests-configmap-k7z9z, resource: bindings, ignored listing per whitelist
Feb 27 03:22:23.395: INFO: namespace e2e-tests-configmap-k7z9z deletion completed in 22.069229742s

• [SLOW TEST:30.216 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:22:23.396: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 03:22:23.458: INFO: Waiting up to 5m0s for pod "downward-api-e61c2af8-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-6rx5b" to be "success or failure"
Feb 27 03:22:23.461: INFO: Pod "downward-api-e61c2af8-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.59338ms
Feb 27 03:22:25.464: INFO: Pod "downward-api-e61c2af8-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005949012s
Feb 27 03:22:27.467: INFO: Pod "downward-api-e61c2af8-3a3e-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008683004s
STEP: Saw pod success
Feb 27 03:22:27.467: INFO: Pod "downward-api-e61c2af8-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:22:27.468: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downward-api-e61c2af8-3a3e-11e9-8c03-2a4c52047ee8 container dapi-container: <nil>
STEP: delete the pod
Feb 27 03:22:27.485: INFO: Waiting for pod downward-api-e61c2af8-3a3e-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:22:27.487: INFO: Pod downward-api-e61c2af8-3a3e-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:22:27.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6rx5b" for this suite.
Feb 27 03:22:33.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:22:33.548: INFO: namespace: e2e-tests-downward-api-6rx5b, resource: bindings, ignored listing per whitelist
Feb 27 03:22:33.556: INFO: namespace e2e-tests-downward-api-6rx5b deletion completed in 6.066345915s

• [SLOW TEST:10.160 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:22:33.556: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ec2a9f6a-3a3e-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 03:22:33.622: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec2afddf-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-configmap-tcbsx" to be "success or failure"
Feb 27 03:22:33.625: INFO: Pod "pod-configmaps-ec2afddf-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.040747ms
Feb 27 03:22:35.628: INFO: Pod "pod-configmaps-ec2afddf-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00591603s
Feb 27 03:22:37.631: INFO: Pod "pod-configmaps-ec2afddf-3a3e-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008843638s
STEP: Saw pod success
Feb 27 03:22:37.631: INFO: Pod "pod-configmaps-ec2afddf-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:22:37.633: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-configmaps-ec2afddf-3a3e-11e9-8c03-2a4c52047ee8 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 03:22:37.652: INFO: Waiting for pod pod-configmaps-ec2afddf-3a3e-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:22:37.655: INFO: Pod pod-configmaps-ec2afddf-3a3e-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:22:37.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tcbsx" for this suite.
Feb 27 03:22:43.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:22:43.703: INFO: namespace: e2e-tests-configmap-tcbsx, resource: bindings, ignored listing per whitelist
Feb 27 03:22:43.725: INFO: namespace e2e-tests-configmap-tcbsx deletion completed in 6.066615029s

• [SLOW TEST:10.169 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:22:43.725: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 27 03:22:43.785: INFO: Waiting up to 5m0s for pod "var-expansion-f23a7932-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-var-expansion-k7lxf" to be "success or failure"
Feb 27 03:22:43.789: INFO: Pod "var-expansion-f23a7932-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.617868ms
Feb 27 03:22:45.792: INFO: Pod "var-expansion-f23a7932-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006433238s
Feb 27 03:22:47.795: INFO: Pod "var-expansion-f23a7932-3a3e-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009843669s
STEP: Saw pod success
Feb 27 03:22:47.795: INFO: Pod "var-expansion-f23a7932-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:22:47.797: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod var-expansion-f23a7932-3a3e-11e9-8c03-2a4c52047ee8 container dapi-container: <nil>
STEP: delete the pod
Feb 27 03:22:47.817: INFO: Waiting for pod var-expansion-f23a7932-3a3e-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:22:47.819: INFO: Pod var-expansion-f23a7932-3a3e-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:22:47.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-k7lxf" for this suite.
Feb 27 03:22:53.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:22:53.854: INFO: namespace: e2e-tests-var-expansion-k7lxf, resource: bindings, ignored listing per whitelist
Feb 27 03:22:53.899: INFO: namespace e2e-tests-var-expansion-k7lxf deletion completed in 6.076630398s

• [SLOW TEST:10.174 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:22:53.900: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:22:53.964: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f84af8ee-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-c5hll" to be "success or failure"
Feb 27 03:22:53.967: INFO: Pod "downwardapi-volume-f84af8ee-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.827601ms
Feb 27 03:22:55.969: INFO: Pod "downwardapi-volume-f84af8ee-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005219072s
Feb 27 03:22:57.972: INFO: Pod "downwardapi-volume-f84af8ee-3a3e-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007933696s
STEP: Saw pod success
Feb 27 03:22:57.972: INFO: Pod "downwardapi-volume-f84af8ee-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:22:57.974: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downwardapi-volume-f84af8ee-3a3e-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:22:57.991: INFO: Waiting for pod downwardapi-volume-f84af8ee-3a3e-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:22:57.997: INFO: Pod downwardapi-volume-f84af8ee-3a3e-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:22:57.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c5hll" for this suite.
Feb 27 03:23:04.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:23:04.019: INFO: namespace: e2e-tests-downward-api-c5hll, resource: bindings, ignored listing per whitelist
Feb 27 03:23:04.072: INFO: namespace e2e-tests-downward-api-c5hll deletion completed in 6.069641087s

• [SLOW TEST:10.172 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:23:04.073: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-fe5bcab8-3a3e-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 03:23:04.143: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe5cb91d-3a3e-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-configmap-qr8tk" to be "success or failure"
Feb 27 03:23:04.145: INFO: Pod "pod-configmaps-fe5cb91d-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.820197ms
Feb 27 03:23:06.148: INFO: Pod "pod-configmaps-fe5cb91d-3a3e-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004771852s
Feb 27 03:23:08.151: INFO: Pod "pod-configmaps-fe5cb91d-3a3e-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007688271s
STEP: Saw pod success
Feb 27 03:23:08.151: INFO: Pod "pod-configmaps-fe5cb91d-3a3e-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:23:08.153: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-configmaps-fe5cb91d-3a3e-11e9-8c03-2a4c52047ee8 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 03:23:08.169: INFO: Waiting for pod pod-configmaps-fe5cb91d-3a3e-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:23:08.175: INFO: Pod pod-configmaps-fe5cb91d-3a3e-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:23:08.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qr8tk" for this suite.
Feb 27 03:23:14.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:23:14.220: INFO: namespace: e2e-tests-configmap-qr8tk, resource: bindings, ignored listing per whitelist
Feb 27 03:23:14.251: INFO: namespace e2e-tests-configmap-qr8tk deletion completed in 6.07289977s

• [SLOW TEST:10.178 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:23:14.251: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 27 03:23:22.336: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 03:23:22.338: INFO: Pod pod-with-prestop-http-hook still exists
Feb 27 03:23:24.338: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 03:23:24.341: INFO: Pod pod-with-prestop-http-hook still exists
Feb 27 03:23:26.338: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 03:23:26.341: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:23:26.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-tbvsr" for this suite.
Feb 27 03:23:48.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:23:48.422: INFO: namespace: e2e-tests-container-lifecycle-hook-tbvsr, resource: bindings, ignored listing per whitelist
Feb 27 03:23:48.425: INFO: namespace e2e-tests-container-lifecycle-hook-tbvsr deletion completed in 22.075372025s

• [SLOW TEST:34.174 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:23:48.425: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 27 03:23:48.489: INFO: Waiting up to 5m0s for pod "var-expansion-18cae256-3a3f-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-var-expansion-4hmkd" to be "success or failure"
Feb 27 03:23:48.493: INFO: Pod "var-expansion-18cae256-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.056329ms
Feb 27 03:23:50.495: INFO: Pod "var-expansion-18cae256-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005748012s
Feb 27 03:23:52.498: INFO: Pod "var-expansion-18cae256-3a3f-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008866917s
STEP: Saw pod success
Feb 27 03:23:52.498: INFO: Pod "var-expansion-18cae256-3a3f-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:23:52.500: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod var-expansion-18cae256-3a3f-11e9-8c03-2a4c52047ee8 container dapi-container: <nil>
STEP: delete the pod
Feb 27 03:23:52.515: INFO: Waiting for pod var-expansion-18cae256-3a3f-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:23:52.520: INFO: Pod var-expansion-18cae256-3a3f-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:23:52.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4hmkd" for this suite.
Feb 27 03:23:58.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:23:58.584: INFO: namespace: e2e-tests-var-expansion-4hmkd, resource: bindings, ignored listing per whitelist
Feb 27 03:23:58.609: INFO: namespace e2e-tests-var-expansion-4hmkd deletion completed in 6.08607697s

• [SLOW TEST:10.184 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:23:58.609: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4td96
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 03:23:58.678: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 03:24:22.735: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.48.211:8080/dial?request=hostName&protocol=http&host=192.168.161.60&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4td96 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:24:22.735: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:24:22.930: INFO: Waiting for endpoints: map[]
Feb 27 03:24:22.933: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.48.211:8080/dial?request=hostName&protocol=http&host=192.168.48.210&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4td96 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:24:22.933: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:24:23.215: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:24:23.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4td96" for this suite.
Feb 27 03:24:45.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:24:45.276: INFO: namespace: e2e-tests-pod-network-test-4td96, resource: bindings, ignored listing per whitelist
Feb 27 03:24:45.319: INFO: namespace e2e-tests-pod-network-test-4td96 deletion completed in 22.100370502s

• [SLOW TEST:46.710 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:24:45.319: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 27 03:24:45.383: INFO: namespace e2e-tests-kubectl-dhjfj
Feb 27 03:24:45.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-dhjfj'
Feb 27 03:24:45.551: INFO: stderr: ""
Feb 27 03:24:45.552: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 27 03:24:46.555: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 03:24:46.555: INFO: Found 0 / 1
Feb 27 03:24:47.555: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 03:24:47.555: INFO: Found 0 / 1
Feb 27 03:24:48.555: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 03:24:48.555: INFO: Found 1 / 1
Feb 27 03:24:48.555: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 27 03:24:48.557: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 03:24:48.557: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 27 03:24:48.557: INFO: wait on redis-master startup in e2e-tests-kubectl-dhjfj 
Feb 27 03:24:48.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 logs redis-master-wqr22 redis-master --namespace=e2e-tests-kubectl-dhjfj'
Feb 27 03:24:48.645: INFO: stderr: ""
Feb 27 03:24:48.645: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Feb 03:24:47.159 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Feb 03:24:47.159 # Server started, Redis version 3.2.12\n1:M 27 Feb 03:24:47.159 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Feb 03:24:47.159 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 27 03:24:48.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-dhjfj'
Feb 27 03:24:48.760: INFO: stderr: ""
Feb 27 03:24:48.760: INFO: stdout: "service/rm2 exposed\n"
Feb 27 03:24:48.766: INFO: Service rm2 in namespace e2e-tests-kubectl-dhjfj found.
STEP: exposing service
Feb 27 03:24:50.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-dhjfj'
Feb 27 03:24:50.861: INFO: stderr: ""
Feb 27 03:24:50.861: INFO: stdout: "service/rm3 exposed\n"
Feb 27 03:24:50.870: INFO: Service rm3 in namespace e2e-tests-kubectl-dhjfj found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:24:52.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dhjfj" for this suite.
Feb 27 03:25:14.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:25:14.900: INFO: namespace: e2e-tests-kubectl-dhjfj, resource: bindings, ignored listing per whitelist
Feb 27 03:25:14.946: INFO: namespace e2e-tests-kubectl-dhjfj deletion completed in 22.069329174s

• [SLOW TEST:29.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:25:14.946: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 27 03:25:15.005: INFO: Waiting up to 5m0s for pod "pod-4c5c184f-3a3f-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-f4657" to be "success or failure"
Feb 27 03:25:15.012: INFO: Pod "pod-4c5c184f-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.956585ms
Feb 27 03:25:17.014: INFO: Pod "pod-4c5c184f-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009614917s
Feb 27 03:25:19.017: INFO: Pod "pod-4c5c184f-3a3f-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012590216s
STEP: Saw pod success
Feb 27 03:25:19.017: INFO: Pod "pod-4c5c184f-3a3f-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:25:19.019: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-4c5c184f-3a3f-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 03:25:19.034: INFO: Waiting for pod pod-4c5c184f-3a3f-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:25:19.039: INFO: Pod pod-4c5c184f-3a3f-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:25:19.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f4657" for this suite.
Feb 27 03:25:25.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:25:25.087: INFO: namespace: e2e-tests-emptydir-f4657, resource: bindings, ignored listing per whitelist
Feb 27 03:25:25.108: INFO: namespace e2e-tests-emptydir-f4657 deletion completed in 6.066393257s

• [SLOW TEST:10.162 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:25:25.109: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-526cb958-3a3f-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 03:25:25.179: INFO: Waiting up to 5m0s for pod "pod-configmaps-526d093a-3a3f-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-configmap-bl6gw" to be "success or failure"
Feb 27 03:25:25.185: INFO: Pod "pod-configmaps-526d093a-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.225843ms
Feb 27 03:25:27.189: INFO: Pod "pod-configmaps-526d093a-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009250444s
Feb 27 03:25:29.192: INFO: Pod "pod-configmaps-526d093a-3a3f-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012273389s
STEP: Saw pod success
Feb 27 03:25:29.192: INFO: Pod "pod-configmaps-526d093a-3a3f-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:25:29.193: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-configmaps-526d093a-3a3f-11e9-8c03-2a4c52047ee8 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 03:25:29.208: INFO: Waiting for pod pod-configmaps-526d093a-3a3f-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:25:29.214: INFO: Pod pod-configmaps-526d093a-3a3f-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:25:29.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bl6gw" for this suite.
Feb 27 03:25:35.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:25:35.236: INFO: namespace: e2e-tests-configmap-bl6gw, resource: bindings, ignored listing per whitelist
Feb 27 03:25:35.337: INFO: namespace e2e-tests-configmap-bl6gw deletion completed in 6.120864059s

• [SLOW TEST:10.228 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:25:35.337: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:25:35.478: INFO: Waiting up to 5m0s for pod "downwardapi-volume-588f49c4-3a3f-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-downward-api-4cdfb" to be "success or failure"
Feb 27 03:25:35.484: INFO: Pod "downwardapi-volume-588f49c4-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.472856ms
Feb 27 03:25:37.488: INFO: Pod "downwardapi-volume-588f49c4-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010110953s
Feb 27 03:25:39.492: INFO: Pod "downwardapi-volume-588f49c4-3a3f-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014475919s
STEP: Saw pod success
Feb 27 03:25:39.492: INFO: Pod "downwardapi-volume-588f49c4-3a3f-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:25:39.494: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downwardapi-volume-588f49c4-3a3f-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:25:39.509: INFO: Waiting for pod downwardapi-volume-588f49c4-3a3f-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:25:39.515: INFO: Pod downwardapi-volume-588f49c4-3a3f-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:25:39.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4cdfb" for this suite.
Feb 27 03:25:45.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:25:45.555: INFO: namespace: e2e-tests-downward-api-4cdfb, resource: bindings, ignored listing per whitelist
Feb 27 03:25:45.617: INFO: namespace e2e-tests-downward-api-4cdfb deletion completed in 6.100099532s

• [SLOW TEST:10.280 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:25:45.618: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb 27 03:25:45.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-bfk27'
Feb 27 03:25:45.840: INFO: stderr: ""
Feb 27 03:25:45.840: INFO: stdout: "pod/pause created\n"
Feb 27 03:25:45.840: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 27 03:25:45.840: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-bfk27" to be "running and ready"
Feb 27 03:25:45.845: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.387127ms
Feb 27 03:25:47.849: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008822835s
Feb 27 03:25:49.852: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.012158103s
Feb 27 03:25:49.852: INFO: Pod "pause" satisfied condition "running and ready"
Feb 27 03:25:49.852: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 27 03:25:49.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-bfk27'
Feb 27 03:25:49.937: INFO: stderr: ""
Feb 27 03:25:49.937: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 27 03:25:49.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pod pause -L testing-label --namespace=e2e-tests-kubectl-bfk27'
Feb 27 03:25:50.014: INFO: stderr: ""
Feb 27 03:25:50.014: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 27 03:25:50.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 label pods pause testing-label- --namespace=e2e-tests-kubectl-bfk27'
Feb 27 03:25:50.089: INFO: stderr: ""
Feb 27 03:25:50.089: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 27 03:25:50.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pod pause -L testing-label --namespace=e2e-tests-kubectl-bfk27'
Feb 27 03:25:50.159: INFO: stderr: ""
Feb 27 03:25:50.159: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb 27 03:25:50.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bfk27'
Feb 27 03:25:50.236: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 03:25:50.236: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 27 03:25:50.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-bfk27'
Feb 27 03:25:50.310: INFO: stderr: "No resources found.\n"
Feb 27 03:25:50.310: INFO: stdout: ""
Feb 27 03:25:50.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -l name=pause --namespace=e2e-tests-kubectl-bfk27 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 03:25:50.381: INFO: stderr: ""
Feb 27 03:25:50.381: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:25:50.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bfk27" for this suite.
Feb 27 03:25:56.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:25:56.437: INFO: namespace: e2e-tests-kubectl-bfk27, resource: bindings, ignored listing per whitelist
Feb 27 03:25:56.451: INFO: namespace e2e-tests-kubectl-bfk27 deletion completed in 6.067831279s

• [SLOW TEST:10.834 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:25:56.451: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-651b9228-3a3f-11e9-8c03-2a4c52047ee8
STEP: Creating configMap with name cm-test-opt-upd-651b9267-3a3f-11e9-8c03-2a4c52047ee8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-651b9228-3a3f-11e9-8c03-2a4c52047ee8
STEP: Updating configmap cm-test-opt-upd-651b9267-3a3f-11e9-8c03-2a4c52047ee8
STEP: Creating configMap with name cm-test-opt-create-651b9283-3a3f-11e9-8c03-2a4c52047ee8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:26:04.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jnzwt" for this suite.
Feb 27 03:26:26.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:26:26.654: INFO: namespace: e2e-tests-projected-jnzwt, resource: bindings, ignored listing per whitelist
Feb 27 03:26:26.659: INFO: namespace e2e-tests-projected-jnzwt deletion completed in 22.067576134s

• [SLOW TEST:30.207 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:26:26.659: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 27 03:26:26.735: INFO: Waiting up to 5m0s for pod "pod-771b7860-3a3f-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-l9zp2" to be "success or failure"
Feb 27 03:26:26.739: INFO: Pod "pod-771b7860-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.945571ms
Feb 27 03:26:28.742: INFO: Pod "pod-771b7860-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00687663s
Feb 27 03:26:30.744: INFO: Pod "pod-771b7860-3a3f-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009565444s
STEP: Saw pod success
Feb 27 03:26:30.744: INFO: Pod "pod-771b7860-3a3f-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:26:30.746: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-771b7860-3a3f-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 03:26:30.764: INFO: Waiting for pod pod-771b7860-3a3f-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:26:30.769: INFO: Pod pod-771b7860-3a3f-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:26:30.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l9zp2" for this suite.
Feb 27 03:26:36.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:26:36.803: INFO: namespace: e2e-tests-emptydir-l9zp2, resource: bindings, ignored listing per whitelist
Feb 27 03:26:36.837: INFO: namespace e2e-tests-emptydir-l9zp2 deletion completed in 6.065856163s

• [SLOW TEST:10.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:26:36.838: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j4n75
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 03:26:36.897: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 03:27:00.954: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.161.63:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j4n75 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:27:00.954: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:27:01.159: INFO: Found all expected endpoints: [netserver-0]
Feb 27 03:27:01.161: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.48.217:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j4n75 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:27:01.161: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
Feb 27 03:27:01.441: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:27:01.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j4n75" for this suite.
Feb 27 03:27:23.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:27:23.473: INFO: namespace: e2e-tests-pod-network-test-j4n75, resource: bindings, ignored listing per whitelist
Feb 27 03:27:23.514: INFO: namespace e2e-tests-pod-network-test-j4n75 deletion completed in 22.070389755s

• [SLOW TEST:46.677 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:27:23.515: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 03:27:23.580: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 27 03:27:23.596: INFO: Number of nodes with available pods: 0
Feb 27 03:27:23.596: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 27 03:27:23.617: INFO: Number of nodes with available pods: 0
Feb 27 03:27:23.617: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:24.622: INFO: Number of nodes with available pods: 0
Feb 27 03:27:24.622: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:25.620: INFO: Number of nodes with available pods: 0
Feb 27 03:27:25.620: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:26.620: INFO: Number of nodes with available pods: 1
Feb 27 03:27:26.620: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 27 03:27:26.634: INFO: Number of nodes with available pods: 1
Feb 27 03:27:26.634: INFO: Number of running nodes: 0, number of available pods: 1
Feb 27 03:27:27.639: INFO: Number of nodes with available pods: 0
Feb 27 03:27:27.639: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 27 03:27:27.667: INFO: Number of nodes with available pods: 0
Feb 27 03:27:27.667: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:28.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:28.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:29.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:29.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:30.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:30.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:31.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:31.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:32.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:32.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:33.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:33.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:34.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:34.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:35.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:35.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:36.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:36.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:37.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:37.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:38.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:38.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:39.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:39.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:40.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:40.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:41.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:41.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:42.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:42.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:43.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:43.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:44.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:44.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:45.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:45.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:46.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:46.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:47.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:47.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:48.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:48.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:49.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:49.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:50.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:50.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:51.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:51.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:52.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:52.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:53.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:53.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:54.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:54.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:55.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:55.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:56.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:56.670: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:57.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:57.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:58.671: INFO: Number of nodes with available pods: 0
Feb 27 03:27:58.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:27:59.670: INFO: Number of nodes with available pods: 0
Feb 27 03:27:59.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:28:00.674: INFO: Number of nodes with available pods: 0
Feb 27 03:28:00.674: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:28:01.670: INFO: Number of nodes with available pods: 0
Feb 27 03:28:01.671: INFO: Node ip-10-0-12-40.us-west-2.compute.internal is running more than one daemon pod
Feb 27 03:28:02.671: INFO: Number of nodes with available pods: 1
Feb 27 03:28:02.671: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-9tg27, will wait for the garbage collector to delete the pods
Feb 27 03:28:02.732: INFO: Deleting DaemonSet.extensions daemon-set took: 6.117198ms
Feb 27 03:28:02.833: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.216764ms
Feb 27 03:28:36.435: INFO: Number of nodes with available pods: 0
Feb 27 03:28:36.435: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 03:28:36.437: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9tg27/daemonsets","resourceVersion":"21735"},"items":null}

Feb 27 03:28:36.439: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9tg27/pods","resourceVersion":"21735"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:28:36.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9tg27" for this suite.
Feb 27 03:28:42.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:28:42.496: INFO: namespace: e2e-tests-daemonsets-9tg27, resource: bindings, ignored listing per whitelist
Feb 27 03:28:42.526: INFO: namespace e2e-tests-daemonsets-9tg27 deletion completed in 6.073312486s

• [SLOW TEST:79.011 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:28:42.527: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 03:28:42.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-glc6t'
Feb 27 03:28:43.201: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 03:28:43.201: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb 27 03:28:43.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-glc6t'
Feb 27 03:28:43.293: INFO: stderr: ""
Feb 27 03:28:43.293: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:28:43.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-glc6t" for this suite.
Feb 27 03:29:05.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:29:05.388: INFO: namespace: e2e-tests-kubectl-glc6t, resource: bindings, ignored listing per whitelist
Feb 27 03:29:05.457: INFO: namespace e2e-tests-kubectl-glc6t deletion completed in 22.160579848s

• [SLOW TEST:22.931 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:29:05.458: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d5c42ec1-3a3f-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 03:29:05.542: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d5c553da-3a3f-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-rs8p2" to be "success or failure"
Feb 27 03:29:05.547: INFO: Pod "pod-projected-configmaps-d5c553da-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.76456ms
Feb 27 03:29:07.550: INFO: Pod "pod-projected-configmaps-d5c553da-3a3f-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008601327s
Feb 27 03:29:09.553: INFO: Pod "pod-projected-configmaps-d5c553da-3a3f-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011629698s
STEP: Saw pod success
Feb 27 03:29:09.553: INFO: Pod "pod-projected-configmaps-d5c553da-3a3f-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:29:09.555: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-projected-configmaps-d5c553da-3a3f-11e9-8c03-2a4c52047ee8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 03:29:09.585: INFO: Waiting for pod pod-projected-configmaps-d5c553da-3a3f-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:29:09.588: INFO: Pod pod-projected-configmaps-d5c553da-3a3f-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:29:09.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rs8p2" for this suite.
Feb 27 03:29:15.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:29:15.651: INFO: namespace: e2e-tests-projected-rs8p2, resource: bindings, ignored listing per whitelist
Feb 27 03:29:15.663: INFO: namespace e2e-tests-projected-rs8p2 deletion completed in 6.072012931s

• [SLOW TEST:10.206 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:29:15.663: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:29:19.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-z865b" for this suite.
Feb 27 03:30:01.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:30:01.773: INFO: namespace: e2e-tests-kubelet-test-z865b, resource: bindings, ignored listing per whitelist
Feb 27 03:30:01.820: INFO: namespace e2e-tests-kubelet-test-z865b deletion completed in 42.068673967s

• [SLOW TEST:46.157 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:30:01.821: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:30:05.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-k75b2" for this suite.
Feb 27 03:30:51.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:30:51.969: INFO: namespace: e2e-tests-kubelet-test-k75b2, resource: bindings, ignored listing per whitelist
Feb 27 03:30:51.973: INFO: namespace e2e-tests-kubelet-test-k75b2 deletion completed in 46.069816862s

• [SLOW TEST:50.153 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:30:51.974: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-153f1dbd-3a40-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume configMaps
Feb 27 03:30:52.040: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-154036b8-3a40-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-jlndd" to be "success or failure"
Feb 27 03:30:52.043: INFO: Pod "pod-projected-configmaps-154036b8-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.469902ms
Feb 27 03:30:54.046: INFO: Pod "pod-projected-configmaps-154036b8-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006118463s
Feb 27 03:30:56.048: INFO: Pod "pod-projected-configmaps-154036b8-3a40-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008768506s
STEP: Saw pod success
Feb 27 03:30:56.049: INFO: Pod "pod-projected-configmaps-154036b8-3a40-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:30:56.050: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-projected-configmaps-154036b8-3a40-11e9-8c03-2a4c52047ee8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 03:30:56.065: INFO: Waiting for pod pod-projected-configmaps-154036b8-3a40-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:30:56.067: INFO: Pod pod-projected-configmaps-154036b8-3a40-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:30:56.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jlndd" for this suite.
Feb 27 03:31:02.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:31:02.098: INFO: namespace: e2e-tests-projected-jlndd, resource: bindings, ignored listing per whitelist
Feb 27 03:31:02.138: INFO: namespace e2e-tests-projected-jlndd deletion completed in 6.068452429s

• [SLOW TEST:10.164 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:31:02.138: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-1b4dc2df-3a40-11e9-8c03-2a4c52047ee8
Feb 27 03:31:02.196: INFO: Pod name my-hostname-basic-1b4dc2df-3a40-11e9-8c03-2a4c52047ee8: Found 0 pods out of 1
Feb 27 03:31:07.199: INFO: Pod name my-hostname-basic-1b4dc2df-3a40-11e9-8c03-2a4c52047ee8: Found 1 pods out of 1
Feb 27 03:31:07.199: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1b4dc2df-3a40-11e9-8c03-2a4c52047ee8" are running
Feb 27 03:31:07.201: INFO: Pod "my-hostname-basic-1b4dc2df-3a40-11e9-8c03-2a4c52047ee8-fhjgz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 03:31:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 03:31:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 03:31:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 03:31:02 +0000 UTC Reason: Message:}])
Feb 27 03:31:07.201: INFO: Trying to dial the pod
Feb 27 03:31:12.209: INFO: Controller my-hostname-basic-1b4dc2df-3a40-11e9-8c03-2a4c52047ee8: Got expected result from replica 1 [my-hostname-basic-1b4dc2df-3a40-11e9-8c03-2a4c52047ee8-fhjgz]: "my-hostname-basic-1b4dc2df-3a40-11e9-8c03-2a4c52047ee8-fhjgz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:31:12.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-nskfm" for this suite.
Feb 27 03:31:18.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:31:18.246: INFO: namespace: e2e-tests-replication-controller-nskfm, resource: bindings, ignored listing per whitelist
Feb 27 03:31:18.283: INFO: namespace e2e-tests-replication-controller-nskfm deletion completed in 6.071445874s

• [SLOW TEST:16.145 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:31:18.283: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0227 03:31:48.877227      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 03:31:48.877: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:31:48.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rt7rc" for this suite.
Feb 27 03:31:54.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:31:54.922: INFO: namespace: e2e-tests-gc-rt7rc, resource: bindings, ignored listing per whitelist
Feb 27 03:31:54.943: INFO: namespace e2e-tests-gc-rt7rc deletion completed in 6.064301372s

• [SLOW TEST:36.660 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:31:54.944: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0227 03:31:56.053319      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 03:31:56.053: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:31:56.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bl7p6" for this suite.
Feb 27 03:32:02.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:32:02.099: INFO: namespace: e2e-tests-gc-bl7p6, resource: bindings, ignored listing per whitelist
Feb 27 03:32:02.124: INFO: namespace e2e-tests-gc-bl7p6 deletion completed in 6.068568155s

• [SLOW TEST:7.180 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:32:02.124: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 03:32:06.698: INFO: Successfully updated pod "labelsupdate3f0e3195-3a40-11e9-8c03-2a4c52047ee8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:32:08.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5x97g" for this suite.
Feb 27 03:32:30.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:32:30.794: INFO: namespace: e2e-tests-projected-5x97g, resource: bindings, ignored listing per whitelist
Feb 27 03:32:30.796: INFO: namespace e2e-tests-projected-5x97g deletion completed in 22.067460421s

• [SLOW TEST:28.672 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:32:30.796: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 27 03:32:30.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:31.005: INFO: stderr: ""
Feb 27 03:32:31.005: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 03:32:31.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:31.091: INFO: stderr: ""
Feb 27 03:32:31.091: INFO: stdout: "update-demo-nautilus-fbnfz update-demo-nautilus-hbn86 "
Feb 27 03:32:31.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-fbnfz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:31.168: INFO: stderr: ""
Feb 27 03:32:31.168: INFO: stdout: ""
Feb 27 03:32:31.168: INFO: update-demo-nautilus-fbnfz is created but not running
Feb 27 03:32:36.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:36.245: INFO: stderr: ""
Feb 27 03:32:36.245: INFO: stdout: "update-demo-nautilus-fbnfz update-demo-nautilus-hbn86 "
Feb 27 03:32:36.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-fbnfz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:36.316: INFO: stderr: ""
Feb 27 03:32:36.316: INFO: stdout: "true"
Feb 27 03:32:36.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-fbnfz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:36.393: INFO: stderr: ""
Feb 27 03:32:36.393: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 03:32:36.393: INFO: validating pod update-demo-nautilus-fbnfz
Feb 27 03:32:36.396: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 03:32:36.396: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 03:32:36.396: INFO: update-demo-nautilus-fbnfz is verified up and running
Feb 27 03:32:36.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-hbn86 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:36.469: INFO: stderr: ""
Feb 27 03:32:36.469: INFO: stdout: "true"
Feb 27 03:32:36.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-hbn86 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:36.539: INFO: stderr: ""
Feb 27 03:32:36.539: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 03:32:36.539: INFO: validating pod update-demo-nautilus-hbn86
Feb 27 03:32:36.542: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 03:32:36.542: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 03:32:36.542: INFO: update-demo-nautilus-hbn86 is verified up and running
STEP: rolling-update to new replication controller
Feb 27 03:32:36.543: INFO: scanned /root for discovery docs: <nil>
Feb 27 03:32:36.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:58.884: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 27 03:32:58.884: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 03:32:58.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:58.959: INFO: stderr: ""
Feb 27 03:32:58.959: INFO: stdout: "update-demo-kitten-64x6h update-demo-kitten-m65vn "
Feb 27 03:32:58.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-kitten-64x6h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:59.033: INFO: stderr: ""
Feb 27 03:32:59.033: INFO: stdout: "true"
Feb 27 03:32:59.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-kitten-64x6h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:59.103: INFO: stderr: ""
Feb 27 03:32:59.103: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 27 03:32:59.103: INFO: validating pod update-demo-kitten-64x6h
Feb 27 03:32:59.106: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 27 03:32:59.106: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 27 03:32:59.106: INFO: update-demo-kitten-64x6h is verified up and running
Feb 27 03:32:59.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-kitten-m65vn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:59.176: INFO: stderr: ""
Feb 27 03:32:59.176: INFO: stdout: "true"
Feb 27 03:32:59.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-kitten-m65vn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w75cs'
Feb 27 03:32:59.255: INFO: stderr: ""
Feb 27 03:32:59.255: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 27 03:32:59.255: INFO: validating pod update-demo-kitten-m65vn
Feb 27 03:32:59.259: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 27 03:32:59.259: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 27 03:32:59.259: INFO: update-demo-kitten-m65vn is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:32:59.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w75cs" for this suite.
Feb 27 03:33:21.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:33:21.282: INFO: namespace: e2e-tests-kubectl-w75cs, resource: bindings, ignored listing per whitelist
Feb 27 03:33:21.330: INFO: namespace e2e-tests-kubectl-w75cs deletion completed in 22.067918085s

• [SLOW TEST:50.534 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:33:21.330: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:33:21.391: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e454912-3a40-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-lhnjx" to be "success or failure"
Feb 27 03:33:21.397: INFO: Pod "downwardapi-volume-6e454912-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.178642ms
Feb 27 03:33:23.399: INFO: Pod "downwardapi-volume-6e454912-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007969428s
Feb 27 03:33:25.403: INFO: Pod "downwardapi-volume-6e454912-3a40-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011300821s
STEP: Saw pod success
Feb 27 03:33:25.403: INFO: Pod "downwardapi-volume-6e454912-3a40-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:33:25.409: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod downwardapi-volume-6e454912-3a40-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:33:25.437: INFO: Waiting for pod downwardapi-volume-6e454912-3a40-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:33:25.443: INFO: Pod downwardapi-volume-6e454912-3a40-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:33:25.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lhnjx" for this suite.
Feb 27 03:33:31.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:33:31.488: INFO: namespace: e2e-tests-projected-lhnjx, resource: bindings, ignored listing per whitelist
Feb 27 03:33:31.520: INFO: namespace e2e-tests-projected-lhnjx deletion completed in 6.074528871s

• [SLOW TEST:10.190 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:33:31.520: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-7458db7c-3a40-11e9-8c03-2a4c52047ee8
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:33:35.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rf6gl" for this suite.
Feb 27 03:33:57.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:33:57.662: INFO: namespace: e2e-tests-configmap-rf6gl, resource: bindings, ignored listing per whitelist
Feb 27 03:33:57.704: INFO: namespace e2e-tests-configmap-rf6gl deletion completed in 22.091508713s

• [SLOW TEST:26.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:33:57.705: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 27 03:33:57.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 create -f - --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:33:57.950: INFO: stderr: ""
Feb 27 03:33:57.950: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 03:33:57.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:33:58.033: INFO: stderr: ""
Feb 27 03:33:58.033: INFO: stdout: "update-demo-nautilus-b92ct update-demo-nautilus-cwlsm "
Feb 27 03:33:58.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-b92ct -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:33:58.108: INFO: stderr: ""
Feb 27 03:33:58.108: INFO: stdout: ""
Feb 27 03:33:58.108: INFO: update-demo-nautilus-b92ct is created but not running
Feb 27 03:34:03.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:03.191: INFO: stderr: ""
Feb 27 03:34:03.191: INFO: stdout: "update-demo-nautilus-b92ct update-demo-nautilus-cwlsm "
Feb 27 03:34:03.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-b92ct -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:03.265: INFO: stderr: ""
Feb 27 03:34:03.265: INFO: stdout: "true"
Feb 27 03:34:03.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-b92ct -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:03.336: INFO: stderr: ""
Feb 27 03:34:03.336: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 03:34:03.336: INFO: validating pod update-demo-nautilus-b92ct
Feb 27 03:34:03.339: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 03:34:03.339: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 03:34:03.339: INFO: update-demo-nautilus-b92ct is verified up and running
Feb 27 03:34:03.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-cwlsm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:03.410: INFO: stderr: ""
Feb 27 03:34:03.410: INFO: stdout: "true"
Feb 27 03:34:03.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-cwlsm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:03.482: INFO: stderr: ""
Feb 27 03:34:03.482: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 03:34:03.482: INFO: validating pod update-demo-nautilus-cwlsm
Feb 27 03:34:03.486: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 03:34:03.486: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 03:34:03.486: INFO: update-demo-nautilus-cwlsm is verified up and running
STEP: scaling down the replication controller
Feb 27 03:34:03.488: INFO: scanned /root for discovery docs: <nil>
Feb 27 03:34:03.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:04.598: INFO: stderr: ""
Feb 27 03:34:04.598: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 03:34:04.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:04.745: INFO: stderr: ""
Feb 27 03:34:04.745: INFO: stdout: "update-demo-nautilus-b92ct update-demo-nautilus-cwlsm "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 27 03:34:09.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:09.823: INFO: stderr: ""
Feb 27 03:34:09.823: INFO: stdout: "update-demo-nautilus-b92ct update-demo-nautilus-cwlsm "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 27 03:34:14.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:14.895: INFO: stderr: ""
Feb 27 03:34:14.895: INFO: stdout: "update-demo-nautilus-cwlsm "
Feb 27 03:34:14.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-cwlsm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:14.966: INFO: stderr: ""
Feb 27 03:34:14.966: INFO: stdout: "true"
Feb 27 03:34:14.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-cwlsm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:15.037: INFO: stderr: ""
Feb 27 03:34:15.037: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 03:34:15.037: INFO: validating pod update-demo-nautilus-cwlsm
Feb 27 03:34:15.039: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 03:34:15.039: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 03:34:15.039: INFO: update-demo-nautilus-cwlsm is verified up and running
STEP: scaling up the replication controller
Feb 27 03:34:15.041: INFO: scanned /root for discovery docs: <nil>
Feb 27 03:34:15.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:16.143: INFO: stderr: ""
Feb 27 03:34:16.143: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 03:34:16.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:16.225: INFO: stderr: ""
Feb 27 03:34:16.225: INFO: stdout: "update-demo-nautilus-2k9xs update-demo-nautilus-cwlsm "
Feb 27 03:34:16.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-2k9xs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:16.294: INFO: stderr: ""
Feb 27 03:34:16.294: INFO: stdout: ""
Feb 27 03:34:16.294: INFO: update-demo-nautilus-2k9xs is created but not running
Feb 27 03:34:21.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:21.377: INFO: stderr: ""
Feb 27 03:34:21.377: INFO: stdout: "update-demo-nautilus-2k9xs update-demo-nautilus-cwlsm "
Feb 27 03:34:21.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-2k9xs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:21.446: INFO: stderr: ""
Feb 27 03:34:21.446: INFO: stdout: "true"
Feb 27 03:34:21.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-2k9xs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:21.528: INFO: stderr: ""
Feb 27 03:34:21.528: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 03:34:21.528: INFO: validating pod update-demo-nautilus-2k9xs
Feb 27 03:34:21.532: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 03:34:21.532: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 03:34:21.532: INFO: update-demo-nautilus-2k9xs is verified up and running
Feb 27 03:34:21.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-cwlsm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:21.602: INFO: stderr: ""
Feb 27 03:34:21.603: INFO: stdout: "true"
Feb 27 03:34:21.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods update-demo-nautilus-cwlsm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:21.675: INFO: stderr: ""
Feb 27 03:34:21.675: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 03:34:21.675: INFO: validating pod update-demo-nautilus-cwlsm
Feb 27 03:34:21.677: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 03:34:21.677: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 03:34:21.677: INFO: update-demo-nautilus-cwlsm is verified up and running
STEP: using delete to clean up resources
Feb 27 03:34:21.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:21.751: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 03:34:21.752: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 27 03:34:21.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-9tblj'
Feb 27 03:34:21.926: INFO: stderr: "No resources found.\n"
Feb 27 03:34:21.926: INFO: stdout: ""
Feb 27 03:34:21.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -l name=update-demo --namespace=e2e-tests-kubectl-9tblj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 03:34:22.041: INFO: stderr: ""
Feb 27 03:34:22.041: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:34:22.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9tblj" for this suite.
Feb 27 03:34:44.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:34:44.064: INFO: namespace: e2e-tests-kubectl-9tblj, resource: bindings, ignored listing per whitelist
Feb 27 03:34:44.119: INFO: namespace e2e-tests-kubectl-9tblj deletion completed in 22.075188797s

• [SLOW TEST:46.414 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:34:44.120: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9f9e3652-3a40-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 03:34:44.189: INFO: Waiting up to 5m0s for pod "pod-secrets-9f9f4930-3a40-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-secrets-gxfsp" to be "success or failure"
Feb 27 03:34:44.192: INFO: Pod "pod-secrets-9f9f4930-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.978068ms
Feb 27 03:34:46.195: INFO: Pod "pod-secrets-9f9f4930-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00599789s
Feb 27 03:34:48.198: INFO: Pod "pod-secrets-9f9f4930-3a40-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009634639s
STEP: Saw pod success
Feb 27 03:34:48.198: INFO: Pod "pod-secrets-9f9f4930-3a40-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:34:48.200: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-secrets-9f9f4930-3a40-11e9-8c03-2a4c52047ee8 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 03:34:48.218: INFO: Waiting for pod pod-secrets-9f9f4930-3a40-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:34:48.224: INFO: Pod pod-secrets-9f9f4930-3a40-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:34:48.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gxfsp" for this suite.
Feb 27 03:34:54.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:34:54.286: INFO: namespace: e2e-tests-secrets-gxfsp, resource: bindings, ignored listing per whitelist
Feb 27 03:34:54.293: INFO: namespace e2e-tests-secrets-gxfsp deletion completed in 6.066769817s

• [SLOW TEST:10.173 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:34:54.293: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:34:54.357: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a5ae7515-3a40-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-xlbgp" to be "success or failure"
Feb 27 03:34:54.360: INFO: Pod "downwardapi-volume-a5ae7515-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.780649ms
Feb 27 03:34:56.363: INFO: Pod "downwardapi-volume-a5ae7515-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005761654s
Feb 27 03:34:58.366: INFO: Pod "downwardapi-volume-a5ae7515-3a40-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008788449s
STEP: Saw pod success
Feb 27 03:34:58.366: INFO: Pod "downwardapi-volume-a5ae7515-3a40-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:34:58.367: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod downwardapi-volume-a5ae7515-3a40-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:34:58.382: INFO: Waiting for pod downwardapi-volume-a5ae7515-3a40-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:34:58.389: INFO: Pod downwardapi-volume-a5ae7515-3a40-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:34:58.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xlbgp" for this suite.
Feb 27 03:35:04.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:35:04.420: INFO: namespace: e2e-tests-projected-xlbgp, resource: bindings, ignored listing per whitelist
Feb 27 03:35:04.460: INFO: namespace e2e-tests-projected-xlbgp deletion completed in 6.068125216s

• [SLOW TEST:10.167 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:35:04.462: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 03:35:09.071: INFO: Successfully updated pod "annotationupdateabc012fa-3a40-11e9-8c03-2a4c52047ee8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:35:11.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jrm8z" for this suite.
Feb 27 03:35:33.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:35:33.129: INFO: namespace: e2e-tests-downward-api-jrm8z, resource: bindings, ignored listing per whitelist
Feb 27 03:35:33.180: INFO: namespace e2e-tests-downward-api-jrm8z deletion completed in 22.093208538s

• [SLOW TEST:28.718 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:35:33.180: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 03:35:33.237: INFO: Creating deployment "nginx-deployment"
Feb 27 03:35:33.245: INFO: Waiting for observed generation 1
Feb 27 03:35:35.253: INFO: Waiting for all required pods to come up
Feb 27 03:35:35.256: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 27 03:35:39.276: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 27 03:35:39.282: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 27 03:35:39.287: INFO: Updating deployment nginx-deployment
Feb 27 03:35:39.287: INFO: Waiting for observed generation 2
Feb 27 03:35:41.292: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 27 03:35:41.294: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 27 03:35:41.296: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 27 03:35:41.301: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 27 03:35:41.301: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 27 03:35:41.303: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 27 03:35:41.306: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 27 03:35:41.306: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 27 03:35:41.310: INFO: Updating deployment nginx-deployment
Feb 27 03:35:41.310: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 27 03:35:41.315: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 27 03:35:41.319: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 03:35:41.345: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5fj7p/deployments/nginx-deployment,UID:bcdb44e2-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23154,Generation:3,CreationTimestamp:2019-02-27 03:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Available True 2019-02-27 03:35:37 +0000 UTC 2019-02-27 03:35:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-27 03:35:39 +0000 UTC 2019-02-27 03:35:33 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 27 03:35:41.367: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5fj7p/replicasets/nginx-deployment-65bbdb5f8,UID:c076a467-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23158,Generation:3,CreationTimestamp:2019-02-27 03:35:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bcdb44e2-3a40-11e9-8378-02ce1f9c2c90 0xc001e6e387 0xc001e6e388}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 03:35:41.368: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 27 03:35:41.368: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5fj7p/replicasets/nginx-deployment-555b55d965,UID:bcdd1de2-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23155,Generation:3,CreationTimestamp:2019-02-27 03:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bcdb44e2-3a40-11e9-8378-02ce1f9c2c90 0xc001e6e1d7 0xc001e6e1d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 27 03:35:41.399: INFO: Pod "nginx-deployment-555b55d965-2t4wl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2t4wl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-2t4wl,UID:bcdfcabe-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23047,Generation:0,CreationTimestamp:2019-02-27 03:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0020f95d7 0xc0020f95d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020f96a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020f96c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.40,PodIP:192.168.161.12,StartTime:2019-02-27 03:35:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 03:35:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://c5dcdb59fd7517ca672f66e38ded13567d7a45a690f7d2baeaa8f6db7daaf097}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.399: INFO: Pod "nginx-deployment-555b55d965-4bnqw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4bnqw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-4bnqw,UID:bcdefcb8-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23067,Generation:0,CreationTimestamp:2019-02-27 03:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0020f9780 0xc0020f9781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020f97e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020f9800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.30.134,PodIP:192.168.48.232,StartTime:2019-02-27 03:35:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 03:35:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://fd058f3e947c48d182cd54d61a6648b785fa47ca6eb3553c521985672779847e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.399: INFO: Pod "nginx-deployment-555b55d965-4wrzs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4wrzs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-4wrzs,UID:bcdfe92e-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23063,Generation:0,CreationTimestamp:2019-02-27 03:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0020f99c0 0xc0020f99c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020f9a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020f9a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.30.134,PodIP:192.168.48.236,StartTime:2019-02-27 03:35:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 03:35:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://b718111411444d528dc7ab2765653e1507339dd90d444dda0b3f691f9f80ad49}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.399: INFO: Pod "nginx-deployment-555b55d965-4z8ht" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4z8ht,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-4z8ht,UID:bce1fb35-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23083,Generation:0,CreationTimestamp:2019-02-27 03:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0020f9bf0 0xc0020f9bf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020f9c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020f9c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.40,PodIP:192.168.161.13,StartTime:2019-02-27 03:35:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 03:35:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://1163eabf43b2d3a6e4bf537c643e98948f6a4fea8d36449ab249d1d2d79dc77c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.399: INFO: Pod "nginx-deployment-555b55d965-6f5qw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6f5qw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-6f5qw,UID:c1b41989-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23183,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0008d2590 0xc0008d2591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008d26b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008d26d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.400: INFO: Pod "nginx-deployment-555b55d965-6sttq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6sttq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-6sttq,UID:bce2e72a-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23070,Generation:0,CreationTimestamp:2019-02-27 03:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0008d2727 0xc0008d2728}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008d2ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008d2b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.30.134,PodIP:192.168.48.234,StartTime:2019-02-27 03:35:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 03:35:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://2fc90858ef96524d97463f37ce0cfb81eca05037bb03eb940c085997523992f8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.400: INFO: Pod "nginx-deployment-555b55d965-hhmdw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hhmdw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-hhmdw,UID:bce65703-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23081,Generation:0,CreationTimestamp:2019-02-27 03:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0008d2bc0 0xc0008d2bc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008d2ca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008d2cc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.40,PodIP:192.168.161.15,StartTime:2019-02-27 03:35:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 03:35:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://f6814c3c991fd1285151ac1bb9e35697a3b0b42f8e36f5fadd26245c21bae4f5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.400: INFO: Pod "nginx-deployment-555b55d965-jmdwj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jmdwj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-jmdwj,UID:c1b42f00-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23173,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0008d3810 0xc0008d3811}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008d3870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008d3890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.400: INFO: Pod "nginx-deployment-555b55d965-k2nrs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k2nrs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-k2nrs,UID:c1b422d6-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23184,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0008d38e7 0xc0008d38e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008d3be0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008d3c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.400: INFO: Pod "nginx-deployment-555b55d965-ktvbx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ktvbx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-ktvbx,UID:c1aea4e5-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23178,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0008d3c97 0xc0008d3c98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008d3d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008d3d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.400: INFO: Pod "nginx-deployment-555b55d965-prh2x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-prh2x,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-prh2x,UID:c1b3ff22-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23181,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0008d3e00 0xc0008d3e01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008d3e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008d3e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.400: INFO: Pod "nginx-deployment-555b55d965-qlrgq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qlrgq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-qlrgq,UID:c1ac630d-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23180,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc0008d3ed7 0xc0008d3ed8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0008d3f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0008d3f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:41 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.40,PodIP:,StartTime:2019-02-27 03:35:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.401: INFO: Pod "nginx-deployment-555b55d965-qmztm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qmztm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-qmztm,UID:bce2f73e-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23072,Generation:0,CreationTimestamp:2019-02-27 03:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc001f8c1a0 0xc001f8c1a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8c220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8c240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.30.134,PodIP:192.168.48.230,StartTime:2019-02-27 03:35:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 03:35:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://d606b9420f78d4e2c7a0be5db33e5e858ca1dad591319e51525541f75f2b4ff8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.401: INFO: Pod "nginx-deployment-555b55d965-rjzlx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rjzlx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-rjzlx,UID:c1ae6eef-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23167,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc001f8c390 0xc001f8c391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8c3f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8c410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.401: INFO: Pod "nginx-deployment-555b55d965-sr65s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-sr65s,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-555b55d965-sr65s,UID:bce26d8a-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23087,Generation:0,CreationTimestamp:2019-02-27 03:35:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bcdd1de2-3a40-11e9-8378-02ce1f9c2c90 0xc001f8c490 0xc001f8c491}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8c500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8c540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.40,PodIP:192.168.161.16,StartTime:2019-02-27 03:35:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 03:35:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://3786a9e02879c7152615b61fb6b57259e92d185249e1f2dbe81e20026784af6c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.401: INFO: Pod "nginx-deployment-65bbdb5f8-666kg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-666kg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-666kg,UID:c084dc0d-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23146,Generation:0,CreationTimestamp:2019-02-27 03:35:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001f8d170 0xc001f8d171}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8d1e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8d200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.40,PodIP:,StartTime:2019-02-27 03:35:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.401: INFO: Pod "nginx-deployment-65bbdb5f8-7knk9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7knk9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-7knk9,UID:c1b39bee-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23176,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001f8d2e0 0xc001f8d2e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8d9b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8d9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.401: INFO: Pod "nginx-deployment-65bbdb5f8-cvmkw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cvmkw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-cvmkw,UID:c086e746-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23145,Generation:0,CreationTimestamp:2019-02-27 03:35:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001f8da27 0xc001f8da28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8db40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8db60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.30.134,PodIP:,StartTime:2019-02-27 03:35:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.402: INFO: Pod "nginx-deployment-65bbdb5f8-czd2q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-czd2q,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-czd2q,UID:c0774428-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23116,Generation:0,CreationTimestamp:2019-02-27 03:35:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001f8dc80 0xc001f8dc81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8dcf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8dd10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.30.134,PodIP:,StartTime:2019-02-27 03:35:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.402: INFO: Pod "nginx-deployment-65bbdb5f8-dqxtc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dqxtc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-dqxtc,UID:c078decb-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23124,Generation:0,CreationTimestamp:2019-02-27 03:35:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001f8de10 0xc001f8de11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f8de80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f8dea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.12.40,PodIP:,StartTime:2019-02-27 03:35:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.402: INFO: Pod "nginx-deployment-65bbdb5f8-gzmtt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gzmtt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-gzmtt,UID:c1b425a1-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23185,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001f8dfa0 0xc001f8dfa1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d6e010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d6e030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.402: INFO: Pod "nginx-deployment-65bbdb5f8-hr9zt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hr9zt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-hr9zt,UID:c1b415eb-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23182,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001d6e087 0xc001d6e088}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d6e130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d6e150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.402: INFO: Pod "nginx-deployment-65bbdb5f8-nnlw8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nnlw8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-nnlw8,UID:c1af433e-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23175,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001d6e1a7 0xc001d6e1a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d6e210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d6e230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.402: INFO: Pod "nginx-deployment-65bbdb5f8-s5jb9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-s5jb9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-s5jb9,UID:c078f831-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23128,Generation:0,CreationTimestamp:2019-02-27 03:35:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001d6e2d0 0xc001d6e2d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d6e340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d6e360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.30.134,PodIP:,StartTime:2019-02-27 03:35:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.402: INFO: Pod "nginx-deployment-65bbdb5f8-twdf8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-twdf8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-twdf8,UID:c1b3e9f8-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23179,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001d6e420 0xc001d6e421}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d6e510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d6e540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.403: INFO: Pod "nginx-deployment-65bbdb5f8-zkhhd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zkhhd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-zkhhd,UID:c1ad67e4-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23168,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001d6e597 0xc001d6e598}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-12-40.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d6e600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d6e690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 03:35:41.403: INFO: Pod "nginx-deployment-65bbdb5f8-zvb9r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zvb9r,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5fj7p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5fj7p/pods/nginx-deployment-65bbdb5f8-zvb9r,UID:c1af4822-3a40-11e9-8378-02ce1f9c2c90,ResourceVersion:23177,Generation:0,CreationTimestamp:2019-02-27 03:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c076a467-3a40-11e9-8378-02ce1f9c2c90 0xc001d6e700 0xc001d6e701}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nlcv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nlcv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7nlcv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-134.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d6e780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d6e7a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 03:35:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:35:41.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5fj7p" for this suite.
Feb 27 03:35:49.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:35:49.530: INFO: namespace: e2e-tests-deployment-5fj7p, resource: bindings, ignored listing per whitelist
Feb 27 03:35:49.574: INFO: namespace e2e-tests-deployment-5fj7p deletion completed in 8.152826193s

• [SLOW TEST:16.394 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:35:49.574: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:35:53.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-p5gwx" for this suite.
Feb 27 03:36:43.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:36:43.737: INFO: namespace: e2e-tests-kubelet-test-p5gwx, resource: bindings, ignored listing per whitelist
Feb 27 03:36:43.774: INFO: namespace e2e-tests-kubelet-test-p5gwx deletion completed in 50.072410623s

• [SLOW TEST:54.199 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:36:43.774: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:36:43.838: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6ef6e69-3a40-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-t8pvv" to be "success or failure"
Feb 27 03:36:43.840: INFO: Pod "downwardapi-volume-e6ef6e69-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.365392ms
Feb 27 03:36:45.843: INFO: Pod "downwardapi-volume-e6ef6e69-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005463937s
Feb 27 03:36:47.847: INFO: Pod "downwardapi-volume-e6ef6e69-3a40-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008857436s
STEP: Saw pod success
Feb 27 03:36:47.847: INFO: Pod "downwardapi-volume-e6ef6e69-3a40-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:36:47.849: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod downwardapi-volume-e6ef6e69-3a40-11e9-8c03-2a4c52047ee8 container client-container: <nil>
STEP: delete the pod
Feb 27 03:36:47.873: INFO: Waiting for pod downwardapi-volume-e6ef6e69-3a40-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:36:47.880: INFO: Pod downwardapi-volume-e6ef6e69-3a40-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:36:47.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t8pvv" for this suite.
Feb 27 03:36:53.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:36:53.930: INFO: namespace: e2e-tests-projected-t8pvv, resource: bindings, ignored listing per whitelist
Feb 27 03:36:53.956: INFO: namespace e2e-tests-projected-t8pvv deletion completed in 6.069562309s

• [SLOW TEST:10.182 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:36:53.956: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 27 03:36:54.022: INFO: Waiting up to 5m0s for pod "pod-ed018e07-3a40-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-emptydir-8qvzg" to be "success or failure"
Feb 27 03:36:54.028: INFO: Pod "pod-ed018e07-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.739372ms
Feb 27 03:36:56.031: INFO: Pod "pod-ed018e07-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008610714s
Feb 27 03:36:58.034: INFO: Pod "pod-ed018e07-3a40-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011471924s
STEP: Saw pod success
Feb 27 03:36:58.034: INFO: Pod "pod-ed018e07-3a40-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:36:58.036: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-ed018e07-3a40-11e9-8c03-2a4c52047ee8 container test-container: <nil>
STEP: delete the pod
Feb 27 03:36:58.050: INFO: Waiting for pod pod-ed018e07-3a40-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:36:58.052: INFO: Pod pod-ed018e07-3a40-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:36:58.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8qvzg" for this suite.
Feb 27 03:37:04.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:37:04.120: INFO: namespace: e2e-tests-emptydir-8qvzg, resource: bindings, ignored listing per whitelist
Feb 27 03:37:04.121: INFO: namespace e2e-tests-emptydir-8qvzg deletion completed in 6.066955947s

• [SLOW TEST:10.165 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:37:04.122: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f3128e4c-3a40-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 03:37:04.202: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f31320b1-3a40-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-t57tj" to be "success or failure"
Feb 27 03:37:04.205: INFO: Pod "pod-projected-secrets-f31320b1-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.925874ms
Feb 27 03:37:06.208: INFO: Pod "pod-projected-secrets-f31320b1-3a40-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005814679s
Feb 27 03:37:08.211: INFO: Pod "pod-projected-secrets-f31320b1-3a40-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008629904s
STEP: Saw pod success
Feb 27 03:37:08.211: INFO: Pod "pod-projected-secrets-f31320b1-3a40-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:37:08.212: INFO: Trying to get logs from node ip-10-0-12-40.us-west-2.compute.internal pod pod-projected-secrets-f31320b1-3a40-11e9-8c03-2a4c52047ee8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 03:37:08.226: INFO: Waiting for pod pod-projected-secrets-f31320b1-3a40-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:37:08.229: INFO: Pod pod-projected-secrets-f31320b1-3a40-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:37:08.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t57tj" for this suite.
Feb 27 03:37:14.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:37:14.275: INFO: namespace: e2e-tests-projected-t57tj, resource: bindings, ignored listing per whitelist
Feb 27 03:37:14.306: INFO: namespace e2e-tests-projected-t57tj deletion completed in 6.074129702s

• [SLOW TEST:10.184 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:37:14.306: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 03:37:14.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-2d8dp'
Feb 27 03:37:14.465: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 03:37:14.465: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 27 03:37:14.477: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 27 03:37:14.484: INFO: scanned /root for discovery docs: <nil>
Feb 27 03:37:14.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-2d8dp'
Feb 27 03:37:30.312: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 27 03:37:30.312: INFO: stdout: "Created e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4\nScaling up e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 27 03:37:30.312: INFO: stdout: "Created e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4\nScaling up e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 27 03:37:30.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2d8dp'
Feb 27 03:37:30.385: INFO: stderr: ""
Feb 27 03:37:30.385: INFO: stdout: "e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4-krwws "
Feb 27 03:37:30.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4-krwws -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2d8dp'
Feb 27 03:37:30.456: INFO: stderr: ""
Feb 27 03:37:30.456: INFO: stdout: "true"
Feb 27 03:37:30.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 get pods e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4-krwws -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2d8dp'
Feb 27 03:37:30.527: INFO: stderr: ""
Feb 27 03:37:30.527: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 27 03:37:30.527: INFO: e2e-test-nginx-rc-e8a094db701285666e2f49123ee8bbe4-krwws is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb 27 03:37:30.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2d8dp'
Feb 27 03:37:30.607: INFO: stderr: ""
Feb 27 03:37:30.607: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:37:30.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2d8dp" for this suite.
Feb 27 03:37:52.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:37:52.640: INFO: namespace: e2e-tests-kubectl-2d8dp, resource: bindings, ignored listing per whitelist
Feb 27 03:37:52.687: INFO: namespace e2e-tests-kubectl-2d8dp deletion completed in 22.074748687s

• [SLOW TEST:38.381 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:37:52.687: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 03:38:14.756: INFO: Container started at 2019-02-27 03:37:54 +0000 UTC, pod became ready at 2019-02-27 03:38:14 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:38:14.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-97gvl" for this suite.
Feb 27 03:38:36.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:38:36.821: INFO: namespace: e2e-tests-container-probe-97gvl, resource: bindings, ignored listing per whitelist
Feb 27 03:38:36.826: INFO: namespace e2e-tests-container-probe-97gvl deletion completed in 22.067022532s

• [SLOW TEST:44.139 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:38:36.826: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 03:38:36.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-861261599 version'
Feb 27 03:38:36.954: INFO: stderr: ""
Feb 27 03:38:36.954: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.2\", GitCommit:\"cff46ab41ff0bb44d8584413b598ad8360ec1def\", GitTreeState:\"clean\", BuildDate:\"2019-01-10T23:28:14Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:38:36.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-547lr" for this suite.
Feb 27 03:38:42.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:38:42.998: INFO: namespace: e2e-tests-kubectl-547lr, resource: bindings, ignored listing per whitelist
Feb 27 03:38:43.023: INFO: namespace e2e-tests-kubectl-547lr deletion completed in 6.066233868s

• [SLOW TEST:6.197 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:38:43.023: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 27 03:38:47.096: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-2e02995b-3a41-11e9-8c03-2a4c52047ee8", GenerateName:"", Namespace:"e2e-tests-pods-tpctr", SelfLink:"/api/v1/namespaces/e2e-tests-pods-tpctr/pods/pod-submit-remove-2e02995b-3a41-11e9-8c03-2a4c52047ee8", UID:"2e02e9a4-3a41-11e9-8378-02ce1f9c2c90", ResourceVersion:"23965", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686835523, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"71836941"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-zpxj9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002496140), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-zpxj9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002426098), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-12-40.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001c22000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024260d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024260f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0024260f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0024260fc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686835523, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686835525, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686835525, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686835523, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.12.40", PodIP:"192.168.161.31", StartTime:(*v1.Time)(0xc002614120), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc002614140), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://4dde1cf0a56acc73c13291b7cd6e92f5720e496a9938b69a80e44939971c922d"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:38:59.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tpctr" for this suite.
Feb 27 03:39:05.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:39:05.525: INFO: namespace: e2e-tests-pods-tpctr, resource: bindings, ignored listing per whitelist
Feb 27 03:39:05.615: INFO: namespace e2e-tests-pods-tpctr deletion completed in 6.106620792s

• [SLOW TEST:22.592 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:39:05.615: INFO: >>> kubeConfig: /tmp/kubeconfig-861261599
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3b7c5fe3-3a41-11e9-8c03-2a4c52047ee8
STEP: Creating a pod to test consume secrets
Feb 27 03:39:05.693: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3b7cc144-3a41-11e9-8c03-2a4c52047ee8" in namespace "e2e-tests-projected-k6bm7" to be "success or failure"
Feb 27 03:39:05.696: INFO: Pod "pod-projected-secrets-3b7cc144-3a41-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.259239ms
Feb 27 03:39:07.700: INFO: Pod "pod-projected-secrets-3b7cc144-3a41-11e9-8c03-2a4c52047ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006694308s
Feb 27 03:39:09.702: INFO: Pod "pod-projected-secrets-3b7cc144-3a41-11e9-8c03-2a4c52047ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008873603s
STEP: Saw pod success
Feb 27 03:39:09.702: INFO: Pod "pod-projected-secrets-3b7cc144-3a41-11e9-8c03-2a4c52047ee8" satisfied condition "success or failure"
Feb 27 03:39:09.703: INFO: Trying to get logs from node ip-10-0-30-134.us-west-2.compute.internal pod pod-projected-secrets-3b7cc144-3a41-11e9-8c03-2a4c52047ee8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 03:39:09.735: INFO: Waiting for pod pod-projected-secrets-3b7cc144-3a41-11e9-8c03-2a4c52047ee8 to disappear
Feb 27 03:39:09.745: INFO: Pod pod-projected-secrets-3b7cc144-3a41-11e9-8c03-2a4c52047ee8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:39:09.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k6bm7" for this suite.
Feb 27 03:39:15.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:39:15.793: INFO: namespace: e2e-tests-projected-k6bm7, resource: bindings, ignored listing per whitelist
Feb 27 03:39:15.828: INFO: namespace e2e-tests-projected-k6bm7 deletion completed in 6.078782629s

• [SLOW TEST:10.212 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSFeb 27 03:39:15.828: INFO: Running AfterSuite actions on all nodes
Feb 27 03:39:15.828: INFO: Running AfterSuite actions on node 1
Feb 27 03:39:15.828: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6180.668 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h43m2.304656286s
Test Suite Passed
