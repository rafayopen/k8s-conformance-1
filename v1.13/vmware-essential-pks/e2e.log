I0319 13:34:40.564507      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-015262165
I0319 13:34:40.564657      15 e2e.go:224] Starting e2e run "bf0a995b-4a4b-11e9-9c64-0a580af40204" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1553002479 - Will randomize all specs
Will run 201 of 1946 specs

Mar 19 13:34:40.715: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 13:34:40.718: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 19 13:34:40.728: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 19 13:34:40.752: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 19 13:34:40.752: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Mar 19 13:34:40.752: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 19 13:34:40.760: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Mar 19 13:34:40.760: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
Mar 19 13:34:40.760: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
Mar 19 13:34:40.760: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
Mar 19 13:34:40.760: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
Mar 19 13:34:40.760: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar 19 13:34:40.760: INFO: e2e test version: v1.13.0
Mar 19 13:34:40.761: INFO: kube-apiserver version: v1.13.4+vmware.1
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:34:40.762: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename gc
Mar 19 13:34:40.814: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0319 13:34:46.835281      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 13:34:46.835: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:34:46.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jt2ft" for this suite.
Mar 19 13:34:52.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:34:52.891: INFO: namespace: e2e-tests-gc-jt2ft, resource: bindings, ignored listing per whitelist
Mar 19 13:34:52.905: INFO: namespace e2e-tests-gc-jt2ft deletion completed in 6.066903163s

â€¢ [SLOW TEST:12.142 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:34:52.906: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar 19 13:34:52.970: INFO: Waiting up to 5m0s for pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204" in namespace "e2e-tests-containers-pmf7m" to be "success or failure"
Mar 19 13:34:52.973: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.593794ms
Mar 19 13:34:54.976: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00565205s
Mar 19 13:34:56.979: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008340399s
Mar 19 13:34:58.982: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011370654s
Mar 19 13:35:00.985: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014549393s
Mar 19 13:35:02.988: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 10.01706681s
Mar 19 13:35:04.991: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020763378s
Mar 19 13:35:06.995: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 14.024404752s
Mar 19 13:35:08.998: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 16.027850058s
Mar 19 13:35:11.001: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 18.030272573s
Mar 19 13:35:13.003: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 20.033012064s
Mar 19 13:35:15.009: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 22.038827045s
Mar 19 13:35:17.012: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 24.041689634s
Mar 19 13:35:19.015: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.044347622s
STEP: Saw pod success
Mar 19 13:35:19.015: INFO: Pod "client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:35:19.018: INFO: Trying to get logs from node essentialpks-conformance-3 pod client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 13:35:19.045: INFO: Waiting for pod client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204 to disappear
Mar 19 13:35:19.048: INFO: Pod client-containers-c6ca09d2-4a4b-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:35:19.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-pmf7m" for this suite.
Mar 19 13:35:25.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:35:25.090: INFO: namespace: e2e-tests-containers-pmf7m, resource: bindings, ignored listing per whitelist
Mar 19 13:35:25.128: INFO: namespace e2e-tests-containers-pmf7m deletion completed in 6.075687789s

â€¢ [SLOW TEST:32.223 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:35:25.128: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 19 13:35:29.198: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-d9fe55ab-4a4b-11e9-9c64-0a580af40204,GenerateName:,Namespace:e2e-tests-events-fdmmg,SelfLink:/api/v1/namespaces/e2e-tests-events-fdmmg/pods/send-events-d9fe55ab-4a4b-11e9-9c64-0a580af40204,UID:d9febc94-4a4b-11e9-9b06-005056a45e5c,ResourceVersion:2146,Generation:0,CreationTimestamp:2019-03-19 13:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 183740693,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9vlnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9vlnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-9vlnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aadbb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aadbd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 13:35:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 13:35:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 13:35:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 13:35:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:10.244.2.10,StartTime:2019-03-19 13:35:25 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-19 13:35:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://51451bfa99c9ddd845918b8011d6305ff8cc05949b1a6d0b9442ebeb7886b9be}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar 19 13:35:31.202: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 19 13:35:33.205: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:35:33.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-fdmmg" for this suite.
Mar 19 13:36:11.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:36:11.325: INFO: namespace: e2e-tests-events-fdmmg, resource: bindings, ignored listing per whitelist
Mar 19 13:36:11.335: INFO: namespace e2e-tests-events-fdmmg deletion completed in 38.122243733s

â€¢ [SLOW TEST:46.206 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:36:11.335: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 19 13:36:11.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-jddr7'
Mar 19 13:36:11.778: INFO: stderr: ""
Mar 19 13:36:11.778: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 13:36:11.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jddr7'
Mar 19 13:36:11.873: INFO: stderr: ""
Mar 19 13:36:11.873: INFO: stdout: "update-demo-nautilus-dmt5l update-demo-nautilus-dvzp8 "
Mar 19 13:36:11.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-dmt5l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jddr7'
Mar 19 13:36:11.953: INFO: stderr: ""
Mar 19 13:36:11.953: INFO: stdout: ""
Mar 19 13:36:11.953: INFO: update-demo-nautilus-dmt5l is created but not running
Mar 19 13:36:16.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jddr7'
Mar 19 13:36:17.035: INFO: stderr: ""
Mar 19 13:36:17.035: INFO: stdout: "update-demo-nautilus-dmt5l update-demo-nautilus-dvzp8 "
Mar 19 13:36:17.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-dmt5l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jddr7'
Mar 19 13:36:17.110: INFO: stderr: ""
Mar 19 13:36:17.110: INFO: stdout: "true"
Mar 19 13:36:17.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-dmt5l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jddr7'
Mar 19 13:36:17.189: INFO: stderr: ""
Mar 19 13:36:17.189: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 13:36:17.189: INFO: validating pod update-demo-nautilus-dmt5l
Mar 19 13:36:17.194: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 13:36:17.194: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 13:36:17.194: INFO: update-demo-nautilus-dmt5l is verified up and running
Mar 19 13:36:17.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-dvzp8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jddr7'
Mar 19 13:36:17.287: INFO: stderr: ""
Mar 19 13:36:17.287: INFO: stdout: "true"
Mar 19 13:36:17.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-dvzp8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jddr7'
Mar 19 13:36:17.366: INFO: stderr: ""
Mar 19 13:36:17.366: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 13:36:17.366: INFO: validating pod update-demo-nautilus-dvzp8
Mar 19 13:36:17.371: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 13:36:17.371: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 13:36:17.371: INFO: update-demo-nautilus-dvzp8 is verified up and running
STEP: using delete to clean up resources
Mar 19 13:36:17.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jddr7'
Mar 19 13:36:17.455: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 13:36:17.455: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 19 13:36:17.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-jddr7'
Mar 19 13:36:17.548: INFO: stderr: "No resources found.\n"
Mar 19 13:36:17.548: INFO: stdout: ""
Mar 19 13:36:17.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -l name=update-demo --namespace=e2e-tests-kubectl-jddr7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 19 13:36:17.632: INFO: stderr: ""
Mar 19 13:36:17.632: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:36:17.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jddr7" for this suite.
Mar 19 13:36:23.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:36:23.668: INFO: namespace: e2e-tests-kubectl-jddr7, resource: bindings, ignored listing per whitelist
Mar 19 13:36:23.705: INFO: namespace e2e-tests-kubectl-jddr7 deletion completed in 6.067593002s

â€¢ [SLOW TEST:12.370 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:36:23.705: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 19 13:36:23.760: INFO: Waiting up to 5m0s for pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-54c2z" to be "success or failure"
Mar 19 13:36:23.765: INFO: Pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.342823ms
Mar 19 13:36:25.768: INFO: Pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007967345s
Mar 19 13:36:27.770: INFO: Pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010309979s
Mar 19 13:36:29.773: INFO: Pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013510267s
Mar 19 13:36:31.776: INFO: Pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016253394s
Mar 19 13:36:33.779: INFO: Pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 10.019041601s
Mar 19 13:36:35.782: INFO: Pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 12.022336366s
Mar 19 13:36:37.785: INFO: Pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 14.025295951s
Mar 19 13:36:39.788: INFO: Pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.02804786s
STEP: Saw pod success
Mar 19 13:36:39.788: INFO: Pod "downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:36:39.791: INFO: Trying to get logs from node essentialpks-conformance-3 pod downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204 container dapi-container: <nil>
STEP: delete the pod
Mar 19 13:36:39.809: INFO: Waiting for pod downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204 to disappear
Mar 19 13:36:39.812: INFO: Pod downward-api-fce73ff0-4a4b-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:36:39.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-54c2z" for this suite.
Mar 19 13:36:45.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:36:45.888: INFO: namespace: e2e-tests-downward-api-54c2z, resource: bindings, ignored listing per whitelist
Mar 19 13:36:45.890: INFO: namespace e2e-tests-downward-api-54c2z deletion completed in 6.073980535s

â€¢ [SLOW TEST:22.185 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:36:45.890: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 13:36:45.945: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-gmbbq" to be "success or failure"
Mar 19 13:36:45.955: INFO: Pod "downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 9.492313ms
Mar 19 13:36:47.958: INFO: Pod "downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012353544s
Mar 19 13:36:49.961: INFO: Pod "downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015480498s
Mar 19 13:36:51.963: INFO: Pod "downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017800126s
Mar 19 13:36:53.966: INFO: Pod "downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 8.020511616s
Mar 19 13:36:55.969: INFO: Pod "downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.023496747s
STEP: Saw pod success
Mar 19 13:36:55.969: INFO: Pod "downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:36:55.972: INFO: Trying to get logs from node essentialpks-conformance-2 pod downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 13:36:55.996: INFO: Waiting for pod downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204 to disappear
Mar 19 13:36:55.998: INFO: Pod downwardapi-volume-0a20bbac-4a4c-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:36:55.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gmbbq" for this suite.
Mar 19 13:37:02.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:37:02.048: INFO: namespace: e2e-tests-projected-gmbbq, resource: bindings, ignored listing per whitelist
Mar 19 13:37:02.082: INFO: namespace e2e-tests-projected-gmbbq deletion completed in 6.080548555s

â€¢ [SLOW TEST:16.193 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:37:02.086: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar 19 13:37:02.143: INFO: Waiting up to 5m0s for pod "var-expansion-13c8355d-4a4c-11e9-9c64-0a580af40204" in namespace "e2e-tests-var-expansion-nlwvt" to be "success or failure"
Mar 19 13:37:02.148: INFO: Pod "var-expansion-13c8355d-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.860803ms
Mar 19 13:37:04.151: INFO: Pod "var-expansion-13c8355d-4a4c-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007629432s
STEP: Saw pod success
Mar 19 13:37:04.151: INFO: Pod "var-expansion-13c8355d-4a4c-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:37:04.153: INFO: Trying to get logs from node essentialpks-conformance-3 pod var-expansion-13c8355d-4a4c-11e9-9c64-0a580af40204 container dapi-container: <nil>
STEP: delete the pod
Mar 19 13:37:04.168: INFO: Waiting for pod var-expansion-13c8355d-4a4c-11e9-9c64-0a580af40204 to disappear
Mar 19 13:37:04.170: INFO: Pod var-expansion-13c8355d-4a4c-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:37:04.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-nlwvt" for this suite.
Mar 19 13:37:10.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:37:10.211: INFO: namespace: e2e-tests-var-expansion-nlwvt, resource: bindings, ignored listing per whitelist
Mar 19 13:37:10.257: INFO: namespace e2e-tests-var-expansion-nlwvt deletion completed in 6.082310891s

â€¢ [SLOW TEST:8.171 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:37:10.257: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 19 13:37:10.322: INFO: Waiting up to 5m0s for pod "pod-18a872f1-4a4c-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-vfvqf" to be "success or failure"
Mar 19 13:37:10.327: INFO: Pod "pod-18a872f1-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.249133ms
Mar 19 13:37:12.330: INFO: Pod "pod-18a872f1-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007802643s
Mar 19 13:37:14.333: INFO: Pod "pod-18a872f1-4a4c-11e9-9c64-0a580af40204": Phase="Running", Reason="", readiness=true. Elapsed: 4.010752407s
Mar 19 13:37:16.335: INFO: Pod "pod-18a872f1-4a4c-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013291933s
STEP: Saw pod success
Mar 19 13:37:16.335: INFO: Pod "pod-18a872f1-4a4c-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:37:16.338: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-18a872f1-4a4c-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 13:37:16.357: INFO: Waiting for pod pod-18a872f1-4a4c-11e9-9c64-0a580af40204 to disappear
Mar 19 13:37:16.359: INFO: Pod pod-18a872f1-4a4c-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:37:16.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vfvqf" for this suite.
Mar 19 13:37:22.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:37:22.377: INFO: namespace: e2e-tests-emptydir-vfvqf, resource: bindings, ignored listing per whitelist
Mar 19 13:37:22.431: INFO: namespace e2e-tests-emptydir-vfvqf deletion completed in 6.070106962s

â€¢ [SLOW TEST:12.175 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:37:22.432: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 19 13:37:22.552: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-m7ffz,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7ffz/configmaps/e2e-watch-test-resource-version,UID:1ff0a3fe-4a4c-11e9-9b06-005056a45e5c,ResourceVersion:2483,Generation:0,CreationTimestamp:2019-03-19 13:37:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 19 13:37:22.553: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-m7ffz,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7ffz/configmaps/e2e-watch-test-resource-version,UID:1ff0a3fe-4a4c-11e9-9b06-005056a45e5c,ResourceVersion:2484,Generation:0,CreationTimestamp:2019-03-19 13:37:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:37:22.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-m7ffz" for this suite.
Mar 19 13:37:28.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:37:28.605: INFO: namespace: e2e-tests-watch-m7ffz, resource: bindings, ignored listing per whitelist
Mar 19 13:37:28.637: INFO: namespace e2e-tests-watch-m7ffz deletion completed in 6.082378468s

â€¢ [SLOW TEST:6.206 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:37:28.638: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Mar 19 13:37:42.728: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:38:04.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-lvbd4" for this suite.
Mar 19 13:38:10.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:38:10.818: INFO: namespace: e2e-tests-namespaces-lvbd4, resource: bindings, ignored listing per whitelist
Mar 19 13:38:10.848: INFO: namespace e2e-tests-namespaces-lvbd4 deletion completed in 6.084113506s
STEP: Destroying namespace "e2e-tests-nsdeletetest-2h7t5" for this suite.
Mar 19 13:38:10.855: INFO: Namespace e2e-tests-nsdeletetest-2h7t5 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-6jhtx" for this suite.
Mar 19 13:38:16.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:38:16.884: INFO: namespace: e2e-tests-nsdeletetest-6jhtx, resource: bindings, ignored listing per whitelist
Mar 19 13:38:16.925: INFO: namespace e2e-tests-nsdeletetest-6jhtx deletion completed in 6.069826217s

â€¢ [SLOW TEST:48.288 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:38:16.926: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-8xwxr
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-8xwxr
STEP: Deleting pre-stop pod
Mar 19 13:38:48.010: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:38:48.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-8xwxr" for this suite.
Mar 19 13:39:34.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:39:34.051: INFO: namespace: e2e-tests-prestop-8xwxr, resource: bindings, ignored listing per whitelist
Mar 19 13:39:34.101: INFO: namespace e2e-tests-prestop-8xwxr deletion completed in 46.077188648s

â€¢ [SLOW TEST:77.175 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:39:34.101: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-ds2s2
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-ds2s2
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-ds2s2
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-ds2s2
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-ds2s2
Mar 19 13:39:36.194: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-ds2s2, name: ss-0, uid: 6e740967-4a4c-11e9-9b06-005056a45e5c, status phase: Pending. Waiting for statefulset controller to delete.
Mar 19 13:39:39.617: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-ds2s2, name: ss-0, uid: 6e740967-4a4c-11e9-9b06-005056a45e5c, status phase: Failed. Waiting for statefulset controller to delete.
Mar 19 13:39:39.634: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-ds2s2, name: ss-0, uid: 6e740967-4a4c-11e9-9b06-005056a45e5c, status phase: Failed. Waiting for statefulset controller to delete.
Mar 19 13:39:39.640: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-ds2s2
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-ds2s2
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-ds2s2 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 19 13:39:41.671: INFO: Deleting all statefulset in ns e2e-tests-statefulset-ds2s2
Mar 19 13:39:41.675: INFO: Scaling statefulset ss to 0
Mar 19 13:39:51.699: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 13:39:51.701: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:39:51.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-ds2s2" for this suite.
Mar 19 13:39:57.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:39:57.741: INFO: namespace: e2e-tests-statefulset-ds2s2, resource: bindings, ignored listing per whitelist
Mar 19 13:39:57.807: INFO: namespace e2e-tests-statefulset-ds2s2 deletion completed in 6.090028753s

â€¢ [SLOW TEST:23.706 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:39:57.807: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 19 13:39:57.870: INFO: Waiting up to 5m0s for pod "pod-7c85c4e1-4a4c-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-fh2fc" to be "success or failure"
Mar 19 13:39:57.883: INFO: Pod "pod-7c85c4e1-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 13.119745ms
Mar 19 13:39:59.886: INFO: Pod "pod-7c85c4e1-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015865351s
Mar 19 13:40:01.888: INFO: Pod "pod-7c85c4e1-4a4c-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018571996s
STEP: Saw pod success
Mar 19 13:40:01.888: INFO: Pod "pod-7c85c4e1-4a4c-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:40:01.891: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-7c85c4e1-4a4c-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 13:40:01.904: INFO: Waiting for pod pod-7c85c4e1-4a4c-11e9-9c64-0a580af40204 to disappear
Mar 19 13:40:01.907: INFO: Pod pod-7c85c4e1-4a4c-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:40:01.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fh2fc" for this suite.
Mar 19 13:40:07.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:40:07.987: INFO: namespace: e2e-tests-emptydir-fh2fc, resource: bindings, ignored listing per whitelist
Mar 19 13:40:07.996: INFO: namespace e2e-tests-emptydir-fh2fc deletion completed in 6.085238178s

â€¢ [SLOW TEST:10.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:40:07.996: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 13:40:08.065: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 19 13:40:08.075: INFO: Number of nodes with available pods: 0
Mar 19 13:40:08.075: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 19 13:40:08.097: INFO: Number of nodes with available pods: 0
Mar 19 13:40:08.097: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:09.100: INFO: Number of nodes with available pods: 0
Mar 19 13:40:09.100: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:10.101: INFO: Number of nodes with available pods: 1
Mar 19 13:40:10.101: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 19 13:40:10.114: INFO: Number of nodes with available pods: 1
Mar 19 13:40:10.114: INFO: Number of running nodes: 0, number of available pods: 1
Mar 19 13:40:11.121: INFO: Number of nodes with available pods: 0
Mar 19 13:40:11.122: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 19 13:40:11.132: INFO: Number of nodes with available pods: 0
Mar 19 13:40:11.133: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:12.138: INFO: Number of nodes with available pods: 0
Mar 19 13:40:12.138: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:13.135: INFO: Number of nodes with available pods: 0
Mar 19 13:40:13.135: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:14.137: INFO: Number of nodes with available pods: 0
Mar 19 13:40:14.137: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:15.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:15.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:16.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:16.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:17.137: INFO: Number of nodes with available pods: 0
Mar 19 13:40:17.137: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:18.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:18.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:19.135: INFO: Number of nodes with available pods: 0
Mar 19 13:40:19.135: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:20.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:20.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:21.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:21.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:22.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:22.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:23.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:23.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:24.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:24.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:25.135: INFO: Number of nodes with available pods: 0
Mar 19 13:40:25.135: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:26.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:26.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:27.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:27.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:28.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:28.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:29.135: INFO: Number of nodes with available pods: 0
Mar 19 13:40:29.135: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:30.138: INFO: Number of nodes with available pods: 0
Mar 19 13:40:30.138: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:31.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:31.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:32.135: INFO: Number of nodes with available pods: 0
Mar 19 13:40:32.135: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:33.135: INFO: Number of nodes with available pods: 0
Mar 19 13:40:33.135: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:34.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:34.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:35.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:35.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:36.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:36.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:37.135: INFO: Number of nodes with available pods: 0
Mar 19 13:40:37.135: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:38.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:38.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:39.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:39.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:40.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:40.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:41.137: INFO: Number of nodes with available pods: 0
Mar 19 13:40:41.137: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:42.135: INFO: Number of nodes with available pods: 0
Mar 19 13:40:42.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:43.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:43.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:44.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:44.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:45.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:45.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:46.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:46.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:47.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:47.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:48.137: INFO: Number of nodes with available pods: 0
Mar 19 13:40:48.137: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:49.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:49.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:50.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:50.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:51.136: INFO: Number of nodes with available pods: 0
Mar 19 13:40:51.136: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:40:52.136: INFO: Number of nodes with available pods: 1
Mar 19 13:40:52.136: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-mvhzd, will wait for the garbage collector to delete the pods
Mar 19 13:40:52.206: INFO: Deleting DaemonSet.extensions daemon-set took: 11.776277ms
Mar 19 13:40:52.306: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.243785ms
Mar 19 13:41:26.109: INFO: Number of nodes with available pods: 0
Mar 19 13:41:26.109: INFO: Number of running nodes: 0, number of available pods: 0
Mar 19 13:41:26.117: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mvhzd/daemonsets","resourceVersion":"3103"},"items":null}

Mar 19 13:41:26.120: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mvhzd/pods","resourceVersion":"3103"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:41:26.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mvhzd" for this suite.
Mar 19 13:41:32.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:41:32.177: INFO: namespace: e2e-tests-daemonsets-mvhzd, resource: bindings, ignored listing per whitelist
Mar 19 13:41:32.205: INFO: namespace e2e-tests-daemonsets-mvhzd deletion completed in 6.070973126s

â€¢ [SLOW TEST:84.210 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:41:32.206: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 19 13:41:32.259: INFO: Waiting up to 5m0s for pod "pod-b4c8f343-4a4c-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-85ggh" to be "success or failure"
Mar 19 13:41:32.262: INFO: Pod "pod-b4c8f343-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.560367ms
Mar 19 13:41:34.265: INFO: Pod "pod-b4c8f343-4a4c-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005731516s
STEP: Saw pod success
Mar 19 13:41:34.265: INFO: Pod "pod-b4c8f343-4a4c-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:41:34.271: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-b4c8f343-4a4c-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 13:41:34.288: INFO: Waiting for pod pod-b4c8f343-4a4c-11e9-9c64-0a580af40204 to disappear
Mar 19 13:41:34.290: INFO: Pod pod-b4c8f343-4a4c-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:41:34.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-85ggh" for this suite.
Mar 19 13:41:40.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:41:40.346: INFO: namespace: e2e-tests-emptydir-85ggh, resource: bindings, ignored listing per whitelist
Mar 19 13:41:40.373: INFO: namespace e2e-tests-emptydir-85ggh deletion completed in 6.080275555s

â€¢ [SLOW TEST:8.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:41:40.373: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 13:41:40.430: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b9a7b365-4a4c-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-msl8z" to be "success or failure"
Mar 19 13:41:40.440: INFO: Pod "downwardapi-volume-b9a7b365-4a4c-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 9.577953ms
Mar 19 13:41:42.442: INFO: Pod "downwardapi-volume-b9a7b365-4a4c-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011998183s
STEP: Saw pod success
Mar 19 13:41:42.442: INFO: Pod "downwardapi-volume-b9a7b365-4a4c-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:41:42.445: INFO: Trying to get logs from node essentialpks-conformance-3 pod downwardapi-volume-b9a7b365-4a4c-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 13:41:42.465: INFO: Waiting for pod downwardapi-volume-b9a7b365-4a4c-11e9-9c64-0a580af40204 to disappear
Mar 19 13:41:42.468: INFO: Pod downwardapi-volume-b9a7b365-4a4c-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:41:42.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-msl8z" for this suite.
Mar 19 13:41:48.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:41:48.509: INFO: namespace: e2e-tests-downward-api-msl8z, resource: bindings, ignored listing per whitelist
Mar 19 13:41:48.554: INFO: namespace e2e-tests-downward-api-msl8z deletion completed in 6.082932332s

â€¢ [SLOW TEST:8.181 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:41:48.555: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 13:41:48.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-gnnqm'
Mar 19 13:41:48.704: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 19 13:41:48.704: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar 19 13:41:48.717: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-h7tkl]
Mar 19 13:41:48.717: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-h7tkl" in namespace "e2e-tests-kubectl-gnnqm" to be "running and ready"
Mar 19 13:41:48.719: INFO: Pod "e2e-test-nginx-rc-h7tkl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014469ms
Mar 19 13:41:50.722: INFO: Pod "e2e-test-nginx-rc-h7tkl": Phase="Running", Reason="", readiness=true. Elapsed: 2.004944289s
Mar 19 13:41:50.722: INFO: Pod "e2e-test-nginx-rc-h7tkl" satisfied condition "running and ready"
Mar 19 13:41:50.722: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-h7tkl]
Mar 19 13:41:50.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-gnnqm'
Mar 19 13:41:50.844: INFO: stderr: ""
Mar 19 13:41:50.844: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Mar 19 13:41:50.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-gnnqm'
Mar 19 13:41:50.930: INFO: stderr: ""
Mar 19 13:41:50.930: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:41:50.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gnnqm" for this suite.
Mar 19 13:41:56.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:41:57.009: INFO: namespace: e2e-tests-kubectl-gnnqm, resource: bindings, ignored listing per whitelist
Mar 19 13:41:57.028: INFO: namespace e2e-tests-kubectl-gnnqm deletion completed in 6.092473548s

â€¢ [SLOW TEST:8.473 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:41:57.031: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar 19 13:41:57.273: INFO: Pod name wrapped-volume-race-c3afb297-4a4c-11e9-9c64-0a580af40204: Found 1 pods out of 5
Mar 19 13:42:02.285: INFO: Pod name wrapped-volume-race-c3afb297-4a4c-11e9-9c64-0a580af40204: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c3afb297-4a4c-11e9-9c64-0a580af40204 in namespace e2e-tests-emptydir-wrapper-mdmm7, will wait for the garbage collector to delete the pods
Mar 19 13:42:12.369: INFO: Deleting ReplicationController wrapped-volume-race-c3afb297-4a4c-11e9-9c64-0a580af40204 took: 6.439502ms
Mar 19 13:42:12.469: INFO: Terminating ReplicationController wrapped-volume-race-c3afb297-4a4c-11e9-9c64-0a580af40204 pods took: 100.279358ms
STEP: Creating RC which spawns configmap-volume pods
Mar 19 13:42:49.685: INFO: Pod name wrapped-volume-race-e2ed9afe-4a4c-11e9-9c64-0a580af40204: Found 0 pods out of 5
Mar 19 13:42:54.690: INFO: Pod name wrapped-volume-race-e2ed9afe-4a4c-11e9-9c64-0a580af40204: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e2ed9afe-4a4c-11e9-9c64-0a580af40204 in namespace e2e-tests-emptydir-wrapper-mdmm7, will wait for the garbage collector to delete the pods
Mar 19 13:43:04.765: INFO: Deleting ReplicationController wrapped-volume-race-e2ed9afe-4a4c-11e9-9c64-0a580af40204 took: 7.085035ms
Mar 19 13:43:04.865: INFO: Terminating ReplicationController wrapped-volume-race-e2ed9afe-4a4c-11e9-9c64-0a580af40204 pods took: 100.308532ms
STEP: Creating RC which spawns configmap-volume pods
Mar 19 13:43:42.582: INFO: Pod name wrapped-volume-race-0274d44b-4a4d-11e9-9c64-0a580af40204: Found 0 pods out of 5
Mar 19 13:43:47.587: INFO: Pod name wrapped-volume-race-0274d44b-4a4d-11e9-9c64-0a580af40204: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0274d44b-4a4d-11e9-9c64-0a580af40204 in namespace e2e-tests-emptydir-wrapper-mdmm7, will wait for the garbage collector to delete the pods
Mar 19 13:43:57.663: INFO: Deleting ReplicationController wrapped-volume-race-0274d44b-4a4d-11e9-9c64-0a580af40204 took: 6.926102ms
Mar 19 13:43:57.763: INFO: Terminating ReplicationController wrapped-volume-race-0274d44b-4a4d-11e9-9c64-0a580af40204 pods took: 100.342716ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:44:40.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-mdmm7" for this suite.
Mar 19 13:44:46.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:44:46.934: INFO: namespace: e2e-tests-emptydir-wrapper-mdmm7, resource: bindings, ignored listing per whitelist
Mar 19 13:44:46.970: INFO: namespace e2e-tests-emptydir-wrapper-mdmm7 deletion completed in 6.079948597s

â€¢ [SLOW TEST:169.939 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:44:46.970: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-75rn
STEP: Creating a pod to test atomic-volume-subpath
Mar 19 13:44:47.101: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-75rn" in namespace "e2e-tests-subpath-sjctn" to be "success or failure"
Mar 19 13:44:47.105: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.83907ms
Mar 19 13:44:49.108: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007673496s
Mar 19 13:44:51.111: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Running", Reason="", readiness=false. Elapsed: 4.010880522s
Mar 19 13:44:53.114: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Running", Reason="", readiness=false. Elapsed: 6.013499329s
Mar 19 13:44:55.116: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Running", Reason="", readiness=false. Elapsed: 8.015819071s
Mar 19 13:44:57.119: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Running", Reason="", readiness=false. Elapsed: 10.018284399s
Mar 19 13:44:59.122: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Running", Reason="", readiness=false. Elapsed: 12.021638901s
Mar 19 13:45:01.125: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Running", Reason="", readiness=false. Elapsed: 14.02444411s
Mar 19 13:45:03.128: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Running", Reason="", readiness=false. Elapsed: 16.02703058s
Mar 19 13:45:05.130: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Running", Reason="", readiness=false. Elapsed: 18.029825898s
Mar 19 13:45:07.136: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Running", Reason="", readiness=false. Elapsed: 20.035659696s
Mar 19 13:45:09.142: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Running", Reason="", readiness=false. Elapsed: 22.041867713s
Mar 19 13:45:11.147: INFO: Pod "pod-subpath-test-secret-75rn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046203722s
STEP: Saw pod success
Mar 19 13:45:11.147: INFO: Pod "pod-subpath-test-secret-75rn" satisfied condition "success or failure"
Mar 19 13:45:11.150: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-subpath-test-secret-75rn container test-container-subpath-secret-75rn: <nil>
STEP: delete the pod
Mar 19 13:45:11.179: INFO: Waiting for pod pod-subpath-test-secret-75rn to disappear
Mar 19 13:45:11.196: INFO: Pod pod-subpath-test-secret-75rn no longer exists
STEP: Deleting pod pod-subpath-test-secret-75rn
Mar 19 13:45:11.196: INFO: Deleting pod "pod-subpath-test-secret-75rn" in namespace "e2e-tests-subpath-sjctn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:45:11.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-sjctn" for this suite.
Mar 19 13:45:17.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:45:17.256: INFO: namespace: e2e-tests-subpath-sjctn, resource: bindings, ignored listing per whitelist
Mar 19 13:45:17.290: INFO: namespace e2e-tests-subpath-sjctn deletion completed in 6.075318683s

â€¢ [SLOW TEST:30.320 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:45:17.290: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-m4npn
Mar 19 13:45:19.369: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-m4npn
STEP: checking the pod's current state and verifying that restartCount is present
Mar 19 13:45:19.373: INFO: Initial restart count of pod liveness-exec is 0
Mar 19 13:46:11.487: INFO: Restart count of pod e2e-tests-container-probe-m4npn/liveness-exec is now 1 (52.113998923s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:46:11.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-m4npn" for this suite.
Mar 19 13:46:17.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:46:17.540: INFO: namespace: e2e-tests-container-probe-m4npn, resource: bindings, ignored listing per whitelist
Mar 19 13:46:17.572: INFO: namespace e2e-tests-container-probe-m4npn deletion completed in 6.068760513s

â€¢ [SLOW TEST:60.282 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:46:17.572: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-5ee0460e-4a4d-11e9-9c64-0a580af40204
Mar 19 13:46:17.627: INFO: Pod name my-hostname-basic-5ee0460e-4a4d-11e9-9c64-0a580af40204: Found 0 pods out of 1
Mar 19 13:46:22.631: INFO: Pod name my-hostname-basic-5ee0460e-4a4d-11e9-9c64-0a580af40204: Found 1 pods out of 1
Mar 19 13:46:22.631: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5ee0460e-4a4d-11e9-9c64-0a580af40204" are running
Mar 19 13:46:32.636: INFO: Pod "my-hostname-basic-5ee0460e-4a4d-11e9-9c64-0a580af40204-jmpzl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 13:46:17 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 13:46:17 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-5ee0460e-4a4d-11e9-9c64-0a580af40204]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 13:46:17 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-5ee0460e-4a4d-11e9-9c64-0a580af40204]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 13:46:17 +0000 UTC Reason: Message:}])
Mar 19 13:46:32.636: INFO: Trying to dial the pod
Mar 19 13:46:37.644: INFO: Controller my-hostname-basic-5ee0460e-4a4d-11e9-9c64-0a580af40204: Got expected result from replica 1 [my-hostname-basic-5ee0460e-4a4d-11e9-9c64-0a580af40204-jmpzl]: "my-hostname-basic-5ee0460e-4a4d-11e9-9c64-0a580af40204-jmpzl", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:46:37.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-hfsmr" for this suite.
Mar 19 13:46:43.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:46:43.695: INFO: namespace: e2e-tests-replication-controller-hfsmr, resource: bindings, ignored listing per whitelist
Mar 19 13:46:43.725: INFO: namespace e2e-tests-replication-controller-hfsmr deletion completed in 6.076764897s

â€¢ [SLOW TEST:26.152 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:46:43.725: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 13:46:43.786: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e780869-4a4d-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-trr85" to be "success or failure"
Mar 19 13:46:43.788: INFO: Pod "downwardapi-volume-6e780869-4a4d-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.822471ms
Mar 19 13:46:45.792: INFO: Pod "downwardapi-volume-6e780869-4a4d-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006354616s
STEP: Saw pod success
Mar 19 13:46:45.792: INFO: Pod "downwardapi-volume-6e780869-4a4d-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:46:45.795: INFO: Trying to get logs from node essentialpks-conformance-3 pod downwardapi-volume-6e780869-4a4d-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 13:46:45.815: INFO: Waiting for pod downwardapi-volume-6e780869-4a4d-11e9-9c64-0a580af40204 to disappear
Mar 19 13:46:45.818: INFO: Pod downwardapi-volume-6e780869-4a4d-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:46:45.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-trr85" for this suite.
Mar 19 13:46:51.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:46:51.886: INFO: namespace: e2e-tests-projected-trr85, resource: bindings, ignored listing per whitelist
Mar 19 13:46:51.895: INFO: namespace e2e-tests-projected-trr85 deletion completed in 6.074147013s

â€¢ [SLOW TEST:8.170 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:46:51.895: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-7355280f-4a4d-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 13:46:51.950: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7355aded-4a4d-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-btdtm" to be "success or failure"
Mar 19 13:46:51.960: INFO: Pod "pod-projected-secrets-7355aded-4a4d-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 10.005707ms
Mar 19 13:46:53.963: INFO: Pod "pod-projected-secrets-7355aded-4a4d-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012972784s
STEP: Saw pod success
Mar 19 13:46:53.963: INFO: Pod "pod-projected-secrets-7355aded-4a4d-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:46:53.965: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-projected-secrets-7355aded-4a4d-11e9-9c64-0a580af40204 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 19 13:46:53.985: INFO: Waiting for pod pod-projected-secrets-7355aded-4a4d-11e9-9c64-0a580af40204 to disappear
Mar 19 13:46:53.989: INFO: Pod pod-projected-secrets-7355aded-4a4d-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:46:53.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-btdtm" for this suite.
Mar 19 13:47:00.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:47:00.028: INFO: namespace: e2e-tests-projected-btdtm, resource: bindings, ignored listing per whitelist
Mar 19 13:47:00.081: INFO: namespace e2e-tests-projected-btdtm deletion completed in 6.088526642s

â€¢ [SLOW TEST:8.186 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:47:00.082: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-78375183-4a4d-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 13:47:00.146: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7837d68e-4a4d-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-qj57h" to be "success or failure"
Mar 19 13:47:00.161: INFO: Pod "pod-projected-configmaps-7837d68e-4a4d-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 14.108355ms
Mar 19 13:47:02.163: INFO: Pod "pod-projected-configmaps-7837d68e-4a4d-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016826264s
STEP: Saw pod success
Mar 19 13:47:02.163: INFO: Pod "pod-projected-configmaps-7837d68e-4a4d-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:47:02.166: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-projected-configmaps-7837d68e-4a4d-11e9-9c64-0a580af40204 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 13:47:02.183: INFO: Waiting for pod pod-projected-configmaps-7837d68e-4a4d-11e9-9c64-0a580af40204 to disappear
Mar 19 13:47:02.187: INFO: Pod pod-projected-configmaps-7837d68e-4a4d-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:47:02.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qj57h" for this suite.
Mar 19 13:47:08.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:47:08.243: INFO: namespace: e2e-tests-projected-qj57h, resource: bindings, ignored listing per whitelist
Mar 19 13:47:08.274: INFO: namespace e2e-tests-projected-qj57h deletion completed in 6.08456858s

â€¢ [SLOW TEST:8.193 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:47:08.275: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:47:12.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-k6f57" for this suite.
Mar 19 13:47:18.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:47:18.475: INFO: namespace: e2e-tests-emptydir-wrapper-k6f57, resource: bindings, ignored listing per whitelist
Mar 19 13:47:18.479: INFO: namespace e2e-tests-emptydir-wrapper-k6f57 deletion completed in 6.105863662s

â€¢ [SLOW TEST:10.204 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:47:18.479: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dhdsl
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar 19 13:47:18.549: INFO: Found 0 stateful pods, waiting for 3
Mar 19 13:47:28.552: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 13:47:28.552: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 13:47:28.552: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 19 13:47:28.578: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 19 13:47:38.616: INFO: Updating stateful set ss2
Mar 19 13:47:38.631: INFO: Waiting for Pod e2e-tests-statefulset-dhdsl/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 19 13:47:48.642: INFO: Waiting for Pod e2e-tests-statefulset-dhdsl/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar 19 13:47:58.679: INFO: Found 2 stateful pods, waiting for 3
Mar 19 13:48:08.683: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 13:48:08.683: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 13:48:08.683: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Mar 19 13:48:18.683: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 13:48:18.683: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 13:48:18.683: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 19 13:48:18.707: INFO: Updating stateful set ss2
Mar 19 13:48:18.723: INFO: Waiting for Pod e2e-tests-statefulset-dhdsl/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 19 13:48:28.728: INFO: Waiting for Pod e2e-tests-statefulset-dhdsl/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 19 13:48:38.748: INFO: Updating stateful set ss2
Mar 19 13:48:38.761: INFO: Waiting for StatefulSet e2e-tests-statefulset-dhdsl/ss2 to complete update
Mar 19 13:48:38.761: INFO: Waiting for Pod e2e-tests-statefulset-dhdsl/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 19 13:48:48.767: INFO: Waiting for StatefulSet e2e-tests-statefulset-dhdsl/ss2 to complete update
Mar 19 13:48:48.767: INFO: Waiting for Pod e2e-tests-statefulset-dhdsl/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 19 13:48:58.766: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dhdsl
Mar 19 13:48:58.769: INFO: Scaling statefulset ss2 to 0
Mar 19 13:49:28.782: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 13:49:28.784: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:49:28.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dhdsl" for this suite.
Mar 19 13:49:34.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:49:34.873: INFO: namespace: e2e-tests-statefulset-dhdsl, resource: bindings, ignored listing per whitelist
Mar 19 13:49:34.903: INFO: namespace e2e-tests-statefulset-dhdsl deletion completed in 6.103624483s

â€¢ [SLOW TEST:136.424 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:49:34.905: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 13:49:34.971: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d480bffb-4a4d-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-ttdtt" to be "success or failure"
Mar 19 13:49:34.976: INFO: Pod "downwardapi-volume-d480bffb-4a4d-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.547849ms
Mar 19 13:49:36.979: INFO: Pod "downwardapi-volume-d480bffb-4a4d-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008312307s
STEP: Saw pod success
Mar 19 13:49:36.979: INFO: Pod "downwardapi-volume-d480bffb-4a4d-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:49:36.981: INFO: Trying to get logs from node essentialpks-conformance-2 pod downwardapi-volume-d480bffb-4a4d-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 13:49:36.995: INFO: Waiting for pod downwardapi-volume-d480bffb-4a4d-11e9-9c64-0a580af40204 to disappear
Mar 19 13:49:36.996: INFO: Pod downwardapi-volume-d480bffb-4a4d-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:49:36.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ttdtt" for this suite.
Mar 19 13:49:43.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:49:43.033: INFO: namespace: e2e-tests-projected-ttdtt, resource: bindings, ignored listing per whitelist
Mar 19 13:49:43.078: INFO: namespace e2e-tests-projected-ttdtt deletion completed in 6.077497614s

â€¢ [SLOW TEST:8.173 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:49:43.079: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d96515ff-4a4d-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 13:49:43.184: INFO: Waiting up to 5m0s for pod "pod-secrets-d965acb0-4a4d-11e9-9c64-0a580af40204" in namespace "e2e-tests-secrets-8nplg" to be "success or failure"
Mar 19 13:49:43.188: INFO: Pod "pod-secrets-d965acb0-4a4d-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054778ms
Mar 19 13:49:45.191: INFO: Pod "pod-secrets-d965acb0-4a4d-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00633679s
STEP: Saw pod success
Mar 19 13:49:45.191: INFO: Pod "pod-secrets-d965acb0-4a4d-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:49:45.193: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-secrets-d965acb0-4a4d-11e9-9c64-0a580af40204 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 13:49:45.208: INFO: Waiting for pod pod-secrets-d965acb0-4a4d-11e9-9c64-0a580af40204 to disappear
Mar 19 13:49:45.211: INFO: Pod pod-secrets-d965acb0-4a4d-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:49:45.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8nplg" for this suite.
Mar 19 13:49:51.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:49:51.284: INFO: namespace: e2e-tests-secrets-8nplg, resource: bindings, ignored listing per whitelist
Mar 19 13:49:51.325: INFO: namespace e2e-tests-secrets-8nplg deletion completed in 6.105219492s

â€¢ [SLOW TEST:8.246 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:49:51.325: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 13:49:51.387: INFO: Waiting up to 5m0s for pod "downwardapi-volume-de49c73c-4a4d-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-n7r4z" to be "success or failure"
Mar 19 13:49:51.392: INFO: Pod "downwardapi-volume-de49c73c-4a4d-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.84166ms
Mar 19 13:49:53.395: INFO: Pod "downwardapi-volume-de49c73c-4a4d-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007973405s
STEP: Saw pod success
Mar 19 13:49:53.395: INFO: Pod "downwardapi-volume-de49c73c-4a4d-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:49:53.399: INFO: Trying to get logs from node essentialpks-conformance-2 pod downwardapi-volume-de49c73c-4a4d-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 13:49:53.417: INFO: Waiting for pod downwardapi-volume-de49c73c-4a4d-11e9-9c64-0a580af40204 to disappear
Mar 19 13:49:53.419: INFO: Pod downwardapi-volume-de49c73c-4a4d-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:49:53.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n7r4z" for this suite.
Mar 19 13:49:59.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:49:59.499: INFO: namespace: e2e-tests-downward-api-n7r4z, resource: bindings, ignored listing per whitelist
Mar 19 13:49:59.506: INFO: namespace e2e-tests-downward-api-n7r4z deletion completed in 6.083908807s

â€¢ [SLOW TEST:8.181 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:49:59.507: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-6gd4t
Mar 19 13:50:03.568: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-6gd4t
STEP: checking the pod's current state and verifying that restartCount is present
Mar 19 13:50:03.570: INFO: Initial restart count of pod liveness-http is 0
Mar 19 13:50:21.598: INFO: Restart count of pod e2e-tests-container-probe-6gd4t/liveness-http is now 1 (18.027210383s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:50:21.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6gd4t" for this suite.
Mar 19 13:50:27.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:50:27.646: INFO: namespace: e2e-tests-container-probe-6gd4t, resource: bindings, ignored listing per whitelist
Mar 19 13:50:27.685: INFO: namespace e2e-tests-container-probe-6gd4t deletion completed in 6.070529415s

â€¢ [SLOW TEST:28.178 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:50:27.685: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 19 13:50:27.741: INFO: Waiting up to 5m0s for pod "downward-api-f3f4ac5d-4a4d-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-jps4c" to be "success or failure"
Mar 19 13:50:27.745: INFO: Pod "downward-api-f3f4ac5d-4a4d-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.283396ms
Mar 19 13:50:29.748: INFO: Pod "downward-api-f3f4ac5d-4a4d-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007174s
STEP: Saw pod success
Mar 19 13:50:29.748: INFO: Pod "downward-api-f3f4ac5d-4a4d-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:50:29.751: INFO: Trying to get logs from node essentialpks-conformance-3 pod downward-api-f3f4ac5d-4a4d-11e9-9c64-0a580af40204 container dapi-container: <nil>
STEP: delete the pod
Mar 19 13:50:29.772: INFO: Waiting for pod downward-api-f3f4ac5d-4a4d-11e9-9c64-0a580af40204 to disappear
Mar 19 13:50:29.779: INFO: Pod downward-api-f3f4ac5d-4a4d-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:50:29.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jps4c" for this suite.
Mar 19 13:50:35.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:50:35.849: INFO: namespace: e2e-tests-downward-api-jps4c, resource: bindings, ignored listing per whitelist
Mar 19 13:50:35.872: INFO: namespace e2e-tests-downward-api-jps4c deletion completed in 6.09000073s

â€¢ [SLOW TEST:8.187 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:50:35.873: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 13:50:35.922: INFO: Creating deployment "test-recreate-deployment"
Mar 19 13:50:35.928: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 19 13:50:35.937: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Mar 19 13:50:37.942: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 19 13:50:37.946: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688600235, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688600235, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688600235, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688600235, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 13:50:39.948: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 19 13:50:39.955: INFO: Updating deployment test-recreate-deployment
Mar 19 13:50:39.955: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 19 13:50:40.055: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-pt9k5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pt9k5/deployments/test-recreate-deployment,UID:f8d64b3b-4a4d-11e9-9b06-005056a45e5c,ResourceVersion:5467,Generation:2,CreationTimestamp:2019-03-19 13:50:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-19 13:50:40 +0000 UTC 2019-03-19 13:50:40 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-19 13:50:40 +0000 UTC 2019-03-19 13:50:35 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 19 13:50:40.098: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-pt9k5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pt9k5/replicasets/test-recreate-deployment-697fbf54bf,UID:fb4159d3-4a4d-11e9-9b06-005056a45e5c,ResourceVersion:5464,Generation:1,CreationTimestamp:2019-03-19 13:50:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f8d64b3b-4a4d-11e9-9b06-005056a45e5c 0xc001acd207 0xc001acd208}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 13:50:40.098: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 19 13:50:40.099: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-pt9k5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pt9k5/replicasets/test-recreate-deployment-5dfdcc846d,UID:f8d749a2-4a4d-11e9-9b06-005056a45e5c,ResourceVersion:5456,Generation:2,CreationTimestamp:2019-03-19 13:50:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f8d64b3b-4a4d-11e9-9b06-005056a45e5c 0xc001acd117 0xc001acd118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 13:50:40.102: INFO: Pod "test-recreate-deployment-697fbf54bf-tngk4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-tngk4,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-pt9k5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-pt9k5/pods/test-recreate-deployment-697fbf54bf-tngk4,UID:fb41eeba-4a4d-11e9-9b06-005056a45e5c,ResourceVersion:5468,Generation:0,CreationTimestamp:2019-03-19 13:50:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf fb4159d3-4a4d-11e9-9b06-005056a45e5c 0xc001acdca7 0xc001acdca8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qpnwd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qpnwd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qpnwd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001acdd10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001acdd30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 13:50:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 13:50:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 13:50:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 13:50:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 13:50:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:50:40.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-pt9k5" for this suite.
Mar 19 13:50:46.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:50:46.139: INFO: namespace: e2e-tests-deployment-pt9k5, resource: bindings, ignored listing per whitelist
Mar 19 13:50:46.180: INFO: namespace e2e-tests-deployment-pt9k5 deletion completed in 6.072699848s

â€¢ [SLOW TEST:10.307 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:50:46.180: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:50:52.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-fr4c2" for this suite.
Mar 19 13:50:58.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:50:58.396: INFO: namespace: e2e-tests-namespaces-fr4c2, resource: bindings, ignored listing per whitelist
Mar 19 13:50:58.401: INFO: namespace e2e-tests-namespaces-fr4c2 deletion completed in 6.097461068s
STEP: Destroying namespace "e2e-tests-nsdeletetest-mdcxb" for this suite.
Mar 19 13:50:58.405: INFO: Namespace e2e-tests-nsdeletetest-mdcxb was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-spplz" for this suite.
Mar 19 13:51:04.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:51:04.432: INFO: namespace: e2e-tests-nsdeletetest-spplz, resource: bindings, ignored listing per whitelist
Mar 19 13:51:04.480: INFO: namespace e2e-tests-nsdeletetest-spplz deletion completed in 6.074768588s

â€¢ [SLOW TEST:18.299 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:51:04.481: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-09e45017-4a4e-11e9-9c64-0a580af40204
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:51:06.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-47hbd" for this suite.
Mar 19 13:51:28.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:51:28.606: INFO: namespace: e2e-tests-configmap-47hbd, resource: bindings, ignored listing per whitelist
Mar 19 13:51:28.651: INFO: namespace e2e-tests-configmap-47hbd deletion completed in 22.07789585s

â€¢ [SLOW TEST:24.170 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:51:28.651: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar 19 13:51:28.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 cluster-info'
Mar 19 13:51:28.924: INFO: stderr: ""
Mar 19 13:51:28.924: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:51:28.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vn79r" for this suite.
Mar 19 13:51:34.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:51:34.989: INFO: namespace: e2e-tests-kubectl-vn79r, resource: bindings, ignored listing per whitelist
Mar 19 13:51:34.996: INFO: namespace e2e-tests-kubectl-vn79r deletion completed in 6.06759114s

â€¢ [SLOW TEST:6.345 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:51:34.997: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-1c1287df-4a4e-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 13:51:35.049: INFO: Waiting up to 5m0s for pod "pod-configmaps-1c12f238-4a4e-11e9-9c64-0a580af40204" in namespace "e2e-tests-configmap-pb97t" to be "success or failure"
Mar 19 13:51:35.057: INFO: Pod "pod-configmaps-1c12f238-4a4e-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 8.458356ms
Mar 19 13:51:37.060: INFO: Pod "pod-configmaps-1c12f238-4a4e-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011090623s
STEP: Saw pod success
Mar 19 13:51:37.060: INFO: Pod "pod-configmaps-1c12f238-4a4e-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:51:37.062: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-configmaps-1c12f238-4a4e-11e9-9c64-0a580af40204 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 13:51:37.080: INFO: Waiting for pod pod-configmaps-1c12f238-4a4e-11e9-9c64-0a580af40204 to disappear
Mar 19 13:51:37.082: INFO: Pod pod-configmaps-1c12f238-4a4e-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:51:37.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pb97t" for this suite.
Mar 19 13:51:43.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:51:43.116: INFO: namespace: e2e-tests-configmap-pb97t, resource: bindings, ignored listing per whitelist
Mar 19 13:51:43.157: INFO: namespace e2e-tests-configmap-pb97t deletion completed in 6.071361917s

â€¢ [SLOW TEST:8.160 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:51:43.157: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 19 13:51:43.211: INFO: namespace e2e-tests-kubectl-lrbhr
Mar 19 13:51:43.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-lrbhr'
Mar 19 13:51:43.375: INFO: stderr: ""
Mar 19 13:51:43.375: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 19 13:51:44.378: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 13:51:44.378: INFO: Found 0 / 1
Mar 19 13:51:45.378: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 13:51:45.378: INFO: Found 1 / 1
Mar 19 13:51:45.378: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 19 13:51:45.381: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 13:51:45.381: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 19 13:51:45.381: INFO: wait on redis-master startup in e2e-tests-kubectl-lrbhr 
Mar 19 13:51:45.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 logs redis-master-7bzk7 redis-master --namespace=e2e-tests-kubectl-lrbhr'
Mar 19 13:51:45.473: INFO: stderr: ""
Mar 19 13:51:45.473: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Mar 13:51:44.192 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Mar 13:51:44.192 # Server started, Redis version 3.2.12\n1:M 19 Mar 13:51:44.192 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Mar 13:51:44.192 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar 19 13:51:45.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-lrbhr'
Mar 19 13:51:45.582: INFO: stderr: ""
Mar 19 13:51:45.582: INFO: stdout: "service/rm2 exposed\n"
Mar 19 13:51:45.586: INFO: Service rm2 in namespace e2e-tests-kubectl-lrbhr found.
STEP: exposing service
Mar 19 13:51:47.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-lrbhr'
Mar 19 13:51:47.690: INFO: stderr: ""
Mar 19 13:51:47.690: INFO: stdout: "service/rm3 exposed\n"
Mar 19 13:51:47.694: INFO: Service rm3 in namespace e2e-tests-kubectl-lrbhr found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:51:49.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lrbhr" for this suite.
Mar 19 13:52:11.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:52:11.765: INFO: namespace: e2e-tests-kubectl-lrbhr, resource: bindings, ignored listing per whitelist
Mar 19 13:52:11.782: INFO: namespace e2e-tests-kubectl-lrbhr deletion completed in 22.081286638s

â€¢ [SLOW TEST:28.625 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:52:11.782: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 13:52:41.859: INFO: Container started at 2019-03-19 13:52:24 +0000 UTC, pod became ready at 2019-03-19 13:52:40 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:52:41.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-prxnp" for this suite.
Mar 19 13:53:03.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:53:03.927: INFO: namespace: e2e-tests-container-probe-prxnp, resource: bindings, ignored listing per whitelist
Mar 19 13:53:03.933: INFO: namespace e2e-tests-container-probe-prxnp deletion completed in 22.069728504s

â€¢ [SLOW TEST:52.150 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:53:03.933: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wd8dm A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-wd8dm;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wd8dm A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-wd8dm;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wd8dm.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-wd8dm.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wd8dm.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-wd8dm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wd8dm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-wd8dm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wd8dm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-wd8dm.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-wd8dm.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 190.172.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.172.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.172.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.172.190_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wd8dm A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-wd8dm;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wd8dm A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-wd8dm.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-wd8dm.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-wd8dm.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wd8dm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-wd8dm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-wd8dm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-wd8dm.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-wd8dm.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 190.172.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.172.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.172.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.172.190_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 19 13:53:22.077: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:22.079: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:22.082: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wd8dm from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:22.088: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:22.091: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:22.094: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:22.097: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:22.100: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:22.118: INFO: Lookups using e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-wd8dm jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm jessie_udp@dns-test-service.e2e-tests-dns-wd8dm.svc jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc]

Mar 19 13:53:27.162: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:27.166: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:27.168: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wd8dm from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:27.171: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:27.174: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:27.177: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:27.180: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:27.183: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:27.200: INFO: Lookups using e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-wd8dm jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm jessie_udp@dns-test-service.e2e-tests-dns-wd8dm.svc jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc]

Mar 19 13:53:32.156: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:32.160: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:32.163: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wd8dm from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:32.166: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:32.169: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:32.172: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:32.175: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:32.178: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:32.193: INFO: Lookups using e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-wd8dm jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm jessie_udp@dns-test-service.e2e-tests-dns-wd8dm.svc jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc]

Mar 19 13:53:37.157: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:37.160: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:37.163: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wd8dm from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:37.166: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:37.169: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:37.172: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:37.175: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:37.178: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc from pod e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204: the server could not find the requested resource (get pods dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204)
Mar 19 13:53:37.193: INFO: Lookups using e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-wd8dm jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm jessie_udp@dns-test-service.e2e-tests-dns-wd8dm.svc jessie_tcp@dns-test-service.e2e-tests-dns-wd8dm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-wd8dm.svc]

Mar 19 13:53:42.196: INFO: DNS probes using e2e-tests-dns-wd8dm/dns-test-511a07ff-4a4e-11e9-9c64-0a580af40204 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:53:42.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-wd8dm" for this suite.
Mar 19 13:53:48.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:53:48.307: INFO: namespace: e2e-tests-dns-wd8dm, resource: bindings, ignored listing per whitelist
Mar 19 13:53:48.342: INFO: namespace e2e-tests-dns-wd8dm deletion completed in 6.082189508s

â€¢ [SLOW TEST:44.410 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:53:48.344: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 13:53:48.393: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:53:49.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-b7dbn" for this suite.
Mar 19 13:53:55.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:53:55.509: INFO: namespace: e2e-tests-custom-resource-definition-b7dbn, resource: bindings, ignored listing per whitelist
Mar 19 13:53:55.535: INFO: namespace e2e-tests-custom-resource-definition-b7dbn deletion completed in 6.074111846s

â€¢ [SLOW TEST:7.192 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:53:55.538: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-2gwc
STEP: Creating a pod to test atomic-volume-subpath
Mar 19 13:53:55.598: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-2gwc" in namespace "e2e-tests-subpath-qpnlb" to be "success or failure"
Mar 19 13:53:55.602: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.186157ms
Mar 19 13:53:57.605: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006045616s
Mar 19 13:53:59.608: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Running", Reason="", readiness=false. Elapsed: 4.009017475s
Mar 19 13:54:01.610: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Running", Reason="", readiness=false. Elapsed: 6.011236655s
Mar 19 13:54:03.613: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Running", Reason="", readiness=false. Elapsed: 8.014331426s
Mar 19 13:54:05.615: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Running", Reason="", readiness=false. Elapsed: 10.016703506s
Mar 19 13:54:07.619: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Running", Reason="", readiness=false. Elapsed: 12.020042521s
Mar 19 13:54:09.621: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Running", Reason="", readiness=false. Elapsed: 14.022691311s
Mar 19 13:54:11.627: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Running", Reason="", readiness=false. Elapsed: 16.028116469s
Mar 19 13:54:13.630: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Running", Reason="", readiness=false. Elapsed: 18.031193156s
Mar 19 13:54:15.633: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Running", Reason="", readiness=false. Elapsed: 20.033912662s
Mar 19 13:54:17.635: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Running", Reason="", readiness=false. Elapsed: 22.036807102s
Mar 19 13:54:19.638: INFO: Pod "pod-subpath-test-projected-2gwc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.039552335s
STEP: Saw pod success
Mar 19 13:54:19.638: INFO: Pod "pod-subpath-test-projected-2gwc" satisfied condition "success or failure"
Mar 19 13:54:19.641: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-subpath-test-projected-2gwc container test-container-subpath-projected-2gwc: <nil>
STEP: delete the pod
Mar 19 13:54:19.664: INFO: Waiting for pod pod-subpath-test-projected-2gwc to disappear
Mar 19 13:54:19.666: INFO: Pod pod-subpath-test-projected-2gwc no longer exists
STEP: Deleting pod pod-subpath-test-projected-2gwc
Mar 19 13:54:19.666: INFO: Deleting pod "pod-subpath-test-projected-2gwc" in namespace "e2e-tests-subpath-qpnlb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:54:19.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qpnlb" for this suite.
Mar 19 13:54:25.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:54:25.746: INFO: namespace: e2e-tests-subpath-qpnlb, resource: bindings, ignored listing per whitelist
Mar 19 13:54:25.752: INFO: namespace e2e-tests-subpath-qpnlb deletion completed in 6.081625846s

â€¢ [SLOW TEST:30.215 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:54:25.753: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-81dbe0bd-4a4e-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 13:54:25.820: INFO: Waiting up to 5m0s for pod "pod-configmaps-81dc8aff-4a4e-11e9-9c64-0a580af40204" in namespace "e2e-tests-configmap-d82js" to be "success or failure"
Mar 19 13:54:25.827: INFO: Pod "pod-configmaps-81dc8aff-4a4e-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 7.135704ms
Mar 19 13:54:27.830: INFO: Pod "pod-configmaps-81dc8aff-4a4e-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009841637s
STEP: Saw pod success
Mar 19 13:54:27.830: INFO: Pod "pod-configmaps-81dc8aff-4a4e-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:54:27.832: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-configmaps-81dc8aff-4a4e-11e9-9c64-0a580af40204 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 13:54:27.848: INFO: Waiting for pod pod-configmaps-81dc8aff-4a4e-11e9-9c64-0a580af40204 to disappear
Mar 19 13:54:27.851: INFO: Pod pod-configmaps-81dc8aff-4a4e-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:54:27.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-d82js" for this suite.
Mar 19 13:54:33.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:54:33.899: INFO: namespace: e2e-tests-configmap-d82js, resource: bindings, ignored listing per whitelist
Mar 19 13:54:33.937: INFO: namespace e2e-tests-configmap-d82js deletion completed in 6.083031223s

â€¢ [SLOW TEST:8.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:54:33.938: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 19 13:54:34.011: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 13:54:34.014: INFO: Number of nodes with available pods: 0
Mar 19 13:54:34.014: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:54:35.017: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 13:54:35.022: INFO: Number of nodes with available pods: 0
Mar 19 13:54:35.022: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 13:54:36.017: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 13:54:36.020: INFO: Number of nodes with available pods: 2
Mar 19 13:54:36.020: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 19 13:54:36.038: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 13:54:36.043: INFO: Number of nodes with available pods: 1
Mar 19 13:54:36.043: INFO: Node essentialpks-conformance-3 is running more than one daemon pod
Mar 19 13:54:37.047: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 13:54:37.049: INFO: Number of nodes with available pods: 1
Mar 19 13:54:37.049: INFO: Node essentialpks-conformance-3 is running more than one daemon pod
Mar 19 13:54:38.047: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 13:54:38.050: INFO: Number of nodes with available pods: 2
Mar 19 13:54:38.050: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-g8fw9, will wait for the garbage collector to delete the pods
Mar 19 13:54:38.114: INFO: Deleting DaemonSet.extensions daemon-set took: 5.783303ms
Mar 19 13:54:38.215: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.2046ms
Mar 19 13:55:12.217: INFO: Number of nodes with available pods: 0
Mar 19 13:55:12.217: INFO: Number of running nodes: 0, number of available pods: 0
Mar 19 13:55:12.219: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-g8fw9/daemonsets","resourceVersion":"6254"},"items":null}

Mar 19 13:55:12.221: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-g8fw9/pods","resourceVersion":"6254"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:55:12.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-g8fw9" for this suite.
Mar 19 13:55:18.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:55:18.299: INFO: namespace: e2e-tests-daemonsets-g8fw9, resource: bindings, ignored listing per whitelist
Mar 19 13:55:18.303: INFO: namespace e2e-tests-daemonsets-g8fw9 deletion completed in 6.071402689s

â€¢ [SLOW TEST:44.365 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:55:18.303: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-g27j6
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-g27j6 to expose endpoints map[]
Mar 19 13:55:18.384: INFO: Get endpoints failed (5.160431ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar 19 13:55:19.386: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-g27j6 exposes endpoints map[] (1.007356639s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-g27j6
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-g27j6 to expose endpoints map[pod1:[100]]
Mar 19 13:55:21.410: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-g27j6 exposes endpoints map[pod1:[100]] (2.018288745s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-g27j6
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-g27j6 to expose endpoints map[pod1:[100] pod2:[101]]
Mar 19 13:55:22.435: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-g27j6 exposes endpoints map[pod1:[100] pod2:[101]] (1.020989238s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-g27j6
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-g27j6 to expose endpoints map[pod2:[101]]
Mar 19 13:55:23.451: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-g27j6 exposes endpoints map[pod2:[101]] (1.01111781s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-g27j6
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-g27j6 to expose endpoints map[]
Mar 19 13:55:24.460: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-g27j6 exposes endpoints map[] (1.005054009s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:55:24.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-g27j6" for this suite.
Mar 19 13:55:46.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:55:46.535: INFO: namespace: e2e-tests-services-g27j6, resource: bindings, ignored listing per whitelist
Mar 19 13:55:46.552: INFO: namespace e2e-tests-services-g27j6 deletion completed in 22.06986052s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:28.248 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:55:46.552: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bbzps
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 19 13:55:46.600: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 19 13:56:10.667: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.1.43 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bbzps PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 13:56:10.668: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 13:56:11.780: INFO: Found all expected endpoints: [netserver-0]
Mar 19 13:56:11.783: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.2.49 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bbzps PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 13:56:11.783: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 13:56:12.883: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:56:12.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bbzps" for this suite.
Mar 19 13:56:34.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:56:34.948: INFO: namespace: e2e-tests-pod-network-test-bbzps, resource: bindings, ignored listing per whitelist
Mar 19 13:56:34.970: INFO: namespace e2e-tests-pod-network-test-bbzps deletion completed in 22.083286041s

â€¢ [SLOW TEST:48.418 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:56:34.970: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-cee33d25-4a4e-11e9-9c64-0a580af40204
STEP: Creating secret with name secret-projected-all-test-volume-cee33d13-4a4e-11e9-9c64-0a580af40204
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 19 13:56:35.058: INFO: Waiting up to 5m0s for pod "projected-volume-cee33cdb-4a4e-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-qnct5" to be "success or failure"
Mar 19 13:56:35.062: INFO: Pod "projected-volume-cee33cdb-4a4e-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.572568ms
Mar 19 13:56:37.065: INFO: Pod "projected-volume-cee33cdb-4a4e-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006793893s
STEP: Saw pod success
Mar 19 13:56:37.065: INFO: Pod "projected-volume-cee33cdb-4a4e-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:56:37.067: INFO: Trying to get logs from node essentialpks-conformance-2 pod projected-volume-cee33cdb-4a4e-11e9-9c64-0a580af40204 container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 19 13:56:37.092: INFO: Waiting for pod projected-volume-cee33cdb-4a4e-11e9-9c64-0a580af40204 to disappear
Mar 19 13:56:37.094: INFO: Pod projected-volume-cee33cdb-4a4e-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:56:37.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qnct5" for this suite.
Mar 19 13:56:43.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:56:43.135: INFO: namespace: e2e-tests-projected-qnct5, resource: bindings, ignored listing per whitelist
Mar 19 13:56:43.172: INFO: namespace e2e-tests-projected-qnct5 deletion completed in 6.074471018s

â€¢ [SLOW TEST:8.202 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:56:43.173: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 19 13:56:43.225: INFO: Waiting up to 5m0s for pod "pod-d3c35797-4a4e-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-dw5cp" to be "success or failure"
Mar 19 13:56:43.229: INFO: Pod "pod-d3c35797-4a4e-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.897798ms
Mar 19 13:56:45.233: INFO: Pod "pod-d3c35797-4a4e-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00728347s
STEP: Saw pod success
Mar 19 13:56:45.233: INFO: Pod "pod-d3c35797-4a4e-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:56:45.235: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-d3c35797-4a4e-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 13:56:45.249: INFO: Waiting for pod pod-d3c35797-4a4e-11e9-9c64-0a580af40204 to disappear
Mar 19 13:56:45.251: INFO: Pod pod-d3c35797-4a4e-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:56:45.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dw5cp" for this suite.
Mar 19 13:56:51.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:56:51.334: INFO: namespace: e2e-tests-emptydir-dw5cp, resource: bindings, ignored listing per whitelist
Mar 19 13:56:51.346: INFO: namespace e2e-tests-emptydir-dw5cp deletion completed in 6.091919714s

â€¢ [SLOW TEST:8.173 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:56:51.346: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 13:56:51.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-hz6xz'
Mar 19 13:56:51.499: INFO: stderr: ""
Mar 19 13:56:51.499: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar 19 13:56:56.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-hz6xz -o json'
Mar 19 13:56:56.639: INFO: stderr: ""
Mar 19 13:56:56.639: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-03-19T13:56:51Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-hz6xz\",\n        \"resourceVersion\": \"6613\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-hz6xz/pods/e2e-test-nginx-pod\",\n        \"uid\": \"d8b01c23-4a4e-11e9-9b06-005056a45e5c\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-w7lrt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"essentialpks-conformance-2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-w7lrt\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-w7lrt\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-19T13:56:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-19T13:56:53Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-19T13:56:53Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-19T13:56:51Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://7b526da1f29d7611849b2fc6263e0fc9d608c7ede5c43c60468125c869605d50\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-19T13:56:52Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.102.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.2.52\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-19T13:56:51Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 19 13:56:56.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 replace -f - --namespace=e2e-tests-kubectl-hz6xz'
Mar 19 13:56:56.825: INFO: stderr: ""
Mar 19 13:56:56.825: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Mar 19 13:56:56.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-hz6xz'
Mar 19 13:56:58.467: INFO: stderr: ""
Mar 19 13:56:58.467: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:56:58.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hz6xz" for this suite.
Mar 19 13:57:04.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:57:04.510: INFO: namespace: e2e-tests-kubectl-hz6xz, resource: bindings, ignored listing per whitelist
Mar 19 13:57:04.558: INFO: namespace e2e-tests-kubectl-hz6xz deletion completed in 6.085456292s

â€¢ [SLOW TEST:13.212 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:57:04.558: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar 19 13:57:04.623: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-d7hlg" to be "success or failure"
Mar 19 13:57:04.637: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 14.434292ms
Mar 19 13:57:06.640: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017756734s
STEP: Saw pod success
Mar 19 13:57:06.640: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 19 13:57:06.645: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 19 13:57:06.670: INFO: Waiting for pod pod-host-path-test to disappear
Mar 19 13:57:06.673: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:57:06.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-d7hlg" for this suite.
Mar 19 13:57:12.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:57:12.698: INFO: namespace: e2e-tests-hostpath-d7hlg, resource: bindings, ignored listing per whitelist
Mar 19 13:57:12.753: INFO: namespace e2e-tests-hostpath-d7hlg deletion completed in 6.074147295s

â€¢ [SLOW TEST:8.196 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:57:12.755: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 13:57:12.808: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:57:14.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-szd8n" for this suite.
Mar 19 13:57:52.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:57:52.987: INFO: namespace: e2e-tests-pods-szd8n, resource: bindings, ignored listing per whitelist
Mar 19 13:57:53.044: INFO: namespace e2e-tests-pods-szd8n deletion completed in 38.078131532s

â€¢ [SLOW TEST:40.289 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:57:53.046: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 13:57:53.111: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd6aab9c-4a4e-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-bv6dd" to be "success or failure"
Mar 19 13:57:53.118: INFO: Pod "downwardapi-volume-fd6aab9c-4a4e-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 6.178109ms
Mar 19 13:57:55.120: INFO: Pod "downwardapi-volume-fd6aab9c-4a4e-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008886001s
STEP: Saw pod success
Mar 19 13:57:55.120: INFO: Pod "downwardapi-volume-fd6aab9c-4a4e-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:57:55.123: INFO: Trying to get logs from node essentialpks-conformance-3 pod downwardapi-volume-fd6aab9c-4a4e-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 13:57:55.139: INFO: Waiting for pod downwardapi-volume-fd6aab9c-4a4e-11e9-9c64-0a580af40204 to disappear
Mar 19 13:57:55.141: INFO: Pod downwardapi-volume-fd6aab9c-4a4e-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:57:55.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bv6dd" for this suite.
Mar 19 13:58:01.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:58:01.203: INFO: namespace: e2e-tests-projected-bv6dd, resource: bindings, ignored listing per whitelist
Mar 19 13:58:01.266: INFO: namespace e2e-tests-projected-bv6dd deletion completed in 6.120015295s

â€¢ [SLOW TEST:8.219 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:58:01.266: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6zdrr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 19 13:58:01.331: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 19 13:58:31.400: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.48:8080/dial?request=hostName&protocol=udp&host=10.244.2.54&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6zdrr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 13:58:31.400: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 13:58:31.504: INFO: Waiting for endpoints: map[]
Mar 19 13:58:31.507: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.48:8080/dial?request=hostName&protocol=udp&host=10.244.1.47&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6zdrr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 13:58:31.507: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 13:58:31.640: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:58:31.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6zdrr" for this suite.
Mar 19 13:58:53.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:58:53.678: INFO: namespace: e2e-tests-pod-network-test-6zdrr, resource: bindings, ignored listing per whitelist
Mar 19 13:58:53.728: INFO: namespace e2e-tests-pod-network-test-6zdrr deletion completed in 22.084413286s

â€¢ [SLOW TEST:52.462 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:58:53.729: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 19 13:58:53.785: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 19 13:58:53.791: INFO: Waiting for terminating namespaces to be deleted...
Mar 19 13:58:53.793: INFO: 
Logging pods the kubelet thinks is on node essentialpks-conformance-2 before test
Mar 19 13:58:53.798: INFO: kube-flannel-ds-amd64-c4rpf from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 13:58:53.798: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 19 13:58:53.798: INFO: sonobuoy-e2e-job-879d35058b7448c9 from heptio-sonobuoy started at 2019-03-19 13:34:37 +0000 UTC (2 container statuses recorded)
Mar 19 13:58:53.798: INFO: 	Container e2e ready: true, restart count 0
Mar 19 13:58:53.798: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 13:58:53.798: INFO: kube-proxy-x8ptf from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 13:58:53.798: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 13:58:53.798: INFO: sonobuoy-systemd-logs-daemon-set-3f70baa84f8b44d1-2l52l from heptio-sonobuoy started at 2019-03-19 13:34:37 +0000 UTC (2 container statuses recorded)
Mar 19 13:58:53.798: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 19 13:58:53.798: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 13:58:53.798: INFO: 
Logging pods the kubelet thinks is on node essentialpks-conformance-3 before test
Mar 19 13:58:53.803: INFO: kube-flannel-ds-amd64-5d5mf from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 13:58:53.804: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 19 13:58:53.804: INFO: kube-proxy-h9j6t from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 13:58:53.804: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 13:58:53.804: INFO: sonobuoy-systemd-logs-daemon-set-3f70baa84f8b44d1-96s5d from heptio-sonobuoy started at 2019-03-19 13:34:37 +0000 UTC (2 container statuses recorded)
Mar 19 13:58:53.804: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 19 13:58:53.804: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 13:58:53.804: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-19 13:34:35 +0000 UTC (1 container statuses recorded)
Mar 19 13:58:53.804: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158d60d9827b7f36], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:58:54.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-xrhps" for this suite.
Mar 19 13:59:00.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:59:00.857: INFO: namespace: e2e-tests-sched-pred-xrhps, resource: bindings, ignored listing per whitelist
Mar 19 13:59:00.908: INFO: namespace e2e-tests-sched-pred-xrhps deletion completed in 6.073075696s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:7.180 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:59:00.909: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-25dbedf5-4a4f-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 13:59:00.965: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-25dc65e4-4a4f-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-9528p" to be "success or failure"
Mar 19 13:59:00.968: INFO: Pod "pod-projected-secrets-25dc65e4-4a4f-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.002963ms
Mar 19 13:59:02.970: INFO: Pod "pod-projected-secrets-25dc65e4-4a4f-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005710934s
STEP: Saw pod success
Mar 19 13:59:02.971: INFO: Pod "pod-projected-secrets-25dc65e4-4a4f-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 13:59:02.973: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-projected-secrets-25dc65e4-4a4f-11e9-9c64-0a580af40204 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 13:59:02.993: INFO: Waiting for pod pod-projected-secrets-25dc65e4-4a4f-11e9-9c64-0a580af40204 to disappear
Mar 19 13:59:02.996: INFO: Pod pod-projected-secrets-25dc65e4-4a4f-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 13:59:02.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9528p" for this suite.
Mar 19 13:59:09.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 13:59:09.025: INFO: namespace: e2e-tests-projected-9528p, resource: bindings, ignored listing per whitelist
Mar 19 13:59:09.078: INFO: namespace e2e-tests-projected-9528p deletion completed in 6.079283466s

â€¢ [SLOW TEST:8.169 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 13:59:09.082: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:00:09.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bnxd9" for this suite.
Mar 19 14:00:31.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:00:31.257: INFO: namespace: e2e-tests-container-probe-bnxd9, resource: bindings, ignored listing per whitelist
Mar 19 14:00:31.264: INFO: namespace e2e-tests-container-probe-bnxd9 deletion completed in 22.114020711s

â€¢ [SLOW TEST:82.182 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:00:31.264: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar 19 14:00:31.355: INFO: Pod name pod-release: Found 0 pods out of 1
Mar 19 14:00:36.359: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:00:36.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-4qhb2" for this suite.
Mar 19 14:00:42.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:00:42.459: INFO: namespace: e2e-tests-replication-controller-4qhb2, resource: bindings, ignored listing per whitelist
Mar 19 14:00:42.470: INFO: namespace e2e-tests-replication-controller-4qhb2 deletion completed in 6.088688532s

â€¢ [SLOW TEST:11.206 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:00:42.471: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:00:42.523: INFO: Creating deployment "nginx-deployment"
Mar 19 14:00:42.530: INFO: Waiting for observed generation 1
Mar 19 14:00:44.535: INFO: Waiting for all required pods to come up
Mar 19 14:00:44.539: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 19 14:00:46.551: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 19 14:00:46.555: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 19 14:00:46.561: INFO: Updating deployment nginx-deployment
Mar 19 14:00:46.561: INFO: Waiting for observed generation 2
Mar 19 14:00:48.566: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 19 14:00:48.569: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 19 14:00:48.571: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 19 14:00:48.577: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 19 14:00:48.577: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 19 14:00:48.579: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 19 14:00:48.583: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 19 14:00:48.583: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 19 14:00:48.591: INFO: Updating deployment nginx-deployment
Mar 19 14:00:48.591: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 19 14:00:48.611: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 19 14:00:50.627: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 19 14:00:50.636: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d8mxl/deployments/nginx-deployment,UID:626608cb-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7478,Generation:3,CreationTimestamp:2019-03-19 14:00:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-03-19 14:00:48 +0000 UTC 2019-03-19 14:00:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-19 14:00:48 +0000 UTC 2019-03-19 14:00:42 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar 19 14:00:50.639: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d8mxl/replicasets/nginx-deployment-65bbdb5f8,UID:64ce4e95-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7475,Generation:3,CreationTimestamp:2019-03-19 14:00:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 626608cb-4a4f-11e9-9b06-005056a45e5c 0xc001b86aa7 0xc001b86aa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 14:00:50.639: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 19 14:00:50.639: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d8mxl/replicasets/nginx-deployment-555b55d965,UID:62679824-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7465,Generation:3,CreationTimestamp:2019-03-19 14:00:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 626608cb-4a4f-11e9-9b06-005056a45e5c 0xc001b869e7 0xc001b869e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar 19 14:00:50.647: INFO: Pod "nginx-deployment-555b55d965-2hqbj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2hqbj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-2hqbj,UID:626a1aa1-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7334,Generation:0,CreationTimestamp:2019-03-19 14:00:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc001b87780 0xc001b87781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b877e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b87800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:10.244.2.61,StartTime:2019-03-19 14:00:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 14:00:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://04e68193e0c7de0961e4849988fc8d71795fc19f80ce227b20867e664a03939b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.647: INFO: Pod "nginx-deployment-555b55d965-6v5ww" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6v5ww,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-6v5ww,UID:660e7f55-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7512,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc001b878d0 0xc001b878d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b87930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b87950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.648: INFO: Pod "nginx-deployment-555b55d965-b8hkw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-b8hkw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-b8hkw,UID:660a505f-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7474,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc001b87a07 0xc001b87a08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226a060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226a080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.648: INFO: Pod "nginx-deployment-555b55d965-bkxg9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bkxg9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-bkxg9,UID:626fec0a-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7315,Generation:0,CreationTimestamp:2019-03-19 14:00:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226a137 0xc00226a138}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226a1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226a1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:10.244.1.51,StartTime:2019-03-19 14:00:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 14:00:43 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://8f1fc0d18008e264f78fcc1277c09603a4f1f650e7d07e25f3718f5f99c463bb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.648: INFO: Pod "nginx-deployment-555b55d965-bnzs2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bnzs2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-bnzs2,UID:6605aa4c-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7457,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226a280 0xc00226a281}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226a2e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226a300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.648: INFO: Pod "nginx-deployment-555b55d965-c5ng2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-c5ng2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-c5ng2,UID:66048505-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7422,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226a3b7 0xc00226a3b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226a420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226a440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.648: INFO: Pod "nginx-deployment-555b55d965-cfscp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cfscp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-cfscp,UID:626c84bd-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7296,Generation:0,CreationTimestamp:2019-03-19 14:00:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226a4f7 0xc00226a4f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226a560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226a580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:10.244.2.57,StartTime:2019-03-19 14:00:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 14:00:43 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://0ca1640ef5b8de8c3b817330c6f77e9e43dd549c901f276dd8275425ec16fa02}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.649: INFO: Pod "nginx-deployment-555b55d965-ctrbv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ctrbv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-ctrbv,UID:626c9894-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7325,Generation:0,CreationTimestamp:2019-03-19 14:00:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226a640 0xc00226a641}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226a6a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226a6c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:10.244.1.54,StartTime:2019-03-19 14:00:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 14:00:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://3c44ff194507e2a3b9c8cd28e951c3501ae93518d165f45f42a3fd0aaf3d81c7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.649: INFO: Pod "nginx-deployment-555b55d965-d59b9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-d59b9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-d59b9,UID:660e5c23-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7481,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226a780 0xc00226a781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226a7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226a800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.649: INFO: Pod "nginx-deployment-555b55d965-dhkmm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dhkmm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-dhkmm,UID:626cbbef-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7340,Generation:0,CreationTimestamp:2019-03-19 14:00:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226a8b7 0xc00226a8b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226a920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226a940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:10.244.2.58,StartTime:2019-03-19 14:00:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 14:00:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://d353261c12f8ca7bb55a895e32dc8f7d37c20009b05e1b8a9b517e92b5aed6e9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.649: INFO: Pod "nginx-deployment-555b55d965-f5cf2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f5cf2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-f5cf2,UID:660ec3ec-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7456,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226aa00 0xc00226aa01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226aa60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226aa80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.649: INFO: Pod "nginx-deployment-555b55d965-fp76b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fp76b,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-fp76b,UID:6609a05d-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7502,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226aaf0 0xc00226aaf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226ab50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226ab70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.650: INFO: Pod "nginx-deployment-555b55d965-gpx24" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gpx24,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-gpx24,UID:626aa519-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7319,Generation:0,CreationTimestamp:2019-03-19 14:00:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226ac27 0xc00226ac28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226ac90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226acb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:10.244.1.52,StartTime:2019-03-19 14:00:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 14:00:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://bbf41f87c00feba420160d00eeb243da4564a31feb298b3453d2c32ac517ddf9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.650: INFO: Pod "nginx-deployment-555b55d965-hg7j2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hg7j2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-hg7j2,UID:626fe081-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7331,Generation:0,CreationTimestamp:2019-03-19 14:00:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226ad70 0xc00226ad71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226add0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226adf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:10.244.2.59,StartTime:2019-03-19 14:00:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 14:00:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://b1fa8cada914bf18497338203f12b312291343ccb49e604692048b72afab82e6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.650: INFO: Pod "nginx-deployment-555b55d965-jxp4r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jxp4r,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-jxp4r,UID:660eb86d-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7521,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226aec0 0xc00226aec1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226af20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226af40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.650: INFO: Pod "nginx-deployment-555b55d965-m79nb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-m79nb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-m79nb,UID:660a172e-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7491,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226b007 0xc00226b008}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226b070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226b090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.650: INFO: Pod "nginx-deployment-555b55d965-mv6vb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mv6vb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-mv6vb,UID:660a7b20-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7487,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226b147 0xc00226b148}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226b1b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226b1d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.650: INFO: Pod "nginx-deployment-555b55d965-qkwc7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qkwc7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-qkwc7,UID:6605cefe-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7460,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226b287 0xc00226b288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226b2f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226b310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.651: INFO: Pod "nginx-deployment-555b55d965-rhtfx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rhtfx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-rhtfx,UID:660ea778-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7515,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226b3c7 0xc00226b3c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226b430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226b450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.651: INFO: Pod "nginx-deployment-555b55d965-zmlmp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zmlmp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-555b55d965-zmlmp,UID:626fc7e7-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7321,Generation:0,CreationTimestamp:2019-03-19 14:00:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 62679824-4a4f-11e9-9b06-005056a45e5c 0xc00226b507 0xc00226b508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226b570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226b590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:10.244.1.55,StartTime:2019-03-19 14:00:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 14:00:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://229d2e794b44726a13bc8c87a9830377fd32ac040c7aaaadf826070fc3efa21b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.651: INFO: Pod "nginx-deployment-65bbdb5f8-2kjsc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2kjsc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-2kjsc,UID:660e01b3-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7516,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00226b650 0xc00226b651}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226b6c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226b6e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.651: INFO: Pod "nginx-deployment-65bbdb5f8-64zvn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-64zvn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-64zvn,UID:660df5e7-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7511,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00226b7a0 0xc00226b7a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226b810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226b830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.651: INFO: Pod "nginx-deployment-65bbdb5f8-b5xp8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-b5xp8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-b5xp8,UID:64ceb2d3-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7363,Generation:0,CreationTimestamp:2019-03-19 14:00:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00226b8f0 0xc00226b8f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226b960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226b980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.651: INFO: Pod "nginx-deployment-65bbdb5f8-bbg7d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bbg7d,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-bbg7d,UID:64da6ff3-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7393,Generation:0,CreationTimestamp:2019-03-19 14:00:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00226ba40 0xc00226ba41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226bab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226bad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.651: INFO: Pod "nginx-deployment-65bbdb5f8-cjbrz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cjbrz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-cjbrz,UID:64d7c23b-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7392,Generation:0,CreationTimestamp:2019-03-19 14:00:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00226bb90 0xc00226bb91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226bc00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226bc20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.651: INFO: Pod "nginx-deployment-65bbdb5f8-dd2qp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dd2qp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-dd2qp,UID:660667ed-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7480,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00226bce0 0xc00226bce1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226bd50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226bd70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.652: INFO: Pod "nginx-deployment-65bbdb5f8-f5srf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-f5srf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-f5srf,UID:660a3296-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7470,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00226be30 0xc00226be31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226bea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00226bec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.652: INFO: Pod "nginx-deployment-65bbdb5f8-gmgtr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gmgtr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-gmgtr,UID:6613b84f-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7522,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00226bf80 0xc00226bf81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00226bff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00237e9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.652: INFO: Pod "nginx-deployment-65bbdb5f8-hbmc7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hbmc7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-hbmc7,UID:660de38c-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7454,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00237ea90 0xc00237ea91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00237eb00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00237eb20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.652: INFO: Pod "nginx-deployment-65bbdb5f8-jfczd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jfczd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-jfczd,UID:660dba88-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7499,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00237eb90 0xc00237eb91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00237ec00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00237ec20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.652: INFO: Pod "nginx-deployment-65bbdb5f8-mgrsq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mgrsq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-mgrsq,UID:64d028f6-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7372,Generation:0,CreationTimestamp:2019-03-19 14:00:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00237ece0 0xc00237ece1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00237ed50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00237ed70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.652: INFO: Pod "nginx-deployment-65bbdb5f8-q9dlk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-q9dlk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-q9dlk,UID:64d039fb-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7381,Generation:0,CreationTimestamp:2019-03-19 14:00:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00237ee30 0xc00237ee31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00237eea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00237eec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:,StartTime:2019-03-19 14:00:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:00:50.652: INFO: Pod "nginx-deployment-65bbdb5f8-xzf6v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xzf6v,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-d8mxl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d8mxl/pods/nginx-deployment-65bbdb5f8-xzf6v,UID:660a6b92-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:7493,Generation:0,CreationTimestamp:2019-03-19 14:00:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 64ce4e95-4a4f-11e9-9b06-005056a45e5c 0xc00237ef80 0xc00237ef81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwfkh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwfkh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwfkh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00237eff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00237f010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:00:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:,StartTime:2019-03-19 14:00:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:00:50.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-d8mxl" for this suite.
Mar 19 14:00:56.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:00:56.731: INFO: namespace: e2e-tests-deployment-d8mxl, resource: bindings, ignored listing per whitelist
Mar 19 14:00:56.762: INFO: namespace e2e-tests-deployment-d8mxl deletion completed in 6.106713425s

â€¢ [SLOW TEST:14.292 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:00:56.763: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-dc8fp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 19 14:00:56.849: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 19 14:01:16.910: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.68:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dc8fp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:01:16.910: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:01:17.049: INFO: Found all expected endpoints: [netserver-0]
Mar 19 14:01:17.052: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.75:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dc8fp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:01:17.052: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:01:17.187: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:01:17.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-dc8fp" for this suite.
Mar 19 14:01:39.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:01:39.235: INFO: namespace: e2e-tests-pod-network-test-dc8fp, resource: bindings, ignored listing per whitelist
Mar 19 14:01:39.275: INFO: namespace e2e-tests-pod-network-test-dc8fp deletion completed in 22.083566769s

â€¢ [SLOW TEST:42.513 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:01:39.276: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 14:01:39.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-mrfvt'
Mar 19 14:01:39.613: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 19 14:01:39.613: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Mar 19 14:01:43.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-mrfvt'
Mar 19 14:01:43.714: INFO: stderr: ""
Mar 19 14:01:43.714: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:01:43.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mrfvt" for this suite.
Mar 19 14:01:49.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:01:49.783: INFO: namespace: e2e-tests-kubectl-mrfvt, resource: bindings, ignored listing per whitelist
Mar 19 14:01:49.796: INFO: namespace e2e-tests-kubectl-mrfvt deletion completed in 6.076625127s

â€¢ [SLOW TEST:10.520 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:01:49.797: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 19 14:01:49.859: INFO: Waiting up to 5m0s for pod "downward-api-8a879392-4a4f-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-x6f6k" to be "success or failure"
Mar 19 14:01:49.865: INFO: Pod "downward-api-8a879392-4a4f-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.316078ms
Mar 19 14:01:51.868: INFO: Pod "downward-api-8a879392-4a4f-11e9-9c64-0a580af40204": Phase="Running", Reason="", readiness=true. Elapsed: 2.008415294s
Mar 19 14:01:53.870: INFO: Pod "downward-api-8a879392-4a4f-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010991145s
STEP: Saw pod success
Mar 19 14:01:53.870: INFO: Pod "downward-api-8a879392-4a4f-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:01:53.873: INFO: Trying to get logs from node essentialpks-conformance-3 pod downward-api-8a879392-4a4f-11e9-9c64-0a580af40204 container dapi-container: <nil>
STEP: delete the pod
Mar 19 14:01:53.891: INFO: Waiting for pod downward-api-8a879392-4a4f-11e9-9c64-0a580af40204 to disappear
Mar 19 14:01:53.894: INFO: Pod downward-api-8a879392-4a4f-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:01:53.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x6f6k" for this suite.
Mar 19 14:01:59.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:01:59.949: INFO: namespace: e2e-tests-downward-api-x6f6k, resource: bindings, ignored listing per whitelist
Mar 19 14:01:59.975: INFO: namespace e2e-tests-downward-api-x6f6k deletion completed in 6.075574067s

â€¢ [SLOW TEST:10.178 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:01:59.975: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 19 14:02:00.057: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:00.061: INFO: Number of nodes with available pods: 0
Mar 19 14:02:00.061: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:01.064: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:01.067: INFO: Number of nodes with available pods: 0
Mar 19 14:02:01.067: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:02.065: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:02.067: INFO: Number of nodes with available pods: 2
Mar 19 14:02:02.067: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 19 14:02:02.079: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:02.082: INFO: Number of nodes with available pods: 1
Mar 19 14:02:02.082: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:03.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:03.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:03.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:04.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:04.087: INFO: Number of nodes with available pods: 1
Mar 19 14:02:04.087: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:05.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:05.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:05.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:06.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:06.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:06.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:07.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:07.090: INFO: Number of nodes with available pods: 1
Mar 19 14:02:07.090: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:08.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:08.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:08.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:09.087: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:09.090: INFO: Number of nodes with available pods: 1
Mar 19 14:02:09.090: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:10.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:10.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:10.089: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:11.088: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:11.093: INFO: Number of nodes with available pods: 1
Mar 19 14:02:11.093: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:12.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:12.091: INFO: Number of nodes with available pods: 1
Mar 19 14:02:12.091: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:13.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:13.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:13.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:14.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:14.089: INFO: Number of nodes with available pods: 1
Mar 19 14:02:14.089: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:15.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:15.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:15.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:16.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:16.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:16.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:17.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:17.087: INFO: Number of nodes with available pods: 1
Mar 19 14:02:17.087: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:18.089: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:18.092: INFO: Number of nodes with available pods: 1
Mar 19 14:02:18.092: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:19.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:19.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:19.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:20.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:20.089: INFO: Number of nodes with available pods: 1
Mar 19 14:02:20.089: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:21.088: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:21.091: INFO: Number of nodes with available pods: 1
Mar 19 14:02:21.091: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:22.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:22.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:22.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:23.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:23.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:23.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:24.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:24.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:24.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:25.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:25.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:25.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:26.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:26.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:26.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:27.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:27.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:27.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:28.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:28.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:28.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:29.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:29.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:29.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:30.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:30.089: INFO: Number of nodes with available pods: 1
Mar 19 14:02:30.089: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:31.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:31.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:31.088: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:32.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:32.088: INFO: Number of nodes with available pods: 1
Mar 19 14:02:32.089: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:33.088: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:33.091: INFO: Number of nodes with available pods: 1
Mar 19 14:02:33.091: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:34.085: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:34.087: INFO: Number of nodes with available pods: 1
Mar 19 14:02:34.087: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:35.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:35.089: INFO: Number of nodes with available pods: 1
Mar 19 14:02:35.089: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:36.087: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:36.091: INFO: Number of nodes with available pods: 1
Mar 19 14:02:36.091: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:02:37.086: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:02:37.089: INFO: Number of nodes with available pods: 2
Mar 19 14:02:37.089: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-stpsk, will wait for the garbage collector to delete the pods
Mar 19 14:02:37.149: INFO: Deleting DaemonSet.extensions daemon-set took: 5.348402ms
Mar 19 14:02:37.249: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.414164ms
Mar 19 14:03:19.652: INFO: Number of nodes with available pods: 0
Mar 19 14:03:19.652: INFO: Number of running nodes: 0, number of available pods: 0
Mar 19 14:03:19.654: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-stpsk/daemonsets","resourceVersion":"8159"},"items":null}

Mar 19 14:03:19.657: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-stpsk/pods","resourceVersion":"8159"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:03:19.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-stpsk" for this suite.
Mar 19 14:03:25.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:03:25.749: INFO: namespace: e2e-tests-daemonsets-stpsk, resource: bindings, ignored listing per whitelist
Mar 19 14:03:25.752: INFO: namespace e2e-tests-daemonsets-stpsk deletion completed in 6.084777675s

â€¢ [SLOW TEST:85.778 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:03:25.753: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-c3b953a4-4a4f-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:03:25.818: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c3b9d3e5-4a4f-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-jcnwn" to be "success or failure"
Mar 19 14:03:25.821: INFO: Pod "pod-projected-secrets-c3b9d3e5-4a4f-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.409296ms
Mar 19 14:03:27.831: INFO: Pod "pod-projected-secrets-c3b9d3e5-4a4f-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012568098s
STEP: Saw pod success
Mar 19 14:03:27.831: INFO: Pod "pod-projected-secrets-c3b9d3e5-4a4f-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:03:27.835: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-projected-secrets-c3b9d3e5-4a4f-11e9-9c64-0a580af40204 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 19 14:03:27.870: INFO: Waiting for pod pod-projected-secrets-c3b9d3e5-4a4f-11e9-9c64-0a580af40204 to disappear
Mar 19 14:03:27.874: INFO: Pod pod-projected-secrets-c3b9d3e5-4a4f-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:03:27.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jcnwn" for this suite.
Mar 19 14:03:33.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:03:33.924: INFO: namespace: e2e-tests-projected-jcnwn, resource: bindings, ignored listing per whitelist
Mar 19 14:03:33.959: INFO: namespace e2e-tests-projected-jcnwn deletion completed in 6.079433086s

â€¢ [SLOW TEST:8.207 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:03:33.959: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0319 14:03:44.026455      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 14:03:44.026: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:03:44.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9cdh7" for this suite.
Mar 19 14:03:50.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:03:50.108: INFO: namespace: e2e-tests-gc-9cdh7, resource: bindings, ignored listing per whitelist
Mar 19 14:03:50.122: INFO: namespace e2e-tests-gc-9cdh7 deletion completed in 6.092879155s

â€¢ [SLOW TEST:16.162 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:03:50.122: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar 19 14:03:50.184: INFO: Waiting up to 5m0s for pod "var-expansion-d23f91e2-4a4f-11e9-9c64-0a580af40204" in namespace "e2e-tests-var-expansion-bxjwn" to be "success or failure"
Mar 19 14:03:50.190: INFO: Pod "var-expansion-d23f91e2-4a4f-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.976833ms
Mar 19 14:03:52.193: INFO: Pod "var-expansion-d23f91e2-4a4f-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008938293s
STEP: Saw pod success
Mar 19 14:03:52.193: INFO: Pod "var-expansion-d23f91e2-4a4f-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:03:52.195: INFO: Trying to get logs from node essentialpks-conformance-2 pod var-expansion-d23f91e2-4a4f-11e9-9c64-0a580af40204 container dapi-container: <nil>
STEP: delete the pod
Mar 19 14:03:52.212: INFO: Waiting for pod var-expansion-d23f91e2-4a4f-11e9-9c64-0a580af40204 to disappear
Mar 19 14:03:52.215: INFO: Pod var-expansion-d23f91e2-4a4f-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:03:52.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-bxjwn" for this suite.
Mar 19 14:03:58.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:03:58.286: INFO: namespace: e2e-tests-var-expansion-bxjwn, resource: bindings, ignored listing per whitelist
Mar 19 14:03:58.295: INFO: namespace e2e-tests-var-expansion-bxjwn deletion completed in 6.076724662s

â€¢ [SLOW TEST:8.173 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:03:58.295: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:04:19.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-b6bs5" for this suite.
Mar 19 14:04:41.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:04:41.404: INFO: namespace: e2e-tests-replication-controller-b6bs5, resource: bindings, ignored listing per whitelist
Mar 19 14:04:41.465: INFO: namespace e2e-tests-replication-controller-b6bs5 deletion completed in 22.084784614s

â€¢ [SLOW TEST:43.170 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:04:41.465: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar 19 14:04:41.511: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-015262165 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:04:41.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bknbv" for this suite.
Mar 19 14:04:47.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:04:47.648: INFO: namespace: e2e-tests-kubectl-bknbv, resource: bindings, ignored listing per whitelist
Mar 19 14:04:47.663: INFO: namespace e2e-tests-kubectl-bknbv deletion completed in 6.085572389s

â€¢ [SLOW TEST:6.198 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:04:47.666: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:04:47.724: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 19 14:04:47.733: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 19 14:04:52.736: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 19 14:04:52.736: INFO: Creating deployment "test-rolling-update-deployment"
Mar 19 14:04:52.741: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 19 14:04:52.747: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 19 14:04:54.752: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 19 14:04:54.755: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 19 14:04:54.762: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-ttgws,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ttgws/deployments/test-rolling-update-deployment,UID:f789a386-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:8506,Generation:1,CreationTimestamp:2019-03-19 14:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-19 14:04:52 +0000 UTC 2019-03-19 14:04:52 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-19 14:04:53 +0000 UTC 2019-03-19 14:04:52 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 19 14:04:54.765: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-ttgws,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ttgws/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:f78c6712-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:8497,Generation:1,CreationTimestamp:2019-03-19 14:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f789a386-4a4f-11e9-9b06-005056a45e5c 0xc0014436b7 0xc0014436b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 19 14:04:54.765: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 19 14:04:54.765: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-ttgws,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ttgws/replicasets/test-rolling-update-controller,UID:f48cc097-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:8505,Generation:2,CreationTimestamp:2019-03-19 14:04:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f789a386-4a4f-11e9-9b06-005056a45e5c 0xc001443587 0xc001443588}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 14:04:54.767: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-rfgjg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-rfgjg,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-ttgws,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ttgws/pods/test-rolling-update-deployment-68b55d7bc6-rfgjg,UID:f78ced4a-4a4f-11e9-9b06-005056a45e5c,ResourceVersion:8496,Generation:0,CreationTimestamp:2019-03-19 14:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 f78c6712-4a4f-11e9-9b06-005056a45e5c 0xc0013e6ce7 0xc0013e6ce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5wvhs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5wvhs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5wvhs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013e6d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013e6d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:04:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:04:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:04:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:04:52 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:10.244.1.76,StartTime:2019-03-19 14:04:52 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-19 14:04:53 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9f78bcfd7731ba7ce3f7c698c1a9de2a6824a02a6d330686da6fb0e7ee588a2b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:04:54.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ttgws" for this suite.
Mar 19 14:05:00.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:05:00.864: INFO: namespace: e2e-tests-deployment-ttgws, resource: bindings, ignored listing per whitelist
Mar 19 14:05:00.874: INFO: namespace e2e-tests-deployment-ttgws deletion completed in 6.102915909s

â€¢ [SLOW TEST:13.209 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:05:00.874: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-fl79c
Mar 19 14:05:14.951: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-fl79c
STEP: checking the pod's current state and verifying that restartCount is present
Mar 19 14:05:14.957: INFO: Initial restart count of pod liveness-http is 0
Mar 19 14:05:28.985: INFO: Restart count of pod e2e-tests-container-probe-fl79c/liveness-http is now 1 (14.02741072s elapsed)
Mar 19 14:05:49.021: INFO: Restart count of pod e2e-tests-container-probe-fl79c/liveness-http is now 2 (34.063249228s elapsed)
Mar 19 14:06:09.054: INFO: Restart count of pod e2e-tests-container-probe-fl79c/liveness-http is now 3 (54.096566317s elapsed)
Mar 19 14:06:29.091: INFO: Restart count of pod e2e-tests-container-probe-fl79c/liveness-http is now 4 (1m14.134163952s elapsed)
Mar 19 14:07:37.198: INFO: Restart count of pod e2e-tests-container-probe-fl79c/liveness-http is now 5 (2m22.24041808s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:07:37.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fl79c" for this suite.
Mar 19 14:07:43.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:07:43.272: INFO: namespace: e2e-tests-container-probe-fl79c, resource: bindings, ignored listing per whitelist
Mar 19 14:07:43.287: INFO: namespace e2e-tests-container-probe-fl79c deletion completed in 6.076206651s

â€¢ [SLOW TEST:162.413 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:07:43.288: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 14:07:43.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-f8rtv'
Mar 19 14:07:43.435: INFO: stderr: ""
Mar 19 14:07:43.435: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Mar 19 14:07:43.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-f8rtv'
Mar 19 14:07:49.385: INFO: stderr: ""
Mar 19 14:07:49.385: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:07:49.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f8rtv" for this suite.
Mar 19 14:07:55.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:07:55.436: INFO: namespace: e2e-tests-kubectl-f8rtv, resource: bindings, ignored listing per whitelist
Mar 19 14:07:55.458: INFO: namespace e2e-tests-kubectl-f8rtv deletion completed in 6.068789246s

â€¢ [SLOW TEST:12.170 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:07:55.458: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-647a08ff-4a50-11e9-9c64-0a580af40204
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-647a08ff-4a50-11e9-9c64-0a580af40204
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:09:21.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kl4zc" for this suite.
Mar 19 14:09:43.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:09:43.998: INFO: namespace: e2e-tests-configmap-kl4zc, resource: bindings, ignored listing per whitelist
Mar 19 14:09:44.029: INFO: namespace e2e-tests-configmap-kl4zc deletion completed in 22.069907299s

â€¢ [SLOW TEST:108.571 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:09:44.030: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-a5306da2-4a50-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:09:44.087: INFO: Waiting up to 5m0s for pod "pod-secrets-a5310902-4a50-11e9-9c64-0a580af40204" in namespace "e2e-tests-secrets-v9fpr" to be "success or failure"
Mar 19 14:09:44.092: INFO: Pod "pod-secrets-a5310902-4a50-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.575758ms
Mar 19 14:09:46.095: INFO: Pod "pod-secrets-a5310902-4a50-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008084647s
STEP: Saw pod success
Mar 19 14:09:46.095: INFO: Pod "pod-secrets-a5310902-4a50-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:09:46.098: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-secrets-a5310902-4a50-11e9-9c64-0a580af40204 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 14:09:46.115: INFO: Waiting for pod pod-secrets-a5310902-4a50-11e9-9c64-0a580af40204 to disappear
Mar 19 14:09:46.119: INFO: Pod pod-secrets-a5310902-4a50-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:09:46.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v9fpr" for this suite.
Mar 19 14:09:52.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:09:52.143: INFO: namespace: e2e-tests-secrets-v9fpr, resource: bindings, ignored listing per whitelist
Mar 19 14:09:52.200: INFO: namespace e2e-tests-secrets-v9fpr deletion completed in 6.077915332s

â€¢ [SLOW TEST:8.170 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:09:52.201: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:09:54.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-259w5" for this suite.
Mar 19 14:10:32.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:10:32.342: INFO: namespace: e2e-tests-kubelet-test-259w5, resource: bindings, ignored listing per whitelist
Mar 19 14:10:32.373: INFO: namespace e2e-tests-kubelet-test-259w5 deletion completed in 38.091115895s

â€¢ [SLOW TEST:40.172 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:10:32.374: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 19 14:10:36.462: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:36.464: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:38.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:38.469: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:40.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:40.467: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:42.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:42.468: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:44.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:44.469: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:46.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:46.469: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:48.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:48.469: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:50.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:50.469: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:52.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:52.467: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:54.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:54.468: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:56.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:56.468: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:10:58.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:10:58.467: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 19 14:11:00.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 19 14:11:00.468: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:11:00.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bzwqz" for this suite.
Mar 19 14:11:22.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:11:22.556: INFO: namespace: e2e-tests-container-lifecycle-hook-bzwqz, resource: bindings, ignored listing per whitelist
Mar 19 14:11:22.556: INFO: namespace e2e-tests-container-lifecycle-hook-bzwqz deletion completed in 22.075733353s

â€¢ [SLOW TEST:50.182 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:11:22.556: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:11:22.716: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"dfec7b7d-4a50-11e9-9b06-005056a45e5c", Controller:(*bool)(0xc000bdd73e), BlockOwnerDeletion:(*bool)(0xc000bdd73f)}}
Mar 19 14:11:22.721: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"dfeaeebe-4a50-11e9-9b06-005056a45e5c", Controller:(*bool)(0xc000d8f136), BlockOwnerDeletion:(*bool)(0xc000d8f137)}}
Mar 19 14:11:22.730: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"dfeb7a58-4a50-11e9-9b06-005056a45e5c", Controller:(*bool)(0xc000bddcaa), BlockOwnerDeletion:(*bool)(0xc000bddcab)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:11:27.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wsbsh" for this suite.
Mar 19 14:11:33.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:11:33.820: INFO: namespace: e2e-tests-gc-wsbsh, resource: bindings, ignored listing per whitelist
Mar 19 14:11:33.822: INFO: namespace e2e-tests-gc-wsbsh deletion completed in 6.075739268s

â€¢ [SLOW TEST:11.266 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:11:33.822: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:11:33.884: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 19 14:11:38.887: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 19 14:11:38.887: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 19 14:11:38.907: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-gvgfz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gvgfz/deployments/test-cleanup-deployment,UID:e99faf4b-4a50-11e9-9b06-005056a45e5c,ResourceVersion:9355,Generation:1,CreationTimestamp:2019-03-19 14:11:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar 19 14:11:38.914: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-gvgfz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gvgfz/replicasets/test-cleanup-deployment-7dbbfcf846,UID:e9a20ccc-4a50-11e9-9b06-005056a45e5c,ResourceVersion:9357,Generation:1,CreationTimestamp:2019-03-19 14:11:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment e99faf4b-4a50-11e9-9b06-005056a45e5c 0xc001d79277 0xc001d79278}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 14:11:38.914: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar 19 14:11:38.914: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-gvgfz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gvgfz/replicasets/test-cleanup-controller,UID:e6a2c9ba-4a50-11e9-9b06-005056a45e5c,ResourceVersion:9356,Generation:1,CreationTimestamp:2019-03-19 14:11:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment e99faf4b-4a50-11e9-9b06-005056a45e5c 0xc001d791af 0xc001d791c0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 19 14:11:38.923: INFO: Pod "test-cleanup-controller-n6h55" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-n6h55,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-gvgfz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gvgfz/pods/test-cleanup-controller-n6h55,UID:e6a49254-4a50-11e9-9b06-005056a45e5c,ResourceVersion:9349,Generation:0,CreationTimestamp:2019-03-19 14:11:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller e6a2c9ba-4a50-11e9-9b06-005056a45e5c 0xc001d79bef 0xc001d79c00}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sz586 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sz586,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sz586 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d79c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d79c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:11:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:11:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:11:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:11:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.3,PodIP:10.244.2.85,StartTime:2019-03-19 14:11:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-19 14:11:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://71d80ad665345a754a2e41d5c5e09efb94ccacb896275e1a23237ed9ba53ff8e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 19 14:11:38.923: INFO: Pod "test-cleanup-deployment-7dbbfcf846-h8tdp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-h8tdp,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-gvgfz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gvgfz/pods/test-cleanup-deployment-7dbbfcf846-h8tdp,UID:e9a29eae-4a50-11e9-9b06-005056a45e5c,ResourceVersion:9358,Generation:0,CreationTimestamp:2019-03-19 14:11:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 e9a20ccc-4a50-11e9-9b06-005056a45e5c 0xc001d79d47 0xc001d79d48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sz586 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sz586,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-sz586 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d79db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d79dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:11:38.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gvgfz" for this suite.
Mar 19 14:11:44.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:11:44.972: INFO: namespace: e2e-tests-deployment-gvgfz, resource: bindings, ignored listing per whitelist
Mar 19 14:11:45.036: INFO: namespace e2e-tests-deployment-gvgfz deletion completed in 6.0990681s

â€¢ [SLOW TEST:11.214 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:11:45.037: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:11:45.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ed5225e9-4a50-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-5gwgz" to be "success or failure"
Mar 19 14:11:45.107: INFO: Pod "downwardapi-volume-ed5225e9-4a50-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 7.578081ms
Mar 19 14:11:47.110: INFO: Pod "downwardapi-volume-ed5225e9-4a50-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010843643s
STEP: Saw pod success
Mar 19 14:11:47.111: INFO: Pod "downwardapi-volume-ed5225e9-4a50-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:11:47.113: INFO: Trying to get logs from node essentialpks-conformance-2 pod downwardapi-volume-ed5225e9-4a50-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:11:47.135: INFO: Waiting for pod downwardapi-volume-ed5225e9-4a50-11e9-9c64-0a580af40204 to disappear
Mar 19 14:11:47.139: INFO: Pod downwardapi-volume-ed5225e9-4a50-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:11:47.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5gwgz" for this suite.
Mar 19 14:11:53.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:11:53.195: INFO: namespace: e2e-tests-downward-api-5gwgz, resource: bindings, ignored listing per whitelist
Mar 19 14:11:53.219: INFO: namespace e2e-tests-downward-api-5gwgz deletion completed in 6.076663284s

â€¢ [SLOW TEST:8.182 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:11:53.219: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-hjnkp in namespace e2e-tests-proxy-mcqvd
I0319 14:11:53.286584      15 runners.go:184] Created replication controller with name: proxy-service-hjnkp, namespace: e2e-tests-proxy-mcqvd, replica count: 1
I0319 14:11:54.337059      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:11:55.337290      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:11:56.337622      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:11:57.337953      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:11:58.338257      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:11:59.338479      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:12:00.338657      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:12:01.338925      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:12:02.339106      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:12:03.339286      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:12:04.339569      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:12:05.339889      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:12:06.340105      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:12:07.340317      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0319 14:12:08.340519      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0319 14:12:09.340745      15 runners.go:184] proxy-service-hjnkp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 19 14:12:09.343: INFO: setup took 16.077081244s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 19 14:12:09.352: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 9.366301ms)
Mar 19 14:12:09.353: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 8.313001ms)
Mar 19 14:12:09.356: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 12.319163ms)
Mar 19 14:12:09.356: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 13.08004ms)
Mar 19 14:12:09.356: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 12.60165ms)
Mar 19 14:12:09.357: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 12.811932ms)
Mar 19 14:12:09.357: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 13.535967ms)
Mar 19 14:12:09.362: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 17.752366ms)
Mar 19 14:12:09.362: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 18.950716ms)
Mar 19 14:12:09.362: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 18.629481ms)
Mar 19 14:12:09.366: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 21.455141ms)
Mar 19 14:12:09.368: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 25.076248ms)
Mar 19 14:12:09.371: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 27.727523ms)
Mar 19 14:12:09.371: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 28.102941ms)
Mar 19 14:12:09.372: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 27.759873ms)
Mar 19 14:12:09.372: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 28.208475ms)
Mar 19 14:12:09.380: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 6.666026ms)
Mar 19 14:12:09.380: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 6.80614ms)
Mar 19 14:12:09.380: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 7.599378ms)
Mar 19 14:12:09.380: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 7.51023ms)
Mar 19 14:12:09.381: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 8.318331ms)
Mar 19 14:12:09.381: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 7.672041ms)
Mar 19 14:12:09.381: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 7.845358ms)
Mar 19 14:12:09.384: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 10.514904ms)
Mar 19 14:12:09.387: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 14.344733ms)
Mar 19 14:12:09.388: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 14.935449ms)
Mar 19 14:12:09.388: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 15.779589ms)
Mar 19 14:12:09.388: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 15.700141ms)
Mar 19 14:12:09.389: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 15.930554ms)
Mar 19 14:12:09.389: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 16.697027ms)
Mar 19 14:12:09.389: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 16.037136ms)
Mar 19 14:12:09.389: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 16.957631ms)
Mar 19 14:12:09.395: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 6.045467ms)
Mar 19 14:12:09.400: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 10.487056ms)
Mar 19 14:12:09.402: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 10.966893ms)
Mar 19 14:12:09.402: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 11.224399ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 11.847332ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 12.824298ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 13.004065ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 12.234879ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 12.343691ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 12.443728ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 13.088835ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 13.41896ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 13.316379ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 13.325376ms)
Mar 19 14:12:09.403: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 13.521822ms)
Mar 19 14:12:09.404: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 13.069706ms)
Mar 19 14:12:09.414: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 10.166785ms)
Mar 19 14:12:09.417: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 13.250228ms)
Mar 19 14:12:09.417: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 11.942769ms)
Mar 19 14:12:09.417: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 12.197424ms)
Mar 19 14:12:09.417: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 11.963578ms)
Mar 19 14:12:09.417: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 12.809571ms)
Mar 19 14:12:09.417: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 12.518316ms)
Mar 19 14:12:09.417: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 12.93802ms)
Mar 19 14:12:09.417: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 13.353757ms)
Mar 19 14:12:09.419: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 13.92749ms)
Mar 19 14:12:09.419: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 15.255846ms)
Mar 19 14:12:09.419: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 14.815682ms)
Mar 19 14:12:09.419: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 15.031369ms)
Mar 19 14:12:09.419: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 15.553985ms)
Mar 19 14:12:09.420: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 14.847817ms)
Mar 19 14:12:09.421: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 16.477657ms)
Mar 19 14:12:09.426: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 4.404547ms)
Mar 19 14:12:09.431: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 8.895267ms)
Mar 19 14:12:09.431: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 9.068551ms)
Mar 19 14:12:09.432: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 10.678408ms)
Mar 19 14:12:09.434: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 12.24311ms)
Mar 19 14:12:09.434: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 12.216226ms)
Mar 19 14:12:09.434: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 12.774669ms)
Mar 19 14:12:09.434: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 12.90874ms)
Mar 19 14:12:09.435: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 13.296596ms)
Mar 19 14:12:09.435: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 13.456816ms)
Mar 19 14:12:09.435: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 13.530365ms)
Mar 19 14:12:09.435: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 13.774474ms)
Mar 19 14:12:09.436: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 13.835347ms)
Mar 19 14:12:09.436: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 14.513245ms)
Mar 19 14:12:09.436: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 15.028139ms)
Mar 19 14:12:09.441: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 19.045235ms)
Mar 19 14:12:09.450: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 8.936856ms)
Mar 19 14:12:09.450: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 8.396557ms)
Mar 19 14:12:09.451: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 9.320169ms)
Mar 19 14:12:09.451: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 10.633669ms)
Mar 19 14:12:09.452: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 10.500618ms)
Mar 19 14:12:09.453: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 11.789073ms)
Mar 19 14:12:09.454: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 12.12011ms)
Mar 19 14:12:09.453: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 12.800617ms)
Mar 19 14:12:09.455: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 12.91619ms)
Mar 19 14:12:09.457: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 15.501304ms)
Mar 19 14:12:09.457: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 16.005778ms)
Mar 19 14:12:09.457: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 16.019147ms)
Mar 19 14:12:09.457: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 16.090521ms)
Mar 19 14:12:09.457: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 15.769561ms)
Mar 19 14:12:09.457: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 15.742683ms)
Mar 19 14:12:09.457: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 15.738319ms)
Mar 19 14:12:09.465: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 7.643811ms)
Mar 19 14:12:09.466: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 8.319507ms)
Mar 19 14:12:09.466: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 8.431003ms)
Mar 19 14:12:09.466: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 8.524982ms)
Mar 19 14:12:09.467: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 8.656524ms)
Mar 19 14:12:09.467: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 9.403977ms)
Mar 19 14:12:09.467: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 9.787055ms)
Mar 19 14:12:09.467: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 9.927198ms)
Mar 19 14:12:09.467: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 10.007909ms)
Mar 19 14:12:09.467: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 9.387512ms)
Mar 19 14:12:09.469: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 10.757654ms)
Mar 19 14:12:09.469: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 10.905973ms)
Mar 19 14:12:09.469: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 10.832716ms)
Mar 19 14:12:09.469: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 11.395579ms)
Mar 19 14:12:09.469: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 10.978656ms)
Mar 19 14:12:09.469: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 11.238915ms)
Mar 19 14:12:09.479: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 9.932ms)
Mar 19 14:12:09.480: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 10.382737ms)
Mar 19 14:12:09.480: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 10.330485ms)
Mar 19 14:12:09.481: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 11.604552ms)
Mar 19 14:12:09.481: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 12.033037ms)
Mar 19 14:12:09.482: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 12.245897ms)
Mar 19 14:12:09.483: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 12.979249ms)
Mar 19 14:12:09.483: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 13.033115ms)
Mar 19 14:12:09.483: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 13.670714ms)
Mar 19 14:12:09.483: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 13.634386ms)
Mar 19 14:12:09.484: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 14.204366ms)
Mar 19 14:12:09.488: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 18.496415ms)
Mar 19 14:12:09.490: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 20.445778ms)
Mar 19 14:12:09.490: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 20.63412ms)
Mar 19 14:12:09.490: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 20.298201ms)
Mar 19 14:12:09.490: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 20.312816ms)
Mar 19 14:12:09.497: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 6.970336ms)
Mar 19 14:12:09.497: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 6.854554ms)
Mar 19 14:12:09.497: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 7.094088ms)
Mar 19 14:12:09.497: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 7.335395ms)
Mar 19 14:12:09.502: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 11.366364ms)
Mar 19 14:12:09.503: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 12.785861ms)
Mar 19 14:12:09.503: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 11.785263ms)
Mar 19 14:12:09.503: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 12.269812ms)
Mar 19 14:12:09.503: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 12.440709ms)
Mar 19 14:12:09.503: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 12.347277ms)
Mar 19 14:12:09.503: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 12.940239ms)
Mar 19 14:12:09.504: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 12.798892ms)
Mar 19 14:12:09.505: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 14.183716ms)
Mar 19 14:12:09.505: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 13.837543ms)
Mar 19 14:12:09.505: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 14.847658ms)
Mar 19 14:12:09.506: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 15.708605ms)
Mar 19 14:12:09.512: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 5.768932ms)
Mar 19 14:12:09.512: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 5.91767ms)
Mar 19 14:12:09.512: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 6.11907ms)
Mar 19 14:12:09.514: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 8.217866ms)
Mar 19 14:12:09.514: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 7.451311ms)
Mar 19 14:12:09.515: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 8.489415ms)
Mar 19 14:12:09.515: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 9.407005ms)
Mar 19 14:12:09.515: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 9.277567ms)
Mar 19 14:12:09.518: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 11.386503ms)
Mar 19 14:12:09.519: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 12.196784ms)
Mar 19 14:12:09.519: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 12.107173ms)
Mar 19 14:12:09.520: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 13.609276ms)
Mar 19 14:12:09.520: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 13.005605ms)
Mar 19 14:12:09.520: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 13.343869ms)
Mar 19 14:12:09.520: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 14.232261ms)
Mar 19 14:12:09.521: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 13.732941ms)
Mar 19 14:12:09.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 7.87637ms)
Mar 19 14:12:09.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 7.912196ms)
Mar 19 14:12:09.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 8.093181ms)
Mar 19 14:12:09.530: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 9.402888ms)
Mar 19 14:12:09.531: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 9.5909ms)
Mar 19 14:12:09.531: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 9.331638ms)
Mar 19 14:12:09.531: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 9.994011ms)
Mar 19 14:12:09.531: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 9.363197ms)
Mar 19 14:12:09.533: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 11.817834ms)
Mar 19 14:12:09.534: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 12.42667ms)
Mar 19 14:12:09.534: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 12.994294ms)
Mar 19 14:12:09.534: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 13.38103ms)
Mar 19 14:12:09.535: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 13.225485ms)
Mar 19 14:12:09.535: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 14.332568ms)
Mar 19 14:12:09.536: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 14.604429ms)
Mar 19 14:12:09.537: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 16.111552ms)
Mar 19 14:12:09.546: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 7.046527ms)
Mar 19 14:12:09.546: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 8.54959ms)
Mar 19 14:12:09.548: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 10.429647ms)
Mar 19 14:12:09.548: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 10.018035ms)
Mar 19 14:12:09.548: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 9.93447ms)
Mar 19 14:12:09.548: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 10.286571ms)
Mar 19 14:12:09.548: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 10.676427ms)
Mar 19 14:12:09.548: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 10.15252ms)
Mar 19 14:12:09.548: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 10.930224ms)
Mar 19 14:12:09.551: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 12.793649ms)
Mar 19 14:12:09.552: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 14.350138ms)
Mar 19 14:12:09.553: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 15.241554ms)
Mar 19 14:12:09.553: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 15.589881ms)
Mar 19 14:12:09.554: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 15.803717ms)
Mar 19 14:12:09.556: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 17.536078ms)
Mar 19 14:12:09.559: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 21.36256ms)
Mar 19 14:12:09.571: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 11.626843ms)
Mar 19 14:12:09.571: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 11.888795ms)
Mar 19 14:12:09.571: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 11.84437ms)
Mar 19 14:12:09.571: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 11.783829ms)
Mar 19 14:12:09.571: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 12.443464ms)
Mar 19 14:12:09.571: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 12.007442ms)
Mar 19 14:12:09.571: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 11.851066ms)
Mar 19 14:12:09.571: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 12.054983ms)
Mar 19 14:12:09.572: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 12.790785ms)
Mar 19 14:12:09.572: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 12.424519ms)
Mar 19 14:12:09.572: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 13.230629ms)
Mar 19 14:12:09.572: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 12.919943ms)
Mar 19 14:12:09.573: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 13.490158ms)
Mar 19 14:12:09.573: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 13.713981ms)
Mar 19 14:12:09.582: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 22.048171ms)
Mar 19 14:12:09.582: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 21.700116ms)
Mar 19 14:12:09.586: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 4.640944ms)
Mar 19 14:12:09.589: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 6.675667ms)
Mar 19 14:12:09.589: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 6.783561ms)
Mar 19 14:12:09.589: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 7.080154ms)
Mar 19 14:12:09.589: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 7.433137ms)
Mar 19 14:12:09.591: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 8.757455ms)
Mar 19 14:12:09.591: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 9.184378ms)
Mar 19 14:12:09.591: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 9.27442ms)
Mar 19 14:12:09.592: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 9.792384ms)
Mar 19 14:12:09.592: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 10.008921ms)
Mar 19 14:12:09.593: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 10.482459ms)
Mar 19 14:12:09.593: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 10.648633ms)
Mar 19 14:12:09.600: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 17.316147ms)
Mar 19 14:12:09.600: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 17.393935ms)
Mar 19 14:12:09.601: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 19.257803ms)
Mar 19 14:12:09.601: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 19.318478ms)
Mar 19 14:12:09.607: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 5.785234ms)
Mar 19 14:12:09.608: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 6.545942ms)
Mar 19 14:12:09.609: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 6.845839ms)
Mar 19 14:12:09.609: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 7.186953ms)
Mar 19 14:12:09.609: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 7.614301ms)
Mar 19 14:12:09.610: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 7.365977ms)
Mar 19 14:12:09.611: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 8.443539ms)
Mar 19 14:12:09.612: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 9.388599ms)
Mar 19 14:12:09.612: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 9.512664ms)
Mar 19 14:12:09.612: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 10.022321ms)
Mar 19 14:12:09.612: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 10.262032ms)
Mar 19 14:12:09.613: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 10.994749ms)
Mar 19 14:12:09.614: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 11.678849ms)
Mar 19 14:12:09.614: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 11.205887ms)
Mar 19 14:12:09.614: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 11.904904ms)
Mar 19 14:12:09.614: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 11.432257ms)
Mar 19 14:12:09.627: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 12.032326ms)
Mar 19 14:12:09.628: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 12.619881ms)
Mar 19 14:12:09.628: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 13.474581ms)
Mar 19 14:12:09.629: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 14.791347ms)
Mar 19 14:12:09.631: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 16.477342ms)
Mar 19 14:12:09.631: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 16.507987ms)
Mar 19 14:12:09.632: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 16.928507ms)
Mar 19 14:12:09.632: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 17.417737ms)
Mar 19 14:12:09.632: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 16.825145ms)
Mar 19 14:12:09.632: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 17.227697ms)
Mar 19 14:12:09.632: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 18.174333ms)
Mar 19 14:12:09.632: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 17.942264ms)
Mar 19 14:12:09.632: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 17.566755ms)
Mar 19 14:12:09.633: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 19.406171ms)
Mar 19 14:12:09.633: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 19.340695ms)
Mar 19 14:12:09.634: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 19.682818ms)
Mar 19 14:12:09.643: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 7.802374ms)
Mar 19 14:12:09.643: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 9.066456ms)
Mar 19 14:12:09.649: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 13.821109ms)
Mar 19 14:12:09.650: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 15.105725ms)
Mar 19 14:12:09.650: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 15.650815ms)
Mar 19 14:12:09.650: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 15.388165ms)
Mar 19 14:12:09.652: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 17.368653ms)
Mar 19 14:12:09.652: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 17.568161ms)
Mar 19 14:12:09.652: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 17.229811ms)
Mar 19 14:12:09.652: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 18.143269ms)
Mar 19 14:12:09.652: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 17.865943ms)
Mar 19 14:12:09.652: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 17.957795ms)
Mar 19 14:12:09.652: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 17.455407ms)
Mar 19 14:12:09.652: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 17.409946ms)
Mar 19 14:12:09.653: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 19.078192ms)
Mar 19 14:12:09.654: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 19.716562ms)
Mar 19 14:12:09.660: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 5.18571ms)
Mar 19 14:12:09.664: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 8.825409ms)
Mar 19 14:12:09.664: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 8.236716ms)
Mar 19 14:12:09.664: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 8.214216ms)
Mar 19 14:12:09.664: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 9.083738ms)
Mar 19 14:12:09.664: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 9.244702ms)
Mar 19 14:12:09.664: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 8.772672ms)
Mar 19 14:12:09.665: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 9.691221ms)
Mar 19 14:12:09.665: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 9.426811ms)
Mar 19 14:12:09.665: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 9.091717ms)
Mar 19 14:12:09.665: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 10.309865ms)
Mar 19 14:12:09.666: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 11.801303ms)
Mar 19 14:12:09.666: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 11.015269ms)
Mar 19 14:12:09.666: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 11.86721ms)
Mar 19 14:12:09.668: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 12.750602ms)
Mar 19 14:12:09.668: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 13.476955ms)
Mar 19 14:12:09.676: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 6.061562ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 8.871882ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 9.463171ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 8.798618ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 8.597449ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 9.030348ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 9.390639ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 8.814972ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 8.745404ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 9.304359ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 9.761699ms)
Mar 19 14:12:09.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 9.678691ms)
Mar 19 14:12:09.682: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 13.895804ms)
Mar 19 14:12:09.683: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 13.691016ms)
Mar 19 14:12:09.683: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 13.904965ms)
Mar 19 14:12:09.683: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 14.370307ms)
Mar 19 14:12:09.693: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 8.663816ms)
Mar 19 14:12:09.693: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:443/proxy/... (200; 9.840103ms)
Mar 19 14:12:09.693: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:162/proxy/: bar (200; 8.84911ms)
Mar 19 14:12:09.694: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:1080/proxy/rewri... (200; 10.427308ms)
Mar 19 14:12:09.695: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk/proxy/rewriteme"... (200; 11.170994ms)
Mar 19 14:12:09.695: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname2/proxy/: bar (200; 11.685894ms)
Mar 19 14:12:09.697: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:1080/proxy/... (200; 12.871665ms)
Mar 19 14:12:09.697: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname2/proxy/: tls qux (200; 13.13467ms)
Mar 19 14:12:09.697: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/http:proxy-service-hjnkp:portname1/proxy/: foo (200; 13.266826ms)
Mar 19 14:12:09.697: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname1/proxy/: foo (200; 13.560822ms)
Mar 19 14:12:09.697: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/http:proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 13.69963ms)
Mar 19 14:12:09.697: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:460/proxy/: tls baz (200; 13.251719ms)
Mar 19 14:12:09.698: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/proxy-service-hjnkp-x4rsk:160/proxy/: foo (200; 13.339739ms)
Mar 19 14:12:09.698: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/https:proxy-service-hjnkp:tlsportname1/proxy/: tls baz (200; 13.701879ms)
Mar 19 14:12:09.699: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/services/proxy-service-hjnkp:portname2/proxy/: bar (200; 15.122059ms)
Mar 19 14:12:09.699: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mcqvd/pods/https:proxy-service-hjnkp-x4rsk:462/proxy/: tls qux (200; 15.221139ms)
STEP: deleting ReplicationController proxy-service-hjnkp in namespace e2e-tests-proxy-mcqvd, will wait for the garbage collector to delete the pods
Mar 19 14:12:09.760: INFO: Deleting ReplicationController proxy-service-hjnkp took: 7.334944ms
Mar 19 14:12:09.860: INFO: Terminating ReplicationController proxy-service-hjnkp pods took: 100.289257ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:12:12.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-mcqvd" for this suite.
Mar 19 14:12:18.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:12:18.082: INFO: namespace: e2e-tests-proxy-mcqvd, resource: bindings, ignored listing per whitelist
Mar 19 14:12:18.133: INFO: namespace e2e-tests-proxy-mcqvd deletion completed in 6.069472218s

â€¢ [SLOW TEST:24.914 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:12:18.133: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:12:18.201: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 19 14:12:23.204: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 19 14:12:23.204: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 19 14:12:25.207: INFO: Creating deployment "test-rollover-deployment"
Mar 19 14:12:25.217: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 19 14:12:27.223: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 19 14:12:27.228: INFO: Ensure that both replica sets have 1 created replica
Mar 19 14:12:27.233: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 19 14:12:27.238: INFO: Updating deployment test-rollover-deployment
Mar 19 14:12:27.238: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 19 14:12:29.247: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 19 14:12:29.257: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 19 14:12:29.262: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 14:12:29.262: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601548, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 14:12:31.267: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 14:12:31.267: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601548, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 14:12:33.270: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 14:12:33.270: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601548, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 14:12:35.269: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 14:12:35.269: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601548, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 14:12:37.267: INFO: all replica sets need to contain the pod-template-hash label
Mar 19 14:12:37.267: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601548, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688601545, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 19 14:12:39.268: INFO: 
Mar 19 14:12:39.268: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 19 14:12:39.275: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-g786g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g786g/deployments/test-rollover-deployment,UID:053b0d32-4a51-11e9-9b06-005056a45e5c,ResourceVersion:9625,Generation:2,CreationTimestamp:2019-03-19 14:12:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-19 14:12:25 +0000 UTC 2019-03-19 14:12:25 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-19 14:12:38 +0000 UTC 2019-03-19 14:12:25 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 19 14:12:39.279: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-g786g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g786g/replicasets/test-rollover-deployment-6b7f9d6597,UID:067121bb-4a51-11e9-9b06-005056a45e5c,ResourceVersion:9616,Generation:2,CreationTimestamp:2019-03-19 14:12:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 053b0d32-4a51-11e9-9b06-005056a45e5c 0xc000d36737 0xc000d36738}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 19 14:12:39.279: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 19 14:12:39.280: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-g786g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g786g/replicasets/test-rollover-controller,UID:010bd9c2-4a51-11e9-9b06-005056a45e5c,ResourceVersion:9624,Generation:2,CreationTimestamp:2019-03-19 14:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 053b0d32-4a51-11e9-9b06-005056a45e5c 0xc000d365af 0xc000d365c0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 14:12:39.280: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-g786g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g786g/replicasets/test-rollover-deployment-6586df867b,UID:053d428f-4a51-11e9-9b06-005056a45e5c,ResourceVersion:9592,Generation:2,CreationTimestamp:2019-03-19 14:12:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 053b0d32-4a51-11e9-9b06-005056a45e5c 0xc000d36677 0xc000d36678}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 19 14:12:39.283: INFO: Pod "test-rollover-deployment-6b7f9d6597-56cmg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-56cmg,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-g786g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g786g/pods/test-rollover-deployment-6b7f9d6597-56cmg,UID:067597ee-4a51-11e9-9b06-005056a45e5c,ResourceVersion:9599,Generation:0,CreationTimestamp:2019-03-19 14:12:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 067121bb-4a51-11e9-9b06-005056a45e5c 0xc000d37487 0xc000d37488}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vfxpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vfxpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vfxpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:essentialpks-conformance-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d374f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d37510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:12:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:12:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:12:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:12:27 +0000 UTC  }],Message:,Reason:,HostIP:192.168.102.4,PodIP:10.244.1.82,StartTime:2019-03-19 14:12:27 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-19 14:12:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://94de5a12ee1e373957a5903e70006823b79ff003f9326d24279c79c6367d1759}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:12:39.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-g786g" for this suite.
Mar 19 14:12:45.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:12:45.396: INFO: namespace: e2e-tests-deployment-g786g, resource: bindings, ignored listing per whitelist
Mar 19 14:12:45.447: INFO: namespace e2e-tests-deployment-g786g deletion completed in 6.16053087s

â€¢ [SLOW TEST:27.314 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:12:45.448: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1153bf5d-4a51-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:12:45.534: INFO: Waiting up to 5m0s for pod "pod-secrets-1157c41b-4a51-11e9-9c64-0a580af40204" in namespace "e2e-tests-secrets-9mb8g" to be "success or failure"
Mar 19 14:12:45.541: INFO: Pod "pod-secrets-1157c41b-4a51-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 7.311359ms
Mar 19 14:12:47.544: INFO: Pod "pod-secrets-1157c41b-4a51-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010405421s
STEP: Saw pod success
Mar 19 14:12:47.544: INFO: Pod "pod-secrets-1157c41b-4a51-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:12:47.547: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-secrets-1157c41b-4a51-11e9-9c64-0a580af40204 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 14:12:47.560: INFO: Waiting for pod pod-secrets-1157c41b-4a51-11e9-9c64-0a580af40204 to disappear
Mar 19 14:12:47.562: INFO: Pod pod-secrets-1157c41b-4a51-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:12:47.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9mb8g" for this suite.
Mar 19 14:12:53.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:12:53.608: INFO: namespace: e2e-tests-secrets-9mb8g, resource: bindings, ignored listing per whitelist
Mar 19 14:12:53.638: INFO: namespace e2e-tests-secrets-9mb8g deletion completed in 6.072567194s
STEP: Destroying namespace "e2e-tests-secret-namespace-86nm7" for this suite.
Mar 19 14:12:59.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:12:59.689: INFO: namespace: e2e-tests-secret-namespace-86nm7, resource: bindings, ignored listing per whitelist
Mar 19 14:12:59.708: INFO: namespace e2e-tests-secret-namespace-86nm7 deletion completed in 6.070703647s

â€¢ [SLOW TEST:14.261 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:12:59.709: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Mar 19 14:12:59.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-wq8zm'
Mar 19 14:13:00.075: INFO: stderr: ""
Mar 19 14:13:00.075: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar 19 14:13:01.078: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:13:01.078: INFO: Found 0 / 1
Mar 19 14:13:02.078: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:13:02.078: INFO: Found 0 / 1
Mar 19 14:13:03.078: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:13:03.078: INFO: Found 1 / 1
Mar 19 14:13:03.078: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 19 14:13:03.080: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:13:03.080: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar 19 14:13:03.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 logs redis-master-ctt9r redis-master --namespace=e2e-tests-kubectl-wq8zm'
Mar 19 14:13:03.176: INFO: stderr: ""
Mar 19 14:13:03.176: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Mar 14:13:02.729 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Mar 14:13:02.729 # Server started, Redis version 3.2.12\n1:M 19 Mar 14:13:02.729 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Mar 14:13:02.729 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar 19 14:13:03.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 log redis-master-ctt9r redis-master --namespace=e2e-tests-kubectl-wq8zm --tail=1'
Mar 19 14:13:03.266: INFO: stderr: ""
Mar 19 14:13:03.266: INFO: stdout: "1:M 19 Mar 14:13:02.729 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar 19 14:13:03.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 log redis-master-ctt9r redis-master --namespace=e2e-tests-kubectl-wq8zm --limit-bytes=1'
Mar 19 14:13:03.354: INFO: stderr: ""
Mar 19 14:13:03.354: INFO: stdout: " "
STEP: exposing timestamps
Mar 19 14:13:03.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 log redis-master-ctt9r redis-master --namespace=e2e-tests-kubectl-wq8zm --tail=1 --timestamps'
Mar 19 14:13:03.437: INFO: stderr: ""
Mar 19 14:13:03.437: INFO: stdout: "2019-03-19T14:13:02.729657729Z 1:M 19 Mar 14:13:02.729 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar 19 14:13:05.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 log redis-master-ctt9r redis-master --namespace=e2e-tests-kubectl-wq8zm --since=1s'
Mar 19 14:13:06.033: INFO: stderr: ""
Mar 19 14:13:06.034: INFO: stdout: ""
Mar 19 14:13:06.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 log redis-master-ctt9r redis-master --namespace=e2e-tests-kubectl-wq8zm --since=24h'
Mar 19 14:13:06.121: INFO: stderr: ""
Mar 19 14:13:06.121: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Mar 14:13:02.729 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Mar 14:13:02.729 # Server started, Redis version 3.2.12\n1:M 19 Mar 14:13:02.729 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Mar 14:13:02.729 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Mar 19 14:13:06.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wq8zm'
Mar 19 14:13:06.204: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 14:13:06.204: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar 19 14:13:06.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-wq8zm'
Mar 19 14:13:06.302: INFO: stderr: "No resources found.\n"
Mar 19 14:13:06.302: INFO: stdout: ""
Mar 19 14:13:06.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -l name=nginx --namespace=e2e-tests-kubectl-wq8zm -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 19 14:13:06.384: INFO: stderr: ""
Mar 19 14:13:06.384: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:13:06.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wq8zm" for this suite.
Mar 19 14:13:12.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:13:12.432: INFO: namespace: e2e-tests-kubectl-wq8zm, resource: bindings, ignored listing per whitelist
Mar 19 14:13:12.466: INFO: namespace e2e-tests-kubectl-wq8zm deletion completed in 6.078465089s

â€¢ [SLOW TEST:12.758 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:13:12.467: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0319 14:13:52.545584      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 14:13:52.545: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:13:52.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-sxnzq" for this suite.
Mar 19 14:13:58.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:13:58.619: INFO: namespace: e2e-tests-gc-sxnzq, resource: bindings, ignored listing per whitelist
Mar 19 14:13:58.628: INFO: namespace e2e-tests-gc-sxnzq deletion completed in 6.074842238s

â€¢ [SLOW TEST:46.161 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:13:58.628: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0319 14:13:59.735594      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 14:13:59.735: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:13:59.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hshzt" for this suite.
Mar 19 14:14:05.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:14:05.783: INFO: namespace: e2e-tests-gc-hshzt, resource: bindings, ignored listing per whitelist
Mar 19 14:14:05.814: INFO: namespace e2e-tests-gc-hshzt deletion completed in 6.073766555s

â€¢ [SLOW TEST:7.186 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:14:05.816: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 19 14:14:05.870: INFO: Waiting up to 5m0s for pod "pod-413a17ff-4a51-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-hj4df" to be "success or failure"
Mar 19 14:14:05.873: INFO: Pod "pod-413a17ff-4a51-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.742803ms
Mar 19 14:14:07.876: INFO: Pod "pod-413a17ff-4a51-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005322153s
STEP: Saw pod success
Mar 19 14:14:07.876: INFO: Pod "pod-413a17ff-4a51-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:14:07.878: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-413a17ff-4a51-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:14:07.895: INFO: Waiting for pod pod-413a17ff-4a51-11e9-9c64-0a580af40204 to disappear
Mar 19 14:14:07.898: INFO: Pod pod-413a17ff-4a51-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:14:07.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hj4df" for this suite.
Mar 19 14:14:13.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:14:13.948: INFO: namespace: e2e-tests-emptydir-hj4df, resource: bindings, ignored listing per whitelist
Mar 19 14:14:13.981: INFO: namespace e2e-tests-emptydir-hj4df deletion completed in 6.079854004s

â€¢ [SLOW TEST:8.165 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:14:13.982: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-7gjnm/secret-test-461a368e-4a51-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:14:14.054: INFO: Waiting up to 5m0s for pod "pod-configmaps-461ae451-4a51-11e9-9c64-0a580af40204" in namespace "e2e-tests-secrets-7gjnm" to be "success or failure"
Mar 19 14:14:14.058: INFO: Pod "pod-configmaps-461ae451-4a51-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.365208ms
Mar 19 14:14:16.061: INFO: Pod "pod-configmaps-461ae451-4a51-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006947091s
STEP: Saw pod success
Mar 19 14:14:16.061: INFO: Pod "pod-configmaps-461ae451-4a51-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:14:16.063: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-configmaps-461ae451-4a51-11e9-9c64-0a580af40204 container env-test: <nil>
STEP: delete the pod
Mar 19 14:14:16.094: INFO: Waiting for pod pod-configmaps-461ae451-4a51-11e9-9c64-0a580af40204 to disappear
Mar 19 14:14:16.096: INFO: Pod pod-configmaps-461ae451-4a51-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:14:16.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7gjnm" for this suite.
Mar 19 14:14:22.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:14:22.143: INFO: namespace: e2e-tests-secrets-7gjnm, resource: bindings, ignored listing per whitelist
Mar 19 14:14:22.182: INFO: namespace e2e-tests-secrets-7gjnm deletion completed in 6.082703482s

â€¢ [SLOW TEST:8.201 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:14:22.186: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4afe8e7c-4a51-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:14:22.265: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4affc6b7-4a51-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-mzdpc" to be "success or failure"
Mar 19 14:14:22.270: INFO: Pod "pod-projected-configmaps-4affc6b7-4a51-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.083301ms
Mar 19 14:14:24.272: INFO: Pod "pod-projected-configmaps-4affc6b7-4a51-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00692898s
STEP: Saw pod success
Mar 19 14:14:24.272: INFO: Pod "pod-projected-configmaps-4affc6b7-4a51-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:14:24.275: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-projected-configmaps-4affc6b7-4a51-11e9-9c64-0a580af40204 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 14:14:24.289: INFO: Waiting for pod pod-projected-configmaps-4affc6b7-4a51-11e9-9c64-0a580af40204 to disappear
Mar 19 14:14:24.292: INFO: Pod pod-projected-configmaps-4affc6b7-4a51-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:14:24.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mzdpc" for this suite.
Mar 19 14:14:30.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:14:30.350: INFO: namespace: e2e-tests-projected-mzdpc, resource: bindings, ignored listing per whitelist
Mar 19 14:14:30.362: INFO: namespace e2e-tests-projected-mzdpc deletion completed in 6.06683567s

â€¢ [SLOW TEST:8.176 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:14:30.362: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-2t9fc
Mar 19 14:14:32.422: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-2t9fc
STEP: checking the pod's current state and verifying that restartCount is present
Mar 19 14:14:32.424: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:18:32.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2t9fc" for this suite.
Mar 19 14:18:38.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:18:38.917: INFO: namespace: e2e-tests-container-probe-2t9fc, resource: bindings, ignored listing per whitelist
Mar 19 14:18:38.934: INFO: namespace e2e-tests-container-probe-2t9fc deletion completed in 6.075022092s

â€¢ [SLOW TEST:248.572 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:18:38.936: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 19 14:18:43.032: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 19 14:18:43.034: INFO: Pod pod-with-prestop-http-hook still exists
Mar 19 14:18:45.035: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 19 14:18:45.037: INFO: Pod pod-with-prestop-http-hook still exists
Mar 19 14:18:47.035: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 19 14:18:47.039: INFO: Pod pod-with-prestop-http-hook still exists
Mar 19 14:18:49.035: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 19 14:18:49.037: INFO: Pod pod-with-prestop-http-hook still exists
Mar 19 14:18:51.035: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 19 14:18:51.038: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:18:51.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-s694v" for this suite.
Mar 19 14:19:13.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:19:13.087: INFO: namespace: e2e-tests-container-lifecycle-hook-s694v, resource: bindings, ignored listing per whitelist
Mar 19 14:19:13.126: INFO: namespace e2e-tests-container-lifecycle-hook-s694v deletion completed in 22.076183873s

â€¢ [SLOW TEST:34.190 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:19:13.126: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:19:15.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-rq2f8" for this suite.
Mar 19 14:19:53.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:19:53.242: INFO: namespace: e2e-tests-kubelet-test-rq2f8, resource: bindings, ignored listing per whitelist
Mar 19 14:19:53.282: INFO: namespace e2e-tests-kubelet-test-rq2f8 deletion completed in 38.080670497s

â€¢ [SLOW TEST:40.156 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:19:53.283: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-zj2q8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-zj2q8 to expose endpoints map[]
Mar 19 14:19:53.364: INFO: Get endpoints failed (5.387309ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar 19 14:19:54.367: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-zj2q8 exposes endpoints map[] (1.008142169s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-zj2q8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-zj2q8 to expose endpoints map[pod1:[80]]
Mar 19 14:19:56.398: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-zj2q8 exposes endpoints map[pod1:[80]] (2.023662801s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-zj2q8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-zj2q8 to expose endpoints map[pod2:[80] pod1:[80]]
Mar 19 14:19:57.438: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-zj2q8 exposes endpoints map[pod1:[80] pod2:[80]] (1.033266341s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-zj2q8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-zj2q8 to expose endpoints map[pod2:[80]]
Mar 19 14:19:58.463: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-zj2q8 exposes endpoints map[pod2:[80]] (1.018065021s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-zj2q8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-zj2q8 to expose endpoints map[]
Mar 19 14:19:58.475: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-zj2q8 exposes endpoints map[] (6.409487ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:19:58.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-zj2q8" for this suite.
Mar 19 14:20:20.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:20:20.587: INFO: namespace: e2e-tests-services-zj2q8, resource: bindings, ignored listing per whitelist
Mar 19 14:20:20.607: INFO: namespace e2e-tests-services-zj2q8 deletion completed in 22.096864776s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:27.325 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:20:20.615: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 19 14:20:20.684: INFO: Waiting up to 5m0s for pod "pod-20a20a26-4a52-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-7c4g4" to be "success or failure"
Mar 19 14:20:20.689: INFO: Pod "pod-20a20a26-4a52-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.373598ms
Mar 19 14:20:22.692: INFO: Pod "pod-20a20a26-4a52-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007345774s
STEP: Saw pod success
Mar 19 14:20:22.692: INFO: Pod "pod-20a20a26-4a52-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:20:22.694: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-20a20a26-4a52-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:20:22.716: INFO: Waiting for pod pod-20a20a26-4a52-11e9-9c64-0a580af40204 to disappear
Mar 19 14:20:22.720: INFO: Pod pod-20a20a26-4a52-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:20:22.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7c4g4" for this suite.
Mar 19 14:20:28.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:20:28.783: INFO: namespace: e2e-tests-emptydir-7c4g4, resource: bindings, ignored listing per whitelist
Mar 19 14:20:28.793: INFO: namespace e2e-tests-emptydir-7c4g4 deletion completed in 6.070790458s

â€¢ [SLOW TEST:8.179 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:20:28.794: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 19 14:20:31.387: INFO: Successfully updated pod "annotationupdate2581afa1-4a52-11e9-9c64-0a580af40204"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:20:33.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6wk8p" for this suite.
Mar 19 14:20:55.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:20:55.433: INFO: namespace: e2e-tests-downward-api-6wk8p, resource: bindings, ignored listing per whitelist
Mar 19 14:20:55.477: INFO: namespace e2e-tests-downward-api-6wk8p deletion completed in 22.064667041s

â€¢ [SLOW TEST:26.683 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:20:55.478: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 19 14:20:55.538: INFO: Waiting up to 5m0s for pod "pod-35687630-4a52-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-77xml" to be "success or failure"
Mar 19 14:20:55.541: INFO: Pod "pod-35687630-4a52-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.140098ms
Mar 19 14:20:57.543: INFO: Pod "pod-35687630-4a52-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005547257s
STEP: Saw pod success
Mar 19 14:20:57.543: INFO: Pod "pod-35687630-4a52-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:20:57.546: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-35687630-4a52-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:20:57.561: INFO: Waiting for pod pod-35687630-4a52-11e9-9c64-0a580af40204 to disappear
Mar 19 14:20:57.565: INFO: Pod pod-35687630-4a52-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:20:57.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-77xml" for this suite.
Mar 19 14:21:03.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:21:03.640: INFO: namespace: e2e-tests-emptydir-77xml, resource: bindings, ignored listing per whitelist
Mar 19 14:21:03.644: INFO: namespace e2e-tests-emptydir-77xml deletion completed in 6.077009695s

â€¢ [SLOW TEST:8.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:21:03.645: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3a456c85-4a52-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:21:03.702: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3a460238-4a52-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-gkps2" to be "success or failure"
Mar 19 14:21:03.709: INFO: Pod "pod-projected-configmaps-3a460238-4a52-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 6.741586ms
Mar 19 14:21:05.711: INFO: Pod "pod-projected-configmaps-3a460238-4a52-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009405149s
STEP: Saw pod success
Mar 19 14:21:05.711: INFO: Pod "pod-projected-configmaps-3a460238-4a52-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:21:05.714: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-projected-configmaps-3a460238-4a52-11e9-9c64-0a580af40204 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 14:21:05.728: INFO: Waiting for pod pod-projected-configmaps-3a460238-4a52-11e9-9c64-0a580af40204 to disappear
Mar 19 14:21:05.732: INFO: Pod pod-projected-configmaps-3a460238-4a52-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:21:05.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gkps2" for this suite.
Mar 19 14:21:11.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:21:11.813: INFO: namespace: e2e-tests-projected-gkps2, resource: bindings, ignored listing per whitelist
Mar 19 14:21:11.816: INFO: namespace e2e-tests-projected-gkps2 deletion completed in 6.081507828s

â€¢ [SLOW TEST:8.172 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:21:11.817: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-3f257459-4a52-11e9-9c64-0a580af40204
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-3f257459-4a52-11e9-9c64-0a580af40204
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:21:15.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x4s7d" for this suite.
Mar 19 14:21:37.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:21:37.949: INFO: namespace: e2e-tests-projected-x4s7d, resource: bindings, ignored listing per whitelist
Mar 19 14:21:37.983: INFO: namespace e2e-tests-projected-x4s7d deletion completed in 22.070920813s

â€¢ [SLOW TEST:26.167 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:21:37.985: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-4ebe43ef-4a52-11e9-9c64-0a580af40204
STEP: Creating secret with name s-test-opt-upd-4ebe4433-4a52-11e9-9c64-0a580af40204
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-4ebe43ef-4a52-11e9-9c64-0a580af40204
STEP: Updating secret s-test-opt-upd-4ebe4433-4a52-11e9-9c64-0a580af40204
STEP: Creating secret with name s-test-opt-create-4ebe4449-4a52-11e9-9c64-0a580af40204
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:23:04.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5l28p" for this suite.
Mar 19 14:23:26.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:23:26.569: INFO: namespace: e2e-tests-projected-5l28p, resource: bindings, ignored listing per whitelist
Mar 19 14:23:26.605: INFO: namespace e2e-tests-projected-5l28p deletion completed in 22.080248483s

â€¢ [SLOW TEST:108.621 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:23:26.606: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qjd56
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-qjd56
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-qjd56
Mar 19 14:23:26.683: INFO: Found 0 stateful pods, waiting for 1
Mar 19 14:23:36.686: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 19 14:23:36.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-qjd56 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 14:23:36.952: INFO: stderr: ""
Mar 19 14:23:36.952: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 14:23:36.952: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 14:23:36.955: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 19 14:23:46.958: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 14:23:46.958: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 14:23:46.973: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999902s
Mar 19 14:23:47.976: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996813954s
Mar 19 14:23:48.980: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993354196s
Mar 19 14:23:49.984: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989937897s
Mar 19 14:23:50.987: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.985731706s
Mar 19 14:23:51.990: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.982980468s
Mar 19 14:23:52.993: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.979734229s
Mar 19 14:23:53.996: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.976133754s
Mar 19 14:23:55.000: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.97314498s
Mar 19 14:23:56.004: INFO: Verifying statefulset ss doesn't scale past 1 for another 968.746784ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-qjd56
Mar 19 14:23:57.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-qjd56 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 14:23:57.192: INFO: stderr: ""
Mar 19 14:23:57.192: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 14:23:57.192: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 14:23:57.195: INFO: Found 1 stateful pods, waiting for 3
Mar 19 14:24:07.199: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 14:24:07.199: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 14:24:07.199: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 19 14:24:07.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-qjd56 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 14:24:07.398: INFO: stderr: ""
Mar 19 14:24:07.398: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 14:24:07.398: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 14:24:07.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-qjd56 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 14:24:07.591: INFO: stderr: ""
Mar 19 14:24:07.591: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 14:24:07.591: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 14:24:07.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-qjd56 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 14:24:07.782: INFO: stderr: ""
Mar 19 14:24:07.782: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 14:24:07.782: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 14:24:07.782: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 14:24:07.785: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 19 14:24:17.791: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 14:24:17.791: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 14:24:17.791: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 14:24:17.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999952s
Mar 19 14:24:18.806: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996230459s
Mar 19 14:24:19.810: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993101944s
Mar 19 14:24:20.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989873999s
Mar 19 14:24:21.826: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977960484s
Mar 19 14:24:22.828: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973608109s
Mar 19 14:24:23.835: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971203235s
Mar 19 14:24:24.839: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964269956s
Mar 19 14:24:25.842: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.959985318s
Mar 19 14:24:26.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.970193ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-qjd56
Mar 19 14:24:27.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-qjd56 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 14:24:28.035: INFO: stderr: ""
Mar 19 14:24:28.035: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 14:24:28.035: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 14:24:28.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-qjd56 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 14:24:28.248: INFO: stderr: ""
Mar 19 14:24:28.248: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 14:24:28.248: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 14:24:28.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-qjd56 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 14:24:28.437: INFO: stderr: ""
Mar 19 14:24:28.437: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 14:24:28.438: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 14:24:28.438: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 19 14:24:58.454: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qjd56
Mar 19 14:24:58.458: INFO: Scaling statefulset ss to 0
Mar 19 14:24:58.465: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 14:24:58.467: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:24:58.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qjd56" for this suite.
Mar 19 14:25:04.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:25:04.509: INFO: namespace: e2e-tests-statefulset-qjd56, resource: bindings, ignored listing per whitelist
Mar 19 14:25:04.554: INFO: namespace e2e-tests-statefulset-qjd56 deletion completed in 6.070257903s

â€¢ [SLOW TEST:97.948 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:25:04.554: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 19 14:25:04.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:04.943: INFO: stderr: ""
Mar 19 14:25:04.943: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 14:25:04.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:05.039: INFO: stderr: ""
Mar 19 14:25:05.039: INFO: stdout: "update-demo-nautilus-s9h64 update-demo-nautilus-tnnj8 "
Mar 19 14:25:05.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-s9h64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:05.114: INFO: stderr: ""
Mar 19 14:25:05.114: INFO: stdout: ""
Mar 19 14:25:05.114: INFO: update-demo-nautilus-s9h64 is created but not running
Mar 19 14:25:10.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:10.188: INFO: stderr: ""
Mar 19 14:25:10.188: INFO: stdout: "update-demo-nautilus-s9h64 update-demo-nautilus-tnnj8 "
Mar 19 14:25:10.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-s9h64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:10.290: INFO: stderr: ""
Mar 19 14:25:10.290: INFO: stdout: "true"
Mar 19 14:25:10.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-s9h64 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:10.361: INFO: stderr: ""
Mar 19 14:25:10.361: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 14:25:10.361: INFO: validating pod update-demo-nautilus-s9h64
Mar 19 14:25:10.367: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 14:25:10.367: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 14:25:10.367: INFO: update-demo-nautilus-s9h64 is verified up and running
Mar 19 14:25:10.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-tnnj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:10.441: INFO: stderr: ""
Mar 19 14:25:10.441: INFO: stdout: "true"
Mar 19 14:25:10.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-tnnj8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:10.516: INFO: stderr: ""
Mar 19 14:25:10.516: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 14:25:10.516: INFO: validating pod update-demo-nautilus-tnnj8
Mar 19 14:25:10.521: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 14:25:10.521: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 14:25:10.521: INFO: update-demo-nautilus-tnnj8 is verified up and running
STEP: scaling down the replication controller
Mar 19 14:25:10.523: INFO: scanned /root for discovery docs: <nil>
Mar 19 14:25:10.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:11.624: INFO: stderr: ""
Mar 19 14:25:11.624: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 14:25:11.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:11.699: INFO: stderr: ""
Mar 19 14:25:11.699: INFO: stdout: "update-demo-nautilus-s9h64 update-demo-nautilus-tnnj8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 19 14:25:16.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:16.802: INFO: stderr: ""
Mar 19 14:25:16.802: INFO: stdout: "update-demo-nautilus-tnnj8 "
Mar 19 14:25:16.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-tnnj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:16.898: INFO: stderr: ""
Mar 19 14:25:16.898: INFO: stdout: "true"
Mar 19 14:25:16.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-tnnj8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:17.007: INFO: stderr: ""
Mar 19 14:25:17.007: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 14:25:17.007: INFO: validating pod update-demo-nautilus-tnnj8
Mar 19 14:25:17.012: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 14:25:17.012: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 14:25:17.012: INFO: update-demo-nautilus-tnnj8 is verified up and running
STEP: scaling up the replication controller
Mar 19 14:25:17.014: INFO: scanned /root for discovery docs: <nil>
Mar 19 14:25:17.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:18.134: INFO: stderr: ""
Mar 19 14:25:18.135: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 14:25:18.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:18.223: INFO: stderr: ""
Mar 19 14:25:18.223: INFO: stdout: "update-demo-nautilus-jmw9g update-demo-nautilus-tnnj8 "
Mar 19 14:25:18.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-jmw9g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:18.310: INFO: stderr: ""
Mar 19 14:25:18.310: INFO: stdout: "true"
Mar 19 14:25:18.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-jmw9g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:18.391: INFO: stderr: ""
Mar 19 14:25:18.391: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 14:25:18.391: INFO: validating pod update-demo-nautilus-jmw9g
Mar 19 14:25:18.398: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 14:25:18.398: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 14:25:18.398: INFO: update-demo-nautilus-jmw9g is verified up and running
Mar 19 14:25:18.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-tnnj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:18.488: INFO: stderr: ""
Mar 19 14:25:18.488: INFO: stdout: "true"
Mar 19 14:25:18.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-tnnj8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:18.572: INFO: stderr: ""
Mar 19 14:25:18.572: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 14:25:18.572: INFO: validating pod update-demo-nautilus-tnnj8
Mar 19 14:25:18.575: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 14:25:18.575: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 14:25:18.575: INFO: update-demo-nautilus-tnnj8 is verified up and running
STEP: using delete to clean up resources
Mar 19 14:25:18.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:18.664: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 14:25:18.664: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 19 14:25:18.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-9v4lr'
Mar 19 14:25:18.762: INFO: stderr: "No resources found.\n"
Mar 19 14:25:18.762: INFO: stdout: ""
Mar 19 14:25:18.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -l name=update-demo --namespace=e2e-tests-kubectl-9v4lr -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 19 14:25:18.886: INFO: stderr: ""
Mar 19 14:25:18.886: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:25:18.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9v4lr" for this suite.
Mar 19 14:25:40.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:25:40.934: INFO: namespace: e2e-tests-kubectl-9v4lr, resource: bindings, ignored listing per whitelist
Mar 19 14:25:40.975: INFO: namespace e2e-tests-kubectl-9v4lr deletion completed in 22.084793145s

â€¢ [SLOW TEST:36.421 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:25:40.975: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mh5hc
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar 19 14:25:41.039: INFO: Found 0 stateful pods, waiting for 3
Mar 19 14:25:51.043: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 14:25:51.043: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 14:25:51.043: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 14:25:51.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-mh5hc ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 14:25:51.227: INFO: stderr: ""
Mar 19 14:25:51.227: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 14:25:51.227: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 19 14:26:01.260: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 19 14:26:11.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-mh5hc ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 14:26:11.476: INFO: stderr: ""
Mar 19 14:26:11.476: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 14:26:11.476: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 14:26:21.495: INFO: Waiting for StatefulSet e2e-tests-statefulset-mh5hc/ss2 to complete update
Mar 19 14:26:21.495: INFO: Waiting for Pod e2e-tests-statefulset-mh5hc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar 19 14:26:31.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-mh5hc ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 14:26:31.678: INFO: stderr: ""
Mar 19 14:26:31.678: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 14:26:31.678: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 14:26:41.707: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 19 14:26:51.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-mh5hc ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 14:26:51.906: INFO: stderr: ""
Mar 19 14:26:51.906: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 14:26:51.906: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 19 14:27:11.923: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mh5hc
Mar 19 14:27:11.925: INFO: Scaling statefulset ss2 to 0
Mar 19 14:27:31.948: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 14:27:31.951: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:27:31.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mh5hc" for this suite.
Mar 19 14:27:37.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:27:38.025: INFO: namespace: e2e-tests-statefulset-mh5hc, resource: bindings, ignored listing per whitelist
Mar 19 14:27:38.051: INFO: namespace e2e-tests-statefulset-mh5hc deletion completed in 6.081534373s

â€¢ [SLOW TEST:117.076 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:27:38.052: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar 19 14:27:38.109: INFO: Waiting up to 5m0s for pod "client-containers-255c1fe1-4a53-11e9-9c64-0a580af40204" in namespace "e2e-tests-containers-kzwnd" to be "success or failure"
Mar 19 14:27:38.114: INFO: Pod "client-containers-255c1fe1-4a53-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.185613ms
Mar 19 14:27:40.116: INFO: Pod "client-containers-255c1fe1-4a53-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006824979s
STEP: Saw pod success
Mar 19 14:27:40.116: INFO: Pod "client-containers-255c1fe1-4a53-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:27:40.118: INFO: Trying to get logs from node essentialpks-conformance-3 pod client-containers-255c1fe1-4a53-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:27:40.137: INFO: Waiting for pod client-containers-255c1fe1-4a53-11e9-9c64-0a580af40204 to disappear
Mar 19 14:27:40.139: INFO: Pod client-containers-255c1fe1-4a53-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:27:40.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-kzwnd" for this suite.
Mar 19 14:27:46.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:27:46.217: INFO: namespace: e2e-tests-containers-kzwnd, resource: bindings, ignored listing per whitelist
Mar 19 14:27:46.230: INFO: namespace e2e-tests-containers-kzwnd deletion completed in 6.087266743s

â€¢ [SLOW TEST:8.178 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:27:46.230: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 19 14:27:48.814: INFO: Successfully updated pod "pod-update-2a3bdd21-4a53-11e9-9c64-0a580af40204"
STEP: verifying the updated pod is in kubernetes
Mar 19 14:27:48.819: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:27:48.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9tsfm" for this suite.
Mar 19 14:28:10.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:28:10.849: INFO: namespace: e2e-tests-pods-9tsfm, resource: bindings, ignored listing per whitelist
Mar 19 14:28:10.898: INFO: namespace e2e-tests-pods-9tsfm deletion completed in 22.075959154s

â€¢ [SLOW TEST:24.668 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:28:10.901: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-38f1397e-4a53-11e9-9c64-0a580af40204
STEP: Creating secret with name s-test-opt-upd-38f139c4-4a53-11e9-9c64-0a580af40204
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-38f1397e-4a53-11e9-9c64-0a580af40204
STEP: Updating secret s-test-opt-upd-38f139c4-4a53-11e9-9c64-0a580af40204
STEP: Creating secret with name s-test-opt-create-38f139f1-4a53-11e9-9c64-0a580af40204
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:29:37.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jm2xv" for this suite.
Mar 19 14:29:59.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:29:59.498: INFO: namespace: e2e-tests-secrets-jm2xv, resource: bindings, ignored listing per whitelist
Mar 19 14:29:59.534: INFO: namespace e2e-tests-secrets-jm2xv deletion completed in 22.070469289s

â€¢ [SLOW TEST:108.633 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:29:59.535: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-79b04fc1-4a53-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:29:59.595: INFO: Waiting up to 5m0s for pod "pod-configmaps-79b0cc42-4a53-11e9-9c64-0a580af40204" in namespace "e2e-tests-configmap-nl65c" to be "success or failure"
Mar 19 14:29:59.603: INFO: Pod "pod-configmaps-79b0cc42-4a53-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 7.36922ms
Mar 19 14:30:01.606: INFO: Pod "pod-configmaps-79b0cc42-4a53-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010458433s
STEP: Saw pod success
Mar 19 14:30:01.606: INFO: Pod "pod-configmaps-79b0cc42-4a53-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:30:01.608: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-configmaps-79b0cc42-4a53-11e9-9c64-0a580af40204 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 14:30:01.624: INFO: Waiting for pod pod-configmaps-79b0cc42-4a53-11e9-9c64-0a580af40204 to disappear
Mar 19 14:30:01.626: INFO: Pod pod-configmaps-79b0cc42-4a53-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:30:01.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nl65c" for this suite.
Mar 19 14:30:07.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:30:07.686: INFO: namespace: e2e-tests-configmap-nl65c, resource: bindings, ignored listing per whitelist
Mar 19 14:30:07.703: INFO: namespace e2e-tests-configmap-nl65c deletion completed in 6.073122337s

â€¢ [SLOW TEST:8.168 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:30:07.704: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-nsx4j.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-nsx4j.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-nsx4j.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-nsx4j.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-nsx4j.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-nsx4j.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 19 14:30:11.834: INFO: DNS probes using e2e-tests-dns-nsx4j/dns-test-7e8ecb6e-4a53-11e9-9c64-0a580af40204 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:30:11.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-nsx4j" for this suite.
Mar 19 14:30:17.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:30:17.903: INFO: namespace: e2e-tests-dns-nsx4j, resource: bindings, ignored listing per whitelist
Mar 19 14:30:17.936: INFO: namespace e2e-tests-dns-nsx4j deletion completed in 6.087054191s

â€¢ [SLOW TEST:10.232 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:30:17.936: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:30:18.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-v6kvs" for this suite.
Mar 19 14:30:40.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:30:40.091: INFO: namespace: e2e-tests-pods-v6kvs, resource: bindings, ignored listing per whitelist
Mar 19 14:30:40.108: INFO: namespace e2e-tests-pods-v6kvs deletion completed in 22.085981354s

â€¢ [SLOW TEST:22.172 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:30:40.108: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 19 14:30:44.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:30:44.209: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:30:46.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:30:46.212: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:30:48.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:30:48.213: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:30:50.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:30:50.214: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:30:52.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:30:52.212: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:30:54.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:30:54.212: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:30:56.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:30:56.212: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:30:58.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:30:58.212: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:31:00.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:31:00.212: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:31:02.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:31:02.215: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:31:04.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:31:04.212: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:31:06.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:31:06.212: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:31:08.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:31:08.215: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 19 14:31:10.209: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 19 14:31:10.214: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:31:10.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-ct4tv" for this suite.
Mar 19 14:31:32.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:31:32.277: INFO: namespace: e2e-tests-container-lifecycle-hook-ct4tv, resource: bindings, ignored listing per whitelist
Mar 19 14:31:32.301: INFO: namespace e2e-tests-container-lifecycle-hook-ct4tv deletion completed in 22.084386974s

â€¢ [SLOW TEST:52.193 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:31:32.302: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 19 14:31:32.361: INFO: Waiting up to 5m0s for pod "pod-b0fbbc4b-4a53-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-5w76g" to be "success or failure"
Mar 19 14:31:32.372: INFO: Pod "pod-b0fbbc4b-4a53-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 10.149912ms
Mar 19 14:31:34.374: INFO: Pod "pod-b0fbbc4b-4a53-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012802672s
STEP: Saw pod success
Mar 19 14:31:34.374: INFO: Pod "pod-b0fbbc4b-4a53-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:31:34.379: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-b0fbbc4b-4a53-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:31:34.398: INFO: Waiting for pod pod-b0fbbc4b-4a53-11e9-9c64-0a580af40204 to disappear
Mar 19 14:31:34.400: INFO: Pod pod-b0fbbc4b-4a53-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:31:34.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5w76g" for this suite.
Mar 19 14:31:40.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:31:40.467: INFO: namespace: e2e-tests-emptydir-5w76g, resource: bindings, ignored listing per whitelist
Mar 19 14:31:40.477: INFO: namespace e2e-tests-emptydir-5w76g deletion completed in 6.073527343s

â€¢ [SLOW TEST:8.175 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:31:40.477: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 19 14:31:40.530: INFO: Waiting up to 5m0s for pod "pod-b5da4cda-4a53-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-vmvhj" to be "success or failure"
Mar 19 14:31:40.535: INFO: Pod "pod-b5da4cda-4a53-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.207693ms
Mar 19 14:31:42.538: INFO: Pod "pod-b5da4cda-4a53-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008325131s
STEP: Saw pod success
Mar 19 14:31:42.538: INFO: Pod "pod-b5da4cda-4a53-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:31:42.541: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-b5da4cda-4a53-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:31:42.557: INFO: Waiting for pod pod-b5da4cda-4a53-11e9-9c64-0a580af40204 to disappear
Mar 19 14:31:42.561: INFO: Pod pod-b5da4cda-4a53-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:31:42.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vmvhj" for this suite.
Mar 19 14:31:48.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:31:48.629: INFO: namespace: e2e-tests-emptydir-vmvhj, resource: bindings, ignored listing per whitelist
Mar 19 14:31:48.643: INFO: namespace e2e-tests-emptydir-vmvhj deletion completed in 6.077826886s

â€¢ [SLOW TEST:8.166 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:31:48.644: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:31:48.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 version --client'
Mar 19 14:31:48.755: INFO: stderr: ""
Mar 19 14:31:48.755: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar 19 14:31:48.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-bvsqr'
Mar 19 14:31:48.934: INFO: stderr: ""
Mar 19 14:31:48.934: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar 19 14:31:48.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-bvsqr'
Mar 19 14:31:49.107: INFO: stderr: ""
Mar 19 14:31:49.107: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 19 14:31:50.110: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:31:50.110: INFO: Found 0 / 1
Mar 19 14:31:51.110: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:31:51.110: INFO: Found 1 / 1
Mar 19 14:31:51.110: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 19 14:31:51.113: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:31:51.113: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 19 14:31:51.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 describe pod redis-master-z92q8 --namespace=e2e-tests-kubectl-bvsqr'
Mar 19 14:31:51.220: INFO: stderr: ""
Mar 19 14:31:51.220: INFO: stdout: "Name:               redis-master-z92q8\nNamespace:          e2e-tests-kubectl-bvsqr\nPriority:           0\nPriorityClassName:  <none>\nNode:               essentialpks-conformance-3/192.168.102.4\nStart Time:         Tue, 19 Mar 2019 14:31:48 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.1.114\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://c415eae1245a5f7ef6e80ba1680067fc5ee6ea42b65af34f6f39d8b6dd7513c3\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Mar 2019 14:31:49 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-75p7q (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-75p7q:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-75p7q\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                 Message\n  ----    ------     ----  ----                                 -------\n  Normal  Scheduled  3s    default-scheduler                    Successfully assigned e2e-tests-kubectl-bvsqr/redis-master-z92q8 to essentialpks-conformance-3\n  Normal  Pulled     2s    kubelet, essentialpks-conformance-3  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, essentialpks-conformance-3  Created container\n  Normal  Started    2s    kubelet, essentialpks-conformance-3  Started container\n"
Mar 19 14:31:51.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 describe rc redis-master --namespace=e2e-tests-kubectl-bvsqr'
Mar 19 14:31:51.330: INFO: stderr: ""
Mar 19 14:31:51.330: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-bvsqr\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-z92q8\n"
Mar 19 14:31:51.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 describe service redis-master --namespace=e2e-tests-kubectl-bvsqr'
Mar 19 14:31:51.435: INFO: stderr: ""
Mar 19 14:31:51.436: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-bvsqr\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.103.201.218\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.114:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 19 14:31:51.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 describe node essentialpks-conformance-1'
Mar 19 14:31:51.560: INFO: stderr: ""
Mar 19 14:31:51.560: INFO: stdout: "Name:               essentialpks-conformance-1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=essentialpks-conformance-1\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"76:9c:b2:7e:2a:37\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.102.2\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 19 Mar 2019 13:23:36 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 19 Mar 2019 14:31:51 +0000   Tue, 19 Mar 2019 13:23:28 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 19 Mar 2019 14:31:51 +0000   Tue, 19 Mar 2019 13:23:28 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 19 Mar 2019 14:31:51 +0000   Tue, 19 Mar 2019 13:23:28 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 19 Mar 2019 14:31:51 +0000   Tue, 19 Mar 2019 13:24:46 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.102.2\n  Hostname:    essentialpks-conformance-1\nCapacity:\n cpu:                2\n ephemeral-storage:  40168028Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8175132Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  37018854544\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8072732Ki\n pods:               110\nSystem Info:\n Machine ID:                 a05031910e15e3003afad29e5c8f7b92\n System UUID:                B4732442-5A30-614F-A047-8F2023A2AFAD\n Boot ID:                    dd70949a-96ad-4d00-bc63-c061f2121713\n Kernel Version:             4.4.0-116-generic\n OS Image:                   Ubuntu 16.04.4 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.13.4+vmware.1\n Kube-Proxy Version:         v1.13.4+vmware.1\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-3f70baa84f8b44d1-qhtqq    0 (0%)        0 (0%)      0 (0%)           0 (0%)         57m\n  kube-system                coredns-59d4dcfccd-4tmr7                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     67m\n  kube-system                coredns-59d4dcfccd-gjs6z                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     67m\n  kube-system                etcd-essentialpks-conformance-1                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         67m\n  kube-system                kube-apiserver-essentialpks-conformance-1                  250m (12%)    0 (0%)      0 (0%)           0 (0%)         67m\n  kube-system                kube-controller-manager-essentialpks-conformance-1         200m (10%)    0 (0%)      0 (0%)           0 (0%)         67m\n  kube-system                kube-flannel-ds-amd64-cs5jp                                100m (5%)     100m (5%)   50Mi (0%)        50Mi (0%)      67m\n  kube-system                kube-proxy-xbbzv                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         67m\n  kube-system                kube-scheduler-essentialpks-conformance-1                  100m (5%)     0 (0%)      0 (0%)           0 (0%)         67m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (42%)  100m (5%)\n  memory             190Mi (2%)  390Mi (4%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Mar 19 14:31:51.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 describe namespace e2e-tests-kubectl-bvsqr'
Mar 19 14:31:51.657: INFO: stderr: ""
Mar 19 14:31:51.657: INFO: stdout: "Name:         e2e-tests-kubectl-bvsqr\nLabels:       e2e-framework=kubectl\n              e2e-run=bf0a995b-4a4b-11e9-9c64-0a580af40204\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:31:51.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bvsqr" for this suite.
Mar 19 14:32:13.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:32:13.741: INFO: namespace: e2e-tests-kubectl-bvsqr, resource: bindings, ignored listing per whitelist
Mar 19 14:32:13.747: INFO: namespace e2e-tests-kubectl-bvsqr deletion completed in 22.083495125s

â€¢ [SLOW TEST:25.103 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:32:13.749: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c9b08130-4a53-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:32:13.812: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9b0fa4d-4a53-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-2dwvc" to be "success or failure"
Mar 19 14:32:13.816: INFO: Pod "pod-projected-configmaps-c9b0fa4d-4a53-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.614342ms
Mar 19 14:32:15.820: INFO: Pod "pod-projected-configmaps-c9b0fa4d-4a53-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007885784s
STEP: Saw pod success
Mar 19 14:32:15.820: INFO: Pod "pod-projected-configmaps-c9b0fa4d-4a53-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:32:15.822: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-projected-configmaps-c9b0fa4d-4a53-11e9-9c64-0a580af40204 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 14:32:15.841: INFO: Waiting for pod pod-projected-configmaps-c9b0fa4d-4a53-11e9-9c64-0a580af40204 to disappear
Mar 19 14:32:15.843: INFO: Pod pod-projected-configmaps-c9b0fa4d-4a53-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:32:15.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2dwvc" for this suite.
Mar 19 14:32:21.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:32:21.937: INFO: namespace: e2e-tests-projected-2dwvc, resource: bindings, ignored listing per whitelist
Mar 19 14:32:21.946: INFO: namespace e2e-tests-projected-2dwvc deletion completed in 6.098750445s

â€¢ [SLOW TEST:8.197 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:32:21.946: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:32:22.068: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ce9c8b54-4a53-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-9nb7l" to be "success or failure"
Mar 19 14:32:22.075: INFO: Pod "downwardapi-volume-ce9c8b54-4a53-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 6.960505ms
Mar 19 14:32:24.079: INFO: Pod "downwardapi-volume-ce9c8b54-4a53-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010467701s
STEP: Saw pod success
Mar 19 14:32:24.079: INFO: Pod "downwardapi-volume-ce9c8b54-4a53-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:32:24.082: INFO: Trying to get logs from node essentialpks-conformance-3 pod downwardapi-volume-ce9c8b54-4a53-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:32:24.097: INFO: Waiting for pod downwardapi-volume-ce9c8b54-4a53-11e9-9c64-0a580af40204 to disappear
Mar 19 14:32:24.099: INFO: Pod downwardapi-volume-ce9c8b54-4a53-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:32:24.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9nb7l" for this suite.
Mar 19 14:32:30.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:32:30.148: INFO: namespace: e2e-tests-projected-9nb7l, resource: bindings, ignored listing per whitelist
Mar 19 14:32:30.180: INFO: namespace e2e-tests-projected-9nb7l deletion completed in 6.077368528s

â€¢ [SLOW TEST:8.233 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:32:30.180: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0319 14:32:40.289263      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 14:32:40.289: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:32:40.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jkrxw" for this suite.
Mar 19 14:32:46.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:32:46.365: INFO: namespace: e2e-tests-gc-jkrxw, resource: bindings, ignored listing per whitelist
Mar 19 14:32:46.366: INFO: namespace e2e-tests-gc-jkrxw deletion completed in 6.068882089s

â€¢ [SLOW TEST:16.186 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:32:46.366: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:32:46.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-wpsws" for this suite.
Mar 19 14:32:52.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:32:52.472: INFO: namespace: e2e-tests-kubelet-test-wpsws, resource: bindings, ignored listing per whitelist
Mar 19 14:32:52.527: INFO: namespace e2e-tests-kubelet-test-wpsws deletion completed in 6.087690755s

â€¢ [SLOW TEST:6.161 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:32:52.530: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e0cc77e6-4a53-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:32:52.584: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e0cce591-4a53-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-rbd8m" to be "success or failure"
Mar 19 14:32:52.591: INFO: Pod "pod-projected-configmaps-e0cce591-4a53-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 6.656399ms
Mar 19 14:32:54.593: INFO: Pod "pod-projected-configmaps-e0cce591-4a53-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008926719s
STEP: Saw pod success
Mar 19 14:32:54.593: INFO: Pod "pod-projected-configmaps-e0cce591-4a53-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:32:54.595: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-projected-configmaps-e0cce591-4a53-11e9-9c64-0a580af40204 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 14:32:54.614: INFO: Waiting for pod pod-projected-configmaps-e0cce591-4a53-11e9-9c64-0a580af40204 to disappear
Mar 19 14:32:54.616: INFO: Pod pod-projected-configmaps-e0cce591-4a53-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:32:54.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rbd8m" for this suite.
Mar 19 14:33:00.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:33:00.648: INFO: namespace: e2e-tests-projected-rbd8m, resource: bindings, ignored listing per whitelist
Mar 19 14:33:00.688: INFO: namespace e2e-tests-projected-rbd8m deletion completed in 6.069336393s

â€¢ [SLOW TEST:8.158 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:33:00.689: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:33:00.743: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e5a9e1ac-4a53-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-mbp2m" to be "success or failure"
Mar 19 14:33:00.747: INFO: Pod "downwardapi-volume-e5a9e1ac-4a53-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014537ms
Mar 19 14:33:02.750: INFO: Pod "downwardapi-volume-e5a9e1ac-4a53-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006967692s
STEP: Saw pod success
Mar 19 14:33:02.750: INFO: Pod "downwardapi-volume-e5a9e1ac-4a53-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:33:02.753: INFO: Trying to get logs from node essentialpks-conformance-3 pod downwardapi-volume-e5a9e1ac-4a53-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:33:02.773: INFO: Waiting for pod downwardapi-volume-e5a9e1ac-4a53-11e9-9c64-0a580af40204 to disappear
Mar 19 14:33:02.775: INFO: Pod downwardapi-volume-e5a9e1ac-4a53-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:33:02.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mbp2m" for this suite.
Mar 19 14:33:08.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:33:08.841: INFO: namespace: e2e-tests-downward-api-mbp2m, resource: bindings, ignored listing per whitelist
Mar 19 14:33:08.880: INFO: namespace e2e-tests-downward-api-mbp2m deletion completed in 6.099910176s

â€¢ [SLOW TEST:8.191 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:33:08.880: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-ea8c251c-4a53-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:33:08.940: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ea8cf60b-4a53-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-5ktnj" to be "success or failure"
Mar 19 14:33:08.945: INFO: Pod "pod-projected-secrets-ea8cf60b-4a53-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.162924ms
Mar 19 14:33:10.949: INFO: Pod "pod-projected-secrets-ea8cf60b-4a53-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008230643s
STEP: Saw pod success
Mar 19 14:33:10.949: INFO: Pod "pod-projected-secrets-ea8cf60b-4a53-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:33:10.958: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-projected-secrets-ea8cf60b-4a53-11e9-9c64-0a580af40204 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 19 14:33:10.978: INFO: Waiting for pod pod-projected-secrets-ea8cf60b-4a53-11e9-9c64-0a580af40204 to disappear
Mar 19 14:33:10.980: INFO: Pod pod-projected-secrets-ea8cf60b-4a53-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:33:10.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5ktnj" for this suite.
Mar 19 14:33:16.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:33:17.034: INFO: namespace: e2e-tests-projected-5ktnj, resource: bindings, ignored listing per whitelist
Mar 19 14:33:17.062: INFO: namespace e2e-tests-projected-5ktnj deletion completed in 6.07939826s

â€¢ [SLOW TEST:8.182 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:33:17.062: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:33:17.136: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Mar 19 14:33:17.140: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-krlvb/daemonsets","resourceVersion":"13406"},"items":null}

Mar 19 14:33:17.142: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-krlvb/pods","resourceVersion":"13406"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:33:17.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-krlvb" for this suite.
Mar 19 14:33:23.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:33:23.175: INFO: namespace: e2e-tests-daemonsets-krlvb, resource: bindings, ignored listing per whitelist
Mar 19 14:33:23.228: INFO: namespace e2e-tests-daemonsets-krlvb deletion completed in 6.076576081s

S [SKIPPING] [6.165 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar 19 14:33:17.136: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:33:23.228: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:33:23.282: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f3194c3a-4a53-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-wdmlz" to be "success or failure"
Mar 19 14:33:23.286: INFO: Pod "downwardapi-volume-f3194c3a-4a53-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.261599ms
Mar 19 14:33:25.289: INFO: Pod "downwardapi-volume-f3194c3a-4a53-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006303715s
STEP: Saw pod success
Mar 19 14:33:25.289: INFO: Pod "downwardapi-volume-f3194c3a-4a53-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:33:25.291: INFO: Trying to get logs from node essentialpks-conformance-3 pod downwardapi-volume-f3194c3a-4a53-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:33:25.308: INFO: Waiting for pod downwardapi-volume-f3194c3a-4a53-11e9-9c64-0a580af40204 to disappear
Mar 19 14:33:25.310: INFO: Pod downwardapi-volume-f3194c3a-4a53-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:33:25.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wdmlz" for this suite.
Mar 19 14:33:31.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:33:31.365: INFO: namespace: e2e-tests-projected-wdmlz, resource: bindings, ignored listing per whitelist
Mar 19 14:33:31.387: INFO: namespace e2e-tests-projected-wdmlz deletion completed in 6.072071494s

â€¢ [SLOW TEST:8.159 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:33:31.387: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 19 14:33:31.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-vkzhr'
Mar 19 14:33:31.618: INFO: stderr: ""
Mar 19 14:33:31.618: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 19 14:33:32.620: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:33:32.620: INFO: Found 0 / 1
Mar 19 14:33:33.621: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:33:33.621: INFO: Found 1 / 1
Mar 19 14:33:33.621: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 19 14:33:33.624: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:33:33.624: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 19 14:33:33.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 patch pod redis-master-4q928 --namespace=e2e-tests-kubectl-vkzhr -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 19 14:33:33.716: INFO: stderr: ""
Mar 19 14:33:33.716: INFO: stdout: "pod/redis-master-4q928 patched\n"
STEP: checking annotations
Mar 19 14:33:33.719: INFO: Selector matched 1 pods for map[app:redis]
Mar 19 14:33:33.719: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:33:33.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vkzhr" for this suite.
Mar 19 14:33:55.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:33:55.790: INFO: namespace: e2e-tests-kubectl-vkzhr, resource: bindings, ignored listing per whitelist
Mar 19 14:33:55.809: INFO: namespace e2e-tests-kubectl-vkzhr deletion completed in 22.085804865s

â€¢ [SLOW TEST:24.422 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:33:55.809: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-068593bd-4a54-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:33:55.872: INFO: Waiting up to 5m0s for pod "pod-configmaps-068646cd-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-configmap-jjg7n" to be "success or failure"
Mar 19 14:33:55.876: INFO: Pod "pod-configmaps-068646cd-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.736062ms
Mar 19 14:33:57.879: INFO: Pod "pod-configmaps-068646cd-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006449439s
STEP: Saw pod success
Mar 19 14:33:57.879: INFO: Pod "pod-configmaps-068646cd-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:33:57.882: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-configmaps-068646cd-4a54-11e9-9c64-0a580af40204 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 14:33:57.895: INFO: Waiting for pod pod-configmaps-068646cd-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:33:57.898: INFO: Pod pod-configmaps-068646cd-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:33:57.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jjg7n" for this suite.
Mar 19 14:34:03.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:34:03.965: INFO: namespace: e2e-tests-configmap-jjg7n, resource: bindings, ignored listing per whitelist
Mar 19 14:34:03.982: INFO: namespace e2e-tests-configmap-jjg7n deletion completed in 6.079711218s

â€¢ [SLOW TEST:8.172 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:34:03.982: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 19 14:34:04.035: INFO: Waiting up to 5m0s for pod "downward-api-0b637427-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-9k7sv" to be "success or failure"
Mar 19 14:34:04.038: INFO: Pod "downward-api-0b637427-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.390472ms
Mar 19 14:34:06.041: INFO: Pod "downward-api-0b637427-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00600642s
STEP: Saw pod success
Mar 19 14:34:06.041: INFO: Pod "downward-api-0b637427-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:34:06.043: INFO: Trying to get logs from node essentialpks-conformance-3 pod downward-api-0b637427-4a54-11e9-9c64-0a580af40204 container dapi-container: <nil>
STEP: delete the pod
Mar 19 14:34:06.062: INFO: Waiting for pod downward-api-0b637427-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:34:06.065: INFO: Pod downward-api-0b637427-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:34:06.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9k7sv" for this suite.
Mar 19 14:34:12.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:34:12.136: INFO: namespace: e2e-tests-downward-api-9k7sv, resource: bindings, ignored listing per whitelist
Mar 19 14:34:12.138: INFO: namespace e2e-tests-downward-api-9k7sv deletion completed in 6.071071015s

â€¢ [SLOW TEST:8.156 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:34:12.139: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 14:34:12.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-nqdtt'
Mar 19 14:34:12.277: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 19 14:34:12.277: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Mar 19 14:34:14.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-nqdtt'
Mar 19 14:34:14.379: INFO: stderr: ""
Mar 19 14:34:14.379: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:34:14.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nqdtt" for this suite.
Mar 19 14:34:20.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:34:20.433: INFO: namespace: e2e-tests-kubectl-nqdtt, resource: bindings, ignored listing per whitelist
Mar 19 14:34:20.474: INFO: namespace e2e-tests-kubectl-nqdtt deletion completed in 6.090880011s

â€¢ [SLOW TEST:8.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:34:20.478: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-15394d8e-4a54-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:34:20.541: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1539e2db-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-hvv9d" to be "success or failure"
Mar 19 14:34:20.551: INFO: Pod "pod-projected-secrets-1539e2db-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 10.400572ms
Mar 19 14:34:22.555: INFO: Pod "pod-projected-secrets-1539e2db-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013683465s
STEP: Saw pod success
Mar 19 14:34:22.555: INFO: Pod "pod-projected-secrets-1539e2db-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:34:22.558: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-projected-secrets-1539e2db-4a54-11e9-9c64-0a580af40204 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 19 14:34:22.583: INFO: Waiting for pod pod-projected-secrets-1539e2db-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:34:22.585: INFO: Pod pod-projected-secrets-1539e2db-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:34:22.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hvv9d" for this suite.
Mar 19 14:34:28.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:34:28.656: INFO: namespace: e2e-tests-projected-hvv9d, resource: bindings, ignored listing per whitelist
Mar 19 14:34:28.663: INFO: namespace e2e-tests-projected-hvv9d deletion completed in 6.072900458s

â€¢ [SLOW TEST:8.185 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:34:28.663: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 19 14:34:28.721: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8dkmt,SelfLink:/api/v1/namespaces/e2e-tests-watch-8dkmt/configmaps/e2e-watch-test-watch-closed,UID:1a19d5d3-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13688,Generation:0,CreationTimestamp:2019-03-19 14:34:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 19 14:34:28.721: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8dkmt,SelfLink:/api/v1/namespaces/e2e-tests-watch-8dkmt/configmaps/e2e-watch-test-watch-closed,UID:1a19d5d3-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13689,Generation:0,CreationTimestamp:2019-03-19 14:34:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 19 14:34:28.737: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8dkmt,SelfLink:/api/v1/namespaces/e2e-tests-watch-8dkmt/configmaps/e2e-watch-test-watch-closed,UID:1a19d5d3-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13690,Generation:0,CreationTimestamp:2019-03-19 14:34:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 19 14:34:28.737: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8dkmt,SelfLink:/api/v1/namespaces/e2e-tests-watch-8dkmt/configmaps/e2e-watch-test-watch-closed,UID:1a19d5d3-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13691,Generation:0,CreationTimestamp:2019-03-19 14:34:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:34:28.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8dkmt" for this suite.
Mar 19 14:34:34.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:34:34.822: INFO: namespace: e2e-tests-watch-8dkmt, resource: bindings, ignored listing per whitelist
Mar 19 14:34:34.832: INFO: namespace e2e-tests-watch-8dkmt deletion completed in 6.09202216s

â€¢ [SLOW TEST:6.169 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:34:34.836: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar 19 14:34:34.890: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-015262165 proxy --unix-socket=/tmp/kubectl-proxy-unix580580144/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:34:34.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zc6g5" for this suite.
Mar 19 14:34:40.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:34:41.078: INFO: namespace: e2e-tests-kubectl-zc6g5, resource: bindings, ignored listing per whitelist
Mar 19 14:34:41.086: INFO: namespace e2e-tests-kubectl-zc6g5 deletion completed in 6.13469235s

â€¢ [SLOW TEST:6.250 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:34:41.086: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:34:41.197: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21893c85-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-9hwd2" to be "success or failure"
Mar 19 14:34:41.218: INFO: Pod "downwardapi-volume-21893c85-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 21.352507ms
Mar 19 14:34:43.221: INFO: Pod "downwardapi-volume-21893c85-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02439689s
STEP: Saw pod success
Mar 19 14:34:43.221: INFO: Pod "downwardapi-volume-21893c85-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:34:43.225: INFO: Trying to get logs from node essentialpks-conformance-3 pod downwardapi-volume-21893c85-4a54-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:34:43.245: INFO: Waiting for pod downwardapi-volume-21893c85-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:34:43.248: INFO: Pod downwardapi-volume-21893c85-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:34:43.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9hwd2" for this suite.
Mar 19 14:34:49.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:34:49.321: INFO: namespace: e2e-tests-projected-9hwd2, resource: bindings, ignored listing per whitelist
Mar 19 14:34:49.331: INFO: namespace e2e-tests-projected-9hwd2 deletion completed in 6.080222015s

â€¢ [SLOW TEST:8.245 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:34:49.332: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-266b1ae1-4a54-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:34:49.385: INFO: Waiting up to 5m0s for pod "pod-secrets-266b76c8-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-secrets-zjkxp" to be "success or failure"
Mar 19 14:34:49.389: INFO: Pod "pod-secrets-266b76c8-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.915179ms
Mar 19 14:34:51.392: INFO: Pod "pod-secrets-266b76c8-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006605088s
STEP: Saw pod success
Mar 19 14:34:51.392: INFO: Pod "pod-secrets-266b76c8-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:34:51.394: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-secrets-266b76c8-4a54-11e9-9c64-0a580af40204 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 14:34:51.411: INFO: Waiting for pod pod-secrets-266b76c8-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:34:51.413: INFO: Pod pod-secrets-266b76c8-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:34:51.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zjkxp" for this suite.
Mar 19 14:34:57.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:34:57.464: INFO: namespace: e2e-tests-secrets-zjkxp, resource: bindings, ignored listing per whitelist
Mar 19 14:34:57.485: INFO: namespace e2e-tests-secrets-zjkxp deletion completed in 6.06877925s

â€¢ [SLOW TEST:8.154 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:34:57.485: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 19 14:34:57.548: INFO: Waiting up to 5m0s for pod "pod-2b48dbcb-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-dsvs7" to be "success or failure"
Mar 19 14:34:57.555: INFO: Pod "pod-2b48dbcb-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 7.548338ms
Mar 19 14:34:59.558: INFO: Pod "pod-2b48dbcb-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010321344s
STEP: Saw pod success
Mar 19 14:34:59.558: INFO: Pod "pod-2b48dbcb-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:34:59.560: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-2b48dbcb-4a54-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:34:59.574: INFO: Waiting for pod pod-2b48dbcb-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:34:59.578: INFO: Pod pod-2b48dbcb-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:34:59.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dsvs7" for this suite.
Mar 19 14:35:05.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:35:05.664: INFO: namespace: e2e-tests-emptydir-dsvs7, resource: bindings, ignored listing per whitelist
Mar 19 14:35:05.666: INFO: namespace e2e-tests-emptydir-dsvs7 deletion completed in 6.084870325s

â€¢ [SLOW TEST:8.181 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:35:05.667: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3028c1f8-4a54-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:35:05.730: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-30292f8d-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-7qs6s" to be "success or failure"
Mar 19 14:35:05.735: INFO: Pod "pod-projected-secrets-30292f8d-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.611409ms
Mar 19 14:35:07.738: INFO: Pod "pod-projected-secrets-30292f8d-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00858338s
STEP: Saw pod success
Mar 19 14:35:07.738: INFO: Pod "pod-projected-secrets-30292f8d-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:35:07.741: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-projected-secrets-30292f8d-4a54-11e9-9c64-0a580af40204 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 19 14:35:07.757: INFO: Waiting for pod pod-projected-secrets-30292f8d-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:35:07.760: INFO: Pod pod-projected-secrets-30292f8d-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:35:07.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7qs6s" for this suite.
Mar 19 14:35:13.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:35:13.802: INFO: namespace: e2e-tests-projected-7qs6s, resource: bindings, ignored listing per whitelist
Mar 19 14:35:13.852: INFO: namespace e2e-tests-projected-7qs6s deletion completed in 6.088668295s

â€¢ [SLOW TEST:8.185 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:35:13.854: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 19 14:35:13.920: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-a,UID:350b99fc-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13914,Generation:0,CreationTimestamp:2019-03-19 14:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 19 14:35:13.920: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-a,UID:350b99fc-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13914,Generation:0,CreationTimestamp:2019-03-19 14:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 19 14:35:23.927: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-a,UID:350b99fc-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13929,Generation:0,CreationTimestamp:2019-03-19 14:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 19 14:35:23.927: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-a,UID:350b99fc-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13929,Generation:0,CreationTimestamp:2019-03-19 14:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 19 14:35:33.933: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-a,UID:350b99fc-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13944,Generation:0,CreationTimestamp:2019-03-19 14:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 19 14:35:33.933: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-a,UID:350b99fc-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13944,Generation:0,CreationTimestamp:2019-03-19 14:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 19 14:35:43.939: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-a,UID:350b99fc-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13960,Generation:0,CreationTimestamp:2019-03-19 14:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 19 14:35:43.939: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-a,UID:350b99fc-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13960,Generation:0,CreationTimestamp:2019-03-19 14:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 19 14:35:53.945: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-b,UID:4ce68e79-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13975,Generation:0,CreationTimestamp:2019-03-19 14:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 19 14:35:53.945: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-b,UID:4ce68e79-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13975,Generation:0,CreationTimestamp:2019-03-19 14:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 19 14:36:03.954: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-b,UID:4ce68e79-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13990,Generation:0,CreationTimestamp:2019-03-19 14:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 19 14:36:03.954: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-b4wpm,SelfLink:/api/v1/namespaces/e2e-tests-watch-b4wpm/configmaps/e2e-watch-test-configmap-b,UID:4ce68e79-4a54-11e9-9b06-005056a45e5c,ResourceVersion:13990,Generation:0,CreationTimestamp:2019-03-19 14:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:36:13.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-b4wpm" for this suite.
Mar 19 14:36:19.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:36:20.017: INFO: namespace: e2e-tests-watch-b4wpm, resource: bindings, ignored listing per whitelist
Mar 19 14:36:20.031: INFO: namespace e2e-tests-watch-b4wpm deletion completed in 6.073131783s

â€¢ [SLOW TEST:66.177 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:36:20.032: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-fmbj
STEP: Creating a pod to test atomic-volume-subpath
Mar 19 14:36:20.107: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-fmbj" in namespace "e2e-tests-subpath-76pgq" to be "success or failure"
Mar 19 14:36:20.112: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.90978ms
Mar 19 14:36:22.116: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008678155s
Mar 19 14:36:24.119: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Running", Reason="", readiness=false. Elapsed: 4.011865661s
Mar 19 14:36:26.124: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Running", Reason="", readiness=false. Elapsed: 6.015952338s
Mar 19 14:36:28.126: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Running", Reason="", readiness=false. Elapsed: 8.018395486s
Mar 19 14:36:30.130: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Running", Reason="", readiness=false. Elapsed: 10.022088284s
Mar 19 14:36:32.133: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Running", Reason="", readiness=false. Elapsed: 12.025515701s
Mar 19 14:36:34.137: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Running", Reason="", readiness=false. Elapsed: 14.029252725s
Mar 19 14:36:36.140: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Running", Reason="", readiness=false. Elapsed: 16.032339716s
Mar 19 14:36:38.143: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Running", Reason="", readiness=false. Elapsed: 18.035814592s
Mar 19 14:36:40.146: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Running", Reason="", readiness=false. Elapsed: 20.03851061s
Mar 19 14:36:42.149: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Running", Reason="", readiness=false. Elapsed: 22.041604307s
Mar 19 14:36:44.154: INFO: Pod "pod-subpath-test-downwardapi-fmbj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046809864s
STEP: Saw pod success
Mar 19 14:36:44.154: INFO: Pod "pod-subpath-test-downwardapi-fmbj" satisfied condition "success or failure"
Mar 19 14:36:44.159: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-subpath-test-downwardapi-fmbj container test-container-subpath-downwardapi-fmbj: <nil>
STEP: delete the pod
Mar 19 14:36:44.177: INFO: Waiting for pod pod-subpath-test-downwardapi-fmbj to disappear
Mar 19 14:36:44.180: INFO: Pod pod-subpath-test-downwardapi-fmbj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-fmbj
Mar 19 14:36:44.180: INFO: Deleting pod "pod-subpath-test-downwardapi-fmbj" in namespace "e2e-tests-subpath-76pgq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:36:44.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-76pgq" for this suite.
Mar 19 14:36:50.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:36:50.227: INFO: namespace: e2e-tests-subpath-76pgq, resource: bindings, ignored listing per whitelist
Mar 19 14:36:50.274: INFO: namespace e2e-tests-subpath-76pgq deletion completed in 6.08869793s

â€¢ [SLOW TEST:30.242 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:36:50.274: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:36:50.347: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e84c65f-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-d2nbj" to be "success or failure"
Mar 19 14:36:50.350: INFO: Pod "downwardapi-volume-6e84c65f-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.554056ms
Mar 19 14:36:52.354: INFO: Pod "downwardapi-volume-6e84c65f-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007149359s
STEP: Saw pod success
Mar 19 14:36:52.354: INFO: Pod "downwardapi-volume-6e84c65f-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:36:52.362: INFO: Trying to get logs from node essentialpks-conformance-3 pod downwardapi-volume-6e84c65f-4a54-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:36:52.379: INFO: Waiting for pod downwardapi-volume-6e84c65f-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:36:52.382: INFO: Pod downwardapi-volume-6e84c65f-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:36:52.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d2nbj" for this suite.
Mar 19 14:36:58.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:36:58.434: INFO: namespace: e2e-tests-downward-api-d2nbj, resource: bindings, ignored listing per whitelist
Mar 19 14:36:58.465: INFO: namespace e2e-tests-downward-api-d2nbj deletion completed in 6.079236237s

â€¢ [SLOW TEST:8.191 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:36:58.465: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar 19 14:36:58.524: INFO: Waiting up to 5m0s for pod "client-containers-7364603b-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-containers-wmlcs" to be "success or failure"
Mar 19 14:36:58.532: INFO: Pod "client-containers-7364603b-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 8.540051ms
Mar 19 14:37:00.535: INFO: Pod "client-containers-7364603b-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011534825s
Mar 19 14:37:02.539: INFO: Pod "client-containers-7364603b-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015381301s
Mar 19 14:37:04.542: INFO: Pod "client-containers-7364603b-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018398048s
Mar 19 14:37:06.546: INFO: Pod "client-containers-7364603b-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021723753s
Mar 19 14:37:08.549: INFO: Pod "client-containers-7364603b-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.024735622s
STEP: Saw pod success
Mar 19 14:37:08.549: INFO: Pod "client-containers-7364603b-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:37:08.551: INFO: Trying to get logs from node essentialpks-conformance-2 pod client-containers-7364603b-4a54-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:37:08.572: INFO: Waiting for pod client-containers-7364603b-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:37:08.575: INFO: Pod client-containers-7364603b-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:37:08.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wmlcs" for this suite.
Mar 19 14:37:14.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:37:14.618: INFO: namespace: e2e-tests-containers-wmlcs, resource: bindings, ignored listing per whitelist
Mar 19 14:37:14.662: INFO: namespace e2e-tests-containers-wmlcs deletion completed in 6.084444843s

â€¢ [SLOW TEST:16.197 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:37:14.663: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7d0d01f2-4a54-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:37:14.730: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d0d7f57-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-configmap-b6h6r" to be "success or failure"
Mar 19 14:37:14.733: INFO: Pod "pod-configmaps-7d0d7f57-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.35206ms
Mar 19 14:37:16.736: INFO: Pod "pod-configmaps-7d0d7f57-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006054239s
STEP: Saw pod success
Mar 19 14:37:16.736: INFO: Pod "pod-configmaps-7d0d7f57-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:37:16.739: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-configmaps-7d0d7f57-4a54-11e9-9c64-0a580af40204 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 14:37:16.754: INFO: Waiting for pod pod-configmaps-7d0d7f57-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:37:16.757: INFO: Pod pod-configmaps-7d0d7f57-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:37:16.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-b6h6r" for this suite.
Mar 19 14:37:22.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:37:22.794: INFO: namespace: e2e-tests-configmap-b6h6r, resource: bindings, ignored listing per whitelist
Mar 19 14:37:22.842: INFO: namespace e2e-tests-configmap-b6h6r deletion completed in 6.081507176s

â€¢ [SLOW TEST:8.179 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:37:22.842: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 19 14:37:25.427: INFO: Successfully updated pod "labelsupdate81ed0309-4a54-11e9-9c64-0a580af40204"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:37:27.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cbrzj" for this suite.
Mar 19 14:37:49.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:37:49.492: INFO: namespace: e2e-tests-downward-api-cbrzj, resource: bindings, ignored listing per whitelist
Mar 19 14:37:49.519: INFO: namespace e2e-tests-downward-api-cbrzj deletion completed in 22.074078946s

â€¢ [SLOW TEST:26.677 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:37:49.519: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar 19 14:37:49.571: INFO: Waiting up to 5m0s for pod "var-expansion-91d1cb4a-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-var-expansion-6smgf" to be "success or failure"
Mar 19 14:37:49.577: INFO: Pod "var-expansion-91d1cb4a-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.97328ms
Mar 19 14:37:51.581: INFO: Pod "var-expansion-91d1cb4a-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009713987s
STEP: Saw pod success
Mar 19 14:37:51.581: INFO: Pod "var-expansion-91d1cb4a-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:37:51.584: INFO: Trying to get logs from node essentialpks-conformance-3 pod var-expansion-91d1cb4a-4a54-11e9-9c64-0a580af40204 container dapi-container: <nil>
STEP: delete the pod
Mar 19 14:37:51.600: INFO: Waiting for pod var-expansion-91d1cb4a-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:37:51.602: INFO: Pod var-expansion-91d1cb4a-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:37:51.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6smgf" for this suite.
Mar 19 14:37:57.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:37:57.651: INFO: namespace: e2e-tests-var-expansion-6smgf, resource: bindings, ignored listing per whitelist
Mar 19 14:37:57.692: INFO: namespace e2e-tests-var-expansion-6smgf deletion completed in 6.087359079s

â€¢ [SLOW TEST:8.174 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:37:57.693: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 19 14:37:57.750: INFO: Waiting up to 5m0s for pod "pod-96b189da-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-2v7zf" to be "success or failure"
Mar 19 14:37:57.756: INFO: Pod "pod-96b189da-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.493239ms
Mar 19 14:37:59.760: INFO: Pod "pod-96b189da-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009416795s
STEP: Saw pod success
Mar 19 14:37:59.760: INFO: Pod "pod-96b189da-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:37:59.764: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-96b189da-4a54-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:37:59.791: INFO: Waiting for pod pod-96b189da-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:37:59.795: INFO: Pod pod-96b189da-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:37:59.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2v7zf" for this suite.
Mar 19 14:38:05.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:38:05.880: INFO: namespace: e2e-tests-emptydir-2v7zf, resource: bindings, ignored listing per whitelist
Mar 19 14:38:05.883: INFO: namespace e2e-tests-emptydir-2v7zf deletion completed in 6.084553177s

â€¢ [SLOW TEST:8.190 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:38:05.884: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:38:05.953: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9b94d275-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-8s2xd" to be "success or failure"
Mar 19 14:38:05.961: INFO: Pod "downwardapi-volume-9b94d275-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 8.449684ms
Mar 19 14:38:07.964: INFO: Pod "downwardapi-volume-9b94d275-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01095736s
STEP: Saw pod success
Mar 19 14:38:07.964: INFO: Pod "downwardapi-volume-9b94d275-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:38:07.967: INFO: Trying to get logs from node essentialpks-conformance-3 pod downwardapi-volume-9b94d275-4a54-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:38:07.989: INFO: Waiting for pod downwardapi-volume-9b94d275-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:38:07.993: INFO: Pod downwardapi-volume-9b94d275-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:38:07.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8s2xd" for this suite.
Mar 19 14:38:14.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:38:14.064: INFO: namespace: e2e-tests-downward-api-8s2xd, resource: bindings, ignored listing per whitelist
Mar 19 14:38:14.072: INFO: namespace e2e-tests-downward-api-8s2xd deletion completed in 6.076141266s

â€¢ [SLOW TEST:8.188 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:38:14.073: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a0774454-4a54-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:38:14.150: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a077e707-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-d9cx9" to be "success or failure"
Mar 19 14:38:14.153: INFO: Pod "pod-projected-configmaps-a077e707-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.790625ms
Mar 19 14:38:16.155: INFO: Pod "pod-projected-configmaps-a077e707-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005657531s
STEP: Saw pod success
Mar 19 14:38:16.155: INFO: Pod "pod-projected-configmaps-a077e707-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:38:16.158: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-projected-configmaps-a077e707-4a54-11e9-9c64-0a580af40204 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 14:38:16.171: INFO: Waiting for pod pod-projected-configmaps-a077e707-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:38:16.174: INFO: Pod pod-projected-configmaps-a077e707-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:38:16.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d9cx9" for this suite.
Mar 19 14:38:22.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:38:22.220: INFO: namespace: e2e-tests-projected-d9cx9, resource: bindings, ignored listing per whitelist
Mar 19 14:38:22.251: INFO: namespace e2e-tests-projected-d9cx9 deletion completed in 6.0742214s

â€¢ [SLOW TEST:8.179 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:38:22.251: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:38:24.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-m78jb" for this suite.
Mar 19 14:39:12.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:39:12.358: INFO: namespace: e2e-tests-kubelet-test-m78jb, resource: bindings, ignored listing per whitelist
Mar 19 14:39:12.405: INFO: namespace e2e-tests-kubelet-test-m78jb deletion completed in 48.07170967s

â€¢ [SLOW TEST:50.154 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:39:12.406: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar 19 14:39:14.475: INFO: Pod pod-hostip-c3397d56-4a54-11e9-9c64-0a580af40204 has hostIP: 192.168.102.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:39:14.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zqxfw" for this suite.
Mar 19 14:39:36.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:39:36.526: INFO: namespace: e2e-tests-pods-zqxfw, resource: bindings, ignored listing per whitelist
Mar 19 14:39:36.551: INFO: namespace e2e-tests-pods-zqxfw deletion completed in 22.072438367s

â€¢ [SLOW TEST:24.145 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:39:36.551: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 19 14:39:36.610: INFO: Waiting up to 5m0s for pod "pod-d19e14f5-4a54-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-d6qww" to be "success or failure"
Mar 19 14:39:36.615: INFO: Pod "pod-d19e14f5-4a54-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.649753ms
Mar 19 14:39:38.618: INFO: Pod "pod-d19e14f5-4a54-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008744769s
STEP: Saw pod success
Mar 19 14:39:38.618: INFO: Pod "pod-d19e14f5-4a54-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:39:38.623: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-d19e14f5-4a54-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:39:38.642: INFO: Waiting for pod pod-d19e14f5-4a54-11e9-9c64-0a580af40204 to disappear
Mar 19 14:39:38.647: INFO: Pod pod-d19e14f5-4a54-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:39:38.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d6qww" for this suite.
Mar 19 14:39:44.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:39:44.692: INFO: namespace: e2e-tests-emptydir-d6qww, resource: bindings, ignored listing per whitelist
Mar 19 14:39:44.726: INFO: namespace e2e-tests-emptydir-d6qww deletion completed in 6.074844676s

â€¢ [SLOW TEST:8.176 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:39:44.729: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar 19 14:39:44.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:39:45.100: INFO: stderr: ""
Mar 19 14:39:45.100: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 14:39:45.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:39:45.192: INFO: stderr: ""
Mar 19 14:39:45.192: INFO: stdout: "update-demo-nautilus-f7v9d update-demo-nautilus-kbpfl "
Mar 19 14:39:45.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-f7v9d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:39:45.277: INFO: stderr: ""
Mar 19 14:39:45.277: INFO: stdout: ""
Mar 19 14:39:45.277: INFO: update-demo-nautilus-f7v9d is created but not running
Mar 19 14:39:50.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:39:50.370: INFO: stderr: ""
Mar 19 14:39:50.370: INFO: stdout: "update-demo-nautilus-f7v9d update-demo-nautilus-kbpfl "
Mar 19 14:39:50.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-f7v9d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:39:50.457: INFO: stderr: ""
Mar 19 14:39:50.457: INFO: stdout: "true"
Mar 19 14:39:50.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-f7v9d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:39:50.542: INFO: stderr: ""
Mar 19 14:39:50.542: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 14:39:50.542: INFO: validating pod update-demo-nautilus-f7v9d
Mar 19 14:39:50.546: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 14:39:50.546: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 14:39:50.546: INFO: update-demo-nautilus-f7v9d is verified up and running
Mar 19 14:39:50.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-kbpfl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:39:50.631: INFO: stderr: ""
Mar 19 14:39:50.631: INFO: stdout: "true"
Mar 19 14:39:50.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-nautilus-kbpfl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:39:50.713: INFO: stderr: ""
Mar 19 14:39:50.713: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 19 14:39:50.713: INFO: validating pod update-demo-nautilus-kbpfl
Mar 19 14:39:50.719: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 19 14:39:50.719: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 19 14:39:50.719: INFO: update-demo-nautilus-kbpfl is verified up and running
STEP: rolling-update to new replication controller
Mar 19 14:39:50.721: INFO: scanned /root for discovery docs: <nil>
Mar 19 14:39:50.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:40:19.169: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 19 14:40:19.169: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 19 14:40:19.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:40:19.247: INFO: stderr: ""
Mar 19 14:40:19.247: INFO: stdout: "update-demo-kitten-4dkdk update-demo-kitten-4rm2d "
Mar 19 14:40:19.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-kitten-4dkdk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:40:19.332: INFO: stderr: ""
Mar 19 14:40:19.332: INFO: stdout: "true"
Mar 19 14:40:19.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-kitten-4dkdk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:40:19.412: INFO: stderr: ""
Mar 19 14:40:19.412: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 19 14:40:19.412: INFO: validating pod update-demo-kitten-4dkdk
Mar 19 14:40:19.416: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 19 14:40:19.416: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 19 14:40:19.416: INFO: update-demo-kitten-4dkdk is verified up and running
Mar 19 14:40:19.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-kitten-4rm2d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:40:19.499: INFO: stderr: ""
Mar 19 14:40:19.499: INFO: stdout: "true"
Mar 19 14:40:19.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods update-demo-kitten-4rm2d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbt8t'
Mar 19 14:40:19.575: INFO: stderr: ""
Mar 19 14:40:19.575: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 19 14:40:19.575: INFO: validating pod update-demo-kitten-4rm2d
Mar 19 14:40:19.580: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 19 14:40:19.580: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 19 14:40:19.580: INFO: update-demo-kitten-4rm2d is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:40:19.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tbt8t" for this suite.
Mar 19 14:40:41.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:40:41.613: INFO: namespace: e2e-tests-kubectl-tbt8t, resource: bindings, ignored listing per whitelist
Mar 19 14:40:41.667: INFO: namespace e2e-tests-kubectl-tbt8t deletion completed in 22.082921587s

â€¢ [SLOW TEST:56.938 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:40:41.667: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:40:41.736: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 19 14:40:41.747: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:41.749: INFO: Number of nodes with available pods: 0
Mar 19 14:40:41.749: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:40:42.753: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:42.755: INFO: Number of nodes with available pods: 0
Mar 19 14:40:42.755: INFO: Node essentialpks-conformance-2 is running more than one daemon pod
Mar 19 14:40:43.753: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:43.755: INFO: Number of nodes with available pods: 2
Mar 19 14:40:43.755: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 19 14:40:43.784: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:43.784: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:43.789: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:44.793: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:44.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:44.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:45.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:45.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:45.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:46.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:46.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:46.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:47.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:47.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:47.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:48.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:48.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:48.794: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:49.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:49.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:49.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:50.793: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:50.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:50.797: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:51.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:51.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:51.794: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:52.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:52.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:52.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:53.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:53.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:53.798: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:54.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:54.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:54.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:55.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:55.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:55.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:56.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:56.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:56.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:57.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:57.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:57.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:58.794: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:58.794: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:58.798: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:40:59.793: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:59.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:40:59.801: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:00.793: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:00.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:00.797: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:01.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:01.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:01.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:02.798: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:02.798: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:02.842: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:03.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:03.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:03.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:04.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:04.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:04.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:05.794: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:05.794: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:05.798: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:06.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:06.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:06.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:07.793: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:07.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:07.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:08.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:08.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:08.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:09.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:09.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:09.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:10.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:10.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:10.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:11.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:11.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:11.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:12.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:12.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:12.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:13.793: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:13.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:13.798: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:14.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:14.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:14.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:15.793: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:15.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:15.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:16.793: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:16.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:16.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:17.792: INFO: Wrong image for pod: daemon-set-2bp95. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:17.792: INFO: Pod daemon-set-2bp95 is not available
Mar 19 14:41:17.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:17.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:18.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:18.792: INFO: Pod daemon-set-vlz2g is not available
Mar 19 14:41:18.794: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:19.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:19.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:20.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:20.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:21.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:21.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:22.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:22.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:23.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:23.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:24.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:24.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:25.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:25.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:26.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:26.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:27.798: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:27.812: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:28.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:28.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:29.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:29.797: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:30.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:30.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:31.791: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:31.794: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:32.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:32.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:33.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:33.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:34.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:34.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:35.797: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:35.806: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:36.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:36.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:37.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:37.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:38.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:38.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:39.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:39.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:40.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:40.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:41.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:41.798: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:42.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:42.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:43.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:43.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:44.794: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:44.797: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:45.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:45.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:46.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:46.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:47.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:47.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:48.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:48.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:49.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:49.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:50.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:50.793: INFO: Pod daemon-set-s4fk7 is not available
Mar 19 14:41:50.797: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:51.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:51.792: INFO: Pod daemon-set-s4fk7 is not available
Mar 19 14:41:51.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:52.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:52.792: INFO: Pod daemon-set-s4fk7 is not available
Mar 19 14:41:52.797: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:53.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:53.792: INFO: Pod daemon-set-s4fk7 is not available
Mar 19 14:41:53.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:54.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:54.793: INFO: Pod daemon-set-s4fk7 is not available
Mar 19 14:41:54.796: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:55.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:55.793: INFO: Pod daemon-set-s4fk7 is not available
Mar 19 14:41:55.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:56.793: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:56.793: INFO: Pod daemon-set-s4fk7 is not available
Mar 19 14:41:56.797: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:57.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:57.792: INFO: Pod daemon-set-s4fk7 is not available
Mar 19 14:41:57.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:58.792: INFO: Wrong image for pod: daemon-set-s4fk7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 19 14:41:58.792: INFO: Pod daemon-set-s4fk7 is not available
Mar 19 14:41:58.795: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:59.793: INFO: Pod daemon-set-7hb5m is not available
Mar 19 14:41:59.797: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 19 14:41:59.801: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:41:59.805: INFO: Number of nodes with available pods: 1
Mar 19 14:41:59.805: INFO: Node essentialpks-conformance-3 is running more than one daemon pod
Mar 19 14:42:00.808: INFO: DaemonSet pods can't tolerate node essentialpks-conformance-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 19 14:42:00.812: INFO: Number of nodes with available pods: 2
Mar 19 14:42:00.812: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-r2j6z, will wait for the garbage collector to delete the pods
Mar 19 14:42:00.890: INFO: Deleting DaemonSet.extensions daemon-set took: 6.780716ms
Mar 19 14:42:00.990: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.153097ms
Mar 19 14:42:09.393: INFO: Number of nodes with available pods: 0
Mar 19 14:42:09.393: INFO: Number of running nodes: 0, number of available pods: 0
Mar 19 14:42:09.395: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-r2j6z/daemonsets","resourceVersion":"15035"},"items":null}

Mar 19 14:42:09.397: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-r2j6z/pods","resourceVersion":"15035"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:42:09.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-r2j6z" for this suite.
Mar 19 14:42:15.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:42:15.431: INFO: namespace: e2e-tests-daemonsets-r2j6z, resource: bindings, ignored listing per whitelist
Mar 19 14:42:15.479: INFO: namespace e2e-tests-daemonsets-r2j6z deletion completed in 6.071927795s

â€¢ [SLOW TEST:93.812 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:42:15.480: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:42:15.539: INFO: Waiting up to 5m0s for pod "downwardapi-volume-30595966-4a55-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-k6w5x" to be "success or failure"
Mar 19 14:42:15.545: INFO: Pod "downwardapi-volume-30595966-4a55-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.83879ms
Mar 19 14:42:17.548: INFO: Pod "downwardapi-volume-30595966-4a55-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008506918s
STEP: Saw pod success
Mar 19 14:42:17.548: INFO: Pod "downwardapi-volume-30595966-4a55-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:42:17.551: INFO: Trying to get logs from node essentialpks-conformance-2 pod downwardapi-volume-30595966-4a55-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:42:17.567: INFO: Waiting for pod downwardapi-volume-30595966-4a55-11e9-9c64-0a580af40204 to disappear
Mar 19 14:42:17.570: INFO: Pod downwardapi-volume-30595966-4a55-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:42:17.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k6w5x" for this suite.
Mar 19 14:42:23.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:42:23.612: INFO: namespace: e2e-tests-downward-api-k6w5x, resource: bindings, ignored listing per whitelist
Mar 19 14:42:23.646: INFO: namespace e2e-tests-downward-api-k6w5x deletion completed in 6.070688384s

â€¢ [SLOW TEST:8.166 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:42:23.646: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:42:23.701: INFO: (0) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.421878ms)
Mar 19 14:42:23.705: INFO: (1) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.650968ms)
Mar 19 14:42:23.709: INFO: (2) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.473891ms)
Mar 19 14:42:23.714: INFO: (3) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.226378ms)
Mar 19 14:42:23.717: INFO: (4) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.518719ms)
Mar 19 14:42:23.721: INFO: (5) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.583356ms)
Mar 19 14:42:23.725: INFO: (6) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.904983ms)
Mar 19 14:42:23.729: INFO: (7) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.055791ms)
Mar 19 14:42:23.733: INFO: (8) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.098492ms)
Mar 19 14:42:23.737: INFO: (9) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.928165ms)
Mar 19 14:42:23.741: INFO: (10) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.3532ms)
Mar 19 14:42:23.744: INFO: (11) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.919796ms)
Mar 19 14:42:23.748: INFO: (12) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.678847ms)
Mar 19 14:42:23.753: INFO: (13) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.39558ms)
Mar 19 14:42:23.755: INFO: (14) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.751613ms)
Mar 19 14:42:23.759: INFO: (15) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.971333ms)
Mar 19 14:42:23.762: INFO: (16) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.88719ms)
Mar 19 14:42:23.766: INFO: (17) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.256735ms)
Mar 19 14:42:23.769: INFO: (18) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.746994ms)
Mar 19 14:42:23.773: INFO: (19) /api/v1/nodes/essentialpks-conformance-2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.424321ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:42:23.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-456vh" for this suite.
Mar 19 14:42:29.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:42:29.851: INFO: namespace: e2e-tests-proxy-456vh, resource: bindings, ignored listing per whitelist
Mar 19 14:42:29.867: INFO: namespace e2e-tests-proxy-456vh deletion completed in 6.089344174s

â€¢ [SLOW TEST:6.221 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:42:29.867: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-38ed4dc0-4a55-11e9-9c64-0a580af40204
STEP: Creating configMap with name cm-test-opt-upd-38ed4e01-4a55-11e9-9c64-0a580af40204
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-38ed4dc0-4a55-11e9-9c64-0a580af40204
STEP: Updating configmap cm-test-opt-upd-38ed4e01-4a55-11e9-9c64-0a580af40204
STEP: Creating configMap with name cm-test-opt-create-38ed4e18-4a55-11e9-9c64-0a580af40204
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:42:34.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ffwcg" for this suite.
Mar 19 14:42:56.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:42:56.070: INFO: namespace: e2e-tests-projected-ffwcg, resource: bindings, ignored listing per whitelist
Mar 19 14:42:56.093: INFO: namespace e2e-tests-projected-ffwcg deletion completed in 22.072587047s

â€¢ [SLOW TEST:26.226 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:42:56.093: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 19 14:42:58.683: INFO: Successfully updated pod "annotationupdate488f1678-4a55-11e9-9c64-0a580af40204"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:43:00.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7cw28" for this suite.
Mar 19 14:43:22.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:43:22.776: INFO: namespace: e2e-tests-projected-7cw28, resource: bindings, ignored listing per whitelist
Mar 19 14:43:22.786: INFO: namespace e2e-tests-projected-7cw28 deletion completed in 22.081833083s

â€¢ [SLOW TEST:26.693 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:43:22.789: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:43:22.852: INFO: Creating ReplicaSet my-hostname-basic-5879418c-4a55-11e9-9c64-0a580af40204
Mar 19 14:43:22.869: INFO: Pod name my-hostname-basic-5879418c-4a55-11e9-9c64-0a580af40204: Found 0 pods out of 1
Mar 19 14:43:27.872: INFO: Pod name my-hostname-basic-5879418c-4a55-11e9-9c64-0a580af40204: Found 1 pods out of 1
Mar 19 14:43:27.872: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-5879418c-4a55-11e9-9c64-0a580af40204" is running
Mar 19 14:43:27.874: INFO: Pod "my-hostname-basic-5879418c-4a55-11e9-9c64-0a580af40204-pv22b" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 14:43:22 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 14:43:24 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 14:43:24 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-19 14:43:22 +0000 UTC Reason: Message:}])
Mar 19 14:43:27.874: INFO: Trying to dial the pod
Mar 19 14:43:32.883: INFO: Controller my-hostname-basic-5879418c-4a55-11e9-9c64-0a580af40204: Got expected result from replica 1 [my-hostname-basic-5879418c-4a55-11e9-9c64-0a580af40204-pv22b]: "my-hostname-basic-5879418c-4a55-11e9-9c64-0a580af40204-pv22b", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:43:32.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-cjp4j" for this suite.
Mar 19 14:43:38.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:43:38.940: INFO: namespace: e2e-tests-replicaset-cjp4j, resource: bindings, ignored listing per whitelist
Mar 19 14:43:38.968: INFO: namespace e2e-tests-replicaset-cjp4j deletion completed in 6.081593483s

â€¢ [SLOW TEST:16.179 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:43:38.968: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:43:43.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-vqp2d" for this suite.
Mar 19 14:43:49.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:43:49.064: INFO: namespace: e2e-tests-kubelet-test-vqp2d, resource: bindings, ignored listing per whitelist
Mar 19 14:43:49.136: INFO: namespace e2e-tests-kubelet-test-vqp2d deletion completed in 6.093077382s

â€¢ [SLOW TEST:10.168 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:43:49.139: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 19 14:43:51.726: INFO: Successfully updated pod "labelsupdate682b7f7a-4a55-11e9-9c64-0a580af40204"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:43:55.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d4s4r" for this suite.
Mar 19 14:44:17.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:44:17.781: INFO: namespace: e2e-tests-projected-d4s4r, resource: bindings, ignored listing per whitelist
Mar 19 14:44:17.826: INFO: namespace e2e-tests-projected-d4s4r deletion completed in 22.075716164s

â€¢ [SLOW TEST:28.687 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:44:17.826: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar 19 14:44:18.390: INFO: Waiting up to 5m0s for pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-vbhvf" in namespace "e2e-tests-svcaccounts-fm29n" to be "success or failure"
Mar 19 14:44:18.396: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-vbhvf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.449995ms
Mar 19 14:44:20.399: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-vbhvf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009434841s
Mar 19 14:44:22.402: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-vbhvf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012117737s
STEP: Saw pod success
Mar 19 14:44:22.402: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-vbhvf" satisfied condition "success or failure"
Mar 19 14:44:22.405: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-vbhvf container token-test: <nil>
STEP: delete the pod
Mar 19 14:44:22.420: INFO: Waiting for pod pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-vbhvf to disappear
Mar 19 14:44:22.425: INFO: Pod pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-vbhvf no longer exists
STEP: Creating a pod to test consume service account root CA
Mar 19 14:44:22.429: INFO: Waiting up to 5m0s for pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-ss95d" in namespace "e2e-tests-svcaccounts-fm29n" to be "success or failure"
Mar 19 14:44:22.434: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-ss95d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.77043ms
Mar 19 14:44:24.437: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-ss95d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008291048s
Mar 19 14:44:26.441: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-ss95d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012120121s
STEP: Saw pod success
Mar 19 14:44:26.441: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-ss95d" satisfied condition "success or failure"
Mar 19 14:44:26.443: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-ss95d container root-ca-test: <nil>
STEP: delete the pod
Mar 19 14:44:26.459: INFO: Waiting for pod pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-ss95d to disappear
Mar 19 14:44:26.461: INFO: Pod pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-ss95d no longer exists
STEP: Creating a pod to test consume service account namespace
Mar 19 14:44:26.465: INFO: Waiting up to 5m0s for pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-xtg62" in namespace "e2e-tests-svcaccounts-fm29n" to be "success or failure"
Mar 19 14:44:26.469: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-xtg62": Phase="Pending", Reason="", readiness=false. Elapsed: 4.592661ms
Mar 19 14:44:28.472: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-xtg62": Phase="Running", Reason="", readiness=false. Elapsed: 2.007607654s
Mar 19 14:44:30.477: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-xtg62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012047334s
STEP: Saw pod success
Mar 19 14:44:30.477: INFO: Pod "pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-xtg62" satisfied condition "success or failure"
Mar 19 14:44:30.480: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-xtg62 container namespace-test: <nil>
STEP: delete the pod
Mar 19 14:44:30.495: INFO: Waiting for pod pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-xtg62 to disappear
Mar 19 14:44:30.498: INFO: Pod pod-service-account-79929e94-4a55-11e9-9c64-0a580af40204-xtg62 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:44:30.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-fm29n" for this suite.
Mar 19 14:44:36.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:44:36.559: INFO: namespace: e2e-tests-svcaccounts-fm29n, resource: bindings, ignored listing per whitelist
Mar 19 14:44:36.578: INFO: namespace e2e-tests-svcaccounts-fm29n deletion completed in 6.076078416s

â€¢ [SLOW TEST:18.752 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:44:36.578: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-84726cb8-4a55-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:44:36.635: INFO: Waiting up to 5m0s for pod "pod-configmaps-8472d66d-4a55-11e9-9c64-0a580af40204" in namespace "e2e-tests-configmap-h2mth" to be "success or failure"
Mar 19 14:44:36.643: INFO: Pod "pod-configmaps-8472d66d-4a55-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 7.917893ms
Mar 19 14:44:38.646: INFO: Pod "pod-configmaps-8472d66d-4a55-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010991886s
STEP: Saw pod success
Mar 19 14:44:38.646: INFO: Pod "pod-configmaps-8472d66d-4a55-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:44:38.649: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-configmaps-8472d66d-4a55-11e9-9c64-0a580af40204 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 14:44:38.668: INFO: Waiting for pod pod-configmaps-8472d66d-4a55-11e9-9c64-0a580af40204 to disappear
Mar 19 14:44:38.673: INFO: Pod pod-configmaps-8472d66d-4a55-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:44:38.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h2mth" for this suite.
Mar 19 14:44:44.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:44:44.702: INFO: namespace: e2e-tests-configmap-h2mth, resource: bindings, ignored listing per whitelist
Mar 19 14:44:44.758: INFO: namespace e2e-tests-configmap-h2mth deletion completed in 6.080403665s

â€¢ [SLOW TEST:8.180 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:44:44.761: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 19 14:44:44.818: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:44:47.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-tfxhl" for this suite.
Mar 19 14:44:53.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:44:53.891: INFO: namespace: e2e-tests-init-container-tfxhl, resource: bindings, ignored listing per whitelist
Mar 19 14:44:53.943: INFO: namespace e2e-tests-init-container-tfxhl deletion completed in 6.07416932s

â€¢ [SLOW TEST:9.182 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:44:53.943: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 19 14:44:53.987: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 19 14:44:53.993: INFO: Waiting for terminating namespaces to be deleted...
Mar 19 14:44:53.995: INFO: 
Logging pods the kubelet thinks is on node essentialpks-conformance-2 before test
Mar 19 14:44:54.000: INFO: kube-proxy-x8ptf from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 14:44:54.000: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 14:44:54.000: INFO: sonobuoy-e2e-job-879d35058b7448c9 from heptio-sonobuoy started at 2019-03-19 13:34:37 +0000 UTC (2 container statuses recorded)
Mar 19 14:44:54.000: INFO: 	Container e2e ready: true, restart count 0
Mar 19 14:44:54.000: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 14:44:54.000: INFO: sonobuoy-systemd-logs-daemon-set-3f70baa84f8b44d1-2l52l from heptio-sonobuoy started at 2019-03-19 13:34:37 +0000 UTC (2 container statuses recorded)
Mar 19 14:44:54.000: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 19 14:44:54.000: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 19 14:44:54.000: INFO: kube-flannel-ds-amd64-c4rpf from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 14:44:54.000: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 19 14:44:54.000: INFO: 
Logging pods the kubelet thinks is on node essentialpks-conformance-3 before test
Mar 19 14:44:54.007: INFO: kube-proxy-h9j6t from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 14:44:54.007: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 14:44:54.007: INFO: kube-flannel-ds-amd64-5d5mf from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 14:44:54.007: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 19 14:44:54.007: INFO: sonobuoy-systemd-logs-daemon-set-3f70baa84f8b44d1-96s5d from heptio-sonobuoy started at 2019-03-19 13:34:37 +0000 UTC (2 container statuses recorded)
Mar 19 14:44:54.007: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 19 14:44:54.007: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 19 14:44:54.007: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-19 13:34:35 +0000 UTC (1 container statuses recorded)
Mar 19 14:44:54.007: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node essentialpks-conformance-2
STEP: verifying the node has the label node essentialpks-conformance-3
Mar 19 14:44:54.037: INFO: Pod sonobuoy requesting resource cpu=0m on Node essentialpks-conformance-3
Mar 19 14:44:54.037: INFO: Pod sonobuoy-e2e-job-879d35058b7448c9 requesting resource cpu=0m on Node essentialpks-conformance-2
Mar 19 14:44:54.037: INFO: Pod sonobuoy-systemd-logs-daemon-set-3f70baa84f8b44d1-2l52l requesting resource cpu=0m on Node essentialpks-conformance-2
Mar 19 14:44:54.037: INFO: Pod sonobuoy-systemd-logs-daemon-set-3f70baa84f8b44d1-96s5d requesting resource cpu=0m on Node essentialpks-conformance-3
Mar 19 14:44:54.037: INFO: Pod kube-flannel-ds-amd64-5d5mf requesting resource cpu=100m on Node essentialpks-conformance-3
Mar 19 14:44:54.037: INFO: Pod kube-flannel-ds-amd64-c4rpf requesting resource cpu=100m on Node essentialpks-conformance-2
Mar 19 14:44:54.037: INFO: Pod kube-proxy-h9j6t requesting resource cpu=0m on Node essentialpks-conformance-3
Mar 19 14:44:54.037: INFO: Pod kube-proxy-x8ptf requesting resource cpu=0m on Node essentialpks-conformance-2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ed2fb3e-4a55-11e9-9c64-0a580af40204.158d635c2c94d15b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4jdxf/filler-pod-8ed2fb3e-4a55-11e9-9c64-0a580af40204 to essentialpks-conformance-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ed2fb3e-4a55-11e9-9c64-0a580af40204.158d635c68cc8f7c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ed2fb3e-4a55-11e9-9c64-0a580af40204.158d635c6c0fc187], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ed2fb3e-4a55-11e9-9c64-0a580af40204.158d635c79a1eba1], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ed3c446-4a55-11e9-9c64-0a580af40204.158d635c2ce5a635], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4jdxf/filler-pod-8ed3c446-4a55-11e9-9c64-0a580af40204 to essentialpks-conformance-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ed3c446-4a55-11e9-9c64-0a580af40204.158d635c588f6468], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ed3c446-4a55-11e9-9c64-0a580af40204.158d635c5b60d000], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8ed3c446-4a55-11e9-9c64-0a580af40204.158d635c636e3b17], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158d635d1c1bae67], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node essentialpks-conformance-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node essentialpks-conformance-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:44:59.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4jdxf" for this suite.
Mar 19 14:45:05.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:45:05.152: INFO: namespace: e2e-tests-sched-pred-4jdxf, resource: bindings, ignored listing per whitelist
Mar 19 14:45:05.208: INFO: namespace e2e-tests-sched-pred-4jdxf deletion completed in 6.08306406s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:11.265 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:45:05.209: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar 19 14:45:07.284: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-9582d404-4a55-11e9-9c64-0a580af40204", GenerateName:"", Namespace:"e2e-tests-pods-6wxhz", SelfLink:"/api/v1/namespaces/e2e-tests-pods-6wxhz/pods/pod-submit-remove-9582d404-4a55-11e9-9c64-0a580af40204", UID:"95839dfa-4a55-11e9-9b06-005056a45e5c", ResourceVersion:"15718", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688603505, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"256560376"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-q8xlr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001b316c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q8xlr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001b29ae8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"essentialpks-conformance-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001ae47e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b29be0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b29f40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001b29f48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001b29f4c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688603505, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688603506, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688603506, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688603505, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.102.4", PodIP:"10.244.1.151", StartTime:(*v1.Time)(0xc000c5bfa0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000c5bfe0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d", ContainerID:"docker://b98aeaab7eb4fd3eee54676eda018d34b62f906392abc78090ac1ba00eca4db6"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:45:19.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6wxhz" for this suite.
Mar 19 14:45:25.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:45:25.469: INFO: namespace: e2e-tests-pods-6wxhz, resource: bindings, ignored listing per whitelist
Mar 19 14:45:25.479: INFO: namespace e2e-tests-pods-6wxhz deletion completed in 6.089449018s

â€¢ [SLOW TEST:20.271 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:45:25.480: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 19 14:45:25.546: INFO: Waiting up to 5m0s for pod "pod-a199bc3d-4a55-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-v2xfn" to be "success or failure"
Mar 19 14:45:25.551: INFO: Pod "pod-a199bc3d-4a55-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.741012ms
Mar 19 14:45:27.554: INFO: Pod "pod-a199bc3d-4a55-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007216582s
STEP: Saw pod success
Mar 19 14:45:27.554: INFO: Pod "pod-a199bc3d-4a55-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:45:27.556: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-a199bc3d-4a55-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:45:27.572: INFO: Waiting for pod pod-a199bc3d-4a55-11e9-9c64-0a580af40204 to disappear
Mar 19 14:45:27.574: INFO: Pod pod-a199bc3d-4a55-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:45:27.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-v2xfn" for this suite.
Mar 19 14:45:33.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:45:33.598: INFO: namespace: e2e-tests-emptydir-v2xfn, resource: bindings, ignored listing per whitelist
Mar 19 14:45:33.651: INFO: namespace e2e-tests-emptydir-v2xfn deletion completed in 6.073432565s

â€¢ [SLOW TEST:8.171 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:45:33.651: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0319 14:46:04.242836      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 19 14:46:04.242: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:46:04.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-tskt7" for this suite.
Mar 19 14:46:10.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:46:10.282: INFO: namespace: e2e-tests-gc-tskt7, resource: bindings, ignored listing per whitelist
Mar 19 14:46:10.316: INFO: namespace e2e-tests-gc-tskt7 deletion completed in 6.071766568s

â€¢ [SLOW TEST:36.666 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:46:10.317: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 19 14:46:12.896: INFO: Successfully updated pod "pod-update-activedeadlineseconds-bc52cd93-4a55-11e9-9c64-0a580af40204"
Mar 19 14:46:12.896: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-bc52cd93-4a55-11e9-9c64-0a580af40204" in namespace "e2e-tests-pods-2trwt" to be "terminated due to deadline exceeded"
Mar 19 14:46:12.899: INFO: Pod "pod-update-activedeadlineseconds-bc52cd93-4a55-11e9-9c64-0a580af40204": Phase="Running", Reason="", readiness=true. Elapsed: 2.343971ms
Mar 19 14:46:14.902: INFO: Pod "pod-update-activedeadlineseconds-bc52cd93-4a55-11e9-9c64-0a580af40204": Phase="Running", Reason="", readiness=true. Elapsed: 2.006077938s
Mar 19 14:46:16.905: INFO: Pod "pod-update-activedeadlineseconds-bc52cd93-4a55-11e9-9c64-0a580af40204": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.008648117s
Mar 19 14:46:16.905: INFO: Pod "pod-update-activedeadlineseconds-bc52cd93-4a55-11e9-9c64-0a580af40204" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:46:16.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2trwt" for this suite.
Mar 19 14:46:22.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:46:22.939: INFO: namespace: e2e-tests-pods-2trwt, resource: bindings, ignored listing per whitelist
Mar 19 14:46:22.987: INFO: namespace e2e-tests-pods-2trwt deletion completed in 6.077372029s

â€¢ [SLOW TEST:12.670 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:46:22.988: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 19 14:46:23.044: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 19 14:46:23.050: INFO: Waiting for terminating namespaces to be deleted...
Mar 19 14:46:23.052: INFO: 
Logging pods the kubelet thinks is on node essentialpks-conformance-2 before test
Mar 19 14:46:23.057: INFO: kube-proxy-x8ptf from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 14:46:23.057: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 19 14:46:23.057: INFO: sonobuoy-e2e-job-879d35058b7448c9 from heptio-sonobuoy started at 2019-03-19 13:34:37 +0000 UTC (2 container statuses recorded)
Mar 19 14:46:23.057: INFO: 	Container e2e ready: true, restart count 0
Mar 19 14:46:23.057: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 19 14:46:23.057: INFO: sonobuoy-systemd-logs-daemon-set-3f70baa84f8b44d1-2l52l from heptio-sonobuoy started at 2019-03-19 13:34:37 +0000 UTC (2 container statuses recorded)
Mar 19 14:46:23.057: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 19 14:46:23.057: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 19 14:46:23.057: INFO: kube-flannel-ds-amd64-c4rpf from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 14:46:23.057: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 19 14:46:23.057: INFO: 
Logging pods the kubelet thinks is on node essentialpks-conformance-3 before test
Mar 19 14:46:23.063: INFO: kube-flannel-ds-amd64-5d5mf from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 14:46:23.063: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 19 14:46:23.063: INFO: sonobuoy-systemd-logs-daemon-set-3f70baa84f8b44d1-96s5d from heptio-sonobuoy started at 2019-03-19 13:34:37 +0000 UTC (2 container statuses recorded)
Mar 19 14:46:23.063: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 19 14:46:23.063: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 19 14:46:23.063: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-19 13:34:35 +0000 UTC (1 container statuses recorded)
Mar 19 14:46:23.063: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 19 14:46:23.063: INFO: kube-proxy-h9j6t from kube-system started at 2019-03-19 13:24:59 +0000 UTC (1 container statuses recorded)
Mar 19 14:46:23.063: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c5181a0b-4a55-11e9-9c64-0a580af40204 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-c5181a0b-4a55-11e9-9c64-0a580af40204 off the node essentialpks-conformance-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c5181a0b-4a55-11e9-9c64-0a580af40204
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:46:27.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-6q2gm" for this suite.
Mar 19 14:46:35.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:46:35.164: INFO: namespace: e2e-tests-sched-pred-6q2gm, resource: bindings, ignored listing per whitelist
Mar 19 14:46:35.210: INFO: namespace e2e-tests-sched-pred-6q2gm deletion completed in 8.08121846s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:12.222 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:46:35.211: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-cb286e1d-4a55-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:46:35.308: INFO: Waiting up to 5m0s for pod "pod-secrets-cb28fb2c-4a55-11e9-9c64-0a580af40204" in namespace "e2e-tests-secrets-mdxnf" to be "success or failure"
Mar 19 14:46:35.329: INFO: Pod "pod-secrets-cb28fb2c-4a55-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 21.006994ms
Mar 19 14:46:37.332: INFO: Pod "pod-secrets-cb28fb2c-4a55-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024244652s
STEP: Saw pod success
Mar 19 14:46:37.332: INFO: Pod "pod-secrets-cb28fb2c-4a55-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:46:37.336: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-secrets-cb28fb2c-4a55-11e9-9c64-0a580af40204 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 14:46:37.354: INFO: Waiting for pod pod-secrets-cb28fb2c-4a55-11e9-9c64-0a580af40204 to disappear
Mar 19 14:46:37.360: INFO: Pod pod-secrets-cb28fb2c-4a55-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:46:37.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mdxnf" for this suite.
Mar 19 14:46:43.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:46:43.404: INFO: namespace: e2e-tests-secrets-mdxnf, resource: bindings, ignored listing per whitelist
Mar 19 14:46:43.442: INFO: namespace e2e-tests-secrets-mdxnf deletion completed in 6.078990066s

â€¢ [SLOW TEST:8.231 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:46:43.442: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:46:43.505: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d0107221-4a55-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-szwsd" to be "success or failure"
Mar 19 14:46:43.508: INFO: Pod "downwardapi-volume-d0107221-4a55-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.742986ms
Mar 19 14:46:45.511: INFO: Pod "downwardapi-volume-d0107221-4a55-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005552417s
STEP: Saw pod success
Mar 19 14:46:45.511: INFO: Pod "downwardapi-volume-d0107221-4a55-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:46:45.514: INFO: Trying to get logs from node essentialpks-conformance-2 pod downwardapi-volume-d0107221-4a55-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:46:45.528: INFO: Waiting for pod downwardapi-volume-d0107221-4a55-11e9-9c64-0a580af40204 to disappear
Mar 19 14:46:45.530: INFO: Pod downwardapi-volume-d0107221-4a55-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:46:45.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-szwsd" for this suite.
Mar 19 14:46:51.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:46:51.558: INFO: namespace: e2e-tests-projected-szwsd, resource: bindings, ignored listing per whitelist
Mar 19 14:46:51.604: INFO: namespace e2e-tests-projected-szwsd deletion completed in 6.071222956s

â€¢ [SLOW TEST:8.162 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:46:51.605: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 19 14:46:55.692: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vv4tj PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:46:55.692: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:46:55.809: INFO: Exec stderr: ""
Mar 19 14:46:55.809: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vv4tj PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:46:55.809: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:46:55.904: INFO: Exec stderr: ""
Mar 19 14:46:55.904: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vv4tj PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:46:55.904: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:46:56.000: INFO: Exec stderr: ""
Mar 19 14:46:56.000: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vv4tj PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:46:56.000: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:46:56.104: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 19 14:46:56.104: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vv4tj PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:46:56.104: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:46:56.198: INFO: Exec stderr: ""
Mar 19 14:46:56.198: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vv4tj PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:46:56.198: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:46:56.303: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 19 14:46:56.304: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vv4tj PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:46:56.304: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:46:56.426: INFO: Exec stderr: ""
Mar 19 14:46:56.426: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vv4tj PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:46:56.426: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:46:56.532: INFO: Exec stderr: ""
Mar 19 14:46:56.532: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vv4tj PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:46:56.532: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:46:56.643: INFO: Exec stderr: ""
Mar 19 14:46:56.643: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-vv4tj PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:46:56.643: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:46:56.739: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:46:56.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-vv4tj" for this suite.
Mar 19 14:47:34.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:47:34.774: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-vv4tj, resource: bindings, ignored listing per whitelist
Mar 19 14:47:34.824: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-vv4tj deletion completed in 38.08219143s

â€¢ [SLOW TEST:43.219 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:47:34.825: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar 19 14:47:35.389: INFO: created pod pod-service-account-defaultsa
Mar 19 14:47:35.389: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 19 14:47:35.399: INFO: created pod pod-service-account-mountsa
Mar 19 14:47:35.399: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 19 14:47:35.410: INFO: created pod pod-service-account-nomountsa
Mar 19 14:47:35.410: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 19 14:47:35.421: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 19 14:47:35.421: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 19 14:47:35.437: INFO: created pod pod-service-account-mountsa-mountspec
Mar 19 14:47:35.437: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 19 14:47:35.444: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 19 14:47:35.444: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 19 14:47:35.454: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 19 14:47:35.454: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 19 14:47:35.466: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 19 14:47:35.466: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 19 14:47:35.478: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 19 14:47:35.479: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:47:35.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-6pb4b" for this suite.
Mar 19 14:47:41.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:47:41.548: INFO: namespace: e2e-tests-svcaccounts-6pb4b, resource: bindings, ignored listing per whitelist
Mar 19 14:47:41.567: INFO: namespace e2e-tests-svcaccounts-6pb4b deletion completed in 6.08110562s

â€¢ [SLOW TEST:6.742 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:47:41.567: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar 19 14:48:08.654: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:48:09.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-5bql8" for this suite.
Mar 19 14:48:31.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:48:31.744: INFO: namespace: e2e-tests-replicaset-5bql8, resource: bindings, ignored listing per whitelist
Mar 19 14:48:31.754: INFO: namespace e2e-tests-replicaset-5bql8 deletion completed in 22.084623687s

â€¢ [SLOW TEST:50.188 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:48:31.756: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:48:31.824: INFO: Waiting up to 5m0s for pod "downwardapi-volume-10a1166e-4a56-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-bnl7b" to be "success or failure"
Mar 19 14:48:31.830: INFO: Pod "downwardapi-volume-10a1166e-4a56-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.815208ms
Mar 19 14:48:33.833: INFO: Pod "downwardapi-volume-10a1166e-4a56-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008488273s
STEP: Saw pod success
Mar 19 14:48:33.833: INFO: Pod "downwardapi-volume-10a1166e-4a56-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:48:33.835: INFO: Trying to get logs from node essentialpks-conformance-2 pod downwardapi-volume-10a1166e-4a56-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:48:33.852: INFO: Waiting for pod downwardapi-volume-10a1166e-4a56-11e9-9c64-0a580af40204 to disappear
Mar 19 14:48:33.855: INFO: Pod downwardapi-volume-10a1166e-4a56-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:48:33.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bnl7b" for this suite.
Mar 19 14:48:39.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:48:39.919: INFO: namespace: e2e-tests-downward-api-bnl7b, resource: bindings, ignored listing per whitelist
Mar 19 14:48:39.932: INFO: namespace e2e-tests-downward-api-bnl7b deletion completed in 6.074647726s

â€¢ [SLOW TEST:8.176 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:48:39.933: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 19 14:48:39.989: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:48:42.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-qr8fp" for this suite.
Mar 19 14:48:48.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:48:48.763: INFO: namespace: e2e-tests-init-container-qr8fp, resource: bindings, ignored listing per whitelist
Mar 19 14:48:48.774: INFO: namespace e2e-tests-init-container-qr8fp deletion completed in 6.071902736s

â€¢ [SLOW TEST:8.841 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:48:48.775: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1ac5d6b2-4a56-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:48:48.857: INFO: Waiting up to 5m0s for pod "pod-secrets-1ac66afe-4a56-11e9-9c64-0a580af40204" in namespace "e2e-tests-secrets-bc6rd" to be "success or failure"
Mar 19 14:48:48.869: INFO: Pod "pod-secrets-1ac66afe-4a56-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 12.153259ms
Mar 19 14:48:50.872: INFO: Pod "pod-secrets-1ac66afe-4a56-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015299074s
STEP: Saw pod success
Mar 19 14:48:50.873: INFO: Pod "pod-secrets-1ac66afe-4a56-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:48:50.875: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-secrets-1ac66afe-4a56-11e9-9c64-0a580af40204 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 14:48:50.899: INFO: Waiting for pod pod-secrets-1ac66afe-4a56-11e9-9c64-0a580af40204 to disappear
Mar 19 14:48:50.903: INFO: Pod pod-secrets-1ac66afe-4a56-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:48:50.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bc6rd" for this suite.
Mar 19 14:48:56.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:48:56.946: INFO: namespace: e2e-tests-secrets-bc6rd, resource: bindings, ignored listing per whitelist
Mar 19 14:48:56.979: INFO: namespace e2e-tests-secrets-bc6rd deletion completed in 6.072601327s

â€¢ [SLOW TEST:8.205 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:48:56.979: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar 19 14:48:57.040: INFO: Waiting up to 5m0s for pod "client-containers-1fa8fe15-4a56-11e9-9c64-0a580af40204" in namespace "e2e-tests-containers-z99v6" to be "success or failure"
Mar 19 14:48:57.044: INFO: Pod "client-containers-1fa8fe15-4a56-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.4489ms
Mar 19 14:48:59.046: INFO: Pod "client-containers-1fa8fe15-4a56-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006287888s
STEP: Saw pod success
Mar 19 14:48:59.046: INFO: Pod "client-containers-1fa8fe15-4a56-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:48:59.049: INFO: Trying to get logs from node essentialpks-conformance-3 pod client-containers-1fa8fe15-4a56-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 14:48:59.065: INFO: Waiting for pod client-containers-1fa8fe15-4a56-11e9-9c64-0a580af40204 to disappear
Mar 19 14:48:59.069: INFO: Pod client-containers-1fa8fe15-4a56-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:48:59.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-z99v6" for this suite.
Mar 19 14:49:05.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:49:05.137: INFO: namespace: e2e-tests-containers-z99v6, resource: bindings, ignored listing per whitelist
Mar 19 14:49:05.150: INFO: namespace e2e-tests-containers-z99v6 deletion completed in 6.077116145s

â€¢ [SLOW TEST:8.171 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:49:05.151: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-r8lqf/configmap-test-2486e06e-4a56-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:49:05.207: INFO: Waiting up to 5m0s for pod "pod-configmaps-24874694-4a56-11e9-9c64-0a580af40204" in namespace "e2e-tests-configmap-r8lqf" to be "success or failure"
Mar 19 14:49:05.213: INFO: Pod "pod-configmaps-24874694-4a56-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.954525ms
Mar 19 14:49:07.216: INFO: Pod "pod-configmaps-24874694-4a56-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008647242s
STEP: Saw pod success
Mar 19 14:49:07.216: INFO: Pod "pod-configmaps-24874694-4a56-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:49:07.218: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-configmaps-24874694-4a56-11e9-9c64-0a580af40204 container env-test: <nil>
STEP: delete the pod
Mar 19 14:49:07.242: INFO: Waiting for pod pod-configmaps-24874694-4a56-11e9-9c64-0a580af40204 to disappear
Mar 19 14:49:07.244: INFO: Pod pod-configmaps-24874694-4a56-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:49:07.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r8lqf" for this suite.
Mar 19 14:49:13.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:49:13.287: INFO: namespace: e2e-tests-configmap-r8lqf, resource: bindings, ignored listing per whitelist
Mar 19 14:49:13.327: INFO: namespace e2e-tests-configmap-r8lqf deletion completed in 6.079658325s

â€¢ [SLOW TEST:8.176 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:49:13.327: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-b9hlq
I0319 14:49:13.377042      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-b9hlq, replica count: 1
I0319 14:49:14.427590      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0319 14:49:15.427798      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 19 14:49:15.538: INFO: Created: latency-svc-fpgv6
Mar 19 14:49:15.547: INFO: Got endpoints: latency-svc-fpgv6 [19.651183ms]
Mar 19 14:49:15.579: INFO: Created: latency-svc-6nj2h
Mar 19 14:49:15.583: INFO: Got endpoints: latency-svc-6nj2h [35.572407ms]
Mar 19 14:49:15.601: INFO: Created: latency-svc-l5p8k
Mar 19 14:49:15.601: INFO: Got endpoints: latency-svc-l5p8k [54.029406ms]
Mar 19 14:49:15.612: INFO: Created: latency-svc-458kr
Mar 19 14:49:15.615: INFO: Got endpoints: latency-svc-458kr [66.645904ms]
Mar 19 14:49:15.629: INFO: Created: latency-svc-2mpmx
Mar 19 14:49:15.629: INFO: Got endpoints: latency-svc-2mpmx [79.487692ms]
Mar 19 14:49:15.648: INFO: Created: latency-svc-67bgh
Mar 19 14:49:15.650: INFO: Got endpoints: latency-svc-67bgh [97.444859ms]
Mar 19 14:49:15.664: INFO: Created: latency-svc-vbc4n
Mar 19 14:49:15.670: INFO: Got endpoints: latency-svc-vbc4n [119.815368ms]
Mar 19 14:49:15.686: INFO: Created: latency-svc-9rp6d
Mar 19 14:49:15.686: INFO: Got endpoints: latency-svc-9rp6d [135.268476ms]
Mar 19 14:49:15.697: INFO: Created: latency-svc-f986q
Mar 19 14:49:15.705: INFO: Got endpoints: latency-svc-f986q [153.760691ms]
Mar 19 14:49:15.721: INFO: Created: latency-svc-8xf4c
Mar 19 14:49:15.731: INFO: Got endpoints: latency-svc-8xf4c [179.678564ms]
Mar 19 14:49:15.739: INFO: Created: latency-svc-brgwq
Mar 19 14:49:15.744: INFO: Got endpoints: latency-svc-brgwq [192.015919ms]
Mar 19 14:49:15.755: INFO: Created: latency-svc-bvzl5
Mar 19 14:49:15.758: INFO: Got endpoints: latency-svc-bvzl5 [206.040951ms]
Mar 19 14:49:15.768: INFO: Created: latency-svc-284r4
Mar 19 14:49:15.776: INFO: Got endpoints: latency-svc-284r4 [228.016965ms]
Mar 19 14:49:15.791: INFO: Created: latency-svc-rhzmx
Mar 19 14:49:15.805: INFO: Got endpoints: latency-svc-rhzmx [251.902592ms]
Mar 19 14:49:15.811: INFO: Created: latency-svc-qxw64
Mar 19 14:49:15.816: INFO: Got endpoints: latency-svc-qxw64 [263.652416ms]
Mar 19 14:49:15.818: INFO: Created: latency-svc-lgh5g
Mar 19 14:49:15.820: INFO: Got endpoints: latency-svc-lgh5g [267.130258ms]
Mar 19 14:49:15.829: INFO: Created: latency-svc-658c5
Mar 19 14:49:15.835: INFO: Got endpoints: latency-svc-658c5 [251.43746ms]
Mar 19 14:49:15.840: INFO: Created: latency-svc-vhlfc
Mar 19 14:49:15.845: INFO: Got endpoints: latency-svc-vhlfc [243.850847ms]
Mar 19 14:49:15.858: INFO: Created: latency-svc-x2bbx
Mar 19 14:49:15.869: INFO: Got endpoints: latency-svc-x2bbx [253.850772ms]
Mar 19 14:49:15.879: INFO: Created: latency-svc-vqgmg
Mar 19 14:49:15.881: INFO: Got endpoints: latency-svc-vqgmg [252.353376ms]
Mar 19 14:49:15.895: INFO: Created: latency-svc-2j2gr
Mar 19 14:49:15.904: INFO: Got endpoints: latency-svc-2j2gr [253.813683ms]
Mar 19 14:49:15.914: INFO: Created: latency-svc-7rwrc
Mar 19 14:49:15.920: INFO: Got endpoints: latency-svc-7rwrc [249.640285ms]
Mar 19 14:49:15.933: INFO: Created: latency-svc-tvtv4
Mar 19 14:49:15.936: INFO: Got endpoints: latency-svc-tvtv4 [249.87055ms]
Mar 19 14:49:15.942: INFO: Created: latency-svc-6kkdw
Mar 19 14:49:15.945: INFO: Got endpoints: latency-svc-6kkdw [240.398891ms]
Mar 19 14:49:15.954: INFO: Created: latency-svc-jlw5r
Mar 19 14:49:15.960: INFO: Got endpoints: latency-svc-jlw5r [228.581462ms]
Mar 19 14:49:15.964: INFO: Created: latency-svc-j5nfh
Mar 19 14:49:15.968: INFO: Got endpoints: latency-svc-j5nfh [224.16103ms]
Mar 19 14:49:15.997: INFO: Created: latency-svc-smwk5
Mar 19 14:49:16.002: INFO: Got endpoints: latency-svc-smwk5 [243.28425ms]
Mar 19 14:49:16.009: INFO: Created: latency-svc-rn8fr
Mar 19 14:49:16.012: INFO: Got endpoints: latency-svc-rn8fr [235.757338ms]
Mar 19 14:49:16.024: INFO: Created: latency-svc-7gfbc
Mar 19 14:49:16.028: INFO: Got endpoints: latency-svc-7gfbc [222.862517ms]
Mar 19 14:49:16.039: INFO: Created: latency-svc-mfxxv
Mar 19 14:49:16.043: INFO: Got endpoints: latency-svc-mfxxv [226.180144ms]
Mar 19 14:49:16.048: INFO: Created: latency-svc-tjcq9
Mar 19 14:49:16.053: INFO: Got endpoints: latency-svc-tjcq9 [232.764973ms]
Mar 19 14:49:16.061: INFO: Created: latency-svc-g6jfd
Mar 19 14:49:16.067: INFO: Got endpoints: latency-svc-g6jfd [231.830961ms]
Mar 19 14:49:16.076: INFO: Created: latency-svc-dwnvc
Mar 19 14:49:16.087: INFO: Got endpoints: latency-svc-dwnvc [241.560837ms]
Mar 19 14:49:16.095: INFO: Created: latency-svc-gx9m9
Mar 19 14:49:16.102: INFO: Got endpoints: latency-svc-gx9m9 [233.120268ms]
Mar 19 14:49:16.112: INFO: Created: latency-svc-9k98p
Mar 19 14:49:16.116: INFO: Got endpoints: latency-svc-9k98p [28.91433ms]
Mar 19 14:49:16.129: INFO: Created: latency-svc-qg8mk
Mar 19 14:49:16.129: INFO: Got endpoints: latency-svc-qg8mk [247.566516ms]
Mar 19 14:49:16.139: INFO: Created: latency-svc-7gssm
Mar 19 14:49:16.142: INFO: Got endpoints: latency-svc-7gssm [238.51199ms]
Mar 19 14:49:16.154: INFO: Created: latency-svc-zgfng
Mar 19 14:49:16.157: INFO: Got endpoints: latency-svc-zgfng [236.899453ms]
Mar 19 14:49:16.170: INFO: Created: latency-svc-ls8js
Mar 19 14:49:16.170: INFO: Got endpoints: latency-svc-ls8js [233.751831ms]
Mar 19 14:49:16.181: INFO: Created: latency-svc-vmbmd
Mar 19 14:49:16.186: INFO: Got endpoints: latency-svc-vmbmd [240.122942ms]
Mar 19 14:49:16.209: INFO: Created: latency-svc-fpmlp
Mar 19 14:49:16.216: INFO: Got endpoints: latency-svc-fpmlp [255.904683ms]
Mar 19 14:49:16.262: INFO: Created: latency-svc-24rnh
Mar 19 14:49:16.262: INFO: Got endpoints: latency-svc-24rnh [293.519023ms]
Mar 19 14:49:16.278: INFO: Created: latency-svc-hbb85
Mar 19 14:49:16.342: INFO: Got endpoints: latency-svc-hbb85 [340.244165ms]
Mar 19 14:49:16.355: INFO: Created: latency-svc-t44dj
Mar 19 14:49:16.383: INFO: Got endpoints: latency-svc-t44dj [370.399501ms]
Mar 19 14:49:16.396: INFO: Created: latency-svc-f6pvh
Mar 19 14:49:16.398: INFO: Got endpoints: latency-svc-f6pvh [369.851229ms]
Mar 19 14:49:16.423: INFO: Created: latency-svc-q8j88
Mar 19 14:49:16.427: INFO: Got endpoints: latency-svc-q8j88 [384.51131ms]
Mar 19 14:49:16.432: INFO: Created: latency-svc-mhnc9
Mar 19 14:49:16.435: INFO: Got endpoints: latency-svc-mhnc9 [381.808883ms]
Mar 19 14:49:16.454: INFO: Created: latency-svc-tnlbs
Mar 19 14:49:16.455: INFO: Got endpoints: latency-svc-tnlbs [388.008258ms]
Mar 19 14:49:16.473: INFO: Created: latency-svc-xssh8
Mar 19 14:49:16.488: INFO: Created: latency-svc-227tl
Mar 19 14:49:16.493: INFO: Got endpoints: latency-svc-xssh8 [391.119106ms]
Mar 19 14:49:16.506: INFO: Created: latency-svc-59gzr
Mar 19 14:49:16.516: INFO: Created: latency-svc-2n8qc
Mar 19 14:49:16.537: INFO: Created: latency-svc-gpdn5
Mar 19 14:49:16.548: INFO: Created: latency-svc-84bch
Mar 19 14:49:16.552: INFO: Got endpoints: latency-svc-227tl [435.436909ms]
Mar 19 14:49:16.562: INFO: Created: latency-svc-n5csx
Mar 19 14:49:16.572: INFO: Created: latency-svc-kzpch
Mar 19 14:49:16.590: INFO: Created: latency-svc-gxscq
Mar 19 14:49:16.601: INFO: Got endpoints: latency-svc-59gzr [471.780361ms]
Mar 19 14:49:16.602: INFO: Created: latency-svc-zhmvf
Mar 19 14:49:16.620: INFO: Created: latency-svc-tzjwh
Mar 19 14:49:16.626: INFO: Created: latency-svc-9qwgm
Mar 19 14:49:16.640: INFO: Created: latency-svc-nrpcw
Mar 19 14:49:16.644: INFO: Got endpoints: latency-svc-2n8qc [501.883959ms]
Mar 19 14:49:16.664: INFO: Created: latency-svc-w8trr
Mar 19 14:49:16.681: INFO: Created: latency-svc-prcsq
Mar 19 14:49:16.704: INFO: Got endpoints: latency-svc-gpdn5 [547.194577ms]
Mar 19 14:49:16.717: INFO: Created: latency-svc-xgprp
Mar 19 14:49:16.725: INFO: Created: latency-svc-r4fwk
Mar 19 14:49:16.738: INFO: Created: latency-svc-kfnfh
Mar 19 14:49:16.744: INFO: Got endpoints: latency-svc-84bch [574.215045ms]
Mar 19 14:49:16.753: INFO: Created: latency-svc-b8c5w
Mar 19 14:49:16.764: INFO: Created: latency-svc-2k5d4
Mar 19 14:49:16.772: INFO: Created: latency-svc-bzr4f
Mar 19 14:49:16.793: INFO: Got endpoints: latency-svc-n5csx [607.451476ms]
Mar 19 14:49:16.814: INFO: Created: latency-svc-mxw9v
Mar 19 14:49:16.844: INFO: Got endpoints: latency-svc-kzpch [628.20096ms]
Mar 19 14:49:16.861: INFO: Created: latency-svc-86s8z
Mar 19 14:49:16.893: INFO: Got endpoints: latency-svc-gxscq [631.660626ms]
Mar 19 14:49:16.915: INFO: Created: latency-svc-r2g5z
Mar 19 14:49:16.944: INFO: Got endpoints: latency-svc-zhmvf [601.398131ms]
Mar 19 14:49:16.961: INFO: Created: latency-svc-xbdq5
Mar 19 14:49:16.996: INFO: Got endpoints: latency-svc-tzjwh [613.63639ms]
Mar 19 14:49:17.011: INFO: Created: latency-svc-gb2st
Mar 19 14:49:17.043: INFO: Got endpoints: latency-svc-9qwgm [644.849056ms]
Mar 19 14:49:17.058: INFO: Created: latency-svc-hczqx
Mar 19 14:49:17.093: INFO: Got endpoints: latency-svc-nrpcw [665.572433ms]
Mar 19 14:49:17.103: INFO: Created: latency-svc-c87cb
Mar 19 14:49:17.144: INFO: Got endpoints: latency-svc-w8trr [708.987594ms]
Mar 19 14:49:17.156: INFO: Created: latency-svc-f6gw9
Mar 19 14:49:17.194: INFO: Got endpoints: latency-svc-prcsq [738.460402ms]
Mar 19 14:49:17.211: INFO: Created: latency-svc-k98bs
Mar 19 14:49:17.243: INFO: Got endpoints: latency-svc-xgprp [750.016371ms]
Mar 19 14:49:17.258: INFO: Created: latency-svc-zvgjw
Mar 19 14:49:17.293: INFO: Got endpoints: latency-svc-r4fwk [741.676644ms]
Mar 19 14:49:17.312: INFO: Created: latency-svc-z9cf8
Mar 19 14:49:17.344: INFO: Got endpoints: latency-svc-kfnfh [743.022806ms]
Mar 19 14:49:17.356: INFO: Created: latency-svc-449hl
Mar 19 14:49:17.393: INFO: Got endpoints: latency-svc-b8c5w [749.013918ms]
Mar 19 14:49:17.415: INFO: Created: latency-svc-tfbcv
Mar 19 14:49:17.445: INFO: Got endpoints: latency-svc-2k5d4 [740.79729ms]
Mar 19 14:49:17.460: INFO: Created: latency-svc-h5zwj
Mar 19 14:49:17.496: INFO: Got endpoints: latency-svc-bzr4f [752.10634ms]
Mar 19 14:49:17.525: INFO: Created: latency-svc-z486w
Mar 19 14:49:17.544: INFO: Got endpoints: latency-svc-mxw9v [750.235867ms]
Mar 19 14:49:17.566: INFO: Created: latency-svc-5fxf7
Mar 19 14:49:17.593: INFO: Got endpoints: latency-svc-86s8z [747.435039ms]
Mar 19 14:49:17.610: INFO: Created: latency-svc-rbgsp
Mar 19 14:49:17.642: INFO: Got endpoints: latency-svc-r2g5z [748.789139ms]
Mar 19 14:49:17.659: INFO: Created: latency-svc-jb9sc
Mar 19 14:49:17.694: INFO: Got endpoints: latency-svc-xbdq5 [749.878108ms]
Mar 19 14:49:17.709: INFO: Created: latency-svc-pfrqd
Mar 19 14:49:17.743: INFO: Got endpoints: latency-svc-gb2st [746.356175ms]
Mar 19 14:49:17.757: INFO: Created: latency-svc-lgq4d
Mar 19 14:49:17.793: INFO: Got endpoints: latency-svc-hczqx [750.045444ms]
Mar 19 14:49:17.809: INFO: Created: latency-svc-f6qgp
Mar 19 14:49:17.843: INFO: Got endpoints: latency-svc-c87cb [749.896209ms]
Mar 19 14:49:17.860: INFO: Created: latency-svc-x8mj7
Mar 19 14:49:17.897: INFO: Got endpoints: latency-svc-f6gw9 [752.732968ms]
Mar 19 14:49:17.914: INFO: Created: latency-svc-fb8gk
Mar 19 14:49:17.945: INFO: Got endpoints: latency-svc-k98bs [751.523228ms]
Mar 19 14:49:17.963: INFO: Created: latency-svc-5hh9h
Mar 19 14:49:17.997: INFO: Got endpoints: latency-svc-zvgjw [753.516159ms]
Mar 19 14:49:18.014: INFO: Created: latency-svc-ns4r2
Mar 19 14:49:18.045: INFO: Got endpoints: latency-svc-z9cf8 [751.40233ms]
Mar 19 14:49:18.063: INFO: Created: latency-svc-rx4mc
Mar 19 14:49:18.097: INFO: Got endpoints: latency-svc-449hl [752.746034ms]
Mar 19 14:49:18.108: INFO: Created: latency-svc-5lrvr
Mar 19 14:49:18.142: INFO: Got endpoints: latency-svc-tfbcv [749.22296ms]
Mar 19 14:49:18.157: INFO: Created: latency-svc-gm6rn
Mar 19 14:49:18.197: INFO: Got endpoints: latency-svc-h5zwj [751.704194ms]
Mar 19 14:49:18.213: INFO: Created: latency-svc-24t98
Mar 19 14:49:18.245: INFO: Got endpoints: latency-svc-z486w [748.78195ms]
Mar 19 14:49:18.261: INFO: Created: latency-svc-pm6mk
Mar 19 14:49:18.294: INFO: Got endpoints: latency-svc-5fxf7 [750.310673ms]
Mar 19 14:49:18.309: INFO: Created: latency-svc-ql4t2
Mar 19 14:49:18.343: INFO: Got endpoints: latency-svc-rbgsp [749.971838ms]
Mar 19 14:49:18.358: INFO: Created: latency-svc-fljjf
Mar 19 14:49:18.394: INFO: Got endpoints: latency-svc-jb9sc [751.984326ms]
Mar 19 14:49:18.408: INFO: Created: latency-svc-8mzpr
Mar 19 14:49:18.443: INFO: Got endpoints: latency-svc-pfrqd [749.302382ms]
Mar 19 14:49:18.461: INFO: Created: latency-svc-lqmj9
Mar 19 14:49:18.494: INFO: Got endpoints: latency-svc-lgq4d [751.067791ms]
Mar 19 14:49:18.517: INFO: Created: latency-svc-g99wh
Mar 19 14:49:18.543: INFO: Got endpoints: latency-svc-f6qgp [750.1265ms]
Mar 19 14:49:18.570: INFO: Created: latency-svc-2hs8f
Mar 19 14:49:18.593: INFO: Got endpoints: latency-svc-x8mj7 [750.629353ms]
Mar 19 14:49:18.613: INFO: Created: latency-svc-s6d6j
Mar 19 14:49:18.645: INFO: Got endpoints: latency-svc-fb8gk [748.133763ms]
Mar 19 14:49:18.665: INFO: Created: latency-svc-9z72h
Mar 19 14:49:18.693: INFO: Got endpoints: latency-svc-5hh9h [747.870364ms]
Mar 19 14:49:18.714: INFO: Created: latency-svc-pfv4h
Mar 19 14:49:18.744: INFO: Got endpoints: latency-svc-ns4r2 [746.578119ms]
Mar 19 14:49:18.761: INFO: Created: latency-svc-t7jnw
Mar 19 14:49:18.797: INFO: Got endpoints: latency-svc-rx4mc [751.900824ms]
Mar 19 14:49:18.825: INFO: Created: latency-svc-klwwp
Mar 19 14:49:18.844: INFO: Got endpoints: latency-svc-5lrvr [747.101016ms]
Mar 19 14:49:18.860: INFO: Created: latency-svc-qkmxd
Mar 19 14:49:18.894: INFO: Got endpoints: latency-svc-gm6rn [750.931819ms]
Mar 19 14:49:18.909: INFO: Created: latency-svc-jhfwv
Mar 19 14:49:18.945: INFO: Got endpoints: latency-svc-24t98 [747.647858ms]
Mar 19 14:49:18.963: INFO: Created: latency-svc-db2f5
Mar 19 14:49:18.993: INFO: Got endpoints: latency-svc-pm6mk [747.727762ms]
Mar 19 14:49:19.012: INFO: Created: latency-svc-z8rsk
Mar 19 14:49:19.042: INFO: Got endpoints: latency-svc-ql4t2 [748.48169ms]
Mar 19 14:49:19.060: INFO: Created: latency-svc-mwlt2
Mar 19 14:49:19.094: INFO: Got endpoints: latency-svc-fljjf [750.509232ms]
Mar 19 14:49:19.108: INFO: Created: latency-svc-5hbfw
Mar 19 14:49:19.145: INFO: Got endpoints: latency-svc-8mzpr [750.428408ms]
Mar 19 14:49:19.157: INFO: Created: latency-svc-6gwjv
Mar 19 14:49:19.193: INFO: Got endpoints: latency-svc-lqmj9 [749.969763ms]
Mar 19 14:49:19.210: INFO: Created: latency-svc-rngnc
Mar 19 14:49:19.242: INFO: Got endpoints: latency-svc-g99wh [748.379732ms]
Mar 19 14:49:19.256: INFO: Created: latency-svc-jmvk8
Mar 19 14:49:19.293: INFO: Got endpoints: latency-svc-2hs8f [749.924298ms]
Mar 19 14:49:19.308: INFO: Created: latency-svc-td8qv
Mar 19 14:49:19.344: INFO: Got endpoints: latency-svc-s6d6j [750.390188ms]
Mar 19 14:49:19.404: INFO: Created: latency-svc-2fqpf
Mar 19 14:49:19.405: INFO: Got endpoints: latency-svc-9z72h [760.253574ms]
Mar 19 14:49:19.444: INFO: Created: latency-svc-v5ptf
Mar 19 14:49:19.446: INFO: Got endpoints: latency-svc-pfv4h [752.347212ms]
Mar 19 14:49:19.480: INFO: Created: latency-svc-9dmx4
Mar 19 14:49:19.493: INFO: Got endpoints: latency-svc-t7jnw [749.336624ms]
Mar 19 14:49:19.510: INFO: Created: latency-svc-cgcn7
Mar 19 14:49:19.543: INFO: Got endpoints: latency-svc-klwwp [746.297353ms]
Mar 19 14:49:19.559: INFO: Created: latency-svc-97c5k
Mar 19 14:49:19.594: INFO: Got endpoints: latency-svc-qkmxd [750.387058ms]
Mar 19 14:49:19.616: INFO: Created: latency-svc-6jpgq
Mar 19 14:49:19.643: INFO: Got endpoints: latency-svc-jhfwv [749.355204ms]
Mar 19 14:49:19.680: INFO: Created: latency-svc-qsv45
Mar 19 14:49:19.693: INFO: Got endpoints: latency-svc-db2f5 [747.552423ms]
Mar 19 14:49:19.710: INFO: Created: latency-svc-kpxhp
Mar 19 14:49:19.744: INFO: Got endpoints: latency-svc-z8rsk [750.31354ms]
Mar 19 14:49:19.756: INFO: Created: latency-svc-2j422
Mar 19 14:49:19.796: INFO: Got endpoints: latency-svc-mwlt2 [752.968815ms]
Mar 19 14:49:19.808: INFO: Created: latency-svc-2qbsq
Mar 19 14:49:19.843: INFO: Got endpoints: latency-svc-5hbfw [749.3758ms]
Mar 19 14:49:19.857: INFO: Created: latency-svc-v2s79
Mar 19 14:49:19.893: INFO: Got endpoints: latency-svc-6gwjv [748.158575ms]
Mar 19 14:49:19.908: INFO: Created: latency-svc-8bhms
Mar 19 14:49:19.948: INFO: Got endpoints: latency-svc-rngnc [754.545543ms]
Mar 19 14:49:19.965: INFO: Created: latency-svc-jp9r5
Mar 19 14:49:19.993: INFO: Got endpoints: latency-svc-jmvk8 [750.247034ms]
Mar 19 14:49:20.008: INFO: Created: latency-svc-n8pdf
Mar 19 14:49:20.043: INFO: Got endpoints: latency-svc-td8qv [749.591275ms]
Mar 19 14:49:20.065: INFO: Created: latency-svc-psv4f
Mar 19 14:49:20.094: INFO: Got endpoints: latency-svc-2fqpf [750.2082ms]
Mar 19 14:49:20.108: INFO: Created: latency-svc-2sf24
Mar 19 14:49:20.148: INFO: Got endpoints: latency-svc-v5ptf [742.775189ms]
Mar 19 14:49:20.169: INFO: Created: latency-svc-2b9fw
Mar 19 14:49:20.194: INFO: Got endpoints: latency-svc-9dmx4 [748.764743ms]
Mar 19 14:49:20.214: INFO: Created: latency-svc-llgrl
Mar 19 14:49:20.249: INFO: Got endpoints: latency-svc-cgcn7 [755.396947ms]
Mar 19 14:49:20.261: INFO: Created: latency-svc-scl4j
Mar 19 14:49:20.293: INFO: Got endpoints: latency-svc-97c5k [749.807656ms]
Mar 19 14:49:20.310: INFO: Created: latency-svc-pz5kb
Mar 19 14:49:20.344: INFO: Got endpoints: latency-svc-6jpgq [749.195678ms]
Mar 19 14:49:20.364: INFO: Created: latency-svc-ntz2k
Mar 19 14:49:20.393: INFO: Got endpoints: latency-svc-qsv45 [749.701422ms]
Mar 19 14:49:20.406: INFO: Created: latency-svc-kdxdv
Mar 19 14:49:20.444: INFO: Got endpoints: latency-svc-kpxhp [751.5912ms]
Mar 19 14:49:20.455: INFO: Created: latency-svc-wsvlp
Mar 19 14:49:20.493: INFO: Got endpoints: latency-svc-2j422 [748.955205ms]
Mar 19 14:49:20.511: INFO: Created: latency-svc-vvdzp
Mar 19 14:49:20.543: INFO: Got endpoints: latency-svc-2qbsq [747.047796ms]
Mar 19 14:49:20.556: INFO: Created: latency-svc-svplf
Mar 19 14:49:20.594: INFO: Got endpoints: latency-svc-v2s79 [751.019291ms]
Mar 19 14:49:20.607: INFO: Created: latency-svc-gsmsx
Mar 19 14:49:20.643: INFO: Got endpoints: latency-svc-8bhms [749.409753ms]
Mar 19 14:49:20.655: INFO: Created: latency-svc-wptgr
Mar 19 14:49:20.693: INFO: Got endpoints: latency-svc-jp9r5 [745.363687ms]
Mar 19 14:49:20.709: INFO: Created: latency-svc-kc7zk
Mar 19 14:49:20.743: INFO: Got endpoints: latency-svc-n8pdf [749.686412ms]
Mar 19 14:49:20.757: INFO: Created: latency-svc-qz64d
Mar 19 14:49:20.793: INFO: Got endpoints: latency-svc-psv4f [750.044062ms]
Mar 19 14:49:20.826: INFO: Created: latency-svc-x2g4w
Mar 19 14:49:20.844: INFO: Got endpoints: latency-svc-2sf24 [749.401128ms]
Mar 19 14:49:20.858: INFO: Created: latency-svc-qd65c
Mar 19 14:49:20.893: INFO: Got endpoints: latency-svc-2b9fw [744.648476ms]
Mar 19 14:49:20.909: INFO: Created: latency-svc-dj9zw
Mar 19 14:49:20.943: INFO: Got endpoints: latency-svc-llgrl [748.035135ms]
Mar 19 14:49:20.967: INFO: Created: latency-svc-wnqkv
Mar 19 14:49:20.997: INFO: Got endpoints: latency-svc-scl4j [748.444605ms]
Mar 19 14:49:21.013: INFO: Created: latency-svc-qf8zn
Mar 19 14:49:21.044: INFO: Got endpoints: latency-svc-pz5kb [750.516403ms]
Mar 19 14:49:21.054: INFO: Created: latency-svc-4p8ms
Mar 19 14:49:21.096: INFO: Got endpoints: latency-svc-ntz2k [752.063754ms]
Mar 19 14:49:21.109: INFO: Created: latency-svc-92d5d
Mar 19 14:49:21.147: INFO: Got endpoints: latency-svc-kdxdv [753.776413ms]
Mar 19 14:49:21.162: INFO: Created: latency-svc-f2g8g
Mar 19 14:49:21.205: INFO: Got endpoints: latency-svc-wsvlp [760.43376ms]
Mar 19 14:49:21.225: INFO: Created: latency-svc-9wr8k
Mar 19 14:49:21.244: INFO: Got endpoints: latency-svc-vvdzp [751.47932ms]
Mar 19 14:49:21.259: INFO: Created: latency-svc-6t7x9
Mar 19 14:49:21.295: INFO: Got endpoints: latency-svc-svplf [752.434342ms]
Mar 19 14:49:21.322: INFO: Created: latency-svc-5qwz6
Mar 19 14:49:21.343: INFO: Got endpoints: latency-svc-gsmsx [748.923621ms]
Mar 19 14:49:21.361: INFO: Created: latency-svc-cqcnr
Mar 19 14:49:21.393: INFO: Got endpoints: latency-svc-wptgr [750.452558ms]
Mar 19 14:49:21.410: INFO: Created: latency-svc-99989
Mar 19 14:49:21.443: INFO: Got endpoints: latency-svc-kc7zk [750.063867ms]
Mar 19 14:49:21.458: INFO: Created: latency-svc-v46tb
Mar 19 14:49:21.493: INFO: Got endpoints: latency-svc-qz64d [750.555182ms]
Mar 19 14:49:21.511: INFO: Created: latency-svc-dqbxz
Mar 19 14:49:21.543: INFO: Got endpoints: latency-svc-x2g4w [749.827614ms]
Mar 19 14:49:21.558: INFO: Created: latency-svc-rvx5x
Mar 19 14:49:21.593: INFO: Got endpoints: latency-svc-qd65c [748.940591ms]
Mar 19 14:49:21.609: INFO: Created: latency-svc-r5xqv
Mar 19 14:49:21.644: INFO: Got endpoints: latency-svc-dj9zw [751.221279ms]
Mar 19 14:49:21.666: INFO: Created: latency-svc-dqvc9
Mar 19 14:49:21.693: INFO: Got endpoints: latency-svc-wnqkv [750.116318ms]
Mar 19 14:49:21.712: INFO: Created: latency-svc-d7lld
Mar 19 14:49:21.744: INFO: Got endpoints: latency-svc-qf8zn [746.29307ms]
Mar 19 14:49:21.763: INFO: Created: latency-svc-l9ftv
Mar 19 14:49:21.797: INFO: Got endpoints: latency-svc-4p8ms [753.435087ms]
Mar 19 14:49:21.809: INFO: Created: latency-svc-qkzjc
Mar 19 14:49:21.844: INFO: Got endpoints: latency-svc-92d5d [748.024934ms]
Mar 19 14:49:21.859: INFO: Created: latency-svc-hx295
Mar 19 14:49:21.897: INFO: Got endpoints: latency-svc-f2g8g [748.595651ms]
Mar 19 14:49:21.913: INFO: Created: latency-svc-9x6sg
Mar 19 14:49:21.943: INFO: Got endpoints: latency-svc-9wr8k [737.680286ms]
Mar 19 14:49:21.963: INFO: Created: latency-svc-g2264
Mar 19 14:49:21.993: INFO: Got endpoints: latency-svc-6t7x9 [748.271124ms]
Mar 19 14:49:22.015: INFO: Created: latency-svc-4z55p
Mar 19 14:49:22.043: INFO: Got endpoints: latency-svc-5qwz6 [747.646982ms]
Mar 19 14:49:22.066: INFO: Created: latency-svc-75f4v
Mar 19 14:49:22.101: INFO: Got endpoints: latency-svc-cqcnr [758.201058ms]
Mar 19 14:49:22.126: INFO: Created: latency-svc-k7mnr
Mar 19 14:49:22.148: INFO: Got endpoints: latency-svc-99989 [754.389262ms]
Mar 19 14:49:22.160: INFO: Created: latency-svc-7f65c
Mar 19 14:49:22.194: INFO: Got endpoints: latency-svc-v46tb [751.183406ms]
Mar 19 14:49:22.207: INFO: Created: latency-svc-k7rxb
Mar 19 14:49:22.246: INFO: Got endpoints: latency-svc-dqbxz [752.322537ms]
Mar 19 14:49:22.265: INFO: Created: latency-svc-t62bk
Mar 19 14:49:22.293: INFO: Got endpoints: latency-svc-rvx5x [750.431146ms]
Mar 19 14:49:22.308: INFO: Created: latency-svc-qvcjk
Mar 19 14:49:22.346: INFO: Got endpoints: latency-svc-r5xqv [753.19358ms]
Mar 19 14:49:22.360: INFO: Created: latency-svc-nq688
Mar 19 14:49:22.392: INFO: Got endpoints: latency-svc-dqvc9 [747.15443ms]
Mar 19 14:49:22.408: INFO: Created: latency-svc-7hrmn
Mar 19 14:49:22.446: INFO: Got endpoints: latency-svc-d7lld [752.735681ms]
Mar 19 14:49:22.470: INFO: Created: latency-svc-dcf8t
Mar 19 14:49:22.498: INFO: Got endpoints: latency-svc-l9ftv [751.41557ms]
Mar 19 14:49:22.511: INFO: Created: latency-svc-zfspl
Mar 19 14:49:22.549: INFO: Got endpoints: latency-svc-qkzjc [751.353559ms]
Mar 19 14:49:22.581: INFO: Created: latency-svc-8xgbd
Mar 19 14:49:22.593: INFO: Got endpoints: latency-svc-hx295 [745.50674ms]
Mar 19 14:49:22.615: INFO: Created: latency-svc-8rdks
Mar 19 14:49:22.646: INFO: Got endpoints: latency-svc-9x6sg [744.908816ms]
Mar 19 14:49:22.665: INFO: Created: latency-svc-wrzzp
Mar 19 14:49:22.693: INFO: Got endpoints: latency-svc-g2264 [746.625342ms]
Mar 19 14:49:22.711: INFO: Created: latency-svc-5th5k
Mar 19 14:49:22.743: INFO: Got endpoints: latency-svc-4z55p [746.459184ms]
Mar 19 14:49:22.759: INFO: Created: latency-svc-5mfxw
Mar 19 14:49:22.793: INFO: Got endpoints: latency-svc-75f4v [750.350166ms]
Mar 19 14:49:22.817: INFO: Created: latency-svc-vvd46
Mar 19 14:49:22.843: INFO: Got endpoints: latency-svc-k7mnr [742.036746ms]
Mar 19 14:49:22.864: INFO: Created: latency-svc-8nkjj
Mar 19 14:49:22.895: INFO: Got endpoints: latency-svc-7f65c [747.471734ms]
Mar 19 14:49:22.911: INFO: Created: latency-svc-ndggb
Mar 19 14:49:22.944: INFO: Got endpoints: latency-svc-k7rxb [749.487158ms]
Mar 19 14:49:22.960: INFO: Created: latency-svc-dh8k2
Mar 19 14:49:22.993: INFO: Got endpoints: latency-svc-t62bk [747.509253ms]
Mar 19 14:49:23.007: INFO: Created: latency-svc-qbvq8
Mar 19 14:49:23.043: INFO: Got endpoints: latency-svc-qvcjk [749.604805ms]
Mar 19 14:49:23.058: INFO: Created: latency-svc-qdwpz
Mar 19 14:49:23.094: INFO: Got endpoints: latency-svc-nq688 [747.907053ms]
Mar 19 14:49:23.108: INFO: Created: latency-svc-42zcj
Mar 19 14:49:23.143: INFO: Got endpoints: latency-svc-7hrmn [750.349015ms]
Mar 19 14:49:23.156: INFO: Created: latency-svc-dn67f
Mar 19 14:49:23.200: INFO: Got endpoints: latency-svc-dcf8t [752.557649ms]
Mar 19 14:49:23.212: INFO: Created: latency-svc-cbwsc
Mar 19 14:49:23.244: INFO: Got endpoints: latency-svc-zfspl [746.04717ms]
Mar 19 14:49:23.262: INFO: Created: latency-svc-642l9
Mar 19 14:49:23.295: INFO: Got endpoints: latency-svc-8xgbd [741.551117ms]
Mar 19 14:49:23.391: INFO: Got endpoints: latency-svc-8rdks [797.380806ms]
Mar 19 14:49:23.398: INFO: Created: latency-svc-hc5b5
Mar 19 14:49:23.399: INFO: Got endpoints: latency-svc-wrzzp [752.867919ms]
Mar 19 14:49:23.442: INFO: Created: latency-svc-5z2j7
Mar 19 14:49:23.444: INFO: Got endpoints: latency-svc-5th5k [751.225976ms]
Mar 19 14:49:23.496: INFO: Got endpoints: latency-svc-5mfxw [753.172056ms]
Mar 19 14:49:23.545: INFO: Got endpoints: latency-svc-vvd46 [751.447662ms]
Mar 19 14:49:23.596: INFO: Got endpoints: latency-svc-8nkjj [747.288246ms]
Mar 19 14:49:23.646: INFO: Got endpoints: latency-svc-ndggb [750.574386ms]
Mar 19 14:49:23.693: INFO: Got endpoints: latency-svc-dh8k2 [749.237037ms]
Mar 19 14:49:23.744: INFO: Got endpoints: latency-svc-qbvq8 [750.730568ms]
Mar 19 14:49:23.793: INFO: Got endpoints: latency-svc-qdwpz [749.981106ms]
Mar 19 14:49:23.844: INFO: Got endpoints: latency-svc-42zcj [749.570968ms]
Mar 19 14:49:23.894: INFO: Got endpoints: latency-svc-dn67f [750.76364ms]
Mar 19 14:49:23.947: INFO: Got endpoints: latency-svc-cbwsc [747.119324ms]
Mar 19 14:49:23.994: INFO: Got endpoints: latency-svc-642l9 [750.008155ms]
Mar 19 14:49:24.044: INFO: Got endpoints: latency-svc-hc5b5 [745.345737ms]
Mar 19 14:49:24.094: INFO: Got endpoints: latency-svc-5z2j7 [702.589622ms]
Mar 19 14:49:24.095: INFO: Latencies: [28.91433ms 35.572407ms 54.029406ms 66.645904ms 79.487692ms 97.444859ms 119.815368ms 135.268476ms 153.760691ms 179.678564ms 192.015919ms 206.040951ms 222.862517ms 224.16103ms 226.180144ms 228.016965ms 228.581462ms 231.830961ms 232.764973ms 233.120268ms 233.751831ms 235.757338ms 236.899453ms 238.51199ms 240.122942ms 240.398891ms 241.560837ms 243.28425ms 243.850847ms 247.566516ms 249.640285ms 249.87055ms 251.43746ms 251.902592ms 252.353376ms 253.813683ms 253.850772ms 255.904683ms 263.652416ms 267.130258ms 293.519023ms 340.244165ms 369.851229ms 370.399501ms 381.808883ms 384.51131ms 388.008258ms 391.119106ms 435.436909ms 471.780361ms 501.883959ms 547.194577ms 574.215045ms 601.398131ms 607.451476ms 613.63639ms 628.20096ms 631.660626ms 644.849056ms 665.572433ms 702.589622ms 708.987594ms 737.680286ms 738.460402ms 740.79729ms 741.551117ms 741.676644ms 742.036746ms 742.775189ms 743.022806ms 744.648476ms 744.908816ms 745.345737ms 745.363687ms 745.50674ms 746.04717ms 746.29307ms 746.297353ms 746.356175ms 746.459184ms 746.578119ms 746.625342ms 747.047796ms 747.101016ms 747.119324ms 747.15443ms 747.288246ms 747.435039ms 747.471734ms 747.509253ms 747.552423ms 747.646982ms 747.647858ms 747.727762ms 747.870364ms 747.907053ms 748.024934ms 748.035135ms 748.133763ms 748.158575ms 748.271124ms 748.379732ms 748.444605ms 748.48169ms 748.595651ms 748.764743ms 748.78195ms 748.789139ms 748.923621ms 748.940591ms 748.955205ms 749.013918ms 749.195678ms 749.22296ms 749.237037ms 749.302382ms 749.336624ms 749.355204ms 749.3758ms 749.401128ms 749.409753ms 749.487158ms 749.570968ms 749.591275ms 749.604805ms 749.686412ms 749.701422ms 749.807656ms 749.827614ms 749.878108ms 749.896209ms 749.924298ms 749.969763ms 749.971838ms 749.981106ms 750.008155ms 750.016371ms 750.044062ms 750.045444ms 750.063867ms 750.116318ms 750.1265ms 750.2082ms 750.235867ms 750.247034ms 750.310673ms 750.31354ms 750.349015ms 750.350166ms 750.387058ms 750.390188ms 750.428408ms 750.431146ms 750.452558ms 750.509232ms 750.516403ms 750.555182ms 750.574386ms 750.629353ms 750.730568ms 750.76364ms 750.931819ms 751.019291ms 751.067791ms 751.183406ms 751.221279ms 751.225976ms 751.353559ms 751.40233ms 751.41557ms 751.447662ms 751.47932ms 751.523228ms 751.5912ms 751.704194ms 751.900824ms 751.984326ms 752.063754ms 752.10634ms 752.322537ms 752.347212ms 752.434342ms 752.557649ms 752.732968ms 752.735681ms 752.746034ms 752.867919ms 752.968815ms 753.172056ms 753.19358ms 753.435087ms 753.516159ms 753.776413ms 754.389262ms 754.545543ms 755.396947ms 758.201058ms 760.253574ms 760.43376ms 797.380806ms]
Mar 19 14:49:24.095: INFO: 50 %ile: 748.271124ms
Mar 19 14:49:24.095: INFO: 90 %ile: 752.347212ms
Mar 19 14:49:24.098: INFO: 99 %ile: 760.43376ms
Mar 19 14:49:24.098: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:49:24.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-b9hlq" for this suite.
Mar 19 14:49:42.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:49:42.165: INFO: namespace: e2e-tests-svc-latency-b9hlq, resource: bindings, ignored listing per whitelist
Mar 19 14:49:42.182: INFO: namespace e2e-tests-svc-latency-b9hlq deletion completed in 18.076972283s

â€¢ [SLOW TEST:28.856 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:49:42.185: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:49:42.239: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:49:44.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6pj98" for this suite.
Mar 19 14:50:22.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:50:22.315: INFO: namespace: e2e-tests-pods-6pj98, resource: bindings, ignored listing per whitelist
Mar 19 14:50:22.359: INFO: namespace e2e-tests-pods-6pj98 deletion completed in 38.08544778s

â€¢ [SLOW TEST:40.175 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:50:22.360: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-xlxh
STEP: Creating a pod to test atomic-volume-subpath
Mar 19 14:50:22.461: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xlxh" in namespace "e2e-tests-subpath-fj7n4" to be "success or failure"
Mar 19 14:50:22.466: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Pending", Reason="", readiness=false. Elapsed: 4.936712ms
Mar 19 14:50:24.469: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007746009s
Mar 19 14:50:26.472: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Running", Reason="", readiness=false. Elapsed: 4.010915755s
Mar 19 14:50:28.475: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Running", Reason="", readiness=false. Elapsed: 6.013249417s
Mar 19 14:50:30.477: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Running", Reason="", readiness=false. Elapsed: 8.015530681s
Mar 19 14:50:32.480: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Running", Reason="", readiness=false. Elapsed: 10.018431933s
Mar 19 14:50:34.482: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Running", Reason="", readiness=false. Elapsed: 12.020923292s
Mar 19 14:50:36.485: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Running", Reason="", readiness=false. Elapsed: 14.02399558s
Mar 19 14:50:38.490: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Running", Reason="", readiness=false. Elapsed: 16.028464642s
Mar 19 14:50:40.493: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Running", Reason="", readiness=false. Elapsed: 18.031426082s
Mar 19 14:50:42.496: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Running", Reason="", readiness=false. Elapsed: 20.034975485s
Mar 19 14:50:44.501: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Running", Reason="", readiness=false. Elapsed: 22.039710034s
Mar 19 14:50:46.504: INFO: Pod "pod-subpath-test-configmap-xlxh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.042546572s
STEP: Saw pod success
Mar 19 14:50:46.504: INFO: Pod "pod-subpath-test-configmap-xlxh" satisfied condition "success or failure"
Mar 19 14:50:46.507: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-subpath-test-configmap-xlxh container test-container-subpath-configmap-xlxh: <nil>
STEP: delete the pod
Mar 19 14:50:46.537: INFO: Waiting for pod pod-subpath-test-configmap-xlxh to disappear
Mar 19 14:50:46.540: INFO: Pod pod-subpath-test-configmap-xlxh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xlxh
Mar 19 14:50:46.540: INFO: Deleting pod "pod-subpath-test-configmap-xlxh" in namespace "e2e-tests-subpath-fj7n4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:50:46.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-fj7n4" for this suite.
Mar 19 14:50:52.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:50:52.628: INFO: namespace: e2e-tests-subpath-fj7n4, resource: bindings, ignored listing per whitelist
Mar 19 14:50:52.630: INFO: namespace e2e-tests-subpath-fj7n4 deletion completed in 6.082072092s

â€¢ [SLOW TEST:30.269 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:50:52.630: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 19 14:50:52.695: INFO: PodSpec: initContainers in spec.initContainers
Mar 19 14:51:39.738: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6499c0ef-4a56-11e9-9c64-0a580af40204", GenerateName:"", Namespace:"e2e-tests-init-container-2kg4b", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-2kg4b/pods/pod-init-6499c0ef-4a56-11e9-9c64-0a580af40204", UID:"649a54ae-4a56-11e9-9b06-005056a45e5c", ResourceVersion:"18155", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688603852, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"695178126"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-gp964", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002522680), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gp964", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gp964", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gp964", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001b86938), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"essentialpks-conformance-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00242d140), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b86da0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b86dc0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001b86dc8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001b86dcc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688603852, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688603852, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688603852, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688603852, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.102.4", PodIP:"10.244.1.166", StartTime:(*v1.Time)(0xc00185d420), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00181c8c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00181c930)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://3955d10a98e394ae3eb94732b48e375f1a56b6b91a946c5f08ce49cc4c9893b0"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00185d4a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00185d460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:51:39.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-2kg4b" for this suite.
Mar 19 14:52:01.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:52:01.766: INFO: namespace: e2e-tests-init-container-2kg4b, resource: bindings, ignored listing per whitelist
Mar 19 14:52:01.812: INFO: namespace e2e-tests-init-container-2kg4b deletion completed in 22.068785397s

â€¢ [SLOW TEST:69.182 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:52:01.814: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Mar 19 14:52:01.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-977cj'
Mar 19 14:52:02.181: INFO: stderr: ""
Mar 19 14:52:02.181: INFO: stdout: "pod/pause created\n"
Mar 19 14:52:02.181: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 19 14:52:02.181: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-977cj" to be "running and ready"
Mar 19 14:52:02.188: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.199805ms
Mar 19 14:52:04.191: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.010553048s
Mar 19 14:52:04.191: INFO: Pod "pause" satisfied condition "running and ready"
Mar 19 14:52:04.192: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 19 14:52:04.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-977cj'
Mar 19 14:52:04.284: INFO: stderr: ""
Mar 19 14:52:04.284: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 19 14:52:04.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pod pause -L testing-label --namespace=e2e-tests-kubectl-977cj'
Mar 19 14:52:04.372: INFO: stderr: ""
Mar 19 14:52:04.373: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 19 14:52:04.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 label pods pause testing-label- --namespace=e2e-tests-kubectl-977cj'
Mar 19 14:52:04.460: INFO: stderr: ""
Mar 19 14:52:04.460: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 19 14:52:04.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pod pause -L testing-label --namespace=e2e-tests-kubectl-977cj'
Mar 19 14:52:04.534: INFO: stderr: ""
Mar 19 14:52:04.534: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Mar 19 14:52:04.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-977cj'
Mar 19 14:52:04.619: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 14:52:04.619: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 19 14:52:04.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-977cj'
Mar 19 14:52:04.711: INFO: stderr: "No resources found.\n"
Mar 19 14:52:04.711: INFO: stdout: ""
Mar 19 14:52:04.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -l name=pause --namespace=e2e-tests-kubectl-977cj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 19 14:52:04.794: INFO: stderr: ""
Mar 19 14:52:04.794: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:52:04.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-977cj" for this suite.
Mar 19 14:52:10.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:52:10.861: INFO: namespace: e2e-tests-kubectl-977cj, resource: bindings, ignored listing per whitelist
Mar 19 14:52:10.888: INFO: namespace e2e-tests-kubectl-977cj deletion completed in 6.08973706s

â€¢ [SLOW TEST:9.074 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:52:10.888: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-t8c2
STEP: Creating a pod to test atomic-volume-subpath
Mar 19 14:52:10.951: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-t8c2" in namespace "e2e-tests-subpath-gwj8m" to be "success or failure"
Mar 19 14:52:10.960: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.998791ms
Mar 19 14:52:12.963: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01194558s
Mar 19 14:52:14.965: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Running", Reason="", readiness=false. Elapsed: 4.014658718s
Mar 19 14:52:16.968: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Running", Reason="", readiness=false. Elapsed: 6.017845761s
Mar 19 14:52:18.972: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Running", Reason="", readiness=false. Elapsed: 8.021249855s
Mar 19 14:52:20.976: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Running", Reason="", readiness=false. Elapsed: 10.025240612s
Mar 19 14:52:22.986: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Running", Reason="", readiness=false. Elapsed: 12.035093701s
Mar 19 14:52:24.990: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Running", Reason="", readiness=false. Elapsed: 14.039921904s
Mar 19 14:52:26.993: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Running", Reason="", readiness=false. Elapsed: 16.042761134s
Mar 19 14:52:28.996: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Running", Reason="", readiness=false. Elapsed: 18.045425518s
Mar 19 14:52:30.998: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Running", Reason="", readiness=false. Elapsed: 20.047874458s
Mar 19 14:52:33.002: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Running", Reason="", readiness=false. Elapsed: 22.051640664s
Mar 19 14:52:35.005: INFO: Pod "pod-subpath-test-configmap-t8c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.054557354s
STEP: Saw pod success
Mar 19 14:52:35.005: INFO: Pod "pod-subpath-test-configmap-t8c2" satisfied condition "success or failure"
Mar 19 14:52:35.008: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-subpath-test-configmap-t8c2 container test-container-subpath-configmap-t8c2: <nil>
STEP: delete the pod
Mar 19 14:52:35.027: INFO: Waiting for pod pod-subpath-test-configmap-t8c2 to disappear
Mar 19 14:52:35.031: INFO: Pod pod-subpath-test-configmap-t8c2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-t8c2
Mar 19 14:52:35.031: INFO: Deleting pod "pod-subpath-test-configmap-t8c2" in namespace "e2e-tests-subpath-gwj8m"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:52:35.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-gwj8m" for this suite.
Mar 19 14:52:41.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:52:41.102: INFO: namespace: e2e-tests-subpath-gwj8m, resource: bindings, ignored listing per whitelist
Mar 19 14:52:41.126: INFO: namespace e2e-tests-subpath-gwj8m deletion completed in 6.088881492s

â€¢ [SLOW TEST:30.238 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:52:41.126: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:52:41.211: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a545c0e9-4a56-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-m8glj" to be "success or failure"
Mar 19 14:52:41.216: INFO: Pod "downwardapi-volume-a545c0e9-4a56-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 5.365472ms
Mar 19 14:52:43.219: INFO: Pod "downwardapi-volume-a545c0e9-4a56-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007877884s
STEP: Saw pod success
Mar 19 14:52:43.219: INFO: Pod "downwardapi-volume-a545c0e9-4a56-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:52:43.221: INFO: Trying to get logs from node essentialpks-conformance-3 pod downwardapi-volume-a545c0e9-4a56-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:52:43.236: INFO: Waiting for pod downwardapi-volume-a545c0e9-4a56-11e9-9c64-0a580af40204 to disappear
Mar 19 14:52:43.240: INFO: Pod downwardapi-volume-a545c0e9-4a56-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:52:43.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m8glj" for this suite.
Mar 19 14:52:49.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:52:49.329: INFO: namespace: e2e-tests-projected-m8glj, resource: bindings, ignored listing per whitelist
Mar 19 14:52:49.329: INFO: namespace e2e-tests-projected-m8glj deletion completed in 6.084340008s

â€¢ [SLOW TEST:8.203 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:52:49.329: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar 19 14:52:49.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 api-versions'
Mar 19 14:52:49.465: INFO: stderr: ""
Mar 19 14:52:49.465: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:52:49.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hl2f6" for this suite.
Mar 19 14:52:55.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:52:55.538: INFO: namespace: e2e-tests-kubectl-hl2f6, resource: bindings, ignored listing per whitelist
Mar 19 14:52:55.540: INFO: namespace e2e-tests-kubectl-hl2f6 deletion completed in 6.070653938s

â€¢ [SLOW TEST:6.211 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:52:55.541: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:52:55.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-x2qdm" for this suite.
Mar 19 14:53:01.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:53:01.669: INFO: namespace: e2e-tests-services-x2qdm, resource: bindings, ignored listing per whitelist
Mar 19 14:53:01.672: INFO: namespace e2e-tests-services-x2qdm deletion completed in 6.071168556s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:6.131 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:53:01.672: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b1817559-4a56-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:53:01.731: INFO: Waiting up to 5m0s for pod "pod-configmaps-b1821018-4a56-11e9-9c64-0a580af40204" in namespace "e2e-tests-configmap-r5hvz" to be "success or failure"
Mar 19 14:53:01.734: INFO: Pod "pod-configmaps-b1821018-4a56-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.420736ms
Mar 19 14:53:03.737: INFO: Pod "pod-configmaps-b1821018-4a56-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005922729s
STEP: Saw pod success
Mar 19 14:53:03.737: INFO: Pod "pod-configmaps-b1821018-4a56-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:53:03.739: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-configmaps-b1821018-4a56-11e9-9c64-0a580af40204 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 14:53:03.757: INFO: Waiting for pod pod-configmaps-b1821018-4a56-11e9-9c64-0a580af40204 to disappear
Mar 19 14:53:03.759: INFO: Pod pod-configmaps-b1821018-4a56-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:53:03.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r5hvz" for this suite.
Mar 19 14:53:09.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:53:09.820: INFO: namespace: e2e-tests-configmap-r5hvz, resource: bindings, ignored listing per whitelist
Mar 19 14:53:09.837: INFO: namespace e2e-tests-configmap-r5hvz deletion completed in 6.074781878s

â€¢ [SLOW TEST:8.165 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:53:09.837: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-tvf9c
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 19 14:53:09.892: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 19 14:53:27.972: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.172:8080/dial?request=hostName&protocol=http&host=10.244.2.148&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-tvf9c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:53:27.973: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:53:28.094: INFO: Waiting for endpoints: map[]
Mar 19 14:53:28.096: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.172:8080/dial?request=hostName&protocol=http&host=10.244.1.171&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-tvf9c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 19 14:53:28.097: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
Mar 19 14:53:28.219: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:53:28.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-tvf9c" for this suite.
Mar 19 14:53:50.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:53:50.264: INFO: namespace: e2e-tests-pod-network-test-tvf9c, resource: bindings, ignored listing per whitelist
Mar 19 14:53:50.301: INFO: namespace e2e-tests-pod-network-test-tvf9c deletion completed in 22.077988006s

â€¢ [SLOW TEST:40.463 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:53:50.301: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:53:50.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 version'
Mar 19 14:53:50.431: INFO: stderr: ""
Mar 19 14:53:50.431: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.4+vmware.1\", GitCommit:\"e36d55a400a393d66bee4f702908a77e859f099d\", GitTreeState:\"clean\", BuildDate:\"2019-03-14T16:35:11Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:53:50.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4xvmc" for this suite.
Mar 19 14:53:56.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:53:56.481: INFO: namespace: e2e-tests-kubectl-4xvmc, resource: bindings, ignored listing per whitelist
Mar 19 14:53:56.514: INFO: namespace e2e-tests-kubectl-4xvmc deletion completed in 6.079738498s

â€¢ [SLOW TEST:6.213 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:53:56.517: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d231aff4-4a56-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 14:53:56.571: INFO: Waiting up to 5m0s for pod "pod-secrets-d232338e-4a56-11e9-9c64-0a580af40204" in namespace "e2e-tests-secrets-86txd" to be "success or failure"
Mar 19 14:53:56.575: INFO: Pod "pod-secrets-d232338e-4a56-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.471531ms
Mar 19 14:53:58.577: INFO: Pod "pod-secrets-d232338e-4a56-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006088125s
STEP: Saw pod success
Mar 19 14:53:58.578: INFO: Pod "pod-secrets-d232338e-4a56-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:53:58.580: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-secrets-d232338e-4a56-11e9-9c64-0a580af40204 container secret-env-test: <nil>
STEP: delete the pod
Mar 19 14:53:58.597: INFO: Waiting for pod pod-secrets-d232338e-4a56-11e9-9c64-0a580af40204 to disappear
Mar 19 14:53:58.600: INFO: Pod pod-secrets-d232338e-4a56-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:53:58.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-86txd" for this suite.
Mar 19 14:54:04.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:54:04.629: INFO: namespace: e2e-tests-secrets-86txd, resource: bindings, ignored listing per whitelist
Mar 19 14:54:04.677: INFO: namespace e2e-tests-secrets-86txd deletion completed in 6.073927978s

â€¢ [SLOW TEST:8.160 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:54:04.678: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 14:54:06.771: INFO: Waiting up to 5m0s for pod "client-envvars-d8465258-4a56-11e9-9c64-0a580af40204" in namespace "e2e-tests-pods-4xz6w" to be "success or failure"
Mar 19 14:54:06.785: INFO: Pod "client-envvars-d8465258-4a56-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 13.720492ms
Mar 19 14:54:08.788: INFO: Pod "client-envvars-d8465258-4a56-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01677661s
STEP: Saw pod success
Mar 19 14:54:08.788: INFO: Pod "client-envvars-d8465258-4a56-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:54:08.790: INFO: Trying to get logs from node essentialpks-conformance-3 pod client-envvars-d8465258-4a56-11e9-9c64-0a580af40204 container env3cont: <nil>
STEP: delete the pod
Mar 19 14:54:08.816: INFO: Waiting for pod client-envvars-d8465258-4a56-11e9-9c64-0a580af40204 to disappear
Mar 19 14:54:08.818: INFO: Pod client-envvars-d8465258-4a56-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:54:08.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4xz6w" for this suite.
Mar 19 14:54:50.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:54:50.900: INFO: namespace: e2e-tests-pods-4xz6w, resource: bindings, ignored listing per whitelist
Mar 19 14:54:50.900: INFO: namespace e2e-tests-pods-4xz6w deletion completed in 42.077891938s

â€¢ [SLOW TEST:46.222 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:54:50.901: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 19 14:54:50.973: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f29dbdf6-4a56-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-sk2qj" to be "success or failure"
Mar 19 14:54:50.977: INFO: Pod "downwardapi-volume-f29dbdf6-4a56-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.789069ms
Mar 19 14:54:52.979: INFO: Pod "downwardapi-volume-f29dbdf6-4a56-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006145918s
STEP: Saw pod success
Mar 19 14:54:52.979: INFO: Pod "downwardapi-volume-f29dbdf6-4a56-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:54:52.982: INFO: Trying to get logs from node essentialpks-conformance-2 pod downwardapi-volume-f29dbdf6-4a56-11e9-9c64-0a580af40204 container client-container: <nil>
STEP: delete the pod
Mar 19 14:54:52.998: INFO: Waiting for pod downwardapi-volume-f29dbdf6-4a56-11e9-9c64-0a580af40204 to disappear
Mar 19 14:54:53.000: INFO: Pod downwardapi-volume-f29dbdf6-4a56-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:54:53.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sk2qj" for this suite.
Mar 19 14:54:59.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:54:59.042: INFO: namespace: e2e-tests-downward-api-sk2qj, resource: bindings, ignored listing per whitelist
Mar 19 14:54:59.074: INFO: namespace e2e-tests-downward-api-sk2qj deletion completed in 6.070711058s

â€¢ [SLOW TEST:8.173 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:54:59.074: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 19 14:54:59.135: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-cz2rt,SelfLink:/api/v1/namespaces/e2e-tests-watch-cz2rt/configmaps/e2e-watch-test-label-changed,UID:f77b98d9-4a56-11e9-9b06-005056a45e5c,ResourceVersion:18767,Generation:0,CreationTimestamp:2019-03-19 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 19 14:54:59.135: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-cz2rt,SelfLink:/api/v1/namespaces/e2e-tests-watch-cz2rt/configmaps/e2e-watch-test-label-changed,UID:f77b98d9-4a56-11e9-9b06-005056a45e5c,ResourceVersion:18768,Generation:0,CreationTimestamp:2019-03-19 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 19 14:54:59.135: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-cz2rt,SelfLink:/api/v1/namespaces/e2e-tests-watch-cz2rt/configmaps/e2e-watch-test-label-changed,UID:f77b98d9-4a56-11e9-9b06-005056a45e5c,ResourceVersion:18769,Generation:0,CreationTimestamp:2019-03-19 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 19 14:55:09.154: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-cz2rt,SelfLink:/api/v1/namespaces/e2e-tests-watch-cz2rt/configmaps/e2e-watch-test-label-changed,UID:f77b98d9-4a56-11e9-9b06-005056a45e5c,ResourceVersion:18785,Generation:0,CreationTimestamp:2019-03-19 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 19 14:55:09.154: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-cz2rt,SelfLink:/api/v1/namespaces/e2e-tests-watch-cz2rt/configmaps/e2e-watch-test-label-changed,UID:f77b98d9-4a56-11e9-9b06-005056a45e5c,ResourceVersion:18786,Generation:0,CreationTimestamp:2019-03-19 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 19 14:55:09.154: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-cz2rt,SelfLink:/api/v1/namespaces/e2e-tests-watch-cz2rt/configmaps/e2e-watch-test-label-changed,UID:f77b98d9-4a56-11e9-9b06-005056a45e5c,ResourceVersion:18787,Generation:0,CreationTimestamp:2019-03-19 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:55:09.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-cz2rt" for this suite.
Mar 19 14:55:15.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:55:15.182: INFO: namespace: e2e-tests-watch-cz2rt, resource: bindings, ignored listing per whitelist
Mar 19 14:55:15.226: INFO: namespace e2e-tests-watch-cz2rt deletion completed in 6.067963935s

â€¢ [SLOW TEST:16.151 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:55:15.226: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 14:55:15.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-bcgdf'
Mar 19 14:55:15.369: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 19 14:55:15.369: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Mar 19 14:55:15.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-bcgdf'
Mar 19 14:55:15.463: INFO: stderr: ""
Mar 19 14:55:15.463: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:55:15.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bcgdf" for this suite.
Mar 19 14:55:21.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:55:21.511: INFO: namespace: e2e-tests-kubectl-bcgdf, resource: bindings, ignored listing per whitelist
Mar 19 14:55:21.536: INFO: namespace e2e-tests-kubectl-bcgdf deletion completed in 6.069409383s

â€¢ [SLOW TEST:6.311 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:55:21.536: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 19 14:55:21.587: INFO: Waiting up to 5m0s for pod "downward-api-04de6278-4a57-11e9-9c64-0a580af40204" in namespace "e2e-tests-downward-api-9qq57" to be "success or failure"
Mar 19 14:55:21.594: INFO: Pod "downward-api-04de6278-4a57-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 6.574862ms
Mar 19 14:55:23.597: INFO: Pod "downward-api-04de6278-4a57-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009143825s
STEP: Saw pod success
Mar 19 14:55:23.597: INFO: Pod "downward-api-04de6278-4a57-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:55:23.599: INFO: Trying to get logs from node essentialpks-conformance-2 pod downward-api-04de6278-4a57-11e9-9c64-0a580af40204 container dapi-container: <nil>
STEP: delete the pod
Mar 19 14:55:23.611: INFO: Waiting for pod downward-api-04de6278-4a57-11e9-9c64-0a580af40204 to disappear
Mar 19 14:55:23.614: INFO: Pod downward-api-04de6278-4a57-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:55:23.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9qq57" for this suite.
Mar 19 14:55:29.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:55:29.656: INFO: namespace: e2e-tests-downward-api-9qq57, resource: bindings, ignored listing per whitelist
Mar 19 14:55:29.692: INFO: namespace e2e-tests-downward-api-9qq57 deletion completed in 6.075716922s

â€¢ [SLOW TEST:8.156 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:55:29.693: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 19 14:55:29.748: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:55:33.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mgffr" for this suite.
Mar 19 14:55:55.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:55:55.223: INFO: namespace: e2e-tests-init-container-mgffr, resource: bindings, ignored listing per whitelist
Mar 19 14:55:55.253: INFO: namespace e2e-tests-init-container-mgffr deletion completed in 22.065331655s

â€¢ [SLOW TEST:25.560 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:55:55.253: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:56:17.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-kfgcb" for this suite.
Mar 19 14:56:23.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:56:23.523: INFO: namespace: e2e-tests-container-runtime-kfgcb, resource: bindings, ignored listing per whitelist
Mar 19 14:56:23.543: INFO: namespace e2e-tests-container-runtime-kfgcb deletion completed in 6.0767228s

â€¢ [SLOW TEST:28.290 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:56:23.543: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-5nkp4/configmap-test-29d6d119-4a57-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 14:56:23.617: INFO: Waiting up to 5m0s for pod "pod-configmaps-29d75c41-4a57-11e9-9c64-0a580af40204" in namespace "e2e-tests-configmap-5nkp4" to be "success or failure"
Mar 19 14:56:23.620: INFO: Pod "pod-configmaps-29d75c41-4a57-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 3.046656ms
Mar 19 14:56:25.622: INFO: Pod "pod-configmaps-29d75c41-4a57-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005707778s
STEP: Saw pod success
Mar 19 14:56:25.622: INFO: Pod "pod-configmaps-29d75c41-4a57-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 14:56:25.625: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-configmaps-29d75c41-4a57-11e9-9c64-0a580af40204 container env-test: <nil>
STEP: delete the pod
Mar 19 14:56:25.642: INFO: Waiting for pod pod-configmaps-29d75c41-4a57-11e9-9c64-0a580af40204 to disappear
Mar 19 14:56:25.644: INFO: Pod pod-configmaps-29d75c41-4a57-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:56:25.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5nkp4" for this suite.
Mar 19 14:56:31.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:56:31.674: INFO: namespace: e2e-tests-configmap-5nkp4, resource: bindings, ignored listing per whitelist
Mar 19 14:56:31.727: INFO: namespace e2e-tests-configmap-5nkp4 deletion completed in 6.079404552s

â€¢ [SLOW TEST:8.184 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:56:31.728: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar 19 14:56:31.788: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar 19 14:56:31.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:56:31.949: INFO: stderr: ""
Mar 19 14:56:31.949: INFO: stdout: "service/redis-slave created\n"
Mar 19 14:56:31.949: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar 19 14:56:31.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:56:32.140: INFO: stderr: ""
Mar 19 14:56:32.140: INFO: stdout: "service/redis-master created\n"
Mar 19 14:56:32.140: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 19 14:56:32.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:56:32.321: INFO: stderr: ""
Mar 19 14:56:32.321: INFO: stdout: "service/frontend created\n"
Mar 19 14:56:32.321: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar 19 14:56:32.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:56:32.499: INFO: stderr: ""
Mar 19 14:56:32.499: INFO: stdout: "deployment.extensions/frontend created\n"
Mar 19 14:56:32.500: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 19 14:56:32.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:56:32.678: INFO: stderr: ""
Mar 19 14:56:32.678: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar 19 14:56:32.678: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar 19 14:56:32.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 create -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:56:32.896: INFO: stderr: ""
Mar 19 14:56:32.896: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar 19 14:56:32.896: INFO: Waiting for all frontend pods to be Running.
Mar 19 14:57:32.949: INFO: Waiting for frontend to serve content.
Mar 19 14:57:32.963: INFO: Trying to add a new entry to the guestbook.
Mar 19 14:57:32.976: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar 19 14:57:32.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:57:33.099: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 14:57:33.099: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 19 14:57:33.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:57:33.205: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 14:57:33.205: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 19 14:57:33.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:57:33.335: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 14:57:33.335: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 19 14:57:33.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:57:33.442: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 14:57:33.442: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 19 14:57:33.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:57:33.573: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 14:57:33.573: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 19 14:57:33.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ffk7v'
Mar 19 14:57:33.723: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 19 14:57:33.723: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:57:33.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ffk7v" for this suite.
Mar 19 14:58:11.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:58:11.790: INFO: namespace: e2e-tests-kubectl-ffk7v, resource: bindings, ignored listing per whitelist
Mar 19 14:58:11.809: INFO: namespace e2e-tests-kubectl-ffk7v deletion completed in 38.082442716s

â€¢ [SLOW TEST:100.081 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:58:11.810: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-n7c9s
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-n7c9s
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-n7c9s
Mar 19 14:58:11.877: INFO: Found 0 stateful pods, waiting for 1
Mar 19 14:58:21.881: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 19 14:58:21.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-n7c9s ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 14:58:22.083: INFO: stderr: ""
Mar 19 14:58:22.083: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 14:58:22.083: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 14:58:22.086: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 19 14:58:32.089: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 14:58:32.089: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 14:58:32.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999232s
Mar 19 14:58:33.127: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995590039s
Mar 19 14:58:34.135: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992342467s
Mar 19 14:58:35.138: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984977242s
Mar 19 14:58:36.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981372168s
Mar 19 14:58:37.145: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978210276s
Mar 19 14:58:38.150: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97459265s
Mar 19 14:58:39.153: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.970217222s
Mar 19 14:58:40.156: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.966901666s
Mar 19 14:58:41.162: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.575771ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-n7c9s
Mar 19 14:58:42.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-n7c9s ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 14:58:42.333: INFO: stderr: ""
Mar 19 14:58:42.333: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 14:58:42.333: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 14:58:42.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-n7c9s ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 14:58:42.531: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 19 14:58:42.531: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 14:58:42.531: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 14:58:42.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-n7c9s ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 19 14:58:42.731: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 19 14:58:42.731: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 19 14:58:42.731: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 19 14:58:42.735: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 14:58:42.735: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 19 14:58:42.735: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 19 14:58:42.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-n7c9s ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 14:58:42.912: INFO: stderr: ""
Mar 19 14:58:42.912: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 14:58:42.912: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 14:58:42.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-n7c9s ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 14:58:43.116: INFO: stderr: ""
Mar 19 14:58:43.116: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 14:58:43.116: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 14:58:43.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 exec --namespace=e2e-tests-statefulset-n7c9s ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 19 14:58:43.313: INFO: stderr: ""
Mar 19 14:58:43.313: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 19 14:58:43.313: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 19 14:58:43.313: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 14:58:43.316: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 19 14:58:53.320: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 14:58:53.320: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 14:58:53.320: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 19 14:58:53.330: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 14:58:53.330: INFO: ss-0  essentialpks-conformance-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  }]
Mar 19 14:58:53.330: INFO: ss-1  essentialpks-conformance-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:53.330: INFO: ss-2  essentialpks-conformance-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:53.330: INFO: 
Mar 19 14:58:53.330: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 14:58:54.333: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 14:58:54.333: INFO: ss-0  essentialpks-conformance-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  }]
Mar 19 14:58:54.333: INFO: ss-1  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:54.333: INFO: ss-2  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:54.333: INFO: 
Mar 19 14:58:54.333: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 14:58:55.336: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 14:58:55.336: INFO: ss-0  essentialpks-conformance-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  }]
Mar 19 14:58:55.336: INFO: ss-1  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:55.336: INFO: ss-2  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:55.336: INFO: 
Mar 19 14:58:55.336: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 14:58:56.341: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 14:58:56.341: INFO: ss-0  essentialpks-conformance-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  }]
Mar 19 14:58:56.341: INFO: ss-1  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:56.341: INFO: ss-2  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:56.341: INFO: 
Mar 19 14:58:56.341: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 14:58:57.344: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 14:58:57.344: INFO: ss-0  essentialpks-conformance-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  }]
Mar 19 14:58:57.344: INFO: ss-1  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:57.344: INFO: ss-2  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:57.344: INFO: 
Mar 19 14:58:57.344: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 14:58:58.348: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 14:58:58.348: INFO: ss-0  essentialpks-conformance-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  }]
Mar 19 14:58:58.348: INFO: ss-1  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:58.348: INFO: ss-2  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:58.348: INFO: 
Mar 19 14:58:58.348: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 14:58:59.351: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Mar 19 14:58:59.352: INFO: ss-0  essentialpks-conformance-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:11 +0000 UTC  }]
Mar 19 14:58:59.352: INFO: ss-1  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:59.352: INFO: ss-2  essentialpks-conformance-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-19 14:58:32 +0000 UTC  }]
Mar 19 14:58:59.352: INFO: 
Mar 19 14:58:59.352: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 19 14:59:00.354: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.974246363s
Mar 19 14:59:01.357: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.97167256s
Mar 19 14:59:02.360: INFO: Verifying statefulset ss doesn't scale past 0 for another 968.486611ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-n7c9s
Mar 19 14:59:03.363: INFO: Scaling statefulset ss to 0
Mar 19 14:59:03.370: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 19 14:59:03.373: INFO: Deleting all statefulset in ns e2e-tests-statefulset-n7c9s
Mar 19 14:59:03.375: INFO: Scaling statefulset ss to 0
Mar 19 14:59:03.383: INFO: Waiting for statefulset status.replicas updated to 0
Mar 19 14:59:03.388: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 14:59:03.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-n7c9s" for this suite.
Mar 19 14:59:09.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 14:59:09.428: INFO: namespace: e2e-tests-statefulset-n7c9s, resource: bindings, ignored listing per whitelist
Mar 19 14:59:09.484: INFO: namespace e2e-tests-statefulset-n7c9s deletion completed in 6.080844781s

â€¢ [SLOW TEST:57.675 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 14:59:09.485: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-sqj9z
Mar 19 14:59:11.547: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-sqj9z
STEP: checking the pod's current state and verifying that restartCount is present
Mar 19 14:59:11.549: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 15:03:11.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-sqj9z" for this suite.
Mar 19 15:03:17.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 15:03:18.006: INFO: namespace: e2e-tests-container-probe-sqj9z, resource: bindings, ignored listing per whitelist
Mar 19 15:03:18.037: INFO: namespace e2e-tests-container-probe-sqj9z deletion completed in 6.078128849s

â€¢ [SLOW TEST:248.552 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 15:03:18.037: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 19 15:03:22.135: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 19 15:03:22.138: INFO: Pod pod-with-poststart-http-hook still exists
Mar 19 15:03:24.138: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 19 15:03:24.141: INFO: Pod pod-with-poststart-http-hook still exists
Mar 19 15:03:26.138: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 19 15:03:26.142: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 15:03:26.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-75npw" for this suite.
Mar 19 15:03:48.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 15:03:48.208: INFO: namespace: e2e-tests-container-lifecycle-hook-75npw, resource: bindings, ignored listing per whitelist
Mar 19 15:03:48.222: INFO: namespace e2e-tests-container-lifecycle-hook-75npw deletion completed in 22.077358603s

â€¢ [SLOW TEST:30.185 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 15:03:48.222: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 19 15:03:48.301: INFO: (0) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.322557ms)
Mar 19 15:03:48.304: INFO: (1) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.486697ms)
Mar 19 15:03:48.307: INFO: (2) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.129933ms)
Mar 19 15:03:48.313: INFO: (3) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.308847ms)
Mar 19 15:03:48.317: INFO: (4) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.268687ms)
Mar 19 15:03:48.320: INFO: (5) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.13535ms)
Mar 19 15:03:48.326: INFO: (6) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.914711ms)
Mar 19 15:03:48.330: INFO: (7) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.249395ms)
Mar 19 15:03:48.334: INFO: (8) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.178497ms)
Mar 19 15:03:48.337: INFO: (9) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.335391ms)
Mar 19 15:03:48.341: INFO: (10) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.846539ms)
Mar 19 15:03:48.345: INFO: (11) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.824606ms)
Mar 19 15:03:48.350: INFO: (12) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.95652ms)
Mar 19 15:03:48.354: INFO: (13) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.972162ms)
Mar 19 15:03:48.359: INFO: (14) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.355636ms)
Mar 19 15:03:48.364: INFO: (15) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.658766ms)
Mar 19 15:03:48.368: INFO: (16) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.222206ms)
Mar 19 15:03:48.372: INFO: (17) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.47574ms)
Mar 19 15:03:48.377: INFO: (18) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.717575ms)
Mar 19 15:03:48.381: INFO: (19) /api/v1/nodes/essentialpks-conformance-2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.529342ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 15:03:48.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-2gcvb" for this suite.
Mar 19 15:03:54.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 15:03:54.432: INFO: namespace: e2e-tests-proxy-2gcvb, resource: bindings, ignored listing per whitelist
Mar 19 15:03:54.455: INFO: namespace e2e-tests-proxy-2gcvb deletion completed in 6.069930211s

â€¢ [SLOW TEST:6.233 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 15:03:54.455: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3697ef87-4a58-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume configMaps
Mar 19 15:03:54.512: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-369866be-4a58-11e9-9c64-0a580af40204" in namespace "e2e-tests-projected-5bsbt" to be "success or failure"
Mar 19 15:03:54.517: INFO: Pod "pod-projected-configmaps-369866be-4a58-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.069922ms
Mar 19 15:03:56.519: INFO: Pod "pod-projected-configmaps-369866be-4a58-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006775016s
STEP: Saw pod success
Mar 19 15:03:56.519: INFO: Pod "pod-projected-configmaps-369866be-4a58-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 15:03:56.522: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-projected-configmaps-369866be-4a58-11e9-9c64-0a580af40204 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 19 15:03:56.534: INFO: Waiting for pod pod-projected-configmaps-369866be-4a58-11e9-9c64-0a580af40204 to disappear
Mar 19 15:03:56.537: INFO: Pod pod-projected-configmaps-369866be-4a58-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 15:03:56.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5bsbt" for this suite.
Mar 19 15:04:02.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 15:04:02.599: INFO: namespace: e2e-tests-projected-5bsbt, resource: bindings, ignored listing per whitelist
Mar 19 15:04:02.620: INFO: namespace e2e-tests-projected-5bsbt deletion completed in 6.080209526s

â€¢ [SLOW TEST:8.165 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 15:04:02.620: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 19 15:04:02.679: INFO: Waiting up to 5m0s for pod "pod-3b76e330-4a58-11e9-9c64-0a580af40204" in namespace "e2e-tests-emptydir-jhn76" to be "success or failure"
Mar 19 15:04:02.684: INFO: Pod "pod-3b76e330-4a58-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.971986ms
Mar 19 15:04:04.687: INFO: Pod "pod-3b76e330-4a58-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007900171s
STEP: Saw pod success
Mar 19 15:04:04.687: INFO: Pod "pod-3b76e330-4a58-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 15:04:04.690: INFO: Trying to get logs from node essentialpks-conformance-3 pod pod-3b76e330-4a58-11e9-9c64-0a580af40204 container test-container: <nil>
STEP: delete the pod
Mar 19 15:04:04.710: INFO: Waiting for pod pod-3b76e330-4a58-11e9-9c64-0a580af40204 to disappear
Mar 19 15:04:04.713: INFO: Pod pod-3b76e330-4a58-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 15:04:04.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jhn76" for this suite.
Mar 19 15:04:10.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 15:04:10.737: INFO: namespace: e2e-tests-emptydir-jhn76, resource: bindings, ignored listing per whitelist
Mar 19 15:04:10.787: INFO: namespace e2e-tests-emptydir-jhn76 deletion completed in 6.070914621s

â€¢ [SLOW TEST:8.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 15:04:10.787: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 19 15:04:10.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-scv9x'
Mar 19 15:04:11.234: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 19 15:04:11.234: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar 19 15:04:11.243: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar 19 15:04:11.260: INFO: scanned /root for discovery docs: <nil>
Mar 19 15:04:11.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-scv9x'
Mar 19 15:04:27.042: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 19 15:04:27.042: INFO: stdout: "Created e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7\nScaling up e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar 19 15:04:27.042: INFO: stdout: "Created e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7\nScaling up e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar 19 15:04:27.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-scv9x'
Mar 19 15:04:27.140: INFO: stderr: ""
Mar 19 15:04:27.141: INFO: stdout: "e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7-89fs9 "
Mar 19 15:04:27.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7-89fs9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-scv9x'
Mar 19 15:04:27.223: INFO: stderr: ""
Mar 19 15:04:27.223: INFO: stdout: "true"
Mar 19 15:04:27.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 get pods e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7-89fs9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-scv9x'
Mar 19 15:04:27.302: INFO: stderr: ""
Mar 19 15:04:27.302: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Mar 19 15:04:27.302: INFO: e2e-test-nginx-rc-54348736cc72117c41eaea76f42b95e7-89fs9 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Mar 19 15:04:27.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-scv9x'
Mar 19 15:04:27.396: INFO: stderr: ""
Mar 19 15:04:27.397: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 15:04:27.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-scv9x" for this suite.
Mar 19 15:04:33.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 15:04:33.470: INFO: namespace: e2e-tests-kubectl-scv9x, resource: bindings, ignored listing per whitelist
Mar 19 15:04:33.504: INFO: namespace e2e-tests-kubectl-scv9x deletion completed in 6.100909981s

â€¢ [SLOW TEST:22.717 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 15:04:33.504: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-4de03008-4a58-11e9-9c64-0a580af40204
STEP: Creating configMap with name cm-test-opt-upd-4de0308e-4a58-11e9-9c64-0a580af40204
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-4de03008-4a58-11e9-9c64-0a580af40204
STEP: Updating configmap cm-test-opt-upd-4de0308e-4a58-11e9-9c64-0a580af40204
STEP: Creating configMap with name cm-test-opt-create-4de030d2-4a58-11e9-9c64-0a580af40204
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 15:04:37.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tpmdg" for this suite.
Mar 19 15:04:59.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 15:04:59.706: INFO: namespace: e2e-tests-configmap-tpmdg, resource: bindings, ignored listing per whitelist
Mar 19 15:04:59.741: INFO: namespace e2e-tests-configmap-tpmdg deletion completed in 22.090046198s

â€¢ [SLOW TEST:26.237 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 15:04:59.741: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar 19 15:04:59.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-015262165 --namespace=e2e-tests-kubectl-6xd9v run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 19 15:05:01.304: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 19 15:05:01.304: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 15:05:03.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6xd9v" for this suite.
Mar 19 15:05:11.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 15:05:11.363: INFO: namespace: e2e-tests-kubectl-6xd9v, resource: bindings, ignored listing per whitelist
Mar 19 15:05:11.381: INFO: namespace e2e-tests-kubectl-6xd9v deletion completed in 8.068987279s

â€¢ [SLOW TEST:11.640 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 19 15:05:11.384: INFO: >>> kubeConfig: /tmp/kubeconfig-015262165
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6473fe3b-4a58-11e9-9c64-0a580af40204
STEP: Creating a pod to test consume secrets
Mar 19 15:05:11.452: INFO: Waiting up to 5m0s for pod "pod-secrets-6474bada-4a58-11e9-9c64-0a580af40204" in namespace "e2e-tests-secrets-mv4c4" to be "success or failure"
Mar 19 15:05:11.461: INFO: Pod "pod-secrets-6474bada-4a58-11e9-9c64-0a580af40204": Phase="Pending", Reason="", readiness=false. Elapsed: 9.089531ms
Mar 19 15:05:13.464: INFO: Pod "pod-secrets-6474bada-4a58-11e9-9c64-0a580af40204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012158721s
STEP: Saw pod success
Mar 19 15:05:13.464: INFO: Pod "pod-secrets-6474bada-4a58-11e9-9c64-0a580af40204" satisfied condition "success or failure"
Mar 19 15:05:13.472: INFO: Trying to get logs from node essentialpks-conformance-2 pod pod-secrets-6474bada-4a58-11e9-9c64-0a580af40204 container secret-volume-test: <nil>
STEP: delete the pod
Mar 19 15:05:13.487: INFO: Waiting for pod pod-secrets-6474bada-4a58-11e9-9c64-0a580af40204 to disappear
Mar 19 15:05:13.491: INFO: Pod pod-secrets-6474bada-4a58-11e9-9c64-0a580af40204 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 19 15:05:13.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mv4c4" for this suite.
Mar 19 15:05:19.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 19 15:05:19.535: INFO: namespace: e2e-tests-secrets-mv4c4, resource: bindings, ignored listing per whitelist
Mar 19 15:05:19.574: INFO: namespace e2e-tests-secrets-mv4c4 deletion completed in 6.07949171s

â€¢ [SLOW TEST:8.191 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSMar 19 15:05:19.575: INFO: Running AfterSuite actions on all nodes
Mar 19 15:05:19.575: INFO: Running AfterSuite actions on node 1
Mar 19 15:05:19.575: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5438.861 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h30m39.685851566s
Test Suite Passed
