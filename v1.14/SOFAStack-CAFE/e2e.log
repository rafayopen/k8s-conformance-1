I0926 03:40:33.193503      21 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-140668964
I0926 03:40:33.193680      21 e2e.go:240] Starting e2e run "642faa03-e00f-11e9-8008-76f27b732d80" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1569469232 - Will randomize all specs
Will run 204 of 3585 specs

Sep 26 03:40:33.311: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 03:40:33.313: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 26 03:40:33.333: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 26 03:40:33.354: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 26 03:40:33.354: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Sep 26 03:40:33.354: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 26 03:40:33.359: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Sep 26 03:40:33.359: INFO: e2e test version: v1.14.3
Sep 26 03:40:33.360: INFO: kube-apiserver version: v1.14.3-359
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:40:33.360: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pod-network-test
Sep 26 03:40:33.379: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1954
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 26 03:40:33.380: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 26 03:40:55.438: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.14:8080/dial?request=hostName&protocol=http&host=10.244.1.105&port=8080&tries=1'] Namespace:pod-network-test-1954 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 03:40:55.438: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 03:40:55.519: INFO: Waiting for endpoints: map[]
Sep 26 03:40:55.521: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.14:8080/dial?request=hostName&protocol=http&host=10.244.0.193&port=8080&tries=1'] Namespace:pod-network-test-1954 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 03:40:55.521: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 03:40:55.622: INFO: Waiting for endpoints: map[]
Sep 26 03:40:55.625: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.14:8080/dial?request=hostName&protocol=http&host=10.244.2.13&port=8080&tries=1'] Namespace:pod-network-test-1954 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 03:40:55.625: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 03:40:55.712: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:40:55.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1954" for this suite.
Sep 26 03:41:17.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:41:17.781: INFO: namespace pod-network-test-1954 deletion completed in 22.065343139s

• [SLOW TEST:44.420 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:41:17.781: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 03:41:17.853: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f6d1c0c-e00f-11e9-8008-76f27b732d80" in namespace "downward-api-4270" to be "success or failure"
Sep 26 03:41:17.861: INFO: Pod "downwardapi-volume-7f6d1c0c-e00f-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 8.180789ms
Sep 26 03:41:19.864: INFO: Pod "downwardapi-volume-7f6d1c0c-e00f-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01092787s
STEP: Saw pod success
Sep 26 03:41:19.864: INFO: Pod "downwardapi-volume-7f6d1c0c-e00f-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:41:19.866: INFO: Trying to get logs from node aks-1-2 pod downwardapi-volume-7f6d1c0c-e00f-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 03:41:19.878: INFO: Waiting for pod downwardapi-volume-7f6d1c0c-e00f-11e9-8008-76f27b732d80 to disappear
Sep 26 03:41:19.883: INFO: Pod downwardapi-volume-7f6d1c0c-e00f-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:41:19.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4270" for this suite.
Sep 26 03:41:25.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:41:25.943: INFO: namespace downward-api-4270 deletion completed in 6.056106594s

• [SLOW TEST:8.163 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:41:25.944: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 03:41:25.976: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 26 03:41:25.989: INFO: Number of nodes with available pods: 0
Sep 26 03:41:25.989: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 03:41:26.994: INFO: Number of nodes with available pods: 0
Sep 26 03:41:26.994: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 03:41:27.994: INFO: Number of nodes with available pods: 1
Sep 26 03:41:27.994: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 03:41:28.994: INFO: Number of nodes with available pods: 1
Sep 26 03:41:28.994: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 03:41:29.993: INFO: Number of nodes with available pods: 1
Sep 26 03:41:29.993: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 03:41:30.994: INFO: Number of nodes with available pods: 1
Sep 26 03:41:30.994: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 03:41:31.994: INFO: Number of nodes with available pods: 1
Sep 26 03:41:31.994: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 03:41:32.995: INFO: Number of nodes with available pods: 2
Sep 26 03:41:32.995: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 03:41:33.994: INFO: Number of nodes with available pods: 3
Sep 26 03:41:33.994: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 26 03:41:34.021: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:34.021: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:34.021: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:35.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:35.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:35.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:36.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:36.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:36.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:37.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:37.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:37.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:37.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:38.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:38.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:38.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:38.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:39.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:39.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:39.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:39.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:40.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:40.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:40.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:40.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:41.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:41.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:41.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:41.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:42.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:42.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:42.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:42.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:43.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:43.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:43.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:43.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:44.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:44.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:44.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:44.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:45.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:45.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:45.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:45.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:46.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:46.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:46.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:46.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:47.026: INFO: Wrong image for pod: daemon-set-5zx4v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:47.026: INFO: Pod daemon-set-5zx4v is not available
Sep 26 03:41:47.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:47.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:48.026: INFO: Pod daemon-set-826rc is not available
Sep 26 03:41:48.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:48.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:49.026: INFO: Pod daemon-set-826rc is not available
Sep 26 03:41:49.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:49.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:50.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:50.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:50.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:41:51.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:51.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:51.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:41:52.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:52.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:52.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:41:53.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:53.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:53.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:41:54.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:54.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:54.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:41:55.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:55.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:55.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:41:56.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:56.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:56.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:41:57.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:57.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:57.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:41:58.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:58.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:58.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:41:59.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:59.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:41:59.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:42:00.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:00.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:00.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:42:01.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:01.026: INFO: Wrong image for pod: daemon-set-wrmm8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:01.026: INFO: Pod daemon-set-wrmm8 is not available
Sep 26 03:42:02.026: INFO: Pod daemon-set-hpjnv is not available
Sep 26 03:42:02.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:03.097: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:04.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:04.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:05.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:05.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:06.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:06.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:07.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:07.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:08.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:08.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:09.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:09.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:10.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:10.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:11.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:11.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:12.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:12.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:13.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:13.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:14.026: INFO: Wrong image for pod: daemon-set-vft9t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 26 03:42:14.026: INFO: Pod daemon-set-vft9t is not available
Sep 26 03:42:15.026: INFO: Pod daemon-set-9mrbv is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 26 03:42:15.032: INFO: Number of nodes with available pods: 2
Sep 26 03:42:15.032: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 03:42:16.037: INFO: Number of nodes with available pods: 2
Sep 26 03:42:16.037: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 03:42:17.037: INFO: Number of nodes with available pods: 3
Sep 26 03:42:17.037: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4968, will wait for the garbage collector to delete the pods
Sep 26 03:42:17.100: INFO: Deleting DaemonSet.extensions daemon-set took: 3.37009ms
Sep 26 03:42:17.401: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.237108ms
Sep 26 03:42:27.803: INFO: Number of nodes with available pods: 0
Sep 26 03:42:27.803: INFO: Number of running nodes: 0, number of available pods: 0
Sep 26 03:42:27.804: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4968/daemonsets","resourceVersion":"31735265"},"items":null}

Sep 26 03:42:27.806: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4968/pods","resourceVersion":"31735265"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:42:27.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4968" for this suite.
Sep 26 03:42:33.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:42:33.874: INFO: namespace daemonsets-4968 deletion completed in 6.057351499s

• [SLOW TEST:67.930 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:42:33.874: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-acc092e9-e00f-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 03:42:33.903: INFO: Waiting up to 5m0s for pod "pod-secrets-acc0ddb3-e00f-11e9-8008-76f27b732d80" in namespace "secrets-8810" to be "success or failure"
Sep 26 03:42:33.906: INFO: Pod "pod-secrets-acc0ddb3-e00f-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.683609ms
Sep 26 03:42:35.908: INFO: Pod "pod-secrets-acc0ddb3-e00f-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005100923s
STEP: Saw pod success
Sep 26 03:42:35.908: INFO: Pod "pod-secrets-acc0ddb3-e00f-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:42:35.910: INFO: Trying to get logs from node aks-1-3 pod pod-secrets-acc0ddb3-e00f-11e9-8008-76f27b732d80 container secret-volume-test: <nil>
STEP: delete the pod
Sep 26 03:42:35.923: INFO: Waiting for pod pod-secrets-acc0ddb3-e00f-11e9-8008-76f27b732d80 to disappear
Sep 26 03:42:35.925: INFO: Pod pod-secrets-acc0ddb3-e00f-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:42:35.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8810" for this suite.
Sep 26 03:42:41.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:42:41.983: INFO: namespace secrets-8810 deletion completed in 6.05605569s

• [SLOW TEST:8.109 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:42:41.984: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep 26 03:42:42.008: INFO: Waiting up to 5m0s for pod "downward-api-b195c2cb-e00f-11e9-8008-76f27b732d80" in namespace "downward-api-8279" to be "success or failure"
Sep 26 03:42:42.010: INFO: Pod "downward-api-b195c2cb-e00f-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.417525ms
Sep 26 03:42:44.013: INFO: Pod "downward-api-b195c2cb-e00f-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005004452s
Sep 26 03:42:46.015: INFO: Pod "downward-api-b195c2cb-e00f-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007499071s
Sep 26 03:42:48.018: INFO: Pod "downward-api-b195c2cb-e00f-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00993051s
STEP: Saw pod success
Sep 26 03:42:48.018: INFO: Pod "downward-api-b195c2cb-e00f-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:42:48.019: INFO: Trying to get logs from node aks-1-3 pod downward-api-b195c2cb-e00f-11e9-8008-76f27b732d80 container dapi-container: <nil>
STEP: delete the pod
Sep 26 03:42:48.032: INFO: Waiting for pod downward-api-b195c2cb-e00f-11e9-8008-76f27b732d80 to disappear
Sep 26 03:42:48.033: INFO: Pod downward-api-b195c2cb-e00f-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:42:48.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8279" for this suite.
Sep 26 03:42:54.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:42:54.091: INFO: namespace downward-api-8279 deletion completed in 6.055830096s

• [SLOW TEST:12.108 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:42:54.091: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 03:42:54.117: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b8cda697-e00f-11e9-8008-76f27b732d80" in namespace "downward-api-5088" to be "success or failure"
Sep 26 03:42:54.122: INFO: Pod "downwardapi-volume-b8cda697-e00f-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 5.053374ms
Sep 26 03:42:56.124: INFO: Pod "downwardapi-volume-b8cda697-e00f-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007718477s
STEP: Saw pod success
Sep 26 03:42:56.124: INFO: Pod "downwardapi-volume-b8cda697-e00f-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:42:56.126: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-b8cda697-e00f-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 03:42:56.144: INFO: Waiting for pod downwardapi-volume-b8cda697-e00f-11e9-8008-76f27b732d80 to disappear
Sep 26 03:42:56.151: INFO: Pod downwardapi-volume-b8cda697-e00f-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:42:56.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5088" for this suite.
Sep 26 03:43:02.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:43:02.213: INFO: namespace downward-api-5088 deletion completed in 6.05975352s

• [SLOW TEST:8.122 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:43:02.213: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep 26 03:43:04.756: INFO: Successfully updated pod "labelsupdatebda48702-e00f-11e9-8008-76f27b732d80"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:43:06.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2922" for this suite.
Sep 26 03:43:28.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:43:28.834: INFO: namespace projected-2922 deletion completed in 22.061018543s

• [SLOW TEST:26.621 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:43:28.835: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:43:28.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2103" for this suite.
Sep 26 03:43:50.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:43:50.925: INFO: namespace pods-2103 deletion completed in 22.058379415s

• [SLOW TEST:22.090 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:43:50.925: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 03:43:50.952: INFO: Waiting up to 5m0s for pod "downwardapi-volume-daadc033-e00f-11e9-8008-76f27b732d80" in namespace "projected-3505" to be "success or failure"
Sep 26 03:43:50.953: INFO: Pod "downwardapi-volume-daadc033-e00f-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.549223ms
Sep 26 03:43:52.956: INFO: Pod "downwardapi-volume-daadc033-e00f-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004133672s
STEP: Saw pod success
Sep 26 03:43:52.956: INFO: Pod "downwardapi-volume-daadc033-e00f-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:43:52.957: INFO: Trying to get logs from node aks-1-2 pod downwardapi-volume-daadc033-e00f-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 03:43:52.973: INFO: Waiting for pod downwardapi-volume-daadc033-e00f-11e9-8008-76f27b732d80 to disappear
Sep 26 03:43:52.976: INFO: Pod downwardapi-volume-daadc033-e00f-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:43:52.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3505" for this suite.
Sep 26 03:43:58.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:43:59.042: INFO: namespace projected-3505 deletion completed in 6.05959696s

• [SLOW TEST:8.116 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:43:59.042: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 03:43:59.065: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df83d440-e00f-11e9-8008-76f27b732d80" in namespace "projected-2782" to be "success or failure"
Sep 26 03:43:59.069: INFO: Pod "downwardapi-volume-df83d440-e00f-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.648164ms
Sep 26 03:44:01.072: INFO: Pod "downwardapi-volume-df83d440-e00f-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006425743s
STEP: Saw pod success
Sep 26 03:44:01.072: INFO: Pod "downwardapi-volume-df83d440-e00f-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:44:01.073: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-df83d440-e00f-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 03:44:01.085: INFO: Waiting for pod downwardapi-volume-df83d440-e00f-11e9-8008-76f27b732d80 to disappear
Sep 26 03:44:01.087: INFO: Pod downwardapi-volume-df83d440-e00f-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:44:01.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2782" for this suite.
Sep 26 03:44:07.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:44:07.152: INFO: namespace projected-2782 deletion completed in 6.061848344s

• [SLOW TEST:8.110 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:44:07.152: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4975
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 26 03:44:07.170: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 26 03:44:27.231: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.24:8080/dial?request=hostName&protocol=udp&host=10.244.0.199&port=8081&tries=1'] Namespace:pod-network-test-4975 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 03:44:27.231: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 03:44:27.315: INFO: Waiting for endpoints: map[]
Sep 26 03:44:27.317: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.24:8080/dial?request=hostName&protocol=udp&host=10.244.1.108&port=8081&tries=1'] Namespace:pod-network-test-4975 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 03:44:27.317: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 03:44:27.383: INFO: Waiting for endpoints: map[]
Sep 26 03:44:27.385: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.24:8080/dial?request=hostName&protocol=udp&host=10.244.2.23&port=8081&tries=1'] Namespace:pod-network-test-4975 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 03:44:27.385: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 03:44:27.449: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:44:27.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4975" for this suite.
Sep 26 03:44:49.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:44:49.511: INFO: namespace pod-network-test-4975 deletion completed in 22.058786501s

• [SLOW TEST:42.360 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:44:49.511: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 26 03:44:49.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8153'
Sep 26 03:44:49.758: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 26 03:44:49.758: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Sep 26 03:44:49.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete jobs e2e-test-nginx-job --namespace=kubectl-8153'
Sep 26 03:44:49.845: INFO: stderr: ""
Sep 26 03:44:49.845: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:44:49.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8153" for this suite.
Sep 26 03:45:11.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:45:11.905: INFO: namespace kubectl-8153 deletion completed in 22.056400221s

• [SLOW TEST:22.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:45:11.905: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:46:11.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-789" for this suite.
Sep 26 03:46:33.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:46:33.988: INFO: namespace container-probe-789 deletion completed in 22.055753193s

• [SLOW TEST:82.083 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:46:33.988: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 26 03:46:34.023: INFO: Waiting up to 5m0s for pod "pod-3be09c8f-e010-11e9-8008-76f27b732d80" in namespace "emptydir-430" to be "success or failure"
Sep 26 03:46:34.033: INFO: Pod "pod-3be09c8f-e010-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 10.132918ms
Sep 26 03:46:36.036: INFO: Pod "pod-3be09c8f-e010-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01231459s
STEP: Saw pod success
Sep 26 03:46:36.036: INFO: Pod "pod-3be09c8f-e010-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:46:36.037: INFO: Trying to get logs from node aks-1-2 pod pod-3be09c8f-e010-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 03:46:36.051: INFO: Waiting for pod pod-3be09c8f-e010-11e9-8008-76f27b732d80 to disappear
Sep 26 03:46:36.056: INFO: Pod pod-3be09c8f-e010-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:46:36.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-430" for this suite.
Sep 26 03:46:42.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:46:42.122: INFO: namespace emptydir-430 deletion completed in 6.063488629s

• [SLOW TEST:8.134 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:46:42.123: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:46:44.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6810" for this suite.
Sep 26 03:47:34.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:47:34.236: INFO: namespace kubelet-test-6810 deletion completed in 50.058264551s

• [SLOW TEST:52.113 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:47:34.236: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 03:47:34.258: INFO: Creating deployment "nginx-deployment"
Sep 26 03:47:34.260: INFO: Waiting for observed generation 1
Sep 26 03:47:36.264: INFO: Waiting for all required pods to come up
Sep 26 03:47:36.267: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 26 03:47:38.278: INFO: Waiting for deployment "nginx-deployment" to complete
Sep 26 03:47:38.282: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep 26 03:47:38.286: INFO: Updating deployment nginx-deployment
Sep 26 03:47:38.286: INFO: Waiting for observed generation 2
Sep 26 03:47:40.290: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 26 03:47:40.292: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 26 03:47:40.293: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 26 03:47:40.298: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 26 03:47:40.298: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 26 03:47:40.299: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 26 03:47:40.301: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep 26 03:47:40.301: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep 26 03:47:40.306: INFO: Updating deployment nginx-deployment
Sep 26 03:47:40.306: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep 26 03:47:40.311: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 26 03:47:40.316: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep 26 03:47:40.348: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-22,SelfLink:/apis/apps/v1/namespaces/deployment-22/deployments/nginx-deployment,UID:5fc88d91-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736353,Generation:3,CreationTimestamp:2019-09-26 03:47:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-09-26 03:47:38 +0000 UTC 2019-09-26 03:47:34 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.} {Available False 2019-09-26 03:47:40 +0000 UTC 2019-09-26 03:47:40 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep 26 03:47:40.380: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-22,SelfLink:/apis/apps/v1/namespaces/deployment-22/replicasets/nginx-deployment-5f9595f595,UID:622f517b-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736349,Generation:3,CreationTimestamp:2019-09-26 03:47:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 5fc88d91-e010-11e9-af5c-00163e006ee4 0xc002ca91a7 0xc002ca91a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 26 03:47:40.380: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep 26 03:47:40.380: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-22,SelfLink:/apis/apps/v1/namespaces/deployment-22/replicasets/nginx-deployment-6f478d8d8,UID:5fc967be-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736347,Generation:3,CreationTimestamp:2019-09-26 03:47:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 5fc88d91-e010-11e9-af5c-00163e006ee4 0xc002ca9277 0xc002ca9278}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep 26 03:47:40.448: INFO: Pod "nginx-deployment-5f9595f595-62k9x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-62k9x,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-62k9x,UID:63682617-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736380,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002916c57 0xc002916c58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002916cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002916cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.448: INFO: Pod "nginx-deployment-5f9595f595-8cpss" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8cpss,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-8cpss,UID:623e7a9d-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736337,Generation:0,CreationTimestamp:2019-09-26 03:47:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002916d77 0xc002916d78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002916df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002916e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.79,PodIP:,StartTime:2019-09-26 03:47:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.448: INFO: Pod "nginx-deployment-5f9595f595-brjln" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-brjln,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-brjln,UID:636d9ab1-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736367,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002916ef7 0xc002916ef8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002916f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002916f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.449: INFO: Pod "nginx-deployment-5f9595f595-bx9bd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-bx9bd,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-bx9bd,UID:636d28e2-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736370,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002916ff0 0xc002916ff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.449: INFO: Pod "nginx-deployment-5f9595f595-cst4c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-cst4c,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-cst4c,UID:623c2250-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736333,Generation:0,CreationTimestamp:2019-09-26 03:47:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc0029170f0 0xc0029170f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.78,PodIP:,StartTime:2019-09-26 03:47:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.449: INFO: Pod "nginx-deployment-5f9595f595-fwt5r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-fwt5r,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-fwt5r,UID:636d7a65-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736374,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002917277 0xc002917278}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029172e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.449: INFO: Pod "nginx-deployment-5f9595f595-g9586" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-g9586,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-g9586,UID:63681731-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736378,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002917370 0xc002917371}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029173f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.449: INFO: Pod "nginx-deployment-5f9595f595-hg7k5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-hg7k5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-hg7k5,UID:62315133-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736325,Generation:0,CreationTimestamp:2019-09-26 03:47:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002917497 0xc002917498}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.81,PodIP:,StartTime:2019-09-26 03:47:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.449: INFO: Pod "nginx-deployment-5f9595f595-jvlnk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-jvlnk,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-jvlnk,UID:636d8c05-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736375,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002917617 0xc002917618}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029176a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.450: INFO: Pod "nginx-deployment-5f9595f595-jxk25" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-jxk25,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-jxk25,UID:62312fe9-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736316,Generation:0,CreationTimestamp:2019-09-26 03:47:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002917710 0xc002917711}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029177b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.79,PodIP:,StartTime:2019-09-26 03:47:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.450: INFO: Pod "nginx-deployment-5f9595f595-pzss9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-pzss9,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-pzss9,UID:622fea42-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736311,Generation:0,CreationTimestamp:2019-09-26 03:47:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002917897 0xc002917898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.78,PodIP:,StartTime:2019-09-26 03:47:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.450: INFO: Pod "nginx-deployment-5f9595f595-tsj6s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-tsj6s,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-5f9595f595-tsj6s,UID:6365b3c8-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736362,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 622f517b-e010-11e9-af5c-00163e006ee4 0xc002917a27 0xc002917a28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.450: INFO: Pod "nginx-deployment-6f478d8d8-286qk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-286qk,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-286qk,UID:636d6ada-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736372,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002917b47 0xc002917b48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.450: INFO: Pod "nginx-deployment-6f478d8d8-8rhbl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8rhbl,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-8rhbl,UID:5fcc27e4-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736276,Generation:0,CreationTimestamp:2019-09-26 03:47:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"nginx":{"creationTimestamp":"2019-09-26T11:47:35.082842489+08:00","finishTimestamp":"2019-09-26T11:47:35.700719164+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002917c40 0xc002917c41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.26,StartTime:2019-09-26 03:47:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-26 03:47:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9ae6f2a915873cdc97cfb6ddea6847c81e48a121e3ea5f1eee133decdb63a86d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.451: INFO: Pod "nginx-deployment-6f478d8d8-8sf5h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8sf5h,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-8sf5h,UID:6368b1e4-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736379,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002917de7 0xc002917de8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.451: INFO: Pod "nginx-deployment-6f478d8d8-9ch8x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9ch8x,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-9ch8x,UID:6368bb4f-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736366,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002917f07 0xc002917f08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002917f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002917fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.451: INFO: Pod "nginx-deployment-6f478d8d8-9d8p7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9d8p7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-9d8p7,UID:5fcc4edb-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736263,Generation:0,CreationTimestamp:2019-09-26 03:47:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"nginx":{"creationTimestamp":"2019-09-26T11:47:35.092004306+08:00","finishTimestamp":"2019-09-26T11:47:35.503298143+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952067 0xc002952068}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029520e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002952100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.81,PodIP:10.244.1.109,StartTime:2019-09-26 03:47:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-26 03:47:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://01d6f984d6a5fb6a491a36558061e58a921f986d59a362b9245d02936e8dd0d2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.451: INFO: Pod "nginx-deployment-6f478d8d8-bbjqp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bbjqp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-bbjqp,UID:6368316a-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736376,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc0029521e7 0xc0029521e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002952260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002952280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.451: INFO: Pod "nginx-deployment-6f478d8d8-dnp8r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dnp8r,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-dnp8r,UID:5fd6d8af-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736279,Generation:0,CreationTimestamp:2019-09-26 03:47:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"nginx":{"creationTimestamp":"2019-09-26T11:47:35.514173887+08:00","finishTimestamp":"2019-09-26T11:47:36.227688761+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952307 0xc002952308}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002952380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029523a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.29,StartTime:2019-09-26 03:47:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-26 03:47:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://de46bf3ab2ced3d4d146ffa595ccf377ab75433f9978a19cae0a46a4451eab33}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.451: INFO: Pod "nginx-deployment-6f478d8d8-f9mx9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-f9mx9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-f9mx9,UID:5fcff2a2-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736281,Generation:0,CreationTimestamp:2019-09-26 03:47:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"nginx":{"creationTimestamp":"2019-09-26T11:47:35.438273202+08:00","finishTimestamp":"2019-09-26T11:47:36.132915357+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952487 0xc002952488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002952500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002952520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.79,PodIP:10.244.0.205,StartTime:2019-09-26 03:47:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-26 03:47:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://09f455dc6fd0f381d31f15d2aafe55e66e7171b56b04e5159a70368742447e7a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.452: INFO: Pod "nginx-deployment-6f478d8d8-hvkcf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hvkcf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-hvkcf,UID:6367eeb8-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736377,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952607 0xc002952608}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002952680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029526a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.452: INFO: Pod "nginx-deployment-6f478d8d8-jxpb9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jxpb9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-jxpb9,UID:636d4b7c-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736368,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952727 0xc002952728}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002952790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029527b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.452: INFO: Pod "nginx-deployment-6f478d8d8-ndg2v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ndg2v,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-ndg2v,UID:63655eb4-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736363,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952820 0xc002952821}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002952890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029528b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.452: INFO: Pod "nginx-deployment-6f478d8d8-nsnrw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-nsnrw,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-nsnrw,UID:5fd04618-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736286,Generation:0,CreationTimestamp:2019-09-26 03:47:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"nginx":{"creationTimestamp":"2019-09-26T11:47:35.250353373+08:00","finishTimestamp":"2019-09-26T11:47:35.88319367+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952937 0xc002952938}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029529b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029529d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.27,StartTime:2019-09-26 03:47:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-26 03:47:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ad29d5b30994df122615db4f1839871e038e994615a5f8a763b36ddea2d46ff9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.452: INFO: Pod "nginx-deployment-6f478d8d8-qbm58" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qbm58,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-qbm58,UID:636d5b73-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736373,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952ab7 0xc002952ab8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002952b20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002952b40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.452: INFO: Pod "nginx-deployment-6f478d8d8-rqqft" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rqqft,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-rqqft,UID:636bece1-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736369,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952bb0 0xc002952bb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002952c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002952c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.452: INFO: Pod "nginx-deployment-6f478d8d8-shzsn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-shzsn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-shzsn,UID:5fcb17c5-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736288,Generation:0,CreationTimestamp:2019-09-26 03:47:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"nginx":{"creationTimestamp":"2019-09-26T11:47:35.07060897+08:00","finishTimestamp":"2019-09-26T11:47:35.65683394+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952ca0 0xc002952ca1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002952d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002952d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.79,PodIP:10.244.0.203,StartTime:2019-09-26 03:47:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-26 03:47:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://10a62bf78b82d39f2d58c17c4df81228c4a25e366ace16f491f14d801e40e727}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.452: INFO: Pod "nginx-deployment-6f478d8d8-sr8h9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-sr8h9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-sr8h9,UID:5fd05532-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736273,Generation:0,CreationTimestamp:2019-09-26 03:47:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"nginx":{"creationTimestamp":"2019-09-26T11:47:35.415845733+08:00","finishTimestamp":"2019-09-26T11:47:35.959691659+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952e17 0xc002952e18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002952e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002952eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.79,PodIP:10.244.0.204,StartTime:2019-09-26 03:47:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-26 03:47:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2eee4275f614c8dca785e195bd82246407542c147d917eca51334f11e5b08cd9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.453: INFO: Pod "nginx-deployment-6f478d8d8-vn9r6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vn9r6,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-vn9r6,UID:63657c6c-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736360,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002952f97 0xc002952f98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002953010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002953030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.453: INFO: Pod "nginx-deployment-6f478d8d8-w6zxm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-w6zxm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-w6zxm,UID:636d3d8c-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736371,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc0029530b7 0xc0029530b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002953120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002953140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.453: INFO: Pod "nginx-deployment-6f478d8d8-xgrvx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-xgrvx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-xgrvx,UID:5fd6209b-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736283,Generation:0,CreationTimestamp:2019-09-26 03:47:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"nginx":{"creationTimestamp":"2019-09-26T11:47:35.512438461+08:00","finishTimestamp":"2019-09-26T11:47:36.100944967+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc0029531b0 0xc0029531b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002953220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002953240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:36 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.28,StartTime:2019-09-26 03:47:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-26 03:47:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9f34159aacd42b0b9388ccde022990990ccbbff4335628fc25c308607c43cbc8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 26 03:47:40.453: INFO: Pod "nginx-deployment-6f478d8d8-xtcj8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-xtcj8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-22,SelfLink:/api/v1/namespaces/deployment-22/pods/nginx-deployment-6f478d8d8-xtcj8,UID:63641571-e010-11e9-af5c-00163e006ee4,ResourceVersion:31736354,Generation:0,CreationTimestamp:2019-09-26 03:47:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 5fc967be-e010-11e9-af5c-00163e006ee4 0xc002953327 0xc002953328}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6nb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6nb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r6nb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029533a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029533c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 03:47:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:47:40.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-22" for this suite.
Sep 26 03:47:46.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:47:46.604: INFO: namespace deployment-22 deletion completed in 6.115922499s

• [SLOW TEST:12.368 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:47:46.605: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-67289bf4-e010-11e9-8008-76f27b732d80
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:47:46.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5674" for this suite.
Sep 26 03:47:52.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:47:52.703: INFO: namespace configmap-5674 deletion completed in 6.063994336s

• [SLOW TEST:6.098 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:47:52.704: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 03:47:52.783: INFO: Create a RollingUpdate DaemonSet
Sep 26 03:47:52.785: INFO: Check that daemon pods launch on every node of the cluster
Sep 26 03:47:52.792: INFO: Number of nodes with available pods: 0
Sep 26 03:47:52.792: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 03:47:53.797: INFO: Number of nodes with available pods: 0
Sep 26 03:47:53.797: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 03:47:54.798: INFO: Number of nodes with available pods: 3
Sep 26 03:47:54.798: INFO: Number of running nodes: 3, number of available pods: 3
Sep 26 03:47:54.798: INFO: Update the DaemonSet to trigger a rollout
Sep 26 03:47:54.802: INFO: Updating DaemonSet daemon-set
Sep 26 03:48:07.809: INFO: Roll back the DaemonSet before rollout is complete
Sep 26 03:48:07.813: INFO: Updating DaemonSet daemon-set
Sep 26 03:48:07.813: INFO: Make sure DaemonSet rollback is complete
Sep 26 03:48:07.815: INFO: Wrong image for pod: daemon-set-m2p7c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 26 03:48:07.815: INFO: Pod daemon-set-m2p7c is not available
Sep 26 03:48:08.821: INFO: Wrong image for pod: daemon-set-m2p7c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 26 03:48:08.821: INFO: Pod daemon-set-m2p7c is not available
Sep 26 03:48:09.822: INFO: Wrong image for pod: daemon-set-m2p7c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 26 03:48:09.822: INFO: Pod daemon-set-m2p7c is not available
Sep 26 03:48:10.821: INFO: Wrong image for pod: daemon-set-m2p7c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 26 03:48:10.821: INFO: Pod daemon-set-m2p7c is not available
Sep 26 03:48:11.821: INFO: Wrong image for pod: daemon-set-m2p7c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 26 03:48:11.821: INFO: Pod daemon-set-m2p7c is not available
Sep 26 03:48:12.821: INFO: Wrong image for pod: daemon-set-m2p7c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 26 03:48:12.821: INFO: Pod daemon-set-m2p7c is not available
Sep 26 03:48:13.821: INFO: Wrong image for pod: daemon-set-m2p7c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 26 03:48:13.821: INFO: Pod daemon-set-m2p7c is not available
Sep 26 03:48:14.821: INFO: Wrong image for pod: daemon-set-m2p7c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 26 03:48:14.821: INFO: Pod daemon-set-m2p7c is not available
Sep 26 03:48:15.821: INFO: Wrong image for pod: daemon-set-m2p7c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 26 03:48:15.821: INFO: Pod daemon-set-m2p7c is not available
Sep 26 03:48:16.821: INFO: Wrong image for pod: daemon-set-m2p7c. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 26 03:48:16.821: INFO: Pod daemon-set-m2p7c is not available
Sep 26 03:48:17.821: INFO: Pod daemon-set-pd98q is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-467, will wait for the garbage collector to delete the pods
Sep 26 03:48:17.887: INFO: Deleting DaemonSet.extensions daemon-set took: 3.038499ms
Sep 26 03:48:18.188: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.16226ms
Sep 26 03:48:27.789: INFO: Number of nodes with available pods: 0
Sep 26 03:48:27.789: INFO: Number of running nodes: 0, number of available pods: 0
Sep 26 03:48:27.791: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-467/daemonsets","resourceVersion":"31736798"},"items":null}

Sep 26 03:48:27.792: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-467/pods","resourceVersion":"31736798"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:48:27.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-467" for this suite.
Sep 26 03:48:33.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:48:33.866: INFO: namespace daemonsets-467 deletion completed in 6.063023665s

• [SLOW TEST:41.163 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:48:33.867: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-83541564-e010-11e9-8008-76f27b732d80
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:48:35.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2565" for this suite.
Sep 26 03:48:57.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:48:57.990: INFO: namespace configmap-2565 deletion completed in 22.068899853s

• [SLOW TEST:24.123 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:48:57.990: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep 26 03:48:58.016: INFO: Waiting up to 5m0s for pod "downward-api-91b40c35-e010-11e9-8008-76f27b732d80" in namespace "downward-api-9984" to be "success or failure"
Sep 26 03:48:58.018: INFO: Pod "downward-api-91b40c35-e010-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.488043ms
Sep 26 03:49:00.021: INFO: Pod "downward-api-91b40c35-e010-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004346085s
STEP: Saw pod success
Sep 26 03:49:00.021: INFO: Pod "downward-api-91b40c35-e010-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:49:00.022: INFO: Trying to get logs from node aks-1-3 pod downward-api-91b40c35-e010-11e9-8008-76f27b732d80 container dapi-container: <nil>
STEP: delete the pod
Sep 26 03:49:00.039: INFO: Waiting for pod downward-api-91b40c35-e010-11e9-8008-76f27b732d80 to disappear
Sep 26 03:49:00.040: INFO: Pod downward-api-91b40c35-e010-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:49:00.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9984" for this suite.
Sep 26 03:49:06.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:49:06.096: INFO: namespace downward-api-9984 deletion completed in 6.054313s

• [SLOW TEST:8.106 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:49:06.097: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 26 03:49:10.139: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 26 03:49:10.144: INFO: Pod pod-with-prestop-http-hook still exists
Sep 26 03:49:12.144: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 26 03:49:12.146: INFO: Pod pod-with-prestop-http-hook still exists
Sep 26 03:49:14.144: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 26 03:49:14.146: INFO: Pod pod-with-prestop-http-hook still exists
Sep 26 03:49:16.144: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 26 03:49:16.146: INFO: Pod pod-with-prestop-http-hook still exists
Sep 26 03:49:18.144: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 26 03:49:18.146: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:49:18.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4058" for this suite.
Sep 26 03:49:40.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:49:40.214: INFO: namespace container-lifecycle-hook-4058 deletion completed in 22.059932667s

• [SLOW TEST:34.117 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:49:40.214: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-aaded73b-e010-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 03:49:40.241: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aadf1357-e010-11e9-8008-76f27b732d80" in namespace "projected-6347" to be "success or failure"
Sep 26 03:49:40.246: INFO: Pod "pod-projected-configmaps-aadf1357-e010-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.980577ms
Sep 26 03:49:42.248: INFO: Pod "pod-projected-configmaps-aadf1357-e010-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007766961s
STEP: Saw pod success
Sep 26 03:49:42.248: INFO: Pod "pod-projected-configmaps-aadf1357-e010-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:49:42.250: INFO: Trying to get logs from node aks-1-3 pod pod-projected-configmaps-aadf1357-e010-11e9-8008-76f27b732d80 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 03:49:42.262: INFO: Waiting for pod pod-projected-configmaps-aadf1357-e010-11e9-8008-76f27b732d80 to disappear
Sep 26 03:49:42.264: INFO: Pod pod-projected-configmaps-aadf1357-e010-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:49:42.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6347" for this suite.
Sep 26 03:49:48.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:49:48.324: INFO: namespace projected-6347 deletion completed in 6.057615163s

• [SLOW TEST:8.110 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:49:48.324: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 03:49:48.342: INFO: Creating ReplicaSet my-hostname-basic-afb416a5-e010-11e9-8008-76f27b732d80
Sep 26 03:49:48.349: INFO: Pod name my-hostname-basic-afb416a5-e010-11e9-8008-76f27b732d80: Found 0 pods out of 1
Sep 26 03:49:53.352: INFO: Pod name my-hostname-basic-afb416a5-e010-11e9-8008-76f27b732d80: Found 1 pods out of 1
Sep 26 03:49:53.352: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-afb416a5-e010-11e9-8008-76f27b732d80" is running
Sep 26 03:49:53.354: INFO: Pod "my-hostname-basic-afb416a5-e010-11e9-8008-76f27b732d80-6cpbr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-26 03:49:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-26 03:49:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-26 03:49:49 +0000 UTC Reason: Message:} {Type:ContainerDiskPressure Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-26 03:49:48 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-26 03:49:48 +0000 UTC Reason: Message:}])
Sep 26 03:49:53.354: INFO: Trying to dial the pod
Sep 26 03:49:58.360: INFO: Controller my-hostname-basic-afb416a5-e010-11e9-8008-76f27b732d80: Got expected result from replica 1 [my-hostname-basic-afb416a5-e010-11e9-8008-76f27b732d80-6cpbr]: "my-hostname-basic-afb416a5-e010-11e9-8008-76f27b732d80-6cpbr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:49:58.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5670" for this suite.
Sep 26 03:50:04.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:50:04.417: INFO: namespace replicaset-5670 deletion completed in 6.054417211s

• [SLOW TEST:16.093 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:50:04.417: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-b94c25e5-e010-11e9-8008-76f27b732d80
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-b94c25e5-e010-11e9-8008-76f27b732d80
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:50:10.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4827" for this suite.
Sep 26 03:50:32.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:50:32.535: INFO: namespace configmap-4827 deletion completed in 22.054997378s

• [SLOW TEST:28.118 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:50:32.536: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 26 03:50:32.560: INFO: Waiting up to 5m0s for pod "pod-ca0e60e8-e010-11e9-8008-76f27b732d80" in namespace "emptydir-1937" to be "success or failure"
Sep 26 03:50:32.565: INFO: Pod "pod-ca0e60e8-e010-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 5.560858ms
Sep 26 03:50:34.568: INFO: Pod "pod-ca0e60e8-e010-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008151019s
STEP: Saw pod success
Sep 26 03:50:34.568: INFO: Pod "pod-ca0e60e8-e010-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:50:34.570: INFO: Trying to get logs from node aks-1-2 pod pod-ca0e60e8-e010-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 03:50:34.585: INFO: Waiting for pod pod-ca0e60e8-e010-11e9-8008-76f27b732d80 to disappear
Sep 26 03:50:34.587: INFO: Pod pod-ca0e60e8-e010-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:50:34.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1937" for this suite.
Sep 26 03:50:40.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:50:40.651: INFO: namespace emptydir-1937 deletion completed in 6.058689368s

• [SLOW TEST:8.116 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:50:40.652: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Sep 26 03:50:40.677: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4140" to be "success or failure"
Sep 26 03:50:40.681: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.549795ms
Sep 26 03:50:42.684: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007444387s
STEP: Saw pod success
Sep 26 03:50:42.684: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep 26 03:50:42.686: INFO: Trying to get logs from node aks-1-3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 26 03:50:42.709: INFO: Waiting for pod pod-host-path-test to disappear
Sep 26 03:50:42.711: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:50:42.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4140" for this suite.
Sep 26 03:50:48.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:50:48.770: INFO: namespace hostpath-4140 deletion completed in 6.056025032s

• [SLOW TEST:8.118 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:50:48.770: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9309
Sep 26 03:50:50.799: INFO: Started pod liveness-http in namespace container-probe-9309
STEP: checking the pod's current state and verifying that restartCount is present
Sep 26 03:50:50.801: INFO: Initial restart count of pod liveness-http is 0
Sep 26 03:51:10.834: INFO: Restart count of pod container-probe-9309/liveness-http is now 1 (20.032796628s elapsed)
Sep 26 03:51:30.873: INFO: Restart count of pod container-probe-9309/liveness-http is now 2 (40.072383157s elapsed)
Sep 26 03:51:50.900: INFO: Restart count of pod container-probe-9309/liveness-http is now 3 (1m0.099447572s elapsed)
Sep 26 03:52:10.928: INFO: Restart count of pod container-probe-9309/liveness-http is now 4 (1m20.126762144s elapsed)
Sep 26 03:53:21.021: INFO: Restart count of pod container-probe-9309/liveness-http is now 5 (2m30.220230955s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:53:21.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9309" for this suite.
Sep 26 03:53:27.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:53:27.095: INFO: namespace container-probe-9309 deletion completed in 6.058157824s

• [SLOW TEST:158.326 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:53:27.096: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-321a39d9-e011-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 03:53:27.121: INFO: Waiting up to 5m0s for pod "pod-configmaps-321a8692-e011-11e9-8008-76f27b732d80" in namespace "configmap-2678" to be "success or failure"
Sep 26 03:53:27.125: INFO: Pod "pod-configmaps-321a8692-e011-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.715546ms
Sep 26 03:53:29.127: INFO: Pod "pod-configmaps-321a8692-e011-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006426017s
STEP: Saw pod success
Sep 26 03:53:29.127: INFO: Pod "pod-configmaps-321a8692-e011-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:53:29.129: INFO: Trying to get logs from node aks-1-3 pod pod-configmaps-321a8692-e011-11e9-8008-76f27b732d80 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 03:53:29.140: INFO: Waiting for pod pod-configmaps-321a8692-e011-11e9-8008-76f27b732d80 to disappear
Sep 26 03:53:29.143: INFO: Pod pod-configmaps-321a8692-e011-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:53:29.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2678" for this suite.
Sep 26 03:53:35.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:53:35.200: INFO: namespace configmap-2678 deletion completed in 6.055149075s

• [SLOW TEST:8.104 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:53:35.200: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-36f671ad-e011-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 03:53:35.278: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-36f6be99-e011-11e9-8008-76f27b732d80" in namespace "projected-6058" to be "success or failure"
Sep 26 03:53:35.295: INFO: Pod "pod-projected-secrets-36f6be99-e011-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 16.959999ms
Sep 26 03:53:37.297: INFO: Pod "pod-projected-secrets-36f6be99-e011-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019847946s
STEP: Saw pod success
Sep 26 03:53:37.297: INFO: Pod "pod-projected-secrets-36f6be99-e011-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:53:37.299: INFO: Trying to get logs from node aks-1-2 pod pod-projected-secrets-36f6be99-e011-11e9-8008-76f27b732d80 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 26 03:53:37.317: INFO: Waiting for pod pod-projected-secrets-36f6be99-e011-11e9-8008-76f27b732d80 to disappear
Sep 26 03:53:37.320: INFO: Pod pod-projected-secrets-36f6be99-e011-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:53:37.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6058" for this suite.
Sep 26 03:53:43.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:53:43.381: INFO: namespace projected-6058 deletion completed in 6.058642934s

• [SLOW TEST:8.181 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:53:43.381: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1249
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1249
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1249
Sep 26 03:53:43.450: INFO: Found 0 stateful pods, waiting for 1
Sep 26 03:53:53.452: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 26 03:53:53.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-1249 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 26 03:53:53.581: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 26 03:53:53.581: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 26 03:53:53.581: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 26 03:53:53.583: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 26 03:54:03.586: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 26 03:54:03.586: INFO: Waiting for statefulset status.replicas updated to 0
Sep 26 03:54:03.596: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999568s
Sep 26 03:54:04.598: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997797664s
Sep 26 03:54:05.601: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994908277s
Sep 26 03:54:06.604: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.992151783s
Sep 26 03:54:07.607: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.98972483s
Sep 26 03:54:08.609: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.986722326s
Sep 26 03:54:09.612: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.984337674s
Sep 26 03:54:10.615: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.981575312s
Sep 26 03:54:11.617: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.978857716s
Sep 26 03:54:12.620: INFO: Verifying statefulset ss doesn't scale past 1 for another 976.027294ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1249
Sep 26 03:54:13.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-1249 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 03:54:13.752: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 26 03:54:13.752: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 26 03:54:13.752: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 26 03:54:13.754: INFO: Found 1 stateful pods, waiting for 3
Sep 26 03:54:23.757: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 03:54:23.757: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 03:54:23.757: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 26 03:54:23.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-1249 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 26 03:54:23.888: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 26 03:54:23.888: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 26 03:54:23.888: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 26 03:54:23.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-1249 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 26 03:54:24.050: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 26 03:54:24.050: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 26 03:54:24.050: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 26 03:54:24.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-1249 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 26 03:54:24.291: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 26 03:54:24.291: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 26 03:54:24.291: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 26 03:54:24.291: INFO: Waiting for statefulset status.replicas updated to 0
Sep 26 03:54:24.296: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 26 03:54:34.301: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 26 03:54:34.301: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 26 03:54:34.301: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 26 03:54:34.317: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999411s
Sep 26 03:54:35.319: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996202876s
Sep 26 03:54:36.322: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99362415s
Sep 26 03:54:37.325: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990933267s
Sep 26 03:54:38.328: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988124692s
Sep 26 03:54:39.331: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985193822s
Sep 26 03:54:40.335: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.981910178s
Sep 26 03:54:41.338: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.977747344s
Sep 26 03:54:42.341: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.974913113s
Sep 26 03:54:43.344: INFO: Verifying statefulset ss doesn't scale past 3 for another 971.869041ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1249
Sep 26 03:54:44.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-1249 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 03:54:44.480: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 26 03:54:44.480: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 26 03:54:44.480: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 26 03:54:44.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-1249 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 03:54:44.612: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 26 03:54:44.612: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 26 03:54:44.612: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 26 03:54:44.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-1249 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 03:54:44.741: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 26 03:54:44.741: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 26 03:54:44.741: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 26 03:54:44.741: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep 26 03:55:14.751: INFO: Deleting all statefulset in ns statefulset-1249
Sep 26 03:55:14.753: INFO: Scaling statefulset ss to 0
Sep 26 03:55:14.758: INFO: Waiting for statefulset status.replicas updated to 0
Sep 26 03:55:14.759: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:55:14.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1249" for this suite.
Sep 26 03:55:20.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:55:20.826: INFO: namespace statefulset-1249 deletion completed in 6.056594986s

• [SLOW TEST:97.444 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:55:20.826: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:55:24.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8121" for this suite.
Sep 26 03:55:30.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:55:30.922: INFO: namespace kubelet-test-8121 deletion completed in 6.056997031s

• [SLOW TEST:10.095 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:55:30.923: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-6751
Sep 26 03:55:32.955: INFO: Started pod liveness-exec in namespace container-probe-6751
STEP: checking the pod's current state and verifying that restartCount is present
Sep 26 03:55:32.956: INFO: Initial restart count of pod liveness-exec is 0
Sep 26 03:56:21.019: INFO: Restart count of pod container-probe-6751/liveness-exec is now 1 (48.062224117s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:56:21.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6751" for this suite.
Sep 26 03:56:27.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:56:27.089: INFO: namespace container-probe-6751 deletion completed in 6.056729375s

• [SLOW TEST:56.167 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:56:27.089: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 26 03:56:30.137: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:56:31.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6210" for this suite.
Sep 26 03:56:53.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:56:53.205: INFO: namespace replicaset-6210 deletion completed in 22.054293659s

• [SLOW TEST:26.116 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:56:53.205: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 03:56:53.228: INFO: Waiting up to 5m0s for pod "downwardapi-volume-acf3d955-e011-11e9-8008-76f27b732d80" in namespace "projected-7691" to be "success or failure"
Sep 26 03:56:53.239: INFO: Pod "downwardapi-volume-acf3d955-e011-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 11.208446ms
Sep 26 03:56:55.242: INFO: Pod "downwardapi-volume-acf3d955-e011-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01394532s
STEP: Saw pod success
Sep 26 03:56:55.242: INFO: Pod "downwardapi-volume-acf3d955-e011-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:56:55.244: INFO: Trying to get logs from node aks-1-2 pod downwardapi-volume-acf3d955-e011-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 03:56:55.257: INFO: Waiting for pod downwardapi-volume-acf3d955-e011-11e9-8008-76f27b732d80 to disappear
Sep 26 03:56:55.270: INFO: Pod downwardapi-volume-acf3d955-e011-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:56:55.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7691" for this suite.
Sep 26 03:57:01.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:57:01.340: INFO: namespace projected-7691 deletion completed in 6.065115129s

• [SLOW TEST:8.135 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:57:01.341: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:57:01.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7240" for this suite.
Sep 26 03:57:07.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:57:07.419: INFO: namespace services-7240 deletion completed in 6.055238836s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.077 seconds]
[sig-network] Services
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:57:07.419: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 26 03:57:07.443: INFO: Waiting up to 5m0s for pod "pod-b56ccbae-e011-11e9-8008-76f27b732d80" in namespace "emptydir-8414" to be "success or failure"
Sep 26 03:57:07.445: INFO: Pod "pod-b56ccbae-e011-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.67818ms
Sep 26 03:57:09.448: INFO: Pod "pod-b56ccbae-e011-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004253931s
Sep 26 03:57:11.450: INFO: Pod "pod-b56ccbae-e011-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007012698s
STEP: Saw pod success
Sep 26 03:57:11.450: INFO: Pod "pod-b56ccbae-e011-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:57:11.452: INFO: Trying to get logs from node aks-1-3 pod pod-b56ccbae-e011-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 03:57:11.465: INFO: Waiting for pod pod-b56ccbae-e011-11e9-8008-76f27b732d80 to disappear
Sep 26 03:57:11.466: INFO: Pod pod-b56ccbae-e011-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:57:11.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8414" for this suite.
Sep 26 03:57:17.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:57:17.523: INFO: namespace emptydir-8414 deletion completed in 6.054665673s

• [SLOW TEST:10.104 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:57:17.523: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 26 03:57:17.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-557'
Sep 26 03:57:17.779: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 26 03:57:17.779: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep 26 03:57:17.789: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-9w48c]
Sep 26 03:57:17.790: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-9w48c" in namespace "kubectl-557" to be "running and ready"
Sep 26 03:57:17.793: INFO: Pod "e2e-test-nginx-rc-9w48c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.110179ms
Sep 26 03:57:19.796: INFO: Pod "e2e-test-nginx-rc-9w48c": Phase="Running", Reason="", readiness=true. Elapsed: 2.00588702s
Sep 26 03:57:19.796: INFO: Pod "e2e-test-nginx-rc-9w48c" satisfied condition "running and ready"
Sep 26 03:57:19.796: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-9w48c]
Sep 26 03:57:19.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 logs rc/e2e-test-nginx-rc --namespace=kubectl-557'
Sep 26 03:57:19.880: INFO: stderr: ""
Sep 26 03:57:19.880: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Sep 26 03:57:19.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete rc e2e-test-nginx-rc --namespace=kubectl-557'
Sep 26 03:57:19.949: INFO: stderr: ""
Sep 26 03:57:19.949: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:57:19.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-557" for this suite.
Sep 26 03:57:25.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:57:26.009: INFO: namespace kubectl-557 deletion completed in 6.056302296s

• [SLOW TEST:8.485 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:57:26.009: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep 26 03:57:26.031: INFO: Waiting up to 5m0s for pod "downward-api-c08156cc-e011-11e9-8008-76f27b732d80" in namespace "downward-api-9993" to be "success or failure"
Sep 26 03:57:26.035: INFO: Pod "downward-api-c08156cc-e011-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.899151ms
Sep 26 03:57:28.038: INFO: Pod "downward-api-c08156cc-e011-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006477204s
STEP: Saw pod success
Sep 26 03:57:28.038: INFO: Pod "downward-api-c08156cc-e011-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:57:28.039: INFO: Trying to get logs from node aks-1-3 pod downward-api-c08156cc-e011-11e9-8008-76f27b732d80 container dapi-container: <nil>
STEP: delete the pod
Sep 26 03:57:28.051: INFO: Waiting for pod downward-api-c08156cc-e011-11e9-8008-76f27b732d80 to disappear
Sep 26 03:57:28.053: INFO: Pod downward-api-c08156cc-e011-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:57:28.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9993" for this suite.
Sep 26 03:57:34.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:57:34.112: INFO: namespace downward-api-9993 deletion completed in 6.056923801s

• [SLOW TEST:8.104 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:57:34.113: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9361
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Sep 26 03:57:34.149: INFO: Found 0 stateful pods, waiting for 3
Sep 26 03:57:44.153: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 03:57:44.153: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 03:57:44.153: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 26 03:57:44.172: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 26 03:57:54.195: INFO: Updating stateful set ss2
Sep 26 03:57:54.202: INFO: Waiting for Pod statefulset-9361/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Sep 26 03:58:04.246: INFO: Found 1 stateful pods, waiting for 3
Sep 26 03:58:14.249: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 03:58:14.249: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 03:58:14.249: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 26 03:58:14.268: INFO: Updating stateful set ss2
Sep 26 03:58:14.283: INFO: Waiting for Pod statefulset-9361/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep 26 03:58:24.304: INFO: Updating stateful set ss2
Sep 26 03:58:24.309: INFO: Waiting for StatefulSet statefulset-9361/ss2 to complete update
Sep 26 03:58:24.309: INFO: Waiting for Pod statefulset-9361/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep 26 03:58:34.314: INFO: Waiting for StatefulSet statefulset-9361/ss2 to complete update
Sep 26 03:58:34.314: INFO: Waiting for Pod statefulset-9361/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep 26 03:58:44.314: INFO: Deleting all statefulset in ns statefulset-9361
Sep 26 03:58:44.315: INFO: Scaling statefulset ss2 to 0
Sep 26 03:59:14.326: INFO: Waiting for statefulset status.replicas updated to 0
Sep 26 03:59:14.328: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:59:14.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9361" for this suite.
Sep 26 03:59:20.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:59:20.394: INFO: namespace statefulset-9361 deletion completed in 6.055251889s

• [SLOW TEST:106.281 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:59:20.394: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-04b6de1f-e012-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 03:59:20.469: INFO: Waiting up to 5m0s for pod "pod-secrets-04b72a22-e012-11e9-8008-76f27b732d80" in namespace "secrets-8190" to be "success or failure"
Sep 26 03:59:20.472: INFO: Pod "pod-secrets-04b72a22-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.740356ms
Sep 26 03:59:22.474: INFO: Pod "pod-secrets-04b72a22-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005527497s
STEP: Saw pod success
Sep 26 03:59:22.474: INFO: Pod "pod-secrets-04b72a22-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:59:22.476: INFO: Trying to get logs from node aks-1-3 pod pod-secrets-04b72a22-e012-11e9-8008-76f27b732d80 container secret-volume-test: <nil>
STEP: delete the pod
Sep 26 03:59:22.487: INFO: Waiting for pod pod-secrets-04b72a22-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 03:59:22.490: INFO: Pod pod-secrets-04b72a22-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:59:22.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8190" for this suite.
Sep 26 03:59:28.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:59:28.556: INFO: namespace secrets-8190 deletion completed in 6.064453695s

• [SLOW TEST:8.162 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:59:28.556: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 26 03:59:28.581: INFO: Waiting up to 5m0s for pod "pod-098cc0c6-e012-11e9-8008-76f27b732d80" in namespace "emptydir-6107" to be "success or failure"
Sep 26 03:59:28.583: INFO: Pod "pod-098cc0c6-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0575ms
Sep 26 03:59:30.586: INFO: Pod "pod-098cc0c6-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004745029s
STEP: Saw pod success
Sep 26 03:59:30.586: INFO: Pod "pod-098cc0c6-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:59:30.587: INFO: Trying to get logs from node aks-1-3 pod pod-098cc0c6-e012-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 03:59:30.599: INFO: Waiting for pod pod-098cc0c6-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 03:59:30.600: INFO: Pod pod-098cc0c6-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:59:30.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6107" for this suite.
Sep 26 03:59:36.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:59:36.656: INFO: namespace emptydir-6107 deletion completed in 6.052962358s

• [SLOW TEST:8.099 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:59:36.656: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 26 03:59:36.678: INFO: Waiting up to 5m0s for pod "pod-0e608002-e012-11e9-8008-76f27b732d80" in namespace "emptydir-3139" to be "success or failure"
Sep 26 03:59:36.689: INFO: Pod "pod-0e608002-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 10.179705ms
Sep 26 03:59:38.691: INFO: Pod "pod-0e608002-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012680416s
STEP: Saw pod success
Sep 26 03:59:38.691: INFO: Pod "pod-0e608002-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:59:38.693: INFO: Trying to get logs from node aks-1-3 pod pod-0e608002-e012-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 03:59:38.707: INFO: Waiting for pod pod-0e608002-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 03:59:38.709: INFO: Pod pod-0e608002-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:59:38.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3139" for this suite.
Sep 26 03:59:44.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:59:44.768: INFO: namespace emptydir-3139 deletion completed in 6.056593351s

• [SLOW TEST:8.112 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:59:44.769: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-884/configmap-test-13364986-e012-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 03:59:44.794: INFO: Waiting up to 5m0s for pod "pod-configmaps-133697f3-e012-11e9-8008-76f27b732d80" in namespace "configmap-884" to be "success or failure"
Sep 26 03:59:44.797: INFO: Pod "pod-configmaps-133697f3-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088087ms
Sep 26 03:59:46.799: INFO: Pod "pod-configmaps-133697f3-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004693424s
STEP: Saw pod success
Sep 26 03:59:46.799: INFO: Pod "pod-configmaps-133697f3-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:59:46.801: INFO: Trying to get logs from node aks-1-3 pod pod-configmaps-133697f3-e012-11e9-8008-76f27b732d80 container env-test: <nil>
STEP: delete the pod
Sep 26 03:59:46.814: INFO: Waiting for pod pod-configmaps-133697f3-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 03:59:46.816: INFO: Pod pod-configmaps-133697f3-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:59:46.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-884" for this suite.
Sep 26 03:59:52.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 03:59:52.872: INFO: namespace configmap-884 deletion completed in 6.054069688s

• [SLOW TEST:8.104 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 03:59:52.873: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 03:59:52.897: INFO: Waiting up to 5m0s for pod "downwardapi-volume-180b5375-e012-11e9-8008-76f27b732d80" in namespace "downward-api-45" to be "success or failure"
Sep 26 03:59:52.903: INFO: Pod "downwardapi-volume-180b5375-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013022ms
Sep 26 03:59:54.906: INFO: Pod "downwardapi-volume-180b5375-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008872975s
STEP: Saw pod success
Sep 26 03:59:54.906: INFO: Pod "downwardapi-volume-180b5375-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 03:59:54.908: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-180b5375-e012-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 03:59:54.920: INFO: Waiting for pod downwardapi-volume-180b5375-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 03:59:54.922: INFO: Pod downwardapi-volume-180b5375-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 03:59:54.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-45" for this suite.
Sep 26 04:00:00.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:00:01.026: INFO: namespace downward-api-45 deletion completed in 6.101955042s

• [SLOW TEST:8.154 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:00:01.026: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Sep 26 04:00:01.052: INFO: Waiting up to 5m0s for pod "client-containers-1ce7889b-e012-11e9-8008-76f27b732d80" in namespace "containers-9920" to be "success or failure"
Sep 26 04:00:01.057: INFO: Pod "client-containers-1ce7889b-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 5.524948ms
Sep 26 04:00:03.060: INFO: Pod "client-containers-1ce7889b-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007814573s
Sep 26 04:00:05.062: INFO: Pod "client-containers-1ce7889b-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01054144s
STEP: Saw pod success
Sep 26 04:00:05.062: INFO: Pod "client-containers-1ce7889b-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:00:05.064: INFO: Trying to get logs from node aks-1-3 pod client-containers-1ce7889b-e012-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:00:05.078: INFO: Waiting for pod client-containers-1ce7889b-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:00:05.079: INFO: Pod client-containers-1ce7889b-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:00:05.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9920" for this suite.
Sep 26 04:00:11.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:00:11.146: INFO: namespace containers-9920 deletion completed in 6.064811899s

• [SLOW TEST:10.120 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:00:11.147: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 26 04:00:11.169: INFO: Waiting up to 5m0s for pod "pod-22ef6cb0-e012-11e9-8008-76f27b732d80" in namespace "emptydir-464" to be "success or failure"
Sep 26 04:00:11.172: INFO: Pod "pod-22ef6cb0-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.178149ms
Sep 26 04:00:13.175: INFO: Pod "pod-22ef6cb0-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006224302s
STEP: Saw pod success
Sep 26 04:00:13.175: INFO: Pod "pod-22ef6cb0-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:00:13.177: INFO: Trying to get logs from node aks-1-2 pod pod-22ef6cb0-e012-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:00:13.193: INFO: Waiting for pod pod-22ef6cb0-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:00:13.196: INFO: Pod pod-22ef6cb0-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:00:13.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-464" for this suite.
Sep 26 04:00:19.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:00:19.258: INFO: namespace emptydir-464 deletion completed in 6.059220742s

• [SLOW TEST:8.111 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:00:19.258: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-27c505a0-e012-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:00:19.282: INFO: Waiting up to 5m0s for pod "pod-configmaps-27c54f5e-e012-11e9-8008-76f27b732d80" in namespace "configmap-7700" to be "success or failure"
Sep 26 04:00:19.285: INFO: Pod "pod-configmaps-27c54f5e-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.868807ms
Sep 26 04:00:21.288: INFO: Pod "pod-configmaps-27c54f5e-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006265209s
STEP: Saw pod success
Sep 26 04:00:21.288: INFO: Pod "pod-configmaps-27c54f5e-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:00:21.290: INFO: Trying to get logs from node aks-1-3 pod pod-configmaps-27c54f5e-e012-11e9-8008-76f27b732d80 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:00:21.302: INFO: Waiting for pod pod-configmaps-27c54f5e-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:00:21.304: INFO: Pod pod-configmaps-27c54f5e-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:00:21.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7700" for this suite.
Sep 26 04:00:27.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:00:27.361: INFO: namespace configmap-7700 deletion completed in 6.054849116s

• [SLOW TEST:8.103 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:00:27.361: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:00:27.383: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c99889e-e012-11e9-8008-76f27b732d80" in namespace "downward-api-2621" to be "success or failure"
Sep 26 04:00:27.387: INFO: Pod "downwardapi-volume-2c99889e-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.258611ms
Sep 26 04:00:29.389: INFO: Pod "downwardapi-volume-2c99889e-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005791527s
STEP: Saw pod success
Sep 26 04:00:29.389: INFO: Pod "downwardapi-volume-2c99889e-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:00:29.391: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-2c99889e-e012-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:00:29.402: INFO: Waiting for pod downwardapi-volume-2c99889e-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:00:29.406: INFO: Pod downwardapi-volume-2c99889e-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:00:29.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2621" for this suite.
Sep 26 04:00:35.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:00:35.464: INFO: namespace downward-api-2621 deletion completed in 6.055917544s

• [SLOW TEST:8.103 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:00:35.465: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-3175c1ef-e012-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:00:35.542: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-31760dec-e012-11e9-8008-76f27b732d80" in namespace "projected-3337" to be "success or failure"
Sep 26 04:00:35.544: INFO: Pod "pod-projected-configmaps-31760dec-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.940315ms
Sep 26 04:00:37.547: INFO: Pod "pod-projected-configmaps-31760dec-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004730705s
STEP: Saw pod success
Sep 26 04:00:37.547: INFO: Pod "pod-projected-configmaps-31760dec-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:00:37.548: INFO: Trying to get logs from node aks-1-3 pod pod-projected-configmaps-31760dec-e012-11e9-8008-76f27b732d80 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:00:37.561: INFO: Waiting for pod pod-projected-configmaps-31760dec-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:00:37.565: INFO: Pod pod-projected-configmaps-31760dec-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:00:37.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3337" for this suite.
Sep 26 04:00:43.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:00:43.626: INFO: namespace projected-3337 deletion completed in 6.058912106s

• [SLOW TEST:8.161 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:00:43.627: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5111
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Sep 26 04:00:43.659: INFO: Found 0 stateful pods, waiting for 3
Sep 26 04:00:53.661: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 04:00:53.661: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 04:00:53.661: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 04:00:53.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-5111 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 26 04:00:53.808: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 26 04:00:53.808: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 26 04:00:53.808: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 26 04:01:03.831: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 26 04:01:13.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-5111 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:01:13.966: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 26 04:01:13.966: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 26 04:01:13.966: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Sep 26 04:01:43.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-5111 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 26 04:01:44.110: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 26 04:01:44.110: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 26 04:01:44.110: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 26 04:01:54.133: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 26 04:02:04.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-5111 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:02:04.286: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 26 04:02:04.287: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 26 04:02:04.287: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep 26 04:02:24.298: INFO: Deleting all statefulset in ns statefulset-5111
Sep 26 04:02:24.300: INFO: Scaling statefulset ss2 to 0
Sep 26 04:02:44.310: INFO: Waiting for statefulset status.replicas updated to 0
Sep 26 04:02:44.312: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:02:44.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5111" for this suite.
Sep 26 04:02:50.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:02:50.386: INFO: namespace statefulset-5111 deletion completed in 6.060844038s

• [SLOW TEST:126.760 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:02:50.387: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:02:50.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 version --client'
Sep 26 04:02:50.458: INFO: stderr: ""
Sep 26 04:02:50.458: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.3\", GitCommit:\"5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:44:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Sep 26 04:02:50.459: INFO: Not supported for server versions before "1.14.3"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:02:50.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3731" for this suite.
Sep 26 04:02:56.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:02:56.519: INFO: namespace kubectl-3731 deletion completed in 6.056909895s

S [SKIPPING] [6.132 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance] [It]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692

    Not supported for server versions before "1.14.3"

    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:922
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:02:56.519: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-858135f9-e012-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:02:56.546: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-858184fd-e012-11e9-8008-76f27b732d80" in namespace "projected-8743" to be "success or failure"
Sep 26 04:02:56.549: INFO: Pod "pod-projected-configmaps-858184fd-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.671406ms
Sep 26 04:02:58.552: INFO: Pod "pod-projected-configmaps-858184fd-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006385378s
STEP: Saw pod success
Sep 26 04:02:58.552: INFO: Pod "pod-projected-configmaps-858184fd-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:02:58.554: INFO: Trying to get logs from node aks-1-3 pod pod-projected-configmaps-858184fd-e012-11e9-8008-76f27b732d80 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:02:58.568: INFO: Waiting for pod pod-projected-configmaps-858184fd-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:02:58.569: INFO: Pod pod-projected-configmaps-858184fd-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:02:58.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8743" for this suite.
Sep 26 04:03:04.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:03:04.630: INFO: namespace projected-8743 deletion completed in 6.058939442s

• [SLOW TEST:8.111 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:03:04.631: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 26 04:03:04.658: INFO: Waiting up to 5m0s for pod "pod-8a5720b6-e012-11e9-8008-76f27b732d80" in namespace "emptydir-8300" to be "success or failure"
Sep 26 04:03:04.666: INFO: Pod "pod-8a5720b6-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 8.080456ms
Sep 26 04:03:06.668: INFO: Pod "pod-8a5720b6-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010816031s
STEP: Saw pod success
Sep 26 04:03:06.669: INFO: Pod "pod-8a5720b6-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:03:06.670: INFO: Trying to get logs from node aks-1-2 pod pod-8a5720b6-e012-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:03:06.689: INFO: Waiting for pod pod-8a5720b6-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:03:06.693: INFO: Pod pod-8a5720b6-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:03:06.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8300" for this suite.
Sep 26 04:03:12.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:03:12.753: INFO: namespace emptydir-8300 deletion completed in 6.057658885s

• [SLOW TEST:8.123 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:03:12.754: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-237.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-237.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 26 04:03:34.804: INFO: DNS probes using dns-237/dns-test-8f2eb035-e012-11e9-8008-76f27b732d80 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:03:34.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-237" for this suite.
Sep 26 04:03:40.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:03:40.874: INFO: namespace dns-237 deletion completed in 6.059203016s

• [SLOW TEST:28.120 seconds]
[sig-network] DNS
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:03:40.875: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-9ff15985-e012-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:03:40.901: INFO: Waiting up to 5m0s for pod "pod-configmaps-9ff1a590-e012-11e9-8008-76f27b732d80" in namespace "configmap-8674" to be "success or failure"
Sep 26 04:03:40.903: INFO: Pod "pod-configmaps-9ff1a590-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.280228ms
Sep 26 04:03:42.905: INFO: Pod "pod-configmaps-9ff1a590-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003528712s
STEP: Saw pod success
Sep 26 04:03:42.905: INFO: Pod "pod-configmaps-9ff1a590-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:03:42.907: INFO: Trying to get logs from node aks-1-2 pod pod-configmaps-9ff1a590-e012-11e9-8008-76f27b732d80 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:03:42.920: INFO: Waiting for pod pod-configmaps-9ff1a590-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:03:42.923: INFO: Pod pod-configmaps-9ff1a590-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:03:42.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8674" for this suite.
Sep 26 04:03:48.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:03:48.984: INFO: namespace configmap-8674 deletion completed in 6.05872107s

• [SLOW TEST:8.109 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:03:48.984: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:03:49.013: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a4c7c2f8-e012-11e9-8008-76f27b732d80" in namespace "downward-api-467" to be "success or failure"
Sep 26 04:03:49.017: INFO: Pod "downwardapi-volume-a4c7c2f8-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.605855ms
Sep 26 04:03:51.020: INFO: Pod "downwardapi-volume-a4c7c2f8-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007410052s
STEP: Saw pod success
Sep 26 04:03:51.020: INFO: Pod "downwardapi-volume-a4c7c2f8-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:03:51.022: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-a4c7c2f8-e012-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:03:51.037: INFO: Waiting for pod downwardapi-volume-a4c7c2f8-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:03:51.039: INFO: Pod downwardapi-volume-a4c7c2f8-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:03:51.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-467" for this suite.
Sep 26 04:03:57.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:03:57.098: INFO: namespace downward-api-467 deletion completed in 6.057039703s

• [SLOW TEST:8.115 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:03:57.099: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:03:57.177: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a9a5447b-e012-11e9-8008-76f27b732d80" in namespace "downward-api-418" to be "success or failure"
Sep 26 04:03:57.179: INFO: Pod "downwardapi-volume-a9a5447b-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.949012ms
Sep 26 04:03:59.182: INFO: Pod "downwardapi-volume-a9a5447b-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004621817s
STEP: Saw pod success
Sep 26 04:03:59.182: INFO: Pod "downwardapi-volume-a9a5447b-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:03:59.184: INFO: Trying to get logs from node aks-1-2 pod downwardapi-volume-a9a5447b-e012-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:03:59.196: INFO: Waiting for pod downwardapi-volume-a9a5447b-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:03:59.198: INFO: Pod downwardapi-volume-a9a5447b-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:03:59.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-418" for this suite.
Sep 26 04:04:05.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:04:05.264: INFO: namespace downward-api-418 deletion completed in 6.061790238s

• [SLOW TEST:8.166 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:04:05.265: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-ae7b6901-e012-11e9-8008-76f27b732d80
STEP: Creating configMap with name cm-test-opt-upd-ae7b6944-e012-11e9-8008-76f27b732d80
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ae7b6901-e012-11e9-8008-76f27b732d80
STEP: Updating configmap cm-test-opt-upd-ae7b6944-e012-11e9-8008-76f27b732d80
STEP: Creating configMap with name cm-test-opt-create-ae7b6965-e012-11e9-8008-76f27b732d80
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:04:09.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3498" for this suite.
Sep 26 04:04:31.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:04:31.412: INFO: namespace projected-3498 deletion completed in 22.059309515s

• [SLOW TEST:26.147 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:04:31.412: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:04:31.479: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"be13eff7-e012-11e9-af5c-00163e006ee4", Controller:(*bool)(0xc002a9b0fa), BlockOwnerDeletion:(*bool)(0xc002a9b0fb)}}
Sep 26 04:04:31.484: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"be11690f-e012-11e9-af5c-00163e006ee4", Controller:(*bool)(0xc002e5332a), BlockOwnerDeletion:(*bool)(0xc002e5332b)}}
Sep 26 04:04:31.491: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"be11eddf-e012-11e9-af5c-00163e006ee4", Controller:(*bool)(0xc002a9b2ca), BlockOwnerDeletion:(*bool)(0xc002a9b2cb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:04:36.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4769" for this suite.
Sep 26 04:04:42.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:04:42.557: INFO: namespace gc-4769 deletion completed in 6.056136163s

• [SLOW TEST:11.145 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:04:42.557: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-c4b57377-e012-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:04:42.582: INFO: Waiting up to 5m0s for pod "pod-configmaps-c4b5aecc-e012-11e9-8008-76f27b732d80" in namespace "configmap-736" to be "success or failure"
Sep 26 04:04:42.585: INFO: Pod "pod-configmaps-c4b5aecc-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.207971ms
Sep 26 04:04:44.587: INFO: Pod "pod-configmaps-c4b5aecc-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005731101s
STEP: Saw pod success
Sep 26 04:04:44.587: INFO: Pod "pod-configmaps-c4b5aecc-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:04:44.589: INFO: Trying to get logs from node aks-1-3 pod pod-configmaps-c4b5aecc-e012-11e9-8008-76f27b732d80 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:04:44.602: INFO: Waiting for pod pod-configmaps-c4b5aecc-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:04:44.603: INFO: Pod pod-configmaps-c4b5aecc-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:04:44.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-736" for this suite.
Sep 26 04:04:50.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:04:50.666: INFO: namespace configmap-736 deletion completed in 6.059701105s

• [SLOW TEST:8.109 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:04:50.666: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 26 04:04:50.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-921'
Sep 26 04:04:50.763: INFO: stderr: ""
Sep 26 04:04:50.763: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Sep 26 04:04:50.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete pods e2e-test-nginx-pod --namespace=kubectl-921'
Sep 26 04:04:57.779: INFO: stderr: ""
Sep 26 04:04:57.779: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:04:57.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-921" for this suite.
Sep 26 04:05:03.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:05:03.844: INFO: namespace kubectl-921 deletion completed in 6.061267853s

• [SLOW TEST:13.177 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:05:03.845: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-d165be8f-e012-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:05:03.872: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1660e09-e012-11e9-8008-76f27b732d80" in namespace "configmap-2593" to be "success or failure"
Sep 26 04:05:03.874: INFO: Pod "pod-configmaps-d1660e09-e012-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.749564ms
Sep 26 04:05:05.877: INFO: Pod "pod-configmaps-d1660e09-e012-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005323456s
STEP: Saw pod success
Sep 26 04:05:05.877: INFO: Pod "pod-configmaps-d1660e09-e012-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:05:05.879: INFO: Trying to get logs from node aks-1-2 pod pod-configmaps-d1660e09-e012-11e9-8008-76f27b732d80 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:05:05.890: INFO: Waiting for pod pod-configmaps-d1660e09-e012-11e9-8008-76f27b732d80 to disappear
Sep 26 04:05:05.892: INFO: Pod pod-configmaps-d1660e09-e012-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:05:05.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2593" for this suite.
Sep 26 04:05:11.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:05:11.950: INFO: namespace configmap-2593 deletion completed in 6.056015006s

• [SLOW TEST:8.106 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:05:11.950: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 26 04:05:11.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-6515'
Sep 26 04:05:12.046: INFO: stderr: ""
Sep 26 04:05:12.046: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep 26 04:05:17.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pod e2e-test-nginx-pod --namespace=kubectl-6515 -o json'
Sep 26 04:05:17.179: INFO: stderr: ""
Sep 26 04:05:17.179: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"pod.beta1.sigma.ali/update-status\": \"{\\\"statuses\\\":{\\\"e2e-test-nginx-pod\\\":{\\\"creationTimestamp\\\":\\\"2019-09-26T12:05:12.6854539+08:00\\\",\\\"finishTimestamp\\\":\\\"2019-09-26T12:05:13.011091574+08:00\\\",\\\"retryCount\\\":0,\\\"currentState\\\":\\\"running\\\",\\\"lastState\\\":\\\"unknown\\\",\\\"action\\\":\\\"start\\\",\\\"success\\\":true,\\\"message\\\":\\\"create start and post start success\\\"}}}\"\n        },\n        \"creationTimestamp\": \"2019-09-26T04:05:12Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-6515\",\n        \"resourceVersion\": \"31740244\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6515/pods/e2e-test-nginx-pod\",\n        \"uid\": \"d644a0d8-e012-11e9-af5c-00163e006ee4\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-9r22g\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"aks-1-2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-9r22g\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-9r22g\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-26T04:05:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-26T04:05:13Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-26T04:05:13Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-26T04:05:12Z\",\n                \"status\": \"False\",\n                \"type\": \"ContainerDiskPressure\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-26T04:05:12Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://6ea221cc1237bdc12332218cc0b88095eeb8262b55d902319c185550f89f8df3\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-26T04:05:13Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.27.79\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.0.237\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-26T04:05:12Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 26 04:05:17.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 replace -f - --namespace=kubectl-6515'
Sep 26 04:05:17.398: INFO: stderr: ""
Sep 26 04:05:17.398: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Sep 26 04:05:17.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete pods e2e-test-nginx-pod --namespace=kubectl-6515'
Sep 26 04:05:27.763: INFO: stderr: ""
Sep 26 04:05:27.763: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:05:27.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6515" for this suite.
Sep 26 04:05:33.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:05:33.826: INFO: namespace kubectl-6515 deletion completed in 6.057535784s

• [SLOW TEST:21.875 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:05:33.826: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Sep 26 04:05:34.305: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep 26 04:05:36.388: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 04:05:38.395: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 04:05:40.390: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 04:05:42.390: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 04:05:44.390: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705067534, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 04:05:47.611: INFO: Waited 1.215747675s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:05:48.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3031" for this suite.
Sep 26 04:05:54.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:05:54.208: INFO: namespace aggregator-3031 deletion completed in 6.150023302s

• [SLOW TEST:20.383 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:05:54.209: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Sep 26 04:05:54.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-2882'
Sep 26 04:05:54.453: INFO: stderr: ""
Sep 26 04:05:54.453: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 26 04:05:54.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2882'
Sep 26 04:05:54.531: INFO: stderr: ""
Sep 26 04:05:54.531: INFO: stdout: "update-demo-nautilus-6dvn7 update-demo-nautilus-xkzrz "
Sep 26 04:05:54.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-6dvn7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:05:54.597: INFO: stderr: ""
Sep 26 04:05:54.597: INFO: stdout: ""
Sep 26 04:05:54.597: INFO: update-demo-nautilus-6dvn7 is created but not running
Sep 26 04:05:59.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2882'
Sep 26 04:05:59.665: INFO: stderr: ""
Sep 26 04:05:59.665: INFO: stdout: "update-demo-nautilus-6dvn7 update-demo-nautilus-xkzrz "
Sep 26 04:05:59.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-6dvn7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:05:59.728: INFO: stderr: ""
Sep 26 04:05:59.728: INFO: stdout: "true"
Sep 26 04:05:59.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-6dvn7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:05:59.790: INFO: stderr: ""
Sep 26 04:05:59.790: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 26 04:05:59.790: INFO: validating pod update-demo-nautilus-6dvn7
Sep 26 04:05:59.793: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 26 04:05:59.793: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 26 04:05:59.793: INFO: update-demo-nautilus-6dvn7 is verified up and running
Sep 26 04:05:59.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-xkzrz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:05:59.855: INFO: stderr: ""
Sep 26 04:05:59.855: INFO: stdout: "true"
Sep 26 04:05:59.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-xkzrz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:05:59.917: INFO: stderr: ""
Sep 26 04:05:59.917: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 26 04:05:59.917: INFO: validating pod update-demo-nautilus-xkzrz
Sep 26 04:05:59.920: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 26 04:05:59.920: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 26 04:05:59.920: INFO: update-demo-nautilus-xkzrz is verified up and running
STEP: scaling down the replication controller
Sep 26 04:05:59.921: INFO: scanned /root for discovery docs: <nil>
Sep 26 04:05:59.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2882'
Sep 26 04:06:01.006: INFO: stderr: ""
Sep 26 04:06:01.006: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 26 04:06:01.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2882'
Sep 26 04:06:01.093: INFO: stderr: ""
Sep 26 04:06:01.093: INFO: stdout: "update-demo-nautilus-6dvn7 update-demo-nautilus-xkzrz "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 26 04:06:06.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2882'
Sep 26 04:06:06.160: INFO: stderr: ""
Sep 26 04:06:06.160: INFO: stdout: "update-demo-nautilus-xkzrz "
Sep 26 04:06:06.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-xkzrz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:06:06.251: INFO: stderr: ""
Sep 26 04:06:06.251: INFO: stdout: "true"
Sep 26 04:06:06.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-xkzrz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:06:06.323: INFO: stderr: ""
Sep 26 04:06:06.323: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 26 04:06:06.323: INFO: validating pod update-demo-nautilus-xkzrz
Sep 26 04:06:06.326: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 26 04:06:06.326: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 26 04:06:06.326: INFO: update-demo-nautilus-xkzrz is verified up and running
STEP: scaling up the replication controller
Sep 26 04:06:06.327: INFO: scanned /root for discovery docs: <nil>
Sep 26 04:06:06.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2882'
Sep 26 04:06:07.416: INFO: stderr: ""
Sep 26 04:06:07.416: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 26 04:06:07.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2882'
Sep 26 04:06:07.485: INFO: stderr: ""
Sep 26 04:06:07.485: INFO: stdout: "update-demo-nautilus-l2fws update-demo-nautilus-xkzrz "
Sep 26 04:06:07.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-l2fws -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:06:07.551: INFO: stderr: ""
Sep 26 04:06:07.551: INFO: stdout: "true"
Sep 26 04:06:07.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-l2fws -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:06:07.615: INFO: stderr: ""
Sep 26 04:06:07.615: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 26 04:06:07.615: INFO: validating pod update-demo-nautilus-l2fws
Sep 26 04:06:07.618: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 26 04:06:07.618: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 26 04:06:07.618: INFO: update-demo-nautilus-l2fws is verified up and running
Sep 26 04:06:07.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-xkzrz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:06:07.680: INFO: stderr: ""
Sep 26 04:06:07.680: INFO: stdout: "true"
Sep 26 04:06:07.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-xkzrz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2882'
Sep 26 04:06:07.749: INFO: stderr: ""
Sep 26 04:06:07.749: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 26 04:06:07.749: INFO: validating pod update-demo-nautilus-xkzrz
Sep 26 04:06:07.751: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 26 04:06:07.751: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 26 04:06:07.751: INFO: update-demo-nautilus-xkzrz is verified up and running
STEP: using delete to clean up resources
Sep 26 04:06:07.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete --grace-period=0 --force -f - --namespace=kubectl-2882'
Sep 26 04:06:07.819: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 26 04:06:07.819: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 26 04:06:07.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2882'
Sep 26 04:06:07.887: INFO: stderr: "No resources found.\n"
Sep 26 04:06:07.887: INFO: stdout: ""
Sep 26 04:06:07.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -l name=update-demo --namespace=kubectl-2882 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 26 04:06:07.953: INFO: stderr: ""
Sep 26 04:06:07.953: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:06:07.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2882" for this suite.
Sep 26 04:06:29.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:06:30.009: INFO: namespace kubectl-2882 deletion completed in 22.054008173s

• [SLOW TEST:35.801 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:06:30.010: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1199
I0926 04:06:30.032419      21 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1199, replica count: 1
I0926 04:06:31.082736      21 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 26 04:06:31.187: INFO: Created: latency-svc-jnxnw
Sep 26 04:06:31.197: INFO: Got endpoints: latency-svc-jnxnw [14.228166ms]
Sep 26 04:06:31.215: INFO: Created: latency-svc-5gqx5
Sep 26 04:06:31.219: INFO: Got endpoints: latency-svc-5gqx5 [22.331501ms]
Sep 26 04:06:31.224: INFO: Created: latency-svc-mst5c
Sep 26 04:06:31.230: INFO: Created: latency-svc-b84g7
Sep 26 04:06:31.231: INFO: Created: latency-svc-ftqt8
Sep 26 04:06:31.235: INFO: Created: latency-svc-lv45p
Sep 26 04:06:31.235: INFO: Created: latency-svc-wmwvq
Sep 26 04:06:31.238: INFO: Got endpoints: latency-svc-mst5c [38.964301ms]
Sep 26 04:06:31.243: INFO: Created: latency-svc-dslk9
Sep 26 04:06:31.252: INFO: Created: latency-svc-glmzr
Sep 26 04:06:31.264: INFO: Got endpoints: latency-svc-ftqt8 [66.455001ms]
Sep 26 04:06:31.264: INFO: Got endpoints: latency-svc-b84g7 [66.658858ms]
Sep 26 04:06:31.277: INFO: Created: latency-svc-n4hns
Sep 26 04:06:31.278: INFO: Created: latency-svc-dx5qd
Sep 26 04:06:31.278: INFO: Created: latency-svc-kcps7
Sep 26 04:06:31.280: INFO: Created: latency-svc-fvt59
Sep 26 04:06:31.282: INFO: Created: latency-svc-hlvs2
Sep 26 04:06:31.312: INFO: Created: latency-svc-llnrj
Sep 26 04:06:31.312: INFO: Got endpoints: latency-svc-wmwvq [114.710882ms]
Sep 26 04:06:31.313: INFO: Got endpoints: latency-svc-dslk9 [114.811082ms]
Sep 26 04:06:31.333: INFO: Got endpoints: latency-svc-lv45p [135.893766ms]
Sep 26 04:06:31.342: INFO: Got endpoints: latency-svc-fvt59 [143.729082ms]
Sep 26 04:06:31.342: INFO: Got endpoints: latency-svc-glmzr [104.404594ms]
Sep 26 04:06:31.342: INFO: Got endpoints: latency-svc-dx5qd [144.328198ms]
Sep 26 04:06:31.343: INFO: Got endpoints: latency-svc-llnrj [144.873209ms]
Sep 26 04:06:31.343: INFO: Got endpoints: latency-svc-kcps7 [145.001337ms]
Sep 26 04:06:31.343: INFO: Got endpoints: latency-svc-hlvs2 [144.777297ms]
Sep 26 04:06:31.343: INFO: Got endpoints: latency-svc-n4hns [145.297457ms]
Sep 26 04:06:31.359: INFO: Created: latency-svc-dlvbc
Sep 26 04:06:31.361: INFO: Created: latency-svc-5p5fm
Sep 26 04:06:31.363: INFO: Created: latency-svc-gqn76
Sep 26 04:06:31.363: INFO: Created: latency-svc-v29g5
Sep 26 04:06:31.363: INFO: Created: latency-svc-w4r2r
Sep 26 04:06:31.363: INFO: Created: latency-svc-l24gg
Sep 26 04:06:31.363: INFO: Created: latency-svc-9ndsr
Sep 26 04:06:31.363: INFO: Created: latency-svc-7dtc7
Sep 26 04:06:31.377: INFO: Got endpoints: latency-svc-dlvbc [43.290794ms]
Sep 26 04:06:31.380: INFO: Created: latency-svc-mwd8d
Sep 26 04:06:31.389: INFO: Created: latency-svc-jvddp
Sep 26 04:06:31.396: INFO: Created: latency-svc-tfng6
Sep 26 04:06:31.403: INFO: Created: latency-svc-k9mxc
Sep 26 04:06:31.408: INFO: Created: latency-svc-d5mwf
Sep 26 04:06:31.413: INFO: Got endpoints: latency-svc-gqn76 [193.433724ms]
Sep 26 04:06:31.413: INFO: Got endpoints: latency-svc-9ndsr [100.342599ms]
Sep 26 04:06:31.413: INFO: Got endpoints: latency-svc-w4r2r [149.284729ms]
Sep 26 04:06:31.418: INFO: Got endpoints: latency-svc-v29g5 [105.735291ms]
Sep 26 04:06:31.418: INFO: Got endpoints: latency-svc-l24gg [154.458412ms]
Sep 26 04:06:31.420: INFO: Created: latency-svc-njcgk
Sep 26 04:06:31.437: INFO: Got endpoints: latency-svc-jvddp [94.668386ms]
Sep 26 04:06:31.441: INFO: Created: latency-svc-5d89w
Sep 26 04:06:31.472: INFO: Got endpoints: latency-svc-njcgk [128.922693ms]
Sep 26 04:06:31.472: INFO: Got endpoints: latency-svc-tfng6 [129.838221ms]
Sep 26 04:06:31.472: INFO: Got endpoints: latency-svc-5p5fm [273.685592ms]
Sep 26 04:06:31.473: INFO: Got endpoints: latency-svc-mwd8d [130.446018ms]
Sep 26 04:06:31.473: INFO: Got endpoints: latency-svc-7dtc7 [275.016588ms]
Sep 26 04:06:31.473: INFO: Got endpoints: latency-svc-d5mwf [129.479469ms]
Sep 26 04:06:31.473: INFO: Got endpoints: latency-svc-k9mxc [130.266551ms]
Sep 26 04:06:31.473: INFO: Created: latency-svc-dmffj
Sep 26 04:06:31.473: INFO: Created: latency-svc-sdw8g
Sep 26 04:06:31.473: INFO: Got endpoints: latency-svc-5d89w [130.209815ms]
Sep 26 04:06:31.499: INFO: Got endpoints: latency-svc-sdw8g [122.357065ms]
Sep 26 04:06:31.499: INFO: Got endpoints: latency-svc-dmffj [86.54564ms]
Sep 26 04:06:31.505: INFO: Created: latency-svc-wp2gr
Sep 26 04:06:31.505: INFO: Got endpoints: latency-svc-wp2gr [86.931423ms]
Sep 26 04:06:31.506: INFO: Created: latency-svc-gvfpj
Sep 26 04:06:31.516: INFO: Got endpoints: latency-svc-gvfpj [78.755929ms]
Sep 26 04:06:31.520: INFO: Created: latency-svc-p5pdn
Sep 26 04:06:31.525: INFO: Got endpoints: latency-svc-p5pdn [53.047441ms]
Sep 26 04:06:31.528: INFO: Created: latency-svc-px6k2
Sep 26 04:06:31.532: INFO: Got endpoints: latency-svc-px6k2 [59.888805ms]
Sep 26 04:06:31.539: INFO: Created: latency-svc-47jn6
Sep 26 04:06:31.547: INFO: Created: latency-svc-8np4n
Sep 26 04:06:31.549: INFO: Created: latency-svc-xc4wj
Sep 26 04:06:31.549: INFO: Got endpoints: latency-svc-47jn6 [24.056114ms]
Sep 26 04:06:31.621: INFO: Created: latency-svc-hfnvd
Sep 26 04:06:31.621: INFO: Got endpoints: latency-svc-xc4wj [88.553007ms]
Sep 26 04:06:31.621: INFO: Created: latency-svc-sb8xp
Sep 26 04:06:31.628: INFO: Created: latency-svc-cdvmz
Sep 26 04:06:31.635: INFO: Created: latency-svc-ckcvw
Sep 26 04:06:31.637: INFO: Created: latency-svc-rmsfb
Sep 26 04:06:31.640: INFO: Created: latency-svc-k8rz9
Sep 26 04:06:31.645: INFO: Got endpoints: latency-svc-8np4n [232.159772ms]
Sep 26 04:06:31.649: INFO: Created: latency-svc-mxk4j
Sep 26 04:06:31.654: INFO: Created: latency-svc-6hvvw
Sep 26 04:06:31.660: INFO: Created: latency-svc-w228d
Sep 26 04:06:31.661: INFO: Created: latency-svc-jkpz8
Sep 26 04:06:31.679: INFO: Created: latency-svc-ldsf4
Sep 26 04:06:31.679: INFO: Created: latency-svc-vhbwl
Sep 26 04:06:31.681: INFO: Created: latency-svc-rvk8s
Sep 26 04:06:31.682: INFO: Created: latency-svc-r7gb2
Sep 26 04:06:31.684: INFO: Created: latency-svc-xn8rq
Sep 26 04:06:31.711: INFO: Got endpoints: latency-svc-hfnvd [239.018762ms]
Sep 26 04:06:31.724: INFO: Created: latency-svc-fh8v7
Sep 26 04:06:31.768: INFO: Got endpoints: latency-svc-sb8xp [294.200558ms]
Sep 26 04:06:31.800: INFO: Got endpoints: latency-svc-cdvmz [327.560341ms]
Sep 26 04:06:31.804: INFO: Created: latency-svc-r44zz
Sep 26 04:06:31.812: INFO: Created: latency-svc-ptjhl
Sep 26 04:06:31.844: INFO: Got endpoints: latency-svc-ckcvw [430.632062ms]
Sep 26 04:06:31.848: INFO: Created: latency-svc-mwgrj
Sep 26 04:06:31.893: INFO: Got endpoints: latency-svc-rmsfb [420.174073ms]
Sep 26 04:06:31.900: INFO: Created: latency-svc-4nw5p
Sep 26 04:06:31.944: INFO: Got endpoints: latency-svc-k8rz9 [471.314241ms]
Sep 26 04:06:31.953: INFO: Created: latency-svc-v7hmt
Sep 26 04:06:31.995: INFO: Got endpoints: latency-svc-mxk4j [521.9244ms]
Sep 26 04:06:32.002: INFO: Created: latency-svc-spf6b
Sep 26 04:06:32.044: INFO: Got endpoints: latency-svc-6hvvw [544.849646ms]
Sep 26 04:06:32.050: INFO: Created: latency-svc-shh7j
Sep 26 04:06:32.095: INFO: Got endpoints: latency-svc-w228d [590.159401ms]
Sep 26 04:06:32.113: INFO: Created: latency-svc-m4srk
Sep 26 04:06:32.144: INFO: Got endpoints: latency-svc-jkpz8 [644.570129ms]
Sep 26 04:06:32.151: INFO: Created: latency-svc-dgbzq
Sep 26 04:06:32.194: INFO: Got endpoints: latency-svc-r7gb2 [677.985841ms]
Sep 26 04:06:32.200: INFO: Created: latency-svc-d7wkc
Sep 26 04:06:32.250: INFO: Got endpoints: latency-svc-vhbwl [832.358144ms]
Sep 26 04:06:32.261: INFO: Created: latency-svc-ps59w
Sep 26 04:06:32.293: INFO: Got endpoints: latency-svc-ldsf4 [743.469847ms]
Sep 26 04:06:32.298: INFO: Created: latency-svc-l6qcm
Sep 26 04:06:32.343: INFO: Got endpoints: latency-svc-rvk8s [722.145252ms]
Sep 26 04:06:32.352: INFO: Created: latency-svc-mcxmm
Sep 26 04:06:32.394: INFO: Got endpoints: latency-svc-xn8rq [748.80239ms]
Sep 26 04:06:32.399: INFO: Created: latency-svc-fnmv8
Sep 26 04:06:32.445: INFO: Got endpoints: latency-svc-fh8v7 [733.844684ms]
Sep 26 04:06:32.452: INFO: Created: latency-svc-t7zvn
Sep 26 04:06:32.495: INFO: Got endpoints: latency-svc-r44zz [727.257029ms]
Sep 26 04:06:32.500: INFO: Created: latency-svc-npk2g
Sep 26 04:06:32.545: INFO: Got endpoints: latency-svc-ptjhl [745.063913ms]
Sep 26 04:06:32.552: INFO: Created: latency-svc-zj8qc
Sep 26 04:06:32.594: INFO: Got endpoints: latency-svc-mwgrj [750.496726ms]
Sep 26 04:06:32.600: INFO: Created: latency-svc-v66qd
Sep 26 04:06:32.642: INFO: Got endpoints: latency-svc-4nw5p [749.558143ms]
Sep 26 04:06:32.650: INFO: Created: latency-svc-c2rdr
Sep 26 04:06:32.699: INFO: Got endpoints: latency-svc-v7hmt [754.431484ms]
Sep 26 04:06:32.706: INFO: Created: latency-svc-bhgtw
Sep 26 04:06:32.752: INFO: Got endpoints: latency-svc-spf6b [757.126878ms]
Sep 26 04:06:32.760: INFO: Created: latency-svc-29r9k
Sep 26 04:06:32.794: INFO: Got endpoints: latency-svc-shh7j [750.204789ms]
Sep 26 04:06:32.798: INFO: Created: latency-svc-8d6lg
Sep 26 04:06:32.846: INFO: Got endpoints: latency-svc-m4srk [751.007384ms]
Sep 26 04:06:32.853: INFO: Created: latency-svc-fdgm9
Sep 26 04:06:32.893: INFO: Got endpoints: latency-svc-dgbzq [748.724254ms]
Sep 26 04:06:32.896: INFO: Created: latency-svc-p84j8
Sep 26 04:06:32.942: INFO: Got endpoints: latency-svc-d7wkc [748.183861ms]
Sep 26 04:06:32.950: INFO: Created: latency-svc-m87tz
Sep 26 04:06:32.993: INFO: Got endpoints: latency-svc-ps59w [742.392405ms]
Sep 26 04:06:32.998: INFO: Created: latency-svc-blwcw
Sep 26 04:06:33.042: INFO: Got endpoints: latency-svc-l6qcm [749.244106ms]
Sep 26 04:06:33.048: INFO: Created: latency-svc-vczwf
Sep 26 04:06:33.093: INFO: Got endpoints: latency-svc-mcxmm [749.25752ms]
Sep 26 04:06:33.098: INFO: Created: latency-svc-96m95
Sep 26 04:06:33.143: INFO: Got endpoints: latency-svc-fnmv8 [749.246713ms]
Sep 26 04:06:33.147: INFO: Created: latency-svc-zphm9
Sep 26 04:06:33.193: INFO: Got endpoints: latency-svc-t7zvn [748.057728ms]
Sep 26 04:06:33.197: INFO: Created: latency-svc-dd2tm
Sep 26 04:06:33.243: INFO: Got endpoints: latency-svc-npk2g [747.72628ms]
Sep 26 04:06:33.249: INFO: Created: latency-svc-8hgkj
Sep 26 04:06:33.292: INFO: Got endpoints: latency-svc-zj8qc [747.319081ms]
Sep 26 04:06:33.296: INFO: Created: latency-svc-422cn
Sep 26 04:06:33.342: INFO: Got endpoints: latency-svc-v66qd [748.329097ms]
Sep 26 04:06:33.346: INFO: Created: latency-svc-5d4rg
Sep 26 04:06:33.394: INFO: Got endpoints: latency-svc-c2rdr [751.403374ms]
Sep 26 04:06:33.398: INFO: Created: latency-svc-zc59z
Sep 26 04:06:33.443: INFO: Got endpoints: latency-svc-bhgtw [744.452507ms]
Sep 26 04:06:33.447: INFO: Created: latency-svc-2nwd8
Sep 26 04:06:33.493: INFO: Got endpoints: latency-svc-29r9k [741.156976ms]
Sep 26 04:06:33.497: INFO: Created: latency-svc-2qmq7
Sep 26 04:06:33.543: INFO: Got endpoints: latency-svc-8d6lg [748.684728ms]
Sep 26 04:06:33.547: INFO: Created: latency-svc-5t7ng
Sep 26 04:06:33.596: INFO: Got endpoints: latency-svc-fdgm9 [749.148465ms]
Sep 26 04:06:33.600: INFO: Created: latency-svc-f5xhb
Sep 26 04:06:33.643: INFO: Got endpoints: latency-svc-p84j8 [750.359324ms]
Sep 26 04:06:33.648: INFO: Created: latency-svc-d76hw
Sep 26 04:06:33.692: INFO: Got endpoints: latency-svc-m87tz [750.031977ms]
Sep 26 04:06:33.698: INFO: Created: latency-svc-zblx8
Sep 26 04:06:33.745: INFO: Got endpoints: latency-svc-blwcw [752.182911ms]
Sep 26 04:06:33.748: INFO: Created: latency-svc-qtqdz
Sep 26 04:06:33.792: INFO: Got endpoints: latency-svc-vczwf [750.151872ms]
Sep 26 04:06:33.797: INFO: Created: latency-svc-2lb4v
Sep 26 04:06:33.842: INFO: Got endpoints: latency-svc-96m95 [749.736496ms]
Sep 26 04:06:33.855: INFO: Created: latency-svc-f9lmc
Sep 26 04:06:33.893: INFO: Got endpoints: latency-svc-zphm9 [750.029201ms]
Sep 26 04:06:33.902: INFO: Created: latency-svc-jzxx7
Sep 26 04:06:33.945: INFO: Got endpoints: latency-svc-dd2tm [751.547823ms]
Sep 26 04:06:33.949: INFO: Created: latency-svc-tt8zx
Sep 26 04:06:33.995: INFO: Got endpoints: latency-svc-8hgkj [752.302877ms]
Sep 26 04:06:34.003: INFO: Created: latency-svc-242sh
Sep 26 04:06:34.046: INFO: Got endpoints: latency-svc-422cn [753.665075ms]
Sep 26 04:06:34.053: INFO: Created: latency-svc-7wpmr
Sep 26 04:06:34.094: INFO: Got endpoints: latency-svc-5d4rg [750.994751ms]
Sep 26 04:06:34.098: INFO: Created: latency-svc-jvcpv
Sep 26 04:06:34.144: INFO: Got endpoints: latency-svc-zc59z [750.431455ms]
Sep 26 04:06:34.155: INFO: Created: latency-svc-9cktr
Sep 26 04:06:34.199: INFO: Got endpoints: latency-svc-2nwd8 [756.177662ms]
Sep 26 04:06:34.206: INFO: Created: latency-svc-mbpll
Sep 26 04:06:34.244: INFO: Got endpoints: latency-svc-2qmq7 [750.168394ms]
Sep 26 04:06:34.251: INFO: Created: latency-svc-j8h6t
Sep 26 04:06:34.298: INFO: Got endpoints: latency-svc-5t7ng [754.985918ms]
Sep 26 04:06:34.305: INFO: Created: latency-svc-vp7sx
Sep 26 04:06:34.343: INFO: Got endpoints: latency-svc-f5xhb [747.423726ms]
Sep 26 04:06:34.353: INFO: Created: latency-svc-4brq4
Sep 26 04:06:34.393: INFO: Got endpoints: latency-svc-d76hw [750.302968ms]
Sep 26 04:06:34.409: INFO: Created: latency-svc-2xbpc
Sep 26 04:06:34.444: INFO: Got endpoints: latency-svc-zblx8 [751.604295ms]
Sep 26 04:06:34.449: INFO: Created: latency-svc-qm79q
Sep 26 04:06:34.493: INFO: Got endpoints: latency-svc-qtqdz [747.606432ms]
Sep 26 04:06:34.499: INFO: Created: latency-svc-zlt28
Sep 26 04:06:34.544: INFO: Got endpoints: latency-svc-2lb4v [751.483794ms]
Sep 26 04:06:34.553: INFO: Created: latency-svc-r59sm
Sep 26 04:06:34.594: INFO: Got endpoints: latency-svc-f9lmc [751.306908ms]
Sep 26 04:06:34.603: INFO: Created: latency-svc-kv2fb
Sep 26 04:06:34.645: INFO: Got endpoints: latency-svc-jzxx7 [751.748895ms]
Sep 26 04:06:34.652: INFO: Created: latency-svc-2cm6m
Sep 26 04:06:34.694: INFO: Got endpoints: latency-svc-tt8zx [748.917937ms]
Sep 26 04:06:34.701: INFO: Created: latency-svc-2gzjm
Sep 26 04:06:34.743: INFO: Got endpoints: latency-svc-242sh [748.3442ms]
Sep 26 04:06:34.751: INFO: Created: latency-svc-2cwcj
Sep 26 04:06:34.795: INFO: Got endpoints: latency-svc-7wpmr [748.603374ms]
Sep 26 04:06:34.802: INFO: Created: latency-svc-xldb8
Sep 26 04:06:34.846: INFO: Got endpoints: latency-svc-jvcpv [752.134462ms]
Sep 26 04:06:34.855: INFO: Created: latency-svc-w8bdk
Sep 26 04:06:34.898: INFO: Got endpoints: latency-svc-9cktr [753.790991ms]
Sep 26 04:06:34.905: INFO: Created: latency-svc-k7xzd
Sep 26 04:06:34.944: INFO: Got endpoints: latency-svc-mbpll [744.134922ms]
Sep 26 04:06:34.951: INFO: Created: latency-svc-mqvsk
Sep 26 04:06:34.996: INFO: Got endpoints: latency-svc-j8h6t [751.961941ms]
Sep 26 04:06:35.005: INFO: Created: latency-svc-jr8dk
Sep 26 04:06:35.045: INFO: Got endpoints: latency-svc-vp7sx [747.31982ms]
Sep 26 04:06:35.052: INFO: Created: latency-svc-p5wbh
Sep 26 04:06:35.096: INFO: Got endpoints: latency-svc-4brq4 [752.482761ms]
Sep 26 04:06:35.103: INFO: Created: latency-svc-j4ws8
Sep 26 04:06:35.145: INFO: Got endpoints: latency-svc-2xbpc [751.871896ms]
Sep 26 04:06:35.154: INFO: Created: latency-svc-fszb7
Sep 26 04:06:35.197: INFO: Got endpoints: latency-svc-qm79q [753.182515ms]
Sep 26 04:06:35.209: INFO: Created: latency-svc-6cds6
Sep 26 04:06:35.247: INFO: Got endpoints: latency-svc-zlt28 [753.922875ms]
Sep 26 04:06:35.257: INFO: Created: latency-svc-5nw7j
Sep 26 04:06:35.295: INFO: Got endpoints: latency-svc-r59sm [751.015568ms]
Sep 26 04:06:35.301: INFO: Created: latency-svc-bm9mx
Sep 26 04:06:35.343: INFO: Got endpoints: latency-svc-kv2fb [748.994473ms]
Sep 26 04:06:35.353: INFO: Created: latency-svc-6hl68
Sep 26 04:06:35.394: INFO: Got endpoints: latency-svc-2cm6m [748.915437ms]
Sep 26 04:06:35.400: INFO: Created: latency-svc-6957l
Sep 26 04:06:35.444: INFO: Got endpoints: latency-svc-2gzjm [750.838776ms]
Sep 26 04:06:35.453: INFO: Created: latency-svc-wr72z
Sep 26 04:06:35.495: INFO: Got endpoints: latency-svc-2cwcj [751.313038ms]
Sep 26 04:06:35.504: INFO: Created: latency-svc-9ds4d
Sep 26 04:06:35.543: INFO: Got endpoints: latency-svc-xldb8 [748.342099ms]
Sep 26 04:06:35.552: INFO: Created: latency-svc-5qfgg
Sep 26 04:06:35.596: INFO: Got endpoints: latency-svc-w8bdk [750.711819ms]
Sep 26 04:06:35.603: INFO: Created: latency-svc-8cj9p
Sep 26 04:06:35.647: INFO: Got endpoints: latency-svc-k7xzd [749.218364ms]
Sep 26 04:06:35.659: INFO: Created: latency-svc-9m89m
Sep 26 04:06:35.694: INFO: Got endpoints: latency-svc-mqvsk [750.701228ms]
Sep 26 04:06:35.703: INFO: Created: latency-svc-b4mfx
Sep 26 04:06:35.755: INFO: Got endpoints: latency-svc-jr8dk [759.56381ms]
Sep 26 04:06:35.760: INFO: Created: latency-svc-sqbk6
Sep 26 04:06:35.795: INFO: Got endpoints: latency-svc-p5wbh [749.323172ms]
Sep 26 04:06:35.805: INFO: Created: latency-svc-tg6fg
Sep 26 04:06:35.845: INFO: Got endpoints: latency-svc-j4ws8 [748.836405ms]
Sep 26 04:06:35.852: INFO: Created: latency-svc-tvsd9
Sep 26 04:06:35.894: INFO: Got endpoints: latency-svc-fszb7 [748.506194ms]
Sep 26 04:06:35.900: INFO: Created: latency-svc-48x6q
Sep 26 04:06:35.946: INFO: Got endpoints: latency-svc-6cds6 [748.655931ms]
Sep 26 04:06:35.952: INFO: Created: latency-svc-6fc5q
Sep 26 04:06:35.994: INFO: Got endpoints: latency-svc-5nw7j [747.459132ms]
Sep 26 04:06:36.000: INFO: Created: latency-svc-tn9r7
Sep 26 04:06:36.044: INFO: Got endpoints: latency-svc-bm9mx [748.535916ms]
Sep 26 04:06:36.053: INFO: Created: latency-svc-8mcgs
Sep 26 04:06:36.093: INFO: Got endpoints: latency-svc-6hl68 [750.60574ms]
Sep 26 04:06:36.106: INFO: Created: latency-svc-vslqr
Sep 26 04:06:36.143: INFO: Got endpoints: latency-svc-6957l [748.65404ms]
Sep 26 04:06:36.150: INFO: Created: latency-svc-7h68x
Sep 26 04:06:36.193: INFO: Got endpoints: latency-svc-wr72z [748.743293ms]
Sep 26 04:06:36.208: INFO: Created: latency-svc-zpjgj
Sep 26 04:06:36.242: INFO: Got endpoints: latency-svc-9ds4d [747.600689ms]
Sep 26 04:06:36.250: INFO: Created: latency-svc-2trcp
Sep 26 04:06:36.294: INFO: Got endpoints: latency-svc-5qfgg [751.303792ms]
Sep 26 04:06:36.301: INFO: Created: latency-svc-8vbjr
Sep 26 04:06:36.344: INFO: Got endpoints: latency-svc-8cj9p [747.497415ms]
Sep 26 04:06:36.350: INFO: Created: latency-svc-57lpq
Sep 26 04:06:36.394: INFO: Got endpoints: latency-svc-9m89m [746.0436ms]
Sep 26 04:06:36.398: INFO: Created: latency-svc-xqw86
Sep 26 04:06:36.445: INFO: Got endpoints: latency-svc-b4mfx [750.861757ms]
Sep 26 04:06:36.449: INFO: Created: latency-svc-csbkt
Sep 26 04:06:36.493: INFO: Got endpoints: latency-svc-sqbk6 [737.749887ms]
Sep 26 04:06:36.498: INFO: Created: latency-svc-f2n2l
Sep 26 04:06:36.547: INFO: Got endpoints: latency-svc-tg6fg [752.356845ms]
Sep 26 04:06:36.557: INFO: Created: latency-svc-gm48q
Sep 26 04:06:36.594: INFO: Got endpoints: latency-svc-tvsd9 [749.396467ms]
Sep 26 04:06:36.604: INFO: Created: latency-svc-4w2b2
Sep 26 04:06:36.646: INFO: Got endpoints: latency-svc-48x6q [752.280157ms]
Sep 26 04:06:36.654: INFO: Created: latency-svc-fjbt2
Sep 26 04:06:36.696: INFO: Got endpoints: latency-svc-6fc5q [750.035343ms]
Sep 26 04:06:36.704: INFO: Created: latency-svc-8vn6m
Sep 26 04:06:36.744: INFO: Got endpoints: latency-svc-tn9r7 [749.597048ms]
Sep 26 04:06:36.753: INFO: Created: latency-svc-bk6jf
Sep 26 04:06:36.796: INFO: Got endpoints: latency-svc-8mcgs [752.300039ms]
Sep 26 04:06:36.804: INFO: Created: latency-svc-nbzj8
Sep 26 04:06:36.846: INFO: Got endpoints: latency-svc-vslqr [752.49253ms]
Sep 26 04:06:36.858: INFO: Created: latency-svc-64mbm
Sep 26 04:06:36.894: INFO: Got endpoints: latency-svc-7h68x [751.419688ms]
Sep 26 04:06:36.899: INFO: Created: latency-svc-v5js9
Sep 26 04:06:36.943: INFO: Got endpoints: latency-svc-zpjgj [750.082076ms]
Sep 26 04:06:36.951: INFO: Created: latency-svc-xbhrq
Sep 26 04:06:36.996: INFO: Got endpoints: latency-svc-2trcp [753.345161ms]
Sep 26 04:06:37.006: INFO: Created: latency-svc-ctlfg
Sep 26 04:06:37.047: INFO: Got endpoints: latency-svc-8vbjr [752.633405ms]
Sep 26 04:06:37.056: INFO: Created: latency-svc-sspt4
Sep 26 04:06:37.093: INFO: Got endpoints: latency-svc-57lpq [748.481733ms]
Sep 26 04:06:37.097: INFO: Created: latency-svc-9rmg8
Sep 26 04:06:37.152: INFO: Got endpoints: latency-svc-xqw86 [758.84579ms]
Sep 26 04:06:37.158: INFO: Created: latency-svc-7qwqf
Sep 26 04:06:37.194: INFO: Got endpoints: latency-svc-csbkt [748.881418ms]
Sep 26 04:06:37.200: INFO: Created: latency-svc-trnt6
Sep 26 04:06:37.245: INFO: Got endpoints: latency-svc-f2n2l [751.693924ms]
Sep 26 04:06:37.248: INFO: Created: latency-svc-5vd46
Sep 26 04:06:37.294: INFO: Got endpoints: latency-svc-gm48q [746.738989ms]
Sep 26 04:06:37.307: INFO: Created: latency-svc-fmrx5
Sep 26 04:06:37.347: INFO: Got endpoints: latency-svc-4w2b2 [753.393832ms]
Sep 26 04:06:37.355: INFO: Created: latency-svc-l5g9p
Sep 26 04:06:37.394: INFO: Got endpoints: latency-svc-fjbt2 [747.911477ms]
Sep 26 04:06:37.402: INFO: Created: latency-svc-ttbw7
Sep 26 04:06:37.447: INFO: Got endpoints: latency-svc-8vn6m [750.96058ms]
Sep 26 04:06:37.453: INFO: Created: latency-svc-7rqpp
Sep 26 04:06:37.493: INFO: Got endpoints: latency-svc-bk6jf [749.095071ms]
Sep 26 04:06:37.502: INFO: Created: latency-svc-c6nq7
Sep 26 04:06:37.545: INFO: Got endpoints: latency-svc-nbzj8 [749.035174ms]
Sep 26 04:06:37.553: INFO: Created: latency-svc-xc2sv
Sep 26 04:06:37.596: INFO: Got endpoints: latency-svc-64mbm [750.315066ms]
Sep 26 04:06:37.601: INFO: Created: latency-svc-czgd8
Sep 26 04:06:37.645: INFO: Got endpoints: latency-svc-v5js9 [750.799079ms]
Sep 26 04:06:37.654: INFO: Created: latency-svc-58mwt
Sep 26 04:06:37.697: INFO: Got endpoints: latency-svc-xbhrq [754.11126ms]
Sep 26 04:06:37.709: INFO: Created: latency-svc-d4qdt
Sep 26 04:06:37.746: INFO: Got endpoints: latency-svc-ctlfg [750.075534ms]
Sep 26 04:06:37.759: INFO: Created: latency-svc-lfqjf
Sep 26 04:06:37.794: INFO: Got endpoints: latency-svc-sspt4 [747.168875ms]
Sep 26 04:06:37.802: INFO: Created: latency-svc-pvjlb
Sep 26 04:06:37.845: INFO: Got endpoints: latency-svc-9rmg8 [752.284249ms]
Sep 26 04:06:37.861: INFO: Created: latency-svc-6zcp9
Sep 26 04:06:37.895: INFO: Got endpoints: latency-svc-7qwqf [742.890402ms]
Sep 26 04:06:37.908: INFO: Created: latency-svc-nvkt7
Sep 26 04:06:37.944: INFO: Got endpoints: latency-svc-trnt6 [749.951818ms]
Sep 26 04:06:37.954: INFO: Created: latency-svc-98w8c
Sep 26 04:06:37.994: INFO: Got endpoints: latency-svc-5vd46 [749.143075ms]
Sep 26 04:06:38.009: INFO: Created: latency-svc-72ww7
Sep 26 04:06:38.044: INFO: Got endpoints: latency-svc-fmrx5 [750.543878ms]
Sep 26 04:06:38.049: INFO: Created: latency-svc-65f6c
Sep 26 04:06:38.097: INFO: Got endpoints: latency-svc-l5g9p [749.444444ms]
Sep 26 04:06:38.101: INFO: Created: latency-svc-kx5j5
Sep 26 04:06:38.151: INFO: Got endpoints: latency-svc-ttbw7 [756.772189ms]
Sep 26 04:06:38.161: INFO: Created: latency-svc-rdjlt
Sep 26 04:06:38.197: INFO: Got endpoints: latency-svc-7rqpp [749.681114ms]
Sep 26 04:06:38.208: INFO: Created: latency-svc-jfr4s
Sep 26 04:06:38.243: INFO: Got endpoints: latency-svc-c6nq7 [750.355799ms]
Sep 26 04:06:38.254: INFO: Created: latency-svc-6qfwc
Sep 26 04:06:38.304: INFO: Got endpoints: latency-svc-xc2sv [759.156615ms]
Sep 26 04:06:38.313: INFO: Created: latency-svc-2zsk9
Sep 26 04:06:38.343: INFO: Got endpoints: latency-svc-czgd8 [746.634292ms]
Sep 26 04:06:38.352: INFO: Created: latency-svc-6qhhx
Sep 26 04:06:38.395: INFO: Got endpoints: latency-svc-58mwt [749.413848ms]
Sep 26 04:06:38.401: INFO: Created: latency-svc-2swt2
Sep 26 04:06:38.443: INFO: Got endpoints: latency-svc-d4qdt [745.948356ms]
Sep 26 04:06:38.448: INFO: Created: latency-svc-mnpxw
Sep 26 04:06:38.494: INFO: Got endpoints: latency-svc-lfqjf [748.211617ms]
Sep 26 04:06:38.500: INFO: Created: latency-svc-8pclm
Sep 26 04:06:38.544: INFO: Got endpoints: latency-svc-pvjlb [750.22966ms]
Sep 26 04:06:38.552: INFO: Created: latency-svc-89xlr
Sep 26 04:06:38.596: INFO: Got endpoints: latency-svc-6zcp9 [750.646969ms]
Sep 26 04:06:38.601: INFO: Created: latency-svc-gf7cw
Sep 26 04:06:38.644: INFO: Got endpoints: latency-svc-nvkt7 [748.108134ms]
Sep 26 04:06:38.655: INFO: Created: latency-svc-vcx7s
Sep 26 04:06:38.693: INFO: Got endpoints: latency-svc-98w8c [748.692304ms]
Sep 26 04:06:38.704: INFO: Created: latency-svc-xwn8d
Sep 26 04:06:38.744: INFO: Got endpoints: latency-svc-72ww7 [750.140774ms]
Sep 26 04:06:38.752: INFO: Created: latency-svc-zgw4t
Sep 26 04:06:38.793: INFO: Got endpoints: latency-svc-65f6c [748.859886ms]
Sep 26 04:06:38.799: INFO: Created: latency-svc-2jgtx
Sep 26 04:06:38.844: INFO: Got endpoints: latency-svc-kx5j5 [747.434743ms]
Sep 26 04:06:38.850: INFO: Created: latency-svc-nmm4h
Sep 26 04:06:38.895: INFO: Got endpoints: latency-svc-rdjlt [743.504991ms]
Sep 26 04:06:38.904: INFO: Created: latency-svc-k8wkc
Sep 26 04:06:38.945: INFO: Got endpoints: latency-svc-jfr4s [747.892238ms]
Sep 26 04:06:38.955: INFO: Created: latency-svc-424nd
Sep 26 04:06:38.995: INFO: Got endpoints: latency-svc-6qfwc [751.049581ms]
Sep 26 04:06:39.001: INFO: Created: latency-svc-rjrdj
Sep 26 04:06:39.045: INFO: Got endpoints: latency-svc-2zsk9 [740.333055ms]
Sep 26 04:06:39.094: INFO: Got endpoints: latency-svc-6qhhx [750.475957ms]
Sep 26 04:06:39.144: INFO: Got endpoints: latency-svc-2swt2 [748.910418ms]
Sep 26 04:06:39.196: INFO: Got endpoints: latency-svc-mnpxw [752.227599ms]
Sep 26 04:06:39.251: INFO: Got endpoints: latency-svc-8pclm [756.79937ms]
Sep 26 04:06:39.293: INFO: Got endpoints: latency-svc-89xlr [748.570543ms]
Sep 26 04:06:39.345: INFO: Got endpoints: latency-svc-gf7cw [748.917605ms]
Sep 26 04:06:39.394: INFO: Got endpoints: latency-svc-vcx7s [750.209746ms]
Sep 26 04:06:39.445: INFO: Got endpoints: latency-svc-xwn8d [751.667837ms]
Sep 26 04:06:39.497: INFO: Got endpoints: latency-svc-zgw4t [753.011625ms]
Sep 26 04:06:39.544: INFO: Got endpoints: latency-svc-2jgtx [750.244189ms]
Sep 26 04:06:39.593: INFO: Got endpoints: latency-svc-nmm4h [748.986691ms]
Sep 26 04:06:39.649: INFO: Got endpoints: latency-svc-k8wkc [754.021463ms]
Sep 26 04:06:39.693: INFO: Got endpoints: latency-svc-424nd [748.683759ms]
Sep 26 04:06:39.743: INFO: Got endpoints: latency-svc-rjrdj [748.77886ms]
Sep 26 04:06:39.743: INFO: Latencies: [22.331501ms 24.056114ms 38.964301ms 43.290794ms 53.047441ms 59.888805ms 66.455001ms 66.658858ms 78.755929ms 86.54564ms 86.931423ms 88.553007ms 94.668386ms 100.342599ms 104.404594ms 105.735291ms 114.710882ms 114.811082ms 122.357065ms 128.922693ms 129.479469ms 129.838221ms 130.209815ms 130.266551ms 130.446018ms 135.893766ms 143.729082ms 144.328198ms 144.777297ms 144.873209ms 145.001337ms 145.297457ms 149.284729ms 154.458412ms 193.433724ms 232.159772ms 239.018762ms 273.685592ms 275.016588ms 294.200558ms 327.560341ms 420.174073ms 430.632062ms 471.314241ms 521.9244ms 544.849646ms 590.159401ms 644.570129ms 677.985841ms 722.145252ms 727.257029ms 733.844684ms 737.749887ms 740.333055ms 741.156976ms 742.392405ms 742.890402ms 743.469847ms 743.504991ms 744.134922ms 744.452507ms 745.063913ms 745.948356ms 746.0436ms 746.634292ms 746.738989ms 747.168875ms 747.319081ms 747.31982ms 747.423726ms 747.434743ms 747.459132ms 747.497415ms 747.600689ms 747.606432ms 747.72628ms 747.892238ms 747.911477ms 748.057728ms 748.108134ms 748.183861ms 748.211617ms 748.329097ms 748.342099ms 748.3442ms 748.481733ms 748.506194ms 748.535916ms 748.570543ms 748.603374ms 748.65404ms 748.655931ms 748.683759ms 748.684728ms 748.692304ms 748.724254ms 748.743293ms 748.77886ms 748.80239ms 748.836405ms 748.859886ms 748.881418ms 748.910418ms 748.915437ms 748.917605ms 748.917937ms 748.986691ms 748.994473ms 749.035174ms 749.095071ms 749.143075ms 749.148465ms 749.218364ms 749.244106ms 749.246713ms 749.25752ms 749.323172ms 749.396467ms 749.413848ms 749.444444ms 749.558143ms 749.597048ms 749.681114ms 749.736496ms 749.951818ms 750.029201ms 750.031977ms 750.035343ms 750.075534ms 750.082076ms 750.140774ms 750.151872ms 750.168394ms 750.204789ms 750.209746ms 750.22966ms 750.244189ms 750.302968ms 750.315066ms 750.355799ms 750.359324ms 750.431455ms 750.475957ms 750.496726ms 750.543878ms 750.60574ms 750.646969ms 750.701228ms 750.711819ms 750.799079ms 750.838776ms 750.861757ms 750.96058ms 750.994751ms 751.007384ms 751.015568ms 751.049581ms 751.303792ms 751.306908ms 751.313038ms 751.403374ms 751.419688ms 751.483794ms 751.547823ms 751.604295ms 751.667837ms 751.693924ms 751.748895ms 751.871896ms 751.961941ms 752.134462ms 752.182911ms 752.227599ms 752.280157ms 752.284249ms 752.300039ms 752.302877ms 752.356845ms 752.482761ms 752.49253ms 752.633405ms 753.011625ms 753.182515ms 753.345161ms 753.393832ms 753.665075ms 753.790991ms 753.922875ms 754.021463ms 754.11126ms 754.431484ms 754.985918ms 756.177662ms 756.772189ms 756.79937ms 757.126878ms 758.84579ms 759.156615ms 759.56381ms 832.358144ms]
Sep 26 04:06:39.744: INFO: 50 %ile: 748.859886ms
Sep 26 04:06:39.744: INFO: 90 %ile: 752.633405ms
Sep 26 04:06:39.744: INFO: 99 %ile: 759.56381ms
Sep 26 04:06:39.744: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:06:39.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1199" for this suite.
Sep 26 04:06:59.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:06:59.814: INFO: namespace svc-latency-1199 deletion completed in 20.065878339s

• [SLOW TEST:29.804 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:06:59.814: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 26 04:07:00.160: INFO: Pod name wrapped-volume-race-169511db-e013-11e9-8008-76f27b732d80: Found 4 pods out of 5
Sep 26 04:07:05.170: INFO: Pod name wrapped-volume-race-169511db-e013-11e9-8008-76f27b732d80: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-169511db-e013-11e9-8008-76f27b732d80 in namespace emptydir-wrapper-2781, will wait for the garbage collector to delete the pods
Sep 26 04:07:15.250: INFO: Deleting ReplicationController wrapped-volume-race-169511db-e013-11e9-8008-76f27b732d80 took: 3.852326ms
Sep 26 04:07:15.550: INFO: Terminating ReplicationController wrapped-volume-race-169511db-e013-11e9-8008-76f27b732d80 pods took: 300.178401ms
STEP: Creating RC which spawns configmap-volume pods
Sep 26 04:07:58.862: INFO: Pod name wrapped-volume-race-39b26f7e-e013-11e9-8008-76f27b732d80: Found 0 pods out of 5
Sep 26 04:08:03.867: INFO: Pod name wrapped-volume-race-39b26f7e-e013-11e9-8008-76f27b732d80: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-39b26f7e-e013-11e9-8008-76f27b732d80 in namespace emptydir-wrapper-2781, will wait for the garbage collector to delete the pods
Sep 26 04:08:15.943: INFO: Deleting ReplicationController wrapped-volume-race-39b26f7e-e013-11e9-8008-76f27b732d80 took: 4.014804ms
Sep 26 04:08:16.443: INFO: Terminating ReplicationController wrapped-volume-race-39b26f7e-e013-11e9-8008-76f27b732d80 pods took: 500.195892ms
STEP: Creating RC which spawns configmap-volume pods
Sep 26 04:08:57.857: INFO: Pod name wrapped-volume-race-5cdc2040-e013-11e9-8008-76f27b732d80: Found 0 pods out of 5
Sep 26 04:09:02.862: INFO: Pod name wrapped-volume-race-5cdc2040-e013-11e9-8008-76f27b732d80: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5cdc2040-e013-11e9-8008-76f27b732d80 in namespace emptydir-wrapper-2781, will wait for the garbage collector to delete the pods
Sep 26 04:09:12.940: INFO: Deleting ReplicationController wrapped-volume-race-5cdc2040-e013-11e9-8008-76f27b732d80 took: 9.339083ms
Sep 26 04:09:13.241: INFO: Terminating ReplicationController wrapped-volume-race-5cdc2040-e013-11e9-8008-76f27b732d80 pods took: 300.18757ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:09:58.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2781" for this suite.
Sep 26 04:10:04.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:10:04.444: INFO: namespace emptydir-wrapper-2781 deletion completed in 6.07018352s

• [SLOW TEST:184.630 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:10:04.444: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Sep 26 04:10:04.463: INFO: namespace kubectl-6932
Sep 26 04:10:04.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-6932'
Sep 26 04:10:04.797: INFO: stderr: ""
Sep 26 04:10:04.797: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 26 04:10:05.799: INFO: Selector matched 1 pods for map[app:redis]
Sep 26 04:10:05.799: INFO: Found 0 / 1
Sep 26 04:10:06.800: INFO: Selector matched 1 pods for map[app:redis]
Sep 26 04:10:06.800: INFO: Found 1 / 1
Sep 26 04:10:06.800: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 26 04:10:06.802: INFO: Selector matched 1 pods for map[app:redis]
Sep 26 04:10:06.802: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 26 04:10:06.802: INFO: wait on redis-master startup in kubectl-6932 
Sep 26 04:10:06.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 logs redis-master-m4x4n redis-master --namespace=kubectl-6932'
Sep 26 04:10:06.880: INFO: stderr: ""
Sep 26 04:10:06.880: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 Sep 04:10:05.621 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 Sep 04:10:05.621 # Server started, Redis version 3.2.12\n1:M 26 Sep 04:10:05.621 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 Sep 04:10:05.621 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep 26 04:10:06.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6932'
Sep 26 04:10:06.970: INFO: stderr: ""
Sep 26 04:10:06.971: INFO: stdout: "service/rm2 exposed\n"
Sep 26 04:10:06.976: INFO: Service rm2 in namespace kubectl-6932 found.
STEP: exposing service
Sep 26 04:10:08.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6932'
Sep 26 04:10:09.063: INFO: stderr: ""
Sep 26 04:10:09.063: INFO: stdout: "service/rm3 exposed\n"
Sep 26 04:10:09.074: INFO: Service rm3 in namespace kubectl-6932 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:10:11.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6932" for this suite.
Sep 26 04:10:33.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:10:33.143: INFO: namespace kubectl-6932 deletion completed in 22.063062314s

• [SLOW TEST:28.699 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:10:33.144: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 26 04:10:33.174: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9,SelfLink:/api/v1/namespaces/watch-9/configmaps/e2e-watch-test-resource-version,UID:95acbde6-e013-11e9-af5c-00163e006ee4,ResourceVersion:31742731,Generation:0,CreationTimestamp:2019-09-26 04:10:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 26 04:10:33.174: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9,SelfLink:/api/v1/namespaces/watch-9/configmaps/e2e-watch-test-resource-version,UID:95acbde6-e013-11e9-af5c-00163e006ee4,ResourceVersion:31742732,Generation:0,CreationTimestamp:2019-09-26 04:10:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:10:33.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9" for this suite.
Sep 26 04:10:39.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:10:39.233: INFO: namespace watch-9 deletion completed in 6.056351806s

• [SLOW TEST:6.089 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:10:39.233: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:10:39.308: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99558e23-e013-11e9-8008-76f27b732d80" in namespace "downward-api-3383" to be "success or failure"
Sep 26 04:10:39.312: INFO: Pod "downwardapi-volume-99558e23-e013-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.311107ms
Sep 26 04:10:41.315: INFO: Pod "downwardapi-volume-99558e23-e013-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006881696s
STEP: Saw pod success
Sep 26 04:10:41.315: INFO: Pod "downwardapi-volume-99558e23-e013-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:10:41.317: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-99558e23-e013-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:10:41.328: INFO: Waiting for pod downwardapi-volume-99558e23-e013-11e9-8008-76f27b732d80 to disappear
Sep 26 04:10:41.329: INFO: Pod downwardapi-volume-99558e23-e013-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:10:41.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3383" for this suite.
Sep 26 04:10:47.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:10:47.391: INFO: namespace downward-api-3383 deletion completed in 6.059969724s

• [SLOW TEST:8.158 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:10:47.392: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Sep 26 04:10:47.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-1115'
Sep 26 04:10:47.616: INFO: stderr: ""
Sep 26 04:10:47.616: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 26 04:10:48.619: INFO: Selector matched 1 pods for map[app:redis]
Sep 26 04:10:48.619: INFO: Found 0 / 1
Sep 26 04:10:49.619: INFO: Selector matched 1 pods for map[app:redis]
Sep 26 04:10:49.619: INFO: Found 1 / 1
Sep 26 04:10:49.619: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 26 04:10:49.621: INFO: Selector matched 1 pods for map[app:redis]
Sep 26 04:10:49.621: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 26 04:10:49.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 patch pod redis-master-pkp6c --namespace=kubectl-1115 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 26 04:10:49.691: INFO: stderr: ""
Sep 26 04:10:49.691: INFO: stdout: "pod/redis-master-pkp6c patched\n"
STEP: checking annotations
Sep 26 04:10:49.693: INFO: Selector matched 1 pods for map[app:redis]
Sep 26 04:10:49.693: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:10:49.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1115" for this suite.
Sep 26 04:11:11.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:11:11.764: INFO: namespace kubectl-1115 deletion completed in 22.068556634s

• [SLOW TEST:24.372 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:11:11.764: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-acb21b77-e013-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:11:11.794: INFO: Waiting up to 5m0s for pod "pod-secrets-acb26374-e013-11e9-8008-76f27b732d80" in namespace "secrets-7462" to be "success or failure"
Sep 26 04:11:11.797: INFO: Pod "pod-secrets-acb26374-e013-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.123382ms
Sep 26 04:11:13.800: INFO: Pod "pod-secrets-acb26374-e013-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005530086s
STEP: Saw pod success
Sep 26 04:11:13.800: INFO: Pod "pod-secrets-acb26374-e013-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:11:13.801: INFO: Trying to get logs from node aks-1-3 pod pod-secrets-acb26374-e013-11e9-8008-76f27b732d80 container secret-volume-test: <nil>
STEP: delete the pod
Sep 26 04:11:13.816: INFO: Waiting for pod pod-secrets-acb26374-e013-11e9-8008-76f27b732d80 to disappear
Sep 26 04:11:13.818: INFO: Pod pod-secrets-acb26374-e013-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:11:13.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7462" for this suite.
Sep 26 04:11:19.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:11:19.881: INFO: namespace secrets-7462 deletion completed in 6.061407146s

• [SLOW TEST:8.117 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:11:19.882: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:11:19.909: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b18878d4-e013-11e9-8008-76f27b732d80" in namespace "downward-api-2883" to be "success or failure"
Sep 26 04:11:19.912: INFO: Pod "downwardapi-volume-b18878d4-e013-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.02321ms
Sep 26 04:11:21.915: INFO: Pod "downwardapi-volume-b18878d4-e013-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005708529s
STEP: Saw pod success
Sep 26 04:11:21.915: INFO: Pod "downwardapi-volume-b18878d4-e013-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:11:21.917: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-b18878d4-e013-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:11:21.929: INFO: Waiting for pod downwardapi-volume-b18878d4-e013-11e9-8008-76f27b732d80 to disappear
Sep 26 04:11:21.930: INFO: Pod downwardapi-volume-b18878d4-e013-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:11:21.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2883" for this suite.
Sep 26 04:11:27.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:11:27.993: INFO: namespace downward-api-2883 deletion completed in 6.060503162s

• [SLOW TEST:8.111 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:11:27.994: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:11:52.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6844" for this suite.
Sep 26 04:11:58.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:11:58.208: INFO: namespace container-runtime-6844 deletion completed in 6.054044478s

• [SLOW TEST:30.214 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:11:58.208: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:11:58.227: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 26 04:11:58.233: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 26 04:12:03.235: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 26 04:12:03.235: INFO: Creating deployment "test-rolling-update-deployment"
Sep 26 04:12:03.239: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 26 04:12:03.242: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 26 04:12:05.247: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 26 04:12:05.248: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep 26 04:12:05.253: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-4955,SelfLink:/apis/apps/v1/namespaces/deployment-4955/deployments/test-rolling-update-deployment,UID:cb5cc0f9-e013-11e9-af5c-00163e006ee4,ResourceVersion:31743110,Generation:1,CreationTimestamp:2019-09-26 04:12:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-26 04:12:03 +0000 UTC 2019-09-26 04:12:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-26 04:12:04 +0000 UTC 2019-09-26 04:12:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 26 04:12:05.255: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-4955,SelfLink:/apis/apps/v1/namespaces/deployment-4955/replicasets/test-rolling-update-deployment-67599b4d9,UID:cb5e0e91-e013-11e9-af5c-00163e006ee4,ResourceVersion:31743101,Generation:1,CreationTimestamp:2019-09-26 04:12:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment cb5cc0f9-e013-11e9-af5c-00163e006ee4 0xc000fa5250 0xc000fa5251}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 26 04:12:05.255: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 26 04:12:05.255: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-4955,SelfLink:/apis/apps/v1/namespaces/deployment-4955/replicasets/test-rolling-update-controller,UID:c86098b9-e013-11e9-af5c-00163e006ee4,ResourceVersion:31743109,Generation:2,CreationTimestamp:2019-09-26 04:11:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment cb5cc0f9-e013-11e9-af5c-00163e006ee4 0xc000fa5177 0xc000fa5178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 26 04:12:05.257: INFO: Pod "test-rolling-update-deployment-67599b4d9-wcfds" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-wcfds,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-4955,SelfLink:/api/v1/namespaces/deployment-4955/pods/test-rolling-update-deployment-67599b4d9-wcfds,UID:cb5ea55d-e013-11e9-af5c-00163e006ee4,ResourceVersion:31743100,Generation:0,CreationTimestamp:2019-09-26 04:12:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"redis":{"creationTimestamp":"2019-09-26T12:12:03.850113409+08:00","finishTimestamp":"2019-09-26T12:12:04.030469526+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 cb5e0e91-e013-11e9-af5c-00163e006ee4 0xc000fa5b60 0xc000fa5b61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tlzn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tlzn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-tlzn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fa5bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fa5bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:12:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:12:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:12:04 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:12:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:12:03 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.91,StartTime:2019-09-26 04:12:03 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-26 04:12:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3ac1ad941e6697ce361dbc9a4351e03e613c04cc042a79a2427f6d41b9d3f3e0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:12:05.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4955" for this suite.
Sep 26 04:12:11.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:12:11.319: INFO: namespace deployment-4955 deletion completed in 6.059451787s

• [SLOW TEST:13.111 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:12:11.319: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3214
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3214
STEP: Creating statefulset with conflicting port in namespace statefulset-3214
STEP: Waiting until pod test-pod will start running in namespace statefulset-3214
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3214
Sep 26 04:12:13.397: INFO: Observed stateful pod in namespace: statefulset-3214, name: ss-0, uid: d04cd994-e013-11e9-af5c-00163e006ee4, status phase: Pending. Waiting for statefulset controller to delete.
Sep 26 04:12:17.750: INFO: Observed stateful pod in namespace: statefulset-3214, name: ss-0, uid: d04cd994-e013-11e9-af5c-00163e006ee4, status phase: Failed. Waiting for statefulset controller to delete.
Sep 26 04:12:17.756: INFO: Observed stateful pod in namespace: statefulset-3214, name: ss-0, uid: d04cd994-e013-11e9-af5c-00163e006ee4, status phase: Failed. Waiting for statefulset controller to delete.
Sep 26 04:12:17.760: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3214
STEP: Removing pod with conflicting port in namespace statefulset-3214
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3214 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep 26 04:12:19.788: INFO: Deleting all statefulset in ns statefulset-3214
Sep 26 04:12:19.790: INFO: Scaling statefulset ss to 0
Sep 26 04:12:29.800: INFO: Waiting for statefulset status.replicas updated to 0
Sep 26 04:12:29.802: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:12:29.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3214" for this suite.
Sep 26 04:12:35.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:12:35.871: INFO: namespace statefulset-3214 deletion completed in 6.056811051s

• [SLOW TEST:24.551 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:12:35.871: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Sep 26 04:12:35.890: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-140668964 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:12:35.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9917" for this suite.
Sep 26 04:12:41.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:12:42.004: INFO: namespace kubectl-9917 deletion completed in 6.054814763s

• [SLOW TEST:6.134 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:12:42.005: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:12:48.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3133" for this suite.
Sep 26 04:12:54.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:12:54.140: INFO: namespace namespaces-3133 deletion completed in 6.05529013s
STEP: Destroying namespace "nsdeletetest-1106" for this suite.
Sep 26 04:12:54.141: INFO: Namespace nsdeletetest-1106 was already deleted
STEP: Destroying namespace "nsdeletetest-411" for this suite.
Sep 26 04:13:00.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:13:00.203: INFO: namespace nsdeletetest-411 deletion completed in 6.061707667s

• [SLOW TEST:18.198 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:13:00.203: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-7605
Sep 26 04:13:02.233: INFO: Started pod liveness-http in namespace container-probe-7605
STEP: checking the pod's current state and verifying that restartCount is present
Sep 26 04:13:02.235: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:17:02.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7605" for this suite.
Sep 26 04:17:08.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:17:08.671: INFO: namespace container-probe-7605 deletion completed in 6.079302368s

• [SLOW TEST:248.467 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:17:08.672: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 26 04:17:08.699: INFO: Waiting up to 5m0s for pod "pod-816e0ed4-e014-11e9-8008-76f27b732d80" in namespace "emptydir-7248" to be "success or failure"
Sep 26 04:17:08.702: INFO: Pod "pod-816e0ed4-e014-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.792615ms
Sep 26 04:17:10.706: INFO: Pod "pod-816e0ed4-e014-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006892209s
STEP: Saw pod success
Sep 26 04:17:10.706: INFO: Pod "pod-816e0ed4-e014-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:17:10.708: INFO: Trying to get logs from node aks-1-2 pod pod-816e0ed4-e014-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:17:10.719: INFO: Waiting for pod pod-816e0ed4-e014-11e9-8008-76f27b732d80 to disappear
Sep 26 04:17:10.726: INFO: Pod pod-816e0ed4-e014-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:17:10.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7248" for this suite.
Sep 26 04:17:16.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:17:16.792: INFO: namespace emptydir-7248 deletion completed in 6.061604104s

• [SLOW TEST:8.121 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:17:16.793: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep 26 04:17:19.340: INFO: Successfully updated pod "annotationupdate864497f2-e014-11e9-8008-76f27b732d80"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:17:21.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1427" for this suite.
Sep 26 04:17:43.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:17:43.412: INFO: namespace projected-1427 deletion completed in 22.055835834s

• [SLOW TEST:26.619 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:17:43.413: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Sep 26 04:17:43.433: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-140668964 proxy --unix-socket=/tmp/kubectl-proxy-unix042895895/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:17:43.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2390" for this suite.
Sep 26 04:17:49.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:17:49.543: INFO: namespace kubectl-2390 deletion completed in 6.055811921s

• [SLOW TEST:6.131 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:17:49.543: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep 26 04:17:49.570: INFO: Waiting up to 5m0s for pod "downward-api-99ca0c7a-e014-11e9-8008-76f27b732d80" in namespace "downward-api-7051" to be "success or failure"
Sep 26 04:17:49.574: INFO: Pod "downward-api-99ca0c7a-e014-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.956377ms
Sep 26 04:17:51.576: INFO: Pod "downward-api-99ca0c7a-e014-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006619683s
STEP: Saw pod success
Sep 26 04:17:51.576: INFO: Pod "downward-api-99ca0c7a-e014-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:17:51.578: INFO: Trying to get logs from node aks-1-3 pod downward-api-99ca0c7a-e014-11e9-8008-76f27b732d80 container dapi-container: <nil>
STEP: delete the pod
Sep 26 04:17:51.590: INFO: Waiting for pod downward-api-99ca0c7a-e014-11e9-8008-76f27b732d80 to disappear
Sep 26 04:17:51.592: INFO: Pod downward-api-99ca0c7a-e014-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:17:51.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7051" for this suite.
Sep 26 04:17:57.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:17:57.649: INFO: namespace downward-api-7051 deletion completed in 6.054713494s

• [SLOW TEST:8.105 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:17:57.649: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-2485/secret-test-9e9eb6be-e014-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:17:57.673: INFO: Waiting up to 5m0s for pod "pod-configmaps-9e9f01a0-e014-11e9-8008-76f27b732d80" in namespace "secrets-2485" to be "success or failure"
Sep 26 04:17:57.692: INFO: Pod "pod-configmaps-9e9f01a0-e014-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 18.458053ms
Sep 26 04:17:59.694: INFO: Pod "pod-configmaps-9e9f01a0-e014-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021282036s
STEP: Saw pod success
Sep 26 04:17:59.694: INFO: Pod "pod-configmaps-9e9f01a0-e014-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:17:59.696: INFO: Trying to get logs from node aks-1-2 pod pod-configmaps-9e9f01a0-e014-11e9-8008-76f27b732d80 container env-test: <nil>
STEP: delete the pod
Sep 26 04:17:59.710: INFO: Waiting for pod pod-configmaps-9e9f01a0-e014-11e9-8008-76f27b732d80 to disappear
Sep 26 04:17:59.715: INFO: Pod pod-configmaps-9e9f01a0-e014-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:17:59.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2485" for this suite.
Sep 26 04:18:05.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:18:05.782: INFO: namespace secrets-2485 deletion completed in 6.065439957s

• [SLOW TEST:8.133 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:18:05.783: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:18:05.806: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a377cdc5-e014-11e9-8008-76f27b732d80" in namespace "projected-4831" to be "success or failure"
Sep 26 04:18:05.816: INFO: Pod "downwardapi-volume-a377cdc5-e014-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 9.92463ms
Sep 26 04:18:07.819: INFO: Pod "downwardapi-volume-a377cdc5-e014-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012289039s
STEP: Saw pod success
Sep 26 04:18:07.819: INFO: Pod "downwardapi-volume-a377cdc5-e014-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:18:07.820: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-a377cdc5-e014-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:18:07.834: INFO: Waiting for pod downwardapi-volume-a377cdc5-e014-11e9-8008-76f27b732d80 to disappear
Sep 26 04:18:07.836: INFO: Pod downwardapi-volume-a377cdc5-e014-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:18:07.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4831" for this suite.
Sep 26 04:18:13.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:18:13.907: INFO: namespace projected-4831 deletion completed in 6.068734059s

• [SLOW TEST:8.125 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:18:13.908: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a8501487-e014-11e9-8008-76f27b732d80
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-a8501487-e014-11e9-8008-76f27b732d80
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:19:24.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1010" for this suite.
Sep 26 04:19:46.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:19:46.281: INFO: namespace projected-1010 deletion completed in 22.063961101s

• [SLOW TEST:92.373 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:19:46.281: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:19:46.439: INFO: (0) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 84.594407ms)
Sep 26 04:19:46.441: INFO: (1) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.704865ms)
Sep 26 04:19:46.444: INFO: (2) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.279171ms)
Sep 26 04:19:46.446: INFO: (3) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.225821ms)
Sep 26 04:19:46.448: INFO: (4) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.084656ms)
Sep 26 04:19:46.450: INFO: (5) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.044056ms)
Sep 26 04:19:46.453: INFO: (6) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.693268ms)
Sep 26 04:19:46.455: INFO: (7) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.141027ms)
Sep 26 04:19:46.460: INFO: (8) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 4.525644ms)
Sep 26 04:19:46.469: INFO: (9) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 9.811206ms)
Sep 26 04:19:46.473: INFO: (10) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 3.265116ms)
Sep 26 04:19:46.476: INFO: (11) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.871911ms)
Sep 26 04:19:46.478: INFO: (12) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.263637ms)
Sep 26 04:19:46.480: INFO: (13) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.454354ms)
Sep 26 04:19:46.485: INFO: (14) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 4.674584ms)
Sep 26 04:19:46.489: INFO: (15) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 3.517902ms)
Sep 26 04:19:46.491: INFO: (16) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.748508ms)
Sep 26 04:19:46.494: INFO: (17) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.638528ms)
Sep 26 04:19:46.496: INFO: (18) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.186487ms)
Sep 26 04:19:46.499: INFO: (19) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.401612ms)
[AfterEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:19:46.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-868" for this suite.
Sep 26 04:19:52.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:19:52.558: INFO: namespace proxy-868 deletion completed in 6.056731187s

• [SLOW TEST:6.276 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:19:52.558: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 26 04:19:52.580: INFO: Waiting up to 5m0s for pod "pod-e31c72c1-e014-11e9-8008-76f27b732d80" in namespace "emptydir-526" to be "success or failure"
Sep 26 04:19:52.582: INFO: Pod "pod-e31c72c1-e014-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.955128ms
Sep 26 04:19:54.585: INFO: Pod "pod-e31c72c1-e014-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00474525s
STEP: Saw pod success
Sep 26 04:19:54.585: INFO: Pod "pod-e31c72c1-e014-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:19:54.587: INFO: Trying to get logs from node aks-1-3 pod pod-e31c72c1-e014-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:19:54.598: INFO: Waiting for pod pod-e31c72c1-e014-11e9-8008-76f27b732d80 to disappear
Sep 26 04:19:54.599: INFO: Pod pod-e31c72c1-e014-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:19:54.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-526" for this suite.
Sep 26 04:20:00.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:20:00.657: INFO: namespace emptydir-526 deletion completed in 6.055520928s

• [SLOW TEST:8.099 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:20:00.658: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-e7f818f0-e014-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:20:00.735: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e7f868ec-e014-11e9-8008-76f27b732d80" in namespace "projected-8385" to be "success or failure"
Sep 26 04:20:00.737: INFO: Pod "pod-projected-configmaps-e7f868ec-e014-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.993513ms
Sep 26 04:20:02.739: INFO: Pod "pod-projected-configmaps-e7f868ec-e014-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004741212s
Sep 26 04:20:04.742: INFO: Pod "pod-projected-configmaps-e7f868ec-e014-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0072373s
STEP: Saw pod success
Sep 26 04:20:04.742: INFO: Pod "pod-projected-configmaps-e7f868ec-e014-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:20:04.743: INFO: Trying to get logs from node aks-1-2 pod pod-projected-configmaps-e7f868ec-e014-11e9-8008-76f27b732d80 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:20:04.760: INFO: Waiting for pod pod-projected-configmaps-e7f868ec-e014-11e9-8008-76f27b732d80 to disappear
Sep 26 04:20:04.762: INFO: Pod pod-projected-configmaps-e7f868ec-e014-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:20:04.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8385" for this suite.
Sep 26 04:20:10.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:20:10.824: INFO: namespace projected-8385 deletion completed in 6.05857684s

• [SLOW TEST:10.166 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:20:10.824: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:20:10.843: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:20:12.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3682" for this suite.
Sep 26 04:20:56.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:20:57.009: INFO: namespace pods-3682 deletion completed in 44.054871348s

• [SLOW TEST:46.185 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:20:57.009: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:20:57.032: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0986f929-e015-11e9-8008-76f27b732d80" in namespace "projected-1761" to be "success or failure"
Sep 26 04:20:57.035: INFO: Pod "downwardapi-volume-0986f929-e015-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.932308ms
Sep 26 04:20:59.038: INFO: Pod "downwardapi-volume-0986f929-e015-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005575639s
STEP: Saw pod success
Sep 26 04:20:59.038: INFO: Pod "downwardapi-volume-0986f929-e015-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:20:59.039: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-0986f929-e015-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:20:59.052: INFO: Waiting for pod downwardapi-volume-0986f929-e015-11e9-8008-76f27b732d80 to disappear
Sep 26 04:20:59.053: INFO: Pod downwardapi-volume-0986f929-e015-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:20:59.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1761" for this suite.
Sep 26 04:21:05.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:21:05.113: INFO: namespace projected-1761 deletion completed in 6.05778048s

• [SLOW TEST:8.104 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:21:05.113: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:21:05.134: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:21:11.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2536" for this suite.
Sep 26 04:21:17.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:21:17.233: INFO: namespace custom-resource-definition-2536 deletion completed in 6.057478038s

• [SLOW TEST:12.120 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:21:17.233: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Sep 26 04:21:17.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 api-versions'
Sep 26 04:21:17.376: INFO: stderr: ""
Sep 26 04:21:17.376: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:21:17.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2500" for this suite.
Sep 26 04:21:23.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:21:23.433: INFO: namespace kubectl-2500 deletion completed in 6.054371253s

• [SLOW TEST:6.200 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:21:23.433: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Sep 26 04:21:23.458: INFO: Waiting up to 5m0s for pod "var-expansion-194707e6-e015-11e9-8008-76f27b732d80" in namespace "var-expansion-7138" to be "success or failure"
Sep 26 04:21:23.460: INFO: Pod "var-expansion-194707e6-e015-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.549118ms
Sep 26 04:21:25.463: INFO: Pod "var-expansion-194707e6-e015-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005144428s
STEP: Saw pod success
Sep 26 04:21:25.463: INFO: Pod "var-expansion-194707e6-e015-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:21:25.464: INFO: Trying to get logs from node aks-1-3 pod var-expansion-194707e6-e015-11e9-8008-76f27b732d80 container dapi-container: <nil>
STEP: delete the pod
Sep 26 04:21:25.477: INFO: Waiting for pod var-expansion-194707e6-e015-11e9-8008-76f27b732d80 to disappear
Sep 26 04:21:25.481: INFO: Pod var-expansion-194707e6-e015-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:21:25.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7138" for this suite.
Sep 26 04:21:31.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:21:31.540: INFO: namespace var-expansion-7138 deletion completed in 6.05655118s

• [SLOW TEST:8.107 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:21:31.540: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-1e1c3cd7-e015-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:21:31.571: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1e1c8f37-e015-11e9-8008-76f27b732d80" in namespace "projected-8065" to be "success or failure"
Sep 26 04:21:31.580: INFO: Pod "pod-projected-secrets-1e1c8f37-e015-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 9.555731ms
Sep 26 04:21:33.583: INFO: Pod "pod-projected-secrets-1e1c8f37-e015-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012125461s
STEP: Saw pod success
Sep 26 04:21:33.583: INFO: Pod "pod-projected-secrets-1e1c8f37-e015-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:21:33.584: INFO: Trying to get logs from node aks-1-2 pod pod-projected-secrets-1e1c8f37-e015-11e9-8008-76f27b732d80 container secret-volume-test: <nil>
STEP: delete the pod
Sep 26 04:21:33.598: INFO: Waiting for pod pod-projected-secrets-1e1c8f37-e015-11e9-8008-76f27b732d80 to disappear
Sep 26 04:21:33.601: INFO: Pod pod-projected-secrets-1e1c8f37-e015-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:21:33.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8065" for this suite.
Sep 26 04:21:39.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:21:39.662: INFO: namespace projected-8065 deletion completed in 6.058504215s

• [SLOW TEST:8.122 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:21:39.662: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-grckf in namespace proxy-2970
I0926 04:21:39.696850      21 runners.go:184] Created replication controller with name: proxy-service-grckf, namespace: proxy-2970, replica count: 1
I0926 04:21:40.747200      21 runners.go:184] proxy-service-grckf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0926 04:21:41.747367      21 runners.go:184] proxy-service-grckf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0926 04:21:42.747560      21 runners.go:184] proxy-service-grckf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0926 04:21:43.747726      21 runners.go:184] proxy-service-grckf Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0926 04:21:44.747884      21 runners.go:184] proxy-service-grckf Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 26 04:21:44.750: INFO: setup took 5.070286595s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 26 04:21:44.761: INFO: (0) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 10.352545ms)
Sep 26 04:21:44.761: INFO: (0) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 10.57879ms)
Sep 26 04:21:44.765: INFO: (0) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 14.295085ms)
Sep 26 04:21:44.765: INFO: (0) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 14.407244ms)
Sep 26 04:21:44.765: INFO: (0) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 14.457761ms)
Sep 26 04:21:44.770: INFO: (0) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 19.373988ms)
Sep 26 04:21:44.771: INFO: (0) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 19.916167ms)
Sep 26 04:21:44.771: INFO: (0) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 20.365759ms)
Sep 26 04:21:44.776: INFO: (0) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 25.100027ms)
Sep 26 04:21:44.777: INFO: (0) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 25.861944ms)
Sep 26 04:21:44.777: INFO: (0) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 26.294232ms)
Sep 26 04:21:44.778: INFO: (0) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 27.00027ms)
Sep 26 04:21:44.778: INFO: (0) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 27.617882ms)
Sep 26 04:21:44.778: INFO: (0) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 27.444617ms)
Sep 26 04:21:44.779: INFO: (0) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 28.199407ms)
Sep 26 04:21:44.781: INFO: (0) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 30.063514ms)
Sep 26 04:21:44.787: INFO: (1) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 6.186184ms)
Sep 26 04:21:44.788: INFO: (1) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 6.60287ms)
Sep 26 04:21:44.788: INFO: (1) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 6.429862ms)
Sep 26 04:21:44.789: INFO: (1) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 7.092559ms)
Sep 26 04:21:44.789: INFO: (1) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 7.567268ms)
Sep 26 04:21:44.789: INFO: (1) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 7.826529ms)
Sep 26 04:21:44.789: INFO: (1) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 7.707478ms)
Sep 26 04:21:44.790: INFO: (1) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 7.965558ms)
Sep 26 04:21:44.790: INFO: (1) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 8.445982ms)
Sep 26 04:21:44.790: INFO: (1) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 8.54331ms)
Sep 26 04:21:44.790: INFO: (1) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 8.915009ms)
Sep 26 04:21:44.791: INFO: (1) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 9.354987ms)
Sep 26 04:21:44.791: INFO: (1) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 9.21181ms)
Sep 26 04:21:44.791: INFO: (1) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 9.864257ms)
Sep 26 04:21:44.791: INFO: (1) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.737222ms)
Sep 26 04:21:44.791: INFO: (1) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 9.652344ms)
Sep 26 04:21:44.797: INFO: (2) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 6.04112ms)
Sep 26 04:21:44.798: INFO: (2) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 6.263393ms)
Sep 26 04:21:44.799: INFO: (2) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 8.074944ms)
Sep 26 04:21:44.800: INFO: (2) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 7.834988ms)
Sep 26 04:21:44.800: INFO: (2) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 8.386212ms)
Sep 26 04:21:44.800: INFO: (2) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 8.526055ms)
Sep 26 04:21:44.800: INFO: (2) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 8.799267ms)
Sep 26 04:21:44.800: INFO: (2) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 8.537394ms)
Sep 26 04:21:44.801: INFO: (2) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 9.276469ms)
Sep 26 04:21:44.801: INFO: (2) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 9.423767ms)
Sep 26 04:21:44.801: INFO: (2) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 9.838012ms)
Sep 26 04:21:44.802: INFO: (2) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.895243ms)
Sep 26 04:21:44.802: INFO: (2) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 9.964798ms)
Sep 26 04:21:44.802: INFO: (2) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 10.037914ms)
Sep 26 04:21:44.802: INFO: (2) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 10.576161ms)
Sep 26 04:21:44.803: INFO: (2) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 10.92907ms)
Sep 26 04:21:44.809: INFO: (3) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 6.282696ms)
Sep 26 04:21:44.810: INFO: (3) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 6.784617ms)
Sep 26 04:21:44.810: INFO: (3) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 7.282325ms)
Sep 26 04:21:44.810: INFO: (3) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 7.641051ms)
Sep 26 04:21:44.811: INFO: (3) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 7.50056ms)
Sep 26 04:21:44.811: INFO: (3) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 7.836371ms)
Sep 26 04:21:44.811: INFO: (3) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 7.811207ms)
Sep 26 04:21:44.811: INFO: (3) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 8.092268ms)
Sep 26 04:21:44.812: INFO: (3) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 8.776678ms)
Sep 26 04:21:44.812: INFO: (3) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 9.290036ms)
Sep 26 04:21:44.812: INFO: (3) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 9.633358ms)
Sep 26 04:21:44.812: INFO: (3) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.518104ms)
Sep 26 04:21:44.813: INFO: (3) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 9.581224ms)
Sep 26 04:21:44.813: INFO: (3) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 9.663777ms)
Sep 26 04:21:44.813: INFO: (3) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 9.902225ms)
Sep 26 04:21:44.813: INFO: (3) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 9.873686ms)
Sep 26 04:21:44.820: INFO: (4) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 6.710146ms)
Sep 26 04:21:44.820: INFO: (4) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 6.424404ms)
Sep 26 04:21:44.820: INFO: (4) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 6.528639ms)
Sep 26 04:21:44.820: INFO: (4) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 6.941549ms)
Sep 26 04:21:44.820: INFO: (4) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 7.194496ms)
Sep 26 04:21:44.821: INFO: (4) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 7.557309ms)
Sep 26 04:21:44.821: INFO: (4) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 7.900562ms)
Sep 26 04:21:44.821: INFO: (4) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 7.967091ms)
Sep 26 04:21:44.822: INFO: (4) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 8.901749ms)
Sep 26 04:21:44.822: INFO: (4) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 8.862504ms)
Sep 26 04:21:44.822: INFO: (4) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 9.251787ms)
Sep 26 04:21:44.823: INFO: (4) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 9.14709ms)
Sep 26 04:21:44.823: INFO: (4) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 9.890476ms)
Sep 26 04:21:44.824: INFO: (4) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 10.77351ms)
Sep 26 04:21:44.825: INFO: (4) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 11.060482ms)
Sep 26 04:21:44.826: INFO: (4) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 11.923281ms)
Sep 26 04:21:44.829: INFO: (5) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 3.526192ms)
Sep 26 04:21:44.830: INFO: (5) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 4.24516ms)
Sep 26 04:21:44.831: INFO: (5) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 5.279801ms)
Sep 26 04:21:44.832: INFO: (5) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 5.698557ms)
Sep 26 04:21:44.832: INFO: (5) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 5.988461ms)
Sep 26 04:21:44.832: INFO: (5) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 5.866817ms)
Sep 26 04:21:44.833: INFO: (5) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 7.059908ms)
Sep 26 04:21:44.834: INFO: (5) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 8.021675ms)
Sep 26 04:21:44.834: INFO: (5) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 7.904835ms)
Sep 26 04:21:44.834: INFO: (5) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 8.229127ms)
Sep 26 04:21:44.835: INFO: (5) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 8.625695ms)
Sep 26 04:21:44.835: INFO: (5) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 9.223703ms)
Sep 26 04:21:44.836: INFO: (5) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.417045ms)
Sep 26 04:21:44.836: INFO: (5) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 9.605707ms)
Sep 26 04:21:44.836: INFO: (5) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 9.929099ms)
Sep 26 04:21:44.836: INFO: (5) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 9.840325ms)
Sep 26 04:21:44.843: INFO: (6) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 7.029573ms)
Sep 26 04:21:44.843: INFO: (6) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 6.901128ms)
Sep 26 04:21:44.844: INFO: (6) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 7.922939ms)
Sep 26 04:21:44.845: INFO: (6) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 7.957687ms)
Sep 26 04:21:44.845: INFO: (6) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 8.497056ms)
Sep 26 04:21:44.845: INFO: (6) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 8.689211ms)
Sep 26 04:21:44.845: INFO: (6) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 8.450725ms)
Sep 26 04:21:44.846: INFO: (6) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 8.719435ms)
Sep 26 04:21:44.846: INFO: (6) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 8.998164ms)
Sep 26 04:21:44.846: INFO: (6) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 8.957459ms)
Sep 26 04:21:44.846: INFO: (6) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 9.332934ms)
Sep 26 04:21:44.846: INFO: (6) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.922382ms)
Sep 26 04:21:44.847: INFO: (6) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 9.638701ms)
Sep 26 04:21:44.847: INFO: (6) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 9.632084ms)
Sep 26 04:21:44.847: INFO: (6) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 10.222798ms)
Sep 26 04:21:44.847: INFO: (6) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 10.155418ms)
Sep 26 04:21:44.849: INFO: (7) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 2.413764ms)
Sep 26 04:21:44.850: INFO: (7) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 3.206194ms)
Sep 26 04:21:44.852: INFO: (7) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 4.710105ms)
Sep 26 04:21:44.852: INFO: (7) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 4.773362ms)
Sep 26 04:21:44.852: INFO: (7) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 4.95719ms)
Sep 26 04:21:44.855: INFO: (7) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 7.979808ms)
Sep 26 04:21:44.856: INFO: (7) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 8.184011ms)
Sep 26 04:21:44.856: INFO: (7) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 8.647199ms)
Sep 26 04:21:44.857: INFO: (7) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.252205ms)
Sep 26 04:21:44.857: INFO: (7) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 9.454321ms)
Sep 26 04:21:44.858: INFO: (7) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 10.812818ms)
Sep 26 04:21:44.859: INFO: (7) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 11.019581ms)
Sep 26 04:21:44.859: INFO: (7) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 11.144777ms)
Sep 26 04:21:44.859: INFO: (7) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 11.654447ms)
Sep 26 04:21:44.859: INFO: (7) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 12.256698ms)
Sep 26 04:21:44.860: INFO: (7) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 11.916068ms)
Sep 26 04:21:44.862: INFO: (8) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 2.068199ms)
Sep 26 04:21:44.862: INFO: (8) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 2.624681ms)
Sep 26 04:21:44.864: INFO: (8) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 4.585856ms)
Sep 26 04:21:44.865: INFO: (8) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 4.743501ms)
Sep 26 04:21:44.865: INFO: (8) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 5.137394ms)
Sep 26 04:21:44.866: INFO: (8) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 5.603152ms)
Sep 26 04:21:44.866: INFO: (8) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 5.906929ms)
Sep 26 04:21:44.866: INFO: (8) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 6.235774ms)
Sep 26 04:21:44.868: INFO: (8) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 7.637404ms)
Sep 26 04:21:44.869: INFO: (8) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 8.720196ms)
Sep 26 04:21:44.870: INFO: (8) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 10.148629ms)
Sep 26 04:21:44.871: INFO: (8) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 10.398848ms)
Sep 26 04:21:44.871: INFO: (8) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 10.78141ms)
Sep 26 04:21:44.871: INFO: (8) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 10.880021ms)
Sep 26 04:21:44.871: INFO: (8) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 10.878372ms)
Sep 26 04:21:44.871: INFO: (8) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 11.022702ms)
Sep 26 04:21:44.874: INFO: (9) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 2.437434ms)
Sep 26 04:21:44.875: INFO: (9) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 3.3822ms)
Sep 26 04:21:44.875: INFO: (9) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 3.837307ms)
Sep 26 04:21:44.879: INFO: (9) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 7.807986ms)
Sep 26 04:21:44.881: INFO: (9) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 8.94935ms)
Sep 26 04:21:44.881: INFO: (9) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 9.361563ms)
Sep 26 04:21:44.881: INFO: (9) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 9.261791ms)
Sep 26 04:21:44.881: INFO: (9) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 9.660804ms)
Sep 26 04:21:44.882: INFO: (9) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 9.752202ms)
Sep 26 04:21:44.882: INFO: (9) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 10.04762ms)
Sep 26 04:21:44.882: INFO: (9) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 10.08572ms)
Sep 26 04:21:44.882: INFO: (9) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 10.331312ms)
Sep 26 04:21:44.882: INFO: (9) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 10.435809ms)
Sep 26 04:21:44.882: INFO: (9) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 10.377301ms)
Sep 26 04:21:44.882: INFO: (9) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 10.580227ms)
Sep 26 04:21:44.883: INFO: (9) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 10.813815ms)
Sep 26 04:21:44.885: INFO: (10) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 2.852394ms)
Sep 26 04:21:44.886: INFO: (10) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 3.460145ms)
Sep 26 04:21:44.887: INFO: (10) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 4.408011ms)
Sep 26 04:21:44.890: INFO: (10) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 7.371127ms)
Sep 26 04:21:44.890: INFO: (10) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 7.47219ms)
Sep 26 04:21:44.891: INFO: (10) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 8.570294ms)
Sep 26 04:21:44.892: INFO: (10) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 9.423878ms)
Sep 26 04:21:44.893: INFO: (10) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 10.104023ms)
Sep 26 04:21:44.893: INFO: (10) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 10.27684ms)
Sep 26 04:21:44.893: INFO: (10) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 10.275491ms)
Sep 26 04:21:44.894: INFO: (10) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 10.648724ms)
Sep 26 04:21:44.894: INFO: (10) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 10.737549ms)
Sep 26 04:21:44.894: INFO: (10) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 10.992437ms)
Sep 26 04:21:44.894: INFO: (10) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 11.215225ms)
Sep 26 04:21:44.894: INFO: (10) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 11.412514ms)
Sep 26 04:21:44.894: INFO: (10) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 11.303333ms)
Sep 26 04:21:44.897: INFO: (11) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 2.986533ms)
Sep 26 04:21:44.899: INFO: (11) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 4.798749ms)
Sep 26 04:21:44.901: INFO: (11) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 5.866799ms)
Sep 26 04:21:44.901: INFO: (11) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 6.535617ms)
Sep 26 04:21:44.901: INFO: (11) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 6.524125ms)
Sep 26 04:21:44.903: INFO: (11) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 7.758632ms)
Sep 26 04:21:44.904: INFO: (11) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.165129ms)
Sep 26 04:21:44.904: INFO: (11) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 9.521977ms)
Sep 26 04:21:44.905: INFO: (11) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 9.536692ms)
Sep 26 04:21:44.905: INFO: (11) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 9.491502ms)
Sep 26 04:21:44.905: INFO: (11) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 10.333588ms)
Sep 26 04:21:44.905: INFO: (11) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 10.256994ms)
Sep 26 04:21:44.906: INFO: (11) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 10.300143ms)
Sep 26 04:21:44.906: INFO: (11) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 10.597353ms)
Sep 26 04:21:44.906: INFO: (11) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 10.518364ms)
Sep 26 04:21:44.906: INFO: (11) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 10.488524ms)
Sep 26 04:21:44.912: INFO: (12) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 5.629026ms)
Sep 26 04:21:44.914: INFO: (12) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 7.261047ms)
Sep 26 04:21:44.914: INFO: (12) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 7.979748ms)
Sep 26 04:21:44.914: INFO: (12) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 8.339027ms)
Sep 26 04:21:44.914: INFO: (12) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 7.989266ms)
Sep 26 04:21:44.915: INFO: (12) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 8.285964ms)
Sep 26 04:21:44.915: INFO: (12) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 8.881046ms)
Sep 26 04:21:44.916: INFO: (12) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 9.240478ms)
Sep 26 04:21:44.916: INFO: (12) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 9.909657ms)
Sep 26 04:21:44.916: INFO: (12) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 9.708712ms)
Sep 26 04:21:44.916: INFO: (12) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 9.519057ms)
Sep 26 04:21:44.916: INFO: (12) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 9.876492ms)
Sep 26 04:21:44.916: INFO: (12) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 10.29372ms)
Sep 26 04:21:44.917: INFO: (12) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 10.417485ms)
Sep 26 04:21:44.917: INFO: (12) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 10.624466ms)
Sep 26 04:21:44.916: INFO: (12) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 10.004242ms)
Sep 26 04:21:44.921: INFO: (13) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 4.513419ms)
Sep 26 04:21:44.923: INFO: (13) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 6.103302ms)
Sep 26 04:21:44.924: INFO: (13) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 6.039213ms)
Sep 26 04:21:44.924: INFO: (13) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 7.020715ms)
Sep 26 04:21:44.924: INFO: (13) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 7.192322ms)
Sep 26 04:21:44.925: INFO: (13) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 7.408008ms)
Sep 26 04:21:44.925: INFO: (13) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 7.738467ms)
Sep 26 04:21:44.925: INFO: (13) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 8.354091ms)
Sep 26 04:21:44.925: INFO: (13) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 8.545874ms)
Sep 26 04:21:44.925: INFO: (13) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 8.297388ms)
Sep 26 04:21:44.926: INFO: (13) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 8.738645ms)
Sep 26 04:21:44.926: INFO: (13) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 9.100111ms)
Sep 26 04:21:44.926: INFO: (13) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 9.670736ms)
Sep 26 04:21:44.927: INFO: (13) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 9.464556ms)
Sep 26 04:21:44.927: INFO: (13) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.609331ms)
Sep 26 04:21:44.927: INFO: (13) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 9.732963ms)
Sep 26 04:21:44.929: INFO: (14) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 2.26464ms)
Sep 26 04:21:44.931: INFO: (14) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 3.682567ms)
Sep 26 04:21:44.931: INFO: (14) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 3.934976ms)
Sep 26 04:21:44.931: INFO: (14) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 4.032115ms)
Sep 26 04:21:44.938: INFO: (14) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 9.857544ms)
Sep 26 04:21:44.938: INFO: (14) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 10.313395ms)
Sep 26 04:21:44.939: INFO: (14) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 10.922221ms)
Sep 26 04:21:44.939: INFO: (14) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 10.912803ms)
Sep 26 04:21:44.939: INFO: (14) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 11.274538ms)
Sep 26 04:21:44.939: INFO: (14) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 11.585939ms)
Sep 26 04:21:44.939: INFO: (14) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 11.960984ms)
Sep 26 04:21:44.942: INFO: (14) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 14.568524ms)
Sep 26 04:21:44.943: INFO: (14) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 14.563451ms)
Sep 26 04:21:44.943: INFO: (14) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 14.535622ms)
Sep 26 04:21:44.943: INFO: (14) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 14.735037ms)
Sep 26 04:21:44.943: INFO: (14) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 14.872502ms)
Sep 26 04:21:44.946: INFO: (15) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 2.919292ms)
Sep 26 04:21:44.946: INFO: (15) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 3.250407ms)
Sep 26 04:21:44.946: INFO: (15) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 3.340932ms)
Sep 26 04:21:44.947: INFO: (15) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 3.502075ms)
Sep 26 04:21:44.950: INFO: (15) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 6.556878ms)
Sep 26 04:21:44.950: INFO: (15) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 6.950814ms)
Sep 26 04:21:44.952: INFO: (15) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 8.456976ms)
Sep 26 04:21:44.952: INFO: (15) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 8.787093ms)
Sep 26 04:21:44.952: INFO: (15) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 8.773294ms)
Sep 26 04:21:44.952: INFO: (15) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 8.917476ms)
Sep 26 04:21:44.952: INFO: (15) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 8.636299ms)
Sep 26 04:21:44.952: INFO: (15) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 8.759281ms)
Sep 26 04:21:44.952: INFO: (15) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 9.299409ms)
Sep 26 04:21:44.953: INFO: (15) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 9.395649ms)
Sep 26 04:21:44.953: INFO: (15) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 9.284786ms)
Sep 26 04:21:44.953: INFO: (15) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.656807ms)
Sep 26 04:21:44.957: INFO: (16) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 3.773897ms)
Sep 26 04:21:44.958: INFO: (16) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 4.223834ms)
Sep 26 04:21:44.958: INFO: (16) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 4.543349ms)
Sep 26 04:21:44.962: INFO: (16) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 8.322311ms)
Sep 26 04:21:44.962: INFO: (16) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 8.374573ms)
Sep 26 04:21:44.962: INFO: (16) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 8.506118ms)
Sep 26 04:21:44.962: INFO: (16) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 8.324775ms)
Sep 26 04:21:44.962: INFO: (16) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 8.43239ms)
Sep 26 04:21:44.962: INFO: (16) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 8.732454ms)
Sep 26 04:21:44.962: INFO: (16) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 8.526352ms)
Sep 26 04:21:44.963: INFO: (16) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 8.617149ms)
Sep 26 04:21:44.963: INFO: (16) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 8.722244ms)
Sep 26 04:21:44.963: INFO: (16) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 9.009388ms)
Sep 26 04:21:44.963: INFO: (16) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 9.251241ms)
Sep 26 04:21:44.964: INFO: (16) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.788698ms)
Sep 26 04:21:44.964: INFO: (16) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 9.676085ms)
Sep 26 04:21:44.970: INFO: (17) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 6.457753ms)
Sep 26 04:21:44.971: INFO: (17) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 7.029784ms)
Sep 26 04:21:44.971: INFO: (17) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 7.284051ms)
Sep 26 04:21:44.971: INFO: (17) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 7.496386ms)
Sep 26 04:21:44.973: INFO: (17) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 9.304799ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 10.698977ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 10.847742ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 10.761165ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 10.745648ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 10.71096ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 10.817581ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 11.102353ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 10.977274ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 11.762003ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 11.130386ms)
Sep 26 04:21:44.975: INFO: (17) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 11.520837ms)
Sep 26 04:21:44.982: INFO: (18) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 5.950987ms)
Sep 26 04:21:44.984: INFO: (18) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 8.250946ms)
Sep 26 04:21:44.984: INFO: (18) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 8.893156ms)
Sep 26 04:21:44.985: INFO: (18) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 8.73677ms)
Sep 26 04:21:44.986: INFO: (18) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 9.580309ms)
Sep 26 04:21:44.986: INFO: (18) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 10.079256ms)
Sep 26 04:21:44.986: INFO: (18) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 9.978402ms)
Sep 26 04:21:44.986: INFO: (18) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 9.979502ms)
Sep 26 04:21:44.986: INFO: (18) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 9.999499ms)
Sep 26 04:21:44.986: INFO: (18) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 9.979559ms)
Sep 26 04:21:44.987: INFO: (18) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 11.024342ms)
Sep 26 04:21:44.987: INFO: (18) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 11.10232ms)
Sep 26 04:21:44.987: INFO: (18) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 10.788034ms)
Sep 26 04:21:44.987: INFO: (18) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 11.717303ms)
Sep 26 04:21:44.987: INFO: (18) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 11.472496ms)
Sep 26 04:21:44.987: INFO: (18) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 11.21844ms)
Sep 26 04:21:44.990: INFO: (19) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd/proxy/rewriteme">test</a> (200; 2.334312ms)
Sep 26 04:21:44.990: INFO: (19) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:443/proxy/tlsrewritem... (200; 2.692432ms)
Sep 26 04:21:44.991: INFO: (19) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname1/proxy/: foo (200; 2.918659ms)
Sep 26 04:21:44.994: INFO: (19) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:1080/proxy/rewriteme">test<... (200; 6.287079ms)
Sep 26 04:21:44.995: INFO: (19) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/: <a href="/api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:1080/proxy/rewriteme">... (200; 7.386747ms)
Sep 26 04:21:44.996: INFO: (19) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:462/proxy/: tls qux (200; 7.90199ms)
Sep 26 04:21:44.996: INFO: (19) /api/v1/namespaces/proxy-2970/pods/https:proxy-service-grckf-xnfpd:460/proxy/: tls baz (200; 8.031605ms)
Sep 26 04:21:44.996: INFO: (19) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:162/proxy/: bar (200; 7.530252ms)
Sep 26 04:21:44.996: INFO: (19) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:162/proxy/: bar (200; 7.97657ms)
Sep 26 04:21:44.996: INFO: (19) /api/v1/namespaces/proxy-2970/pods/http:proxy-service-grckf-xnfpd:160/proxy/: foo (200; 7.948347ms)
Sep 26 04:21:44.996: INFO: (19) /api/v1/namespaces/proxy-2970/pods/proxy-service-grckf-xnfpd:160/proxy/: foo (200; 8.208697ms)
Sep 26 04:21:44.997: INFO: (19) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname1/proxy/: foo (200; 8.878442ms)
Sep 26 04:21:44.997: INFO: (19) /api/v1/namespaces/proxy-2970/services/http:proxy-service-grckf:portname2/proxy/: bar (200; 8.909536ms)
Sep 26 04:21:44.997: INFO: (19) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname2/proxy/: tls qux (200; 9.129274ms)
Sep 26 04:21:44.997: INFO: (19) /api/v1/namespaces/proxy-2970/services/proxy-service-grckf:portname2/proxy/: bar (200; 9.247907ms)
Sep 26 04:21:44.997: INFO: (19) /api/v1/namespaces/proxy-2970/services/https:proxy-service-grckf:tlsportname1/proxy/: tls baz (200; 9.211487ms)
STEP: deleting ReplicationController proxy-service-grckf in namespace proxy-2970, will wait for the garbage collector to delete the pods
Sep 26 04:21:45.055: INFO: Deleting ReplicationController proxy-service-grckf took: 5.675293ms
Sep 26 04:21:45.355: INFO: Terminating ReplicationController proxy-service-grckf pods took: 300.160592ms
[AfterEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:21:54.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2970" for this suite.
Sep 26 04:22:00.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:22:01.019: INFO: namespace proxy-2970 deletion completed in 6.060677157s

• [SLOW TEST:21.357 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:22:01.019: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Sep 26 04:22:01.560: INFO: created pod pod-service-account-defaultsa
Sep 26 04:22:01.560: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 26 04:22:01.567: INFO: created pod pod-service-account-mountsa
Sep 26 04:22:01.567: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 26 04:22:01.581: INFO: created pod pod-service-account-nomountsa
Sep 26 04:22:01.581: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 26 04:22:01.628: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 26 04:22:01.628: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 26 04:22:01.641: INFO: created pod pod-service-account-mountsa-mountspec
Sep 26 04:22:01.641: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 26 04:22:01.689: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 26 04:22:01.689: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 26 04:22:01.704: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 26 04:22:01.704: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 26 04:22:01.730: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 26 04:22:01.730: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 26 04:22:01.781: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 26 04:22:01.781: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:22:01.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3559" for this suite.
Sep 26 04:22:07.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:22:07.878: INFO: namespace svcaccounts-3559 deletion completed in 6.081225894s

• [SLOW TEST:6.858 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:22:07.878: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:22:11.966: INFO: Waiting up to 5m0s for pod "client-envvars-362cca0e-e015-11e9-8008-76f27b732d80" in namespace "pods-9340" to be "success or failure"
Sep 26 04:22:11.972: INFO: Pod "client-envvars-362cca0e-e015-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 5.400765ms
Sep 26 04:22:13.975: INFO: Pod "client-envvars-362cca0e-e015-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008280809s
STEP: Saw pod success
Sep 26 04:22:13.975: INFO: Pod "client-envvars-362cca0e-e015-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:22:13.977: INFO: Trying to get logs from node aks-1-2 pod client-envvars-362cca0e-e015-11e9-8008-76f27b732d80 container env3cont: <nil>
STEP: delete the pod
Sep 26 04:22:14.004: INFO: Waiting for pod client-envvars-362cca0e-e015-11e9-8008-76f27b732d80 to disappear
Sep 26 04:22:14.006: INFO: Pod client-envvars-362cca0e-e015-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:22:14.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9340" for this suite.
Sep 26 04:22:58.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:22:58.075: INFO: namespace pods-9340 deletion completed in 44.065399792s

• [SLOW TEST:50.198 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:22:58.076: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Sep 26 04:22:58.102: INFO: Waiting up to 5m0s for pod "client-containers-51b0a54e-e015-11e9-8008-76f27b732d80" in namespace "containers-7504" to be "success or failure"
Sep 26 04:22:58.108: INFO: Pod "client-containers-51b0a54e-e015-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.599188ms
Sep 26 04:23:00.111: INFO: Pod "client-containers-51b0a54e-e015-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008874097s
STEP: Saw pod success
Sep 26 04:23:00.111: INFO: Pod "client-containers-51b0a54e-e015-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:23:00.112: INFO: Trying to get logs from node aks-1-3 pod client-containers-51b0a54e-e015-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:23:00.126: INFO: Waiting for pod client-containers-51b0a54e-e015-11e9-8008-76f27b732d80 to disappear
Sep 26 04:23:00.127: INFO: Pod client-containers-51b0a54e-e015-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:23:00.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7504" for this suite.
Sep 26 04:23:06.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:23:06.185: INFO: namespace containers-7504 deletion completed in 6.055500657s

• [SLOW TEST:8.109 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:23:06.186: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 26 04:23:08.725: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9084 pod-service-account-56d2eb20-e015-11e9-8008-76f27b732d80 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 26 04:23:08.860: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9084 pod-service-account-56d2eb20-e015-11e9-8008-76f27b732d80 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 26 04:23:08.988: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9084 pod-service-account-56d2eb20-e015-11e9-8008-76f27b732d80 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:23:09.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9084" for this suite.
Sep 26 04:23:15.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:23:15.173: INFO: namespace svcaccounts-9084 deletion completed in 6.053878569s

• [SLOW TEST:8.988 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:23:15.174: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 26 04:23:15.251: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-996,SelfLink:/api/v1/namespaces/watch-996/configmaps/e2e-watch-test-watch-closed,UID:5be95df2-e015-11e9-af5c-00163e006ee4,ResourceVersion:31744928,Generation:0,CreationTimestamp:2019-09-26 04:23:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 26 04:23:15.251: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-996,SelfLink:/api/v1/namespaces/watch-996/configmaps/e2e-watch-test-watch-closed,UID:5be95df2-e015-11e9-af5c-00163e006ee4,ResourceVersion:31744929,Generation:0,CreationTimestamp:2019-09-26 04:23:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 26 04:23:15.257: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-996,SelfLink:/api/v1/namespaces/watch-996/configmaps/e2e-watch-test-watch-closed,UID:5be95df2-e015-11e9-af5c-00163e006ee4,ResourceVersion:31744930,Generation:0,CreationTimestamp:2019-09-26 04:23:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 26 04:23:15.257: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-996,SelfLink:/api/v1/namespaces/watch-996/configmaps/e2e-watch-test-watch-closed,UID:5be95df2-e015-11e9-af5c-00163e006ee4,ResourceVersion:31744931,Generation:0,CreationTimestamp:2019-09-26 04:23:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:23:15.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-996" for this suite.
Sep 26 04:23:21.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:23:21.316: INFO: namespace watch-996 deletion completed in 6.056508788s

• [SLOW TEST:6.142 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:23:21.317: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep 26 04:23:21.335: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 26 04:23:21.340: INFO: Waiting for terminating namespaces to be deleted...
Sep 26 04:23:21.341: INFO: 
Logging pods the kubelet thinks is on node aks-1-2 before test
Sep 26 04:23:21.345: INFO: sonobuoy-systemd-logs-daemon-set-82964ffec36e47b5-v2964 from sonobuoy started at 2019-09-26 03:39:59 +0000 UTC (2 container statuses recorded)
Sep 26 04:23:21.345: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 26 04:23:21.345: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 26 04:23:21.345: INFO: kube-flannel-ds-amd64-tkn7p from kube-system started at 2019-09-24 08:45:03 +0000 UTC (1 container statuses recorded)
Sep 26 04:23:21.345: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 26 04:23:21.345: INFO: coredns-6db98fd5fc-cccmw from kube-system started at 2019-09-24 08:44:09 +0000 UTC (1 container statuses recorded)
Sep 26 04:23:21.345: INFO: 	Container coredns ready: true, restart count 0
Sep 26 04:23:21.345: INFO: sonobuoy from sonobuoy started at 2019-09-26 03:39:58 +0000 UTC (1 container statuses recorded)
Sep 26 04:23:21.345: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 26 04:23:21.345: INFO: 
Logging pods the kubelet thinks is on node aks-1-3 before test
Sep 26 04:23:21.349: INFO: coredns-6db98fd5fc-nl9wc from kube-system started at 2019-09-20 07:03:40 +0000 UTC (1 container statuses recorded)
Sep 26 04:23:21.349: INFO: 	Container coredns ready: true, restart count 0
Sep 26 04:23:21.349: INFO: kube-flannel-ds-amd64-88xww from kube-system started at 2019-02-13 09:55:14 +0000 UTC (1 container statuses recorded)
Sep 26 04:23:21.349: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 26 04:23:21.349: INFO: sonobuoy-systemd-logs-daemon-set-82964ffec36e47b5-s78qg from sonobuoy started at 2019-09-26 03:39:59 +0000 UTC (2 container statuses recorded)
Sep 26 04:23:21.349: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 26 04:23:21.349: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 26 04:23:21.349: INFO: 
Logging pods the kubelet thinks is on node aks-1-4 before test
Sep 26 04:23:21.355: INFO: sonobuoy-systemd-logs-daemon-set-82964ffec36e47b5-vg7sd from sonobuoy started at 2019-09-26 03:39:59 +0000 UTC (2 container statuses recorded)
Sep 26 04:23:21.355: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 26 04:23:21.355: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 26 04:23:21.355: INFO: kube-flannel-ds-amd64-6tzhn from kube-system started at 2019-02-14 02:52:31 +0000 UTC (1 container statuses recorded)
Sep 26 04:23:21.355: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 26 04:23:21.355: INFO: coredns-6db98fd5fc-4bp4n from kube-system started at 2019-09-20 07:03:06 +0000 UTC (1 container statuses recorded)
Sep 26 04:23:21.355: INFO: 	Container coredns ready: true, restart count 0
Sep 26 04:23:21.355: INFO: sonobuoy-e2e-job-b47746facd3b4ea5 from sonobuoy started at 2019-09-26 03:39:59 +0000 UTC (2 container statuses recorded)
Sep 26 04:23:21.355: INFO: 	Container e2e ready: true, restart count 0
Sep 26 04:23:21.355: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-60c15d27-e015-11e9-8008-76f27b732d80 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-60c15d27-e015-11e9-8008-76f27b732d80 off the node aks-1-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-60c15d27-e015-11e9-8008-76f27b732d80
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:23:25.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1979" for this suite.
Sep 26 04:23:37.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:23:37.461: INFO: namespace sched-pred-1979 deletion completed in 12.056748601s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.144 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:23:37.461: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:23:39.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1052" for this suite.
Sep 26 04:24:19.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:24:19.563: INFO: namespace kubelet-test-1052 deletion completed in 40.062491386s

• [SLOW TEST:42.102 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:24:19.564: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:24:19.591: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82427d92-e015-11e9-8008-76f27b732d80" in namespace "projected-3725" to be "success or failure"
Sep 26 04:24:19.594: INFO: Pod "downwardapi-volume-82427d92-e015-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.58427ms
Sep 26 04:24:21.597: INFO: Pod "downwardapi-volume-82427d92-e015-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006366845s
STEP: Saw pod success
Sep 26 04:24:21.597: INFO: Pod "downwardapi-volume-82427d92-e015-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:24:21.599: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-82427d92-e015-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:24:21.611: INFO: Waiting for pod downwardapi-volume-82427d92-e015-11e9-8008-76f27b732d80 to disappear
Sep 26 04:24:21.613: INFO: Pod downwardapi-volume-82427d92-e015-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:24:21.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3725" for this suite.
Sep 26 04:24:27.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:24:27.670: INFO: namespace projected-3725 deletion completed in 6.055513921s

• [SLOW TEST:8.107 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:24:27.671: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:24:27.693: INFO: Waiting up to 5m0s for pod "downwardapi-volume-871734d7-e015-11e9-8008-76f27b732d80" in namespace "downward-api-7985" to be "success or failure"
Sep 26 04:24:27.698: INFO: Pod "downwardapi-volume-871734d7-e015-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.320701ms
Sep 26 04:24:29.700: INFO: Pod "downwardapi-volume-871734d7-e015-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007162355s
STEP: Saw pod success
Sep 26 04:24:29.700: INFO: Pod "downwardapi-volume-871734d7-e015-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:24:29.702: INFO: Trying to get logs from node aks-1-2 pod downwardapi-volume-871734d7-e015-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:24:29.716: INFO: Waiting for pod downwardapi-volume-871734d7-e015-11e9-8008-76f27b732d80 to disappear
Sep 26 04:24:29.729: INFO: Pod downwardapi-volume-871734d7-e015-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:24:29.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7985" for this suite.
Sep 26 04:24:35.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:24:35.790: INFO: namespace downward-api-7985 deletion completed in 6.059441167s

• [SLOW TEST:8.119 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:24:35.790: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0926 04:24:45.835876      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 26 04:24:45.835: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:24:45.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9305" for this suite.
Sep 26 04:24:51.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:24:51.898: INFO: namespace gc-9305 deletion completed in 6.060510223s

• [SLOW TEST:16.108 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:24:51.899: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:24:51.923: INFO: (0) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.238924ms)
Sep 26 04:24:51.925: INFO: (1) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.287706ms)
Sep 26 04:24:51.927: INFO: (2) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.129012ms)
Sep 26 04:24:51.930: INFO: (3) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.216722ms)
Sep 26 04:24:51.932: INFO: (4) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 1.864096ms)
Sep 26 04:24:51.934: INFO: (5) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.044328ms)
Sep 26 04:24:51.936: INFO: (6) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 1.949087ms)
Sep 26 04:24:51.938: INFO: (7) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.012361ms)
Sep 26 04:24:51.940: INFO: (8) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.569686ms)
Sep 26 04:24:51.942: INFO: (9) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.257115ms)
Sep 26 04:24:51.945: INFO: (10) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.260321ms)
Sep 26 04:24:51.947: INFO: (11) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.241731ms)
Sep 26 04:24:51.949: INFO: (12) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.144706ms)
Sep 26 04:24:51.952: INFO: (13) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.397884ms)
Sep 26 04:24:51.954: INFO: (14) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 1.961452ms)
Sep 26 04:24:51.956: INFO: (15) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.029608ms)
Sep 26 04:24:51.958: INFO: (16) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.12032ms)
Sep 26 04:24:51.960: INFO: (17) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 2.15186ms)
Sep 26 04:24:51.962: INFO: (18) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 1.938141ms)
Sep 26 04:24:51.964: INFO: (19) /api/v1/nodes/aks-1-2:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20190921">btmp-201909... (200; 1.837089ms)
[AfterEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:24:51.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4998" for this suite.
Sep 26 04:24:57.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:24:58.024: INFO: namespace proxy-4998 deletion completed in 6.057749622s

• [SLOW TEST:6.125 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:24:58.024: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 26 04:24:58.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-4257'
Sep 26 04:24:58.341: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 26 04:24:58.341: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Sep 26 04:25:00.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4257'
Sep 26 04:25:00.428: INFO: stderr: ""
Sep 26 04:25:00.428: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:25:00.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4257" for this suite.
Sep 26 04:25:22.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:25:22.494: INFO: namespace kubectl-4257 deletion completed in 22.063989336s

• [SLOW TEST:24.470 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:25:22.494: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-5846
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5846 to expose endpoints map[]
Sep 26 04:25:22.524: INFO: Get endpoints failed (2.350309ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep 26 04:25:23.526: INFO: successfully validated that service multi-endpoint-test in namespace services-5846 exposes endpoints map[] (1.004710359s elapsed)
STEP: Creating pod pod1 in namespace services-5846
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5846 to expose endpoints map[pod1:[100]]
Sep 26 04:25:25.559: INFO: successfully validated that service multi-endpoint-test in namespace services-5846 exposes endpoints map[pod1:[100]] (2.025269665s elapsed)
STEP: Creating pod pod2 in namespace services-5846
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5846 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 26 04:25:27.594: INFO: successfully validated that service multi-endpoint-test in namespace services-5846 exposes endpoints map[pod1:[100] pod2:[101]] (2.027346833s elapsed)
STEP: Deleting pod pod1 in namespace services-5846
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5846 to expose endpoints map[pod2:[101]]
Sep 26 04:25:28.608: INFO: successfully validated that service multi-endpoint-test in namespace services-5846 exposes endpoints map[pod2:[101]] (1.011502281s elapsed)
STEP: Deleting pod pod2 in namespace services-5846
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5846 to expose endpoints map[]
Sep 26 04:25:28.620: INFO: successfully validated that service multi-endpoint-test in namespace services-5846 exposes endpoints map[] (8.773782ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:25:28.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5846" for this suite.
Sep 26 04:25:50.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:25:50.746: INFO: namespace services-5846 deletion completed in 22.08178113s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:28.252 seconds]
[sig-network] Services
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:25:50.746: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7645
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-7645
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7645
Sep 26 04:25:50.785: INFO: Found 0 stateful pods, waiting for 1
Sep 26 04:26:00.788: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 26 04:26:00.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 26 04:26:00.928: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 26 04:26:00.928: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 26 04:26:00.928: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 26 04:26:00.931: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 26 04:26:10.934: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 26 04:26:10.934: INFO: Waiting for statefulset status.replicas updated to 0
Sep 26 04:26:10.946: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:10.946: INFO: ss-0  aks-1-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  }]
Sep 26 04:26:10.946: INFO: ss-1           Pending         []
Sep 26 04:26:10.946: INFO: 
Sep 26 04:26:10.946: INFO: StatefulSet ss has not reached scale 3, at 2
Sep 26 04:26:11.949: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995385795s
Sep 26 04:26:12.952: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992421944s
Sep 26 04:26:13.955: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989318231s
Sep 26 04:26:14.957: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986483329s
Sep 26 04:26:15.960: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983783807s
Sep 26 04:26:16.963: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.980877477s
Sep 26 04:26:17.966: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.978024397s
Sep 26 04:26:18.969: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.975277967s
Sep 26 04:26:19.972: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.41581ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7645
Sep 26 04:26:20.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:26:21.118: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 26 04:26:21.118: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 26 04:26:21.118: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 26 04:26:21.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:26:21.255: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 26 04:26:21.255: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 26 04:26:21.255: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 26 04:26:21.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:26:21.392: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 26 04:26:21.393: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 26 04:26:21.393: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 26 04:26:21.395: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 26 04:26:31.398: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 04:26:31.398: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 26 04:26:31.398: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 26 04:26:31.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 26 04:26:31.542: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 26 04:26:31.542: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 26 04:26:31.542: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 26 04:26:31.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 26 04:26:31.676: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 26 04:26:31.676: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 26 04:26:31.676: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 26 04:26:31.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 26 04:26:31.811: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 26 04:26:31.811: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 26 04:26:31.811: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 26 04:26:31.811: INFO: Waiting for statefulset status.replicas updated to 0
Sep 26 04:26:31.814: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep 26 04:26:41.818: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 26 04:26:41.818: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 26 04:26:41.818: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 26 04:26:41.826: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:41.826: INFO: ss-0  aks-1-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  }]
Sep 26 04:26:41.826: INFO: ss-1  aks-1-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:41.826: INFO: ss-2  aks-1-4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:41.826: INFO: 
Sep 26 04:26:41.826: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 26 04:26:42.829: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:42.829: INFO: ss-0  aks-1-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  }]
Sep 26 04:26:42.829: INFO: ss-1  aks-1-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:42.829: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:42.829: INFO: 
Sep 26 04:26:42.829: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 26 04:26:43.832: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:43.832: INFO: ss-0  aks-1-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  }]
Sep 26 04:26:43.832: INFO: ss-1  aks-1-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:43.832: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:43.832: INFO: 
Sep 26 04:26:43.832: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 26 04:26:44.835: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:44.835: INFO: ss-0  aks-1-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  }]
Sep 26 04:26:44.835: INFO: ss-1  aks-1-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:44.835: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:44.835: INFO: 
Sep 26 04:26:44.835: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 26 04:26:45.838: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:45.838: INFO: ss-0  aks-1-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  }]
Sep 26 04:26:45.838: INFO: ss-1  aks-1-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:45.838: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:45.838: INFO: 
Sep 26 04:26:45.838: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 26 04:26:46.841: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:46.841: INFO: ss-0  aks-1-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:25:50 +0000 UTC  }]
Sep 26 04:26:46.841: INFO: ss-1  aks-1-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:46.841: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:46.841: INFO: 
Sep 26 04:26:46.841: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 26 04:26:47.844: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:47.844: INFO: ss-1  aks-1-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:47.844: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:47.844: INFO: 
Sep 26 04:26:47.844: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 26 04:26:48.846: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:48.846: INFO: ss-1  aks-1-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:48.846: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:48.846: INFO: 
Sep 26 04:26:48.846: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 26 04:26:49.849: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:49.849: INFO: ss-1  aks-1-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:49.849: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:49.849: INFO: 
Sep 26 04:26:49.849: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 26 04:26:50.852: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 26 04:26:50.852: INFO: ss-1  aks-1-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:50.852: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:26:10 +0000 UTC  }]
Sep 26 04:26:50.852: INFO: 
Sep 26 04:26:50.852: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7645
Sep 26 04:26:51.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:26:51.943: INFO: rc: 1
Sep 26 04:26:51.943: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0029cedb0 exit status 1 <nil> <nil> true [0xc0011e69f8 0xc0011e6a10 0xc0011e6a28] [0xc0011e69f8 0xc0011e6a10 0xc0011e6a28] [0xc0011e6a08 0xc0011e6a20] [0x9c00a0 0x9c00a0] 0xc001afa900 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Sep 26 04:27:01.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:27:02.019: INFO: rc: 1
Sep 26 04:27:02.019: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001fa2b40 exit status 1 <nil> <nil> true [0xc00306e798 0xc00306e7b0 0xc00306e7c8] [0xc00306e798 0xc00306e7b0 0xc00306e7c8] [0xc00306e7a8 0xc00306e7c0] [0x9c00a0 0x9c00a0] 0xc001ac6cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:27:12.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:27:12.079: INFO: rc: 1
Sep 26 04:27:12.079: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001fa3080 exit status 1 <nil> <nil> true [0xc00306e7d0 0xc00306e7e8 0xc00306e800] [0xc00306e7d0 0xc00306e7e8 0xc00306e800] [0xc00306e7e0 0xc00306e7f8] [0x9c00a0 0x9c00a0] 0xc001ac70e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:27:22.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:27:22.139: INFO: rc: 1
Sep 26 04:27:22.139: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8c330 exit status 1 <nil> <nil> true [0xc0001842f8 0xc000184580 0xc00059da18] [0xc0001842f8 0xc000184580 0xc00059da18] [0xc0001844b0 0xc000184848] [0x9c00a0 0x9c00a0] 0xc0026648a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:27:32.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:27:32.197: INFO: rc: 1
Sep 26 04:27:32.197: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3c480 exit status 1 <nil> <nil> true [0xc000010058 0xc000010880 0xc000011130] [0xc000010058 0xc000010880 0xc000011130] [0xc000010458 0xc000010fd0] [0x9c00a0 0x9c00a0] 0xc0025055c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:27:42.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:27:42.259: INFO: rc: 1
Sep 26 04:27:42.260: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8c6c0 exit status 1 <nil> <nil> true [0xc00059da60 0xc00059db60 0xc00059dc10] [0xc00059da60 0xc00059db60 0xc00059dc10] [0xc00059db30 0xc00059dbe8] [0x9c00a0 0x9c00a0] 0xc0022421e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:27:52.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:27:52.321: INFO: rc: 1
Sep 26 04:27:52.321: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8ca20 exit status 1 <nil> <nil> true [0xc00059dc68 0xc00059dd08 0xc00059dd90] [0xc00059dc68 0xc00059dd08 0xc00059dd90] [0xc00059dcf0 0xc00059dd58] [0x9c00a0 0x9c00a0] 0xc002243560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:28:02.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:28:02.381: INFO: rc: 1
Sep 26 04:28:02.381: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3c870 exit status 1 <nil> <nil> true [0xc000011228 0xc000011300 0xc0000113c0] [0xc000011228 0xc000011300 0xc0000113c0] [0xc0000112b0 0xc000011330] [0x9c00a0 0x9c00a0] 0xc002217020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:28:12.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:28:12.441: INFO: rc: 1
Sep 26 04:28:12.441: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3cbd0 exit status 1 <nil> <nil> true [0xc000011490 0xc0000116f8 0xc000011958] [0xc000011490 0xc0000116f8 0xc000011958] [0xc000011680 0xc000011900] [0x9c00a0 0x9c00a0] 0xc0014285a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:28:22.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:28:22.503: INFO: rc: 1
Sep 26 04:28:22.503: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3cf30 exit status 1 <nil> <nil> true [0xc000011a48 0xc000011b70 0xc000011ca0] [0xc000011a48 0xc000011b70 0xc000011ca0] [0xc000011ae8 0xc000011b90] [0x9c00a0 0x9c00a0] 0xc001429c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:28:32.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:28:32.567: INFO: rc: 1
Sep 26 04:28:32.567: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3d290 exit status 1 <nil> <nil> true [0xc000011cb8 0xc000011f80 0xc00106e2a8] [0xc000011cb8 0xc000011f80 0xc00106e2a8] [0xc000011e58 0xc00106e188] [0x9c00a0 0x9c00a0] 0xc0017a4d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:28:42.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:28:42.626: INFO: rc: 1
Sep 26 04:28:42.626: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3d620 exit status 1 <nil> <nil> true [0xc00106e500 0xc00106e820 0xc00106ea80] [0xc00106e500 0xc00106e820 0xc00106ea80] [0xc00106e808 0xc00106e9c0] [0x9c00a0 0x9c00a0] 0xc00194e4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:28:52.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:28:52.690: INFO: rc: 1
Sep 26 04:28:52.690: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3d980 exit status 1 <nil> <nil> true [0xc00106eb00 0xc00106ef68 0xc00106f3c8] [0xc00106eb00 0xc00106ef68 0xc00106f3c8] [0xc00106eda0 0xc00106f208] [0x9c00a0 0x9c00a0] 0xc001c3a360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:29:02.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:29:02.749: INFO: rc: 1
Sep 26 04:29:02.749: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8ce70 exit status 1 <nil> <nil> true [0xc00059dde8 0xc00059de68 0xc00059deb0] [0xc00059dde8 0xc00059de68 0xc00059deb0] [0xc00059de48 0xc00059de88] [0x9c00a0 0x9c00a0] 0xc001f03140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:29:12.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:29:12.808: INFO: rc: 1
Sep 26 04:29:12.808: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8d200 exit status 1 <nil> <nil> true [0xc00059dee0 0xc00059df28 0xc00059df88] [0xc00059dee0 0xc00059df28 0xc00059df88] [0xc00059df08 0xc00059df60] [0x9c00a0 0x9c00a0] 0xc001c8de00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:29:22.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:29:22.868: INFO: rc: 1
Sep 26 04:29:22.868: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3c420 exit status 1 <nil> <nil> true [0xc0000100b0 0xc0000109f8 0xc000011228] [0xc0000100b0 0xc0000109f8 0xc000011228] [0xc000010880 0xc000011130] [0x9c00a0 0x9c00a0] 0xc001c7dc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:29:32.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:29:32.928: INFO: rc: 1
Sep 26 04:29:32.928: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3c810 exit status 1 <nil> <nil> true [0xc000011238 0xc000011320 0xc000011490] [0xc000011238 0xc000011320 0xc000011490] [0xc000011300 0xc0000113c0] [0x9c00a0 0x9c00a0] 0xc00194e660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:29:42.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:29:42.996: INFO: rc: 1
Sep 26 04:29:42.996: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8c390 exit status 1 <nil> <nil> true [0xc000184168 0xc0001844b0 0xc000184848] [0xc000184168 0xc0001844b0 0xc000184848] [0xc000184310 0xc0001847c8] [0x9c00a0 0x9c00a0] 0xc0017a5020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:29:52.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:29:53.057: INFO: rc: 1
Sep 26 04:29:53.057: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8c720 exit status 1 <nil> <nil> true [0xc00106e028 0xc00106e500 0xc00106e820] [0xc00106e028 0xc00106e500 0xc00106e820] [0xc00106e2a8 0xc00106e808] [0x9c00a0 0x9c00a0] 0xc001428960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:30:03.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:30:03.127: INFO: rc: 1
Sep 26 04:30:03.127: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8cae0 exit status 1 <nil> <nil> true [0xc00106e880 0xc00106eb00 0xc00106ef68] [0xc00106e880 0xc00106eb00 0xc00106ef68] [0xc00106ea80 0xc00106eda0] [0x9c00a0 0x9c00a0] 0xc001429e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:30:13.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:30:13.190: INFO: rc: 1
Sep 26 04:30:13.190: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8cea0 exit status 1 <nil> <nil> true [0xc00106f0c0 0xc00106f540 0xc00106f778] [0xc00106f0c0 0xc00106f540 0xc00106f778] [0xc00106f3c8 0xc00106f6a0] [0x9c00a0 0x9c00a0] 0xc0022171a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:30:23.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:30:23.254: INFO: rc: 1
Sep 26 04:30:23.254: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8d260 exit status 1 <nil> <nil> true [0xc00106f7b0 0xc00106f9a8 0xc00106fbb8] [0xc00106f7b0 0xc00106f9a8 0xc00106fbb8] [0xc00106f938 0xc00106fb48] [0x9c00a0 0x9c00a0] 0xc002242540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:30:33.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:30:33.324: INFO: rc: 1
Sep 26 04:30:33.324: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3cc60 exit status 1 <nil> <nil> true [0xc0000115f0 0xc000011768 0xc000011a48] [0xc0000115f0 0xc000011768 0xc000011a48] [0xc0000116f8 0xc000011958] [0x9c00a0 0x9c00a0] 0xc002504480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:30:43.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:30:43.387: INFO: rc: 1
Sep 26 04:30:43.387: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3d020 exit status 1 <nil> <nil> true [0xc000011a90 0xc000011b78 0xc000011cb8] [0xc000011a90 0xc000011b78 0xc000011cb8] [0xc000011b70 0xc000011ca0] [0x9c00a0 0x9c00a0] 0xc002664000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:30:53.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:30:53.450: INFO: rc: 1
Sep 26 04:30:53.450: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8d710 exit status 1 <nil> <nil> true [0xc00106fbd8 0xc00106fc40 0xc00106fcd8] [0xc00106fbd8 0xc00106fc40 0xc00106fcd8] [0xc00106fc20 0xc00106fcb0] [0x9c00a0 0x9c00a0] 0xc002243b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:31:03.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:31:03.510: INFO: rc: 1
Sep 26 04:31:03.510: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8dad0 exit status 1 <nil> <nil> true [0xc00106fd00 0xc00106fd98 0xc00106fec0] [0xc00106fd00 0xc00106fd98 0xc00106fec0] [0xc00106fd60 0xc00106fe88] [0x9c00a0 0x9c00a0] 0xc001c3ac00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:31:13.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:31:13.570: INFO: rc: 1
Sep 26 04:31:13.570: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3d3e0 exit status 1 <nil> <nil> true [0xc000011d08 0xc00059da18 0xc00059db30] [0xc000011d08 0xc00059da18 0xc00059db30] [0xc000011f80 0xc00059daa0] [0x9c00a0 0x9c00a0] 0xc002665920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:31:23.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:31:23.630: INFO: rc: 1
Sep 26 04:31:23.630: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3c450 exit status 1 <nil> <nil> true [0xc0001842f8 0xc000184580 0xc000010058] [0xc0001842f8 0xc000184580 0xc000010058] [0xc0001844b0 0xc000184848] [0x9c00a0 0x9c00a0] 0xc002504a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:31:33.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:31:33.689: INFO: rc: 1
Sep 26 04:31:33.689: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001e8c360 exit status 1 <nil> <nil> true [0xc00059da18 0xc00059db30 0xc00059dbe8] [0xc00059da18 0xc00059db30 0xc00059dbe8] [0xc00059daa0 0xc00059dba8] [0x9c00a0 0x9c00a0] 0xc002243200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:31:43.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:31:43.754: INFO: rc: 1
Sep 26 04:31:43.754: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001b3c7e0 exit status 1 <nil> <nil> true [0xc0000100b0 0xc0000109f8 0xc000011228] [0xc0000100b0 0xc0000109f8 0xc000011228] [0xc000010880 0xc000011130] [0x9c00a0 0x9c00a0] 0xc002216600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Sep 26 04:31:53.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 exec --namespace=statefulset-7645 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 26 04:31:53.814: INFO: rc: 1
Sep 26 04:31:53.814: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Sep 26 04:31:53.814: INFO: Scaling statefulset ss to 0
Sep 26 04:31:53.820: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep 26 04:31:53.821: INFO: Deleting all statefulset in ns statefulset-7645
Sep 26 04:31:53.823: INFO: Scaling statefulset ss to 0
Sep 26 04:31:53.827: INFO: Waiting for statefulset status.replicas updated to 0
Sep 26 04:31:53.829: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:31:53.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7645" for this suite.
Sep 26 04:31:59.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:31:59.899: INFO: namespace statefulset-7645 deletion completed in 6.061900428s

• [SLOW TEST:369.153 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:31:59.900: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 26 04:31:59.938: INFO: Number of nodes with available pods: 0
Sep 26 04:31:59.938: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 04:32:00.943: INFO: Number of nodes with available pods: 0
Sep 26 04:32:00.943: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 04:32:01.947: INFO: Number of nodes with available pods: 3
Sep 26 04:32:01.947: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 26 04:32:01.963: INFO: Number of nodes with available pods: 2
Sep 26 04:32:01.964: INFO: Node aks-1-4 is running more than one daemon pod
Sep 26 04:32:02.969: INFO: Number of nodes with available pods: 2
Sep 26 04:32:02.969: INFO: Node aks-1-4 is running more than one daemon pod
Sep 26 04:32:03.969: INFO: Number of nodes with available pods: 3
Sep 26 04:32:03.969: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1551, will wait for the garbage collector to delete the pods
Sep 26 04:32:04.028: INFO: Deleting DaemonSet.extensions daemon-set took: 4.347971ms
Sep 26 04:32:04.129: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.157954ms
Sep 26 04:32:15.030: INFO: Number of nodes with available pods: 0
Sep 26 04:32:15.030: INFO: Number of running nodes: 0, number of available pods: 0
Sep 26 04:32:15.032: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1551/daemonsets","resourceVersion":"31746233"},"items":null}

Sep 26 04:32:15.033: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1551/pods","resourceVersion":"31746233"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:32:15.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1551" for this suite.
Sep 26 04:32:21.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:32:21.103: INFO: namespace daemonsets-1551 deletion completed in 6.06023197s

• [SLOW TEST:21.203 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:32:21.103: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 26 04:32:25.148: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5744 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:32:25.148: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:32:25.215: INFO: Exec stderr: ""
Sep 26 04:32:25.215: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5744 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:32:25.215: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:32:25.280: INFO: Exec stderr: ""
Sep 26 04:32:25.280: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5744 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:32:25.280: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:32:25.354: INFO: Exec stderr: ""
Sep 26 04:32:25.354: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5744 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:32:25.354: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:32:25.424: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 26 04:32:25.424: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5744 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:32:25.424: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:32:25.513: INFO: Exec stderr: ""
Sep 26 04:32:25.513: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5744 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:32:25.513: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:32:25.578: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 26 04:32:25.578: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5744 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:32:25.578: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:32:25.657: INFO: Exec stderr: ""
Sep 26 04:32:25.657: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5744 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:32:25.657: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:32:25.718: INFO: Exec stderr: ""
Sep 26 04:32:25.718: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5744 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:32:25.718: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:32:25.775: INFO: Exec stderr: ""
Sep 26 04:32:25.775: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5744 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:32:25.775: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:32:25.832: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:32:25.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5744" for this suite.
Sep 26 04:33:15.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:33:15.891: INFO: namespace e2e-kubelet-etc-hosts-5744 deletion completed in 50.055957025s

• [SLOW TEST:54.787 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:33:15.891: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:33:15.910: INFO: Creating deployment "test-recreate-deployment"
Sep 26 04:33:15.913: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 26 04:33:15.920: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep 26 04:33:17.925: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 26 04:33:17.926: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 26 04:33:17.931: INFO: Updating deployment test-recreate-deployment
Sep 26 04:33:17.931: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep 26 04:33:18.004: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-8129,SelfLink:/apis/apps/v1/namespaces/deployment-8129/deployments/test-recreate-deployment,UID:c1ef75fb-e016-11e9-af5c-00163e006ee4,ResourceVersion:31746450,Generation:2,CreationTimestamp:2019-09-26 04:33:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-26 04:33:17 +0000 UTC 2019-09-26 04:33:17 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-26 04:33:17 +0000 UTC 2019-09-26 04:33:15 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep 26 04:33:18.006: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-8129,SelfLink:/apis/apps/v1/namespaces/deployment-8129/replicasets/test-recreate-deployment-c9cbd8684,UID:c328079d-e016-11e9-af5c-00163e006ee4,ResourceVersion:31746448,Generation:1,CreationTimestamp:2019-09-26 04:33:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment c1ef75fb-e016-11e9-af5c-00163e006ee4 0xc002dedc50 0xc002dedc51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 26 04:33:18.006: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 26 04:33:18.007: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-8129,SelfLink:/apis/apps/v1/namespaces/deployment-8129/replicasets/test-recreate-deployment-7d57d5ff7c,UID:c1eff784-e016-11e9-af5c-00163e006ee4,ResourceVersion:31746440,Generation:2,CreationTimestamp:2019-09-26 04:33:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment c1ef75fb-e016-11e9-af5c-00163e006ee4 0xc002dedb77 0xc002dedb78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 26 04:33:18.009: INFO: Pod "test-recreate-deployment-c9cbd8684-zcv66" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-zcv66,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-8129,SelfLink:/api/v1/namespaces/deployment-8129/pods/test-recreate-deployment-c9cbd8684-zcv66,UID:c3289ed3-e016-11e9-af5c-00163e006ee4,ResourceVersion:31746446,Generation:0,CreationTimestamp:2019-09-26 04:33:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 c328079d-e016-11e9-af5c-00163e006ee4 0xc002e0e510 0xc002e0e511}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-x6znx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-x6znx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-x6znx true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e0e580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e0e5b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:33:17 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:33:18.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8129" for this suite.
Sep 26 04:33:24.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:33:24.072: INFO: namespace deployment-8129 deletion completed in 6.056752666s

• [SLOW TEST:8.181 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:33:24.073: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep 26 04:33:24.093: INFO: PodSpec: initContainers in spec.initContainers
Sep 26 04:34:09.502: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c6d002e8-e016-11e9-8008-76f27b732d80", GenerateName:"", Namespace:"init-container-107", SelfLink:"/api/v1/namespaces/init-container-107/pods/pod-init-c6d002e8-e016-11e9-8008-76f27b732d80", UID:"c6d04bf1-e016-11e9-af5c-00163e006ee4", ResourceVersion:"31746574", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63705069204, loc:(*time.Location)(0x8a1a0e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"93418374"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-d5nvj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0032afac0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d5nvj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d5nvj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d5nvj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003093318), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"aks-1-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003295920), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0030933a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0030933c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0030933c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0030933cc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705069204, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705069204, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705069204, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainerDiskPressure", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705069204, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705069204, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.27.78", PodIP:"10.244.2.122", StartTime:(*v1.Time)(0xc0026f7660), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000f34700)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000f34770)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://109b3a9439108ba09a01cdfa7069027c88934fe90dfb4da079d1009e23a65de0"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0026f76a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0026f7680), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:34:09.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-107" for this suite.
Sep 26 04:34:31.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:34:31.560: INFO: namespace init-container-107 deletion completed in 22.054737527s

• [SLOW TEST:67.487 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:34:31.560: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Sep 26 04:34:31.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 cluster-info'
Sep 26 04:34:31.667: INFO: stderr: ""
Sep 26 04:34:31.667: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:34:31.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1522" for this suite.
Sep 26 04:34:37.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:34:37.725: INFO: namespace kubectl-1522 deletion completed in 6.055535919s

• [SLOW TEST:6.165 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:34:37.726: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 26 04:34:37.754: INFO: Waiting up to 5m0s for pod "pod-f2b6f169-e016-11e9-8008-76f27b732d80" in namespace "emptydir-3613" to be "success or failure"
Sep 26 04:34:37.757: INFO: Pod "pod-f2b6f169-e016-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.808207ms
Sep 26 04:34:39.760: INFO: Pod "pod-f2b6f169-e016-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006525533s
STEP: Saw pod success
Sep 26 04:34:39.760: INFO: Pod "pod-f2b6f169-e016-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:34:39.762: INFO: Trying to get logs from node aks-1-2 pod pod-f2b6f169-e016-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:34:39.779: INFO: Waiting for pod pod-f2b6f169-e016-11e9-8008-76f27b732d80 to disappear
Sep 26 04:34:39.784: INFO: Pod pod-f2b6f169-e016-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:34:39.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3613" for this suite.
Sep 26 04:34:45.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:34:45.854: INFO: namespace emptydir-3613 deletion completed in 6.064933657s

• [SLOW TEST:8.128 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:34:45.854: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-f78eacc3-e016-11e9-8008-76f27b732d80
STEP: Creating secret with name secret-projected-all-test-volume-f78eacab-e016-11e9-8008-76f27b732d80
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 26 04:34:45.881: INFO: Waiting up to 5m0s for pod "projected-volume-f78eac7a-e016-11e9-8008-76f27b732d80" in namespace "projected-7459" to be "success or failure"
Sep 26 04:34:45.886: INFO: Pod "projected-volume-f78eac7a-e016-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 5.158502ms
Sep 26 04:34:47.889: INFO: Pod "projected-volume-f78eac7a-e016-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007840066s
STEP: Saw pod success
Sep 26 04:34:47.889: INFO: Pod "projected-volume-f78eac7a-e016-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:34:47.891: INFO: Trying to get logs from node aks-1-3 pod projected-volume-f78eac7a-e016-11e9-8008-76f27b732d80 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 26 04:34:47.907: INFO: Waiting for pod projected-volume-f78eac7a-e016-11e9-8008-76f27b732d80 to disappear
Sep 26 04:34:47.909: INFO: Pod projected-volume-f78eac7a-e016-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:34:47.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7459" for this suite.
Sep 26 04:34:53.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:34:53.974: INFO: namespace projected-7459 deletion completed in 6.063094561s

• [SLOW TEST:8.120 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:34:53.975: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-6197
Sep 26 04:34:56.002: INFO: Started pod liveness-exec in namespace container-probe-6197
STEP: checking the pod's current state and verifying that restartCount is present
Sep 26 04:34:56.003: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:38:56.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6197" for this suite.
Sep 26 04:39:02.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:39:02.409: INFO: namespace container-probe-6197 deletion completed in 6.075508288s

• [SLOW TEST:248.435 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:39:02.410: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:39:02.440: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 26 04:39:07.443: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 26 04:39:07.443: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep 26 04:39:07.454: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-5563,SelfLink:/apis/apps/v1/namespaces/deployment-5563/deployments/test-cleanup-deployment,UID:937793a6-e017-11e9-af5c-00163e006ee4,ResourceVersion:31747136,Generation:1,CreationTimestamp:2019-09-26 04:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep 26 04:39:07.456: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Sep 26 04:39:07.456: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep 26 04:39:07.456: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-5563,SelfLink:/apis/apps/v1/namespaces/deployment-5563/replicasets/test-cleanup-controller,UID:907af9c3-e017-11e9-af5c-00163e006ee4,ResourceVersion:31747137,Generation:1,CreationTimestamp:2019-09-26 04:39:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 937793a6-e017-11e9-af5c-00163e006ee4 0xc00036a237 0xc00036a238}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 26 04:39:07.468: INFO: Pod "test-cleanup-controller-xmtzh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-xmtzh,GenerateName:test-cleanup-controller-,Namespace:deployment-5563,SelfLink:/api/v1/namespaces/deployment-5563/pods/test-cleanup-controller-xmtzh,UID:907bc2b1-e017-11e9-af5c-00163e006ee4,ResourceVersion:31747128,Generation:0,CreationTimestamp:2019-09-26 04:39:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"nginx":{"creationTimestamp":"2019-09-26T12:39:03.090794725+08:00","finishTimestamp":"2019-09-26T12:39:03.368316911+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 907af9c3-e017-11e9-af5c-00163e006ee4 0xc000169977 0xc000169978}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-f98mq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-f98mq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-f98mq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000169a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000169ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:39:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:39:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:39:03 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:39:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 04:39:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.124,StartTime:2019-09-26 04:39:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-26 04:39:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a588fb4fc545e5074a13dea911931a697b4d8d0f5664bfffed6c10d40f4ca80c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:39:07.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5563" for this suite.
Sep 26 04:39:13.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:39:13.562: INFO: namespace deployment-5563 deletion completed in 6.08292114s

• [SLOW TEST:11.153 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:39:13.562: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 26 04:39:13.589: INFO: Waiting up to 5m0s for pod "pod-97203cdb-e017-11e9-8008-76f27b732d80" in namespace "emptydir-879" to be "success or failure"
Sep 26 04:39:13.591: INFO: Pod "pod-97203cdb-e017-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.999174ms
Sep 26 04:39:15.594: INFO: Pod "pod-97203cdb-e017-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004839309s
STEP: Saw pod success
Sep 26 04:39:15.594: INFO: Pod "pod-97203cdb-e017-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:39:15.596: INFO: Trying to get logs from node aks-1-3 pod pod-97203cdb-e017-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:39:15.608: INFO: Waiting for pod pod-97203cdb-e017-11e9-8008-76f27b732d80 to disappear
Sep 26 04:39:15.610: INFO: Pod pod-97203cdb-e017-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:39:15.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-879" for this suite.
Sep 26 04:39:21.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:39:21.684: INFO: namespace emptydir-879 deletion completed in 6.072567087s

• [SLOW TEST:8.122 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:39:21.685: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-vt5h
STEP: Creating a pod to test atomic-volume-subpath
Sep 26 04:39:21.716: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-vt5h" in namespace "subpath-5861" to be "success or failure"
Sep 26 04:39:21.720: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Pending", Reason="", readiness=false. Elapsed: 4.392199ms
Sep 26 04:39:23.723: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Running", Reason="", readiness=true. Elapsed: 2.006743059s
Sep 26 04:39:25.725: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Running", Reason="", readiness=true. Elapsed: 4.009579175s
Sep 26 04:39:27.728: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Running", Reason="", readiness=true. Elapsed: 6.012327246s
Sep 26 04:39:29.731: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Running", Reason="", readiness=true. Elapsed: 8.014949889s
Sep 26 04:39:31.734: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Running", Reason="", readiness=true. Elapsed: 10.017686041s
Sep 26 04:39:33.736: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Running", Reason="", readiness=true. Elapsed: 12.019844454s
Sep 26 04:39:35.738: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Running", Reason="", readiness=true. Elapsed: 14.022460963s
Sep 26 04:39:37.742: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Running", Reason="", readiness=true. Elapsed: 16.026013067s
Sep 26 04:39:39.745: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Running", Reason="", readiness=true. Elapsed: 18.029129995s
Sep 26 04:39:41.748: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Running", Reason="", readiness=true. Elapsed: 20.031879351s
Sep 26 04:39:43.750: INFO: Pod "pod-subpath-test-projected-vt5h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.034377209s
STEP: Saw pod success
Sep 26 04:39:43.750: INFO: Pod "pod-subpath-test-projected-vt5h" satisfied condition "success or failure"
Sep 26 04:39:43.752: INFO: Trying to get logs from node aks-1-2 pod pod-subpath-test-projected-vt5h container test-container-subpath-projected-vt5h: <nil>
STEP: delete the pod
Sep 26 04:39:43.768: INFO: Waiting for pod pod-subpath-test-projected-vt5h to disappear
Sep 26 04:39:43.771: INFO: Pod pod-subpath-test-projected-vt5h no longer exists
STEP: Deleting pod pod-subpath-test-projected-vt5h
Sep 26 04:39:43.771: INFO: Deleting pod "pod-subpath-test-projected-vt5h" in namespace "subpath-5861"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:39:43.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5861" for this suite.
Sep 26 04:39:49.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:39:49.837: INFO: namespace subpath-5861 deletion completed in 6.061420119s

• [SLOW TEST:28.153 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:39:49.838: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 26 04:39:53.954: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:39:53.956: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 26 04:39:55.956: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:39:55.958: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 26 04:39:57.956: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:39:57.959: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 26 04:39:59.956: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:39:59.959: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 26 04:40:01.956: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:40:01.958: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 26 04:40:03.956: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:40:03.958: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 26 04:40:05.956: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:40:05.958: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 26 04:40:07.956: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:40:07.958: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 26 04:40:09.956: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:40:09.958: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 26 04:40:11.956: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:40:11.958: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 26 04:40:13.956: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 26 04:40:13.958: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:40:13.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-387" for this suite.
Sep 26 04:40:35.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:40:36.048: INFO: namespace container-lifecycle-hook-387 deletion completed in 22.087236201s

• [SLOW TEST:46.210 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:40:36.048: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Sep 26 04:40:36.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-1694'
Sep 26 04:40:36.548: INFO: stderr: ""
Sep 26 04:40:36.548: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 26 04:40:36.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1694'
Sep 26 04:40:36.654: INFO: stderr: ""
Sep 26 04:40:36.654: INFO: stdout: "update-demo-nautilus-4ffqk update-demo-nautilus-4nsn8 "
Sep 26 04:40:36.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-4ffqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1694'
Sep 26 04:40:36.728: INFO: stderr: ""
Sep 26 04:40:36.728: INFO: stdout: ""
Sep 26 04:40:36.728: INFO: update-demo-nautilus-4ffqk is created but not running
Sep 26 04:40:41.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1694'
Sep 26 04:40:41.879: INFO: stderr: ""
Sep 26 04:40:41.879: INFO: stdout: "update-demo-nautilus-4ffqk update-demo-nautilus-4nsn8 "
Sep 26 04:40:41.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-4ffqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1694'
Sep 26 04:40:41.954: INFO: stderr: ""
Sep 26 04:40:41.954: INFO: stdout: "true"
Sep 26 04:40:41.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-4ffqk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1694'
Sep 26 04:40:42.025: INFO: stderr: ""
Sep 26 04:40:42.025: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 26 04:40:42.025: INFO: validating pod update-demo-nautilus-4ffqk
Sep 26 04:40:42.028: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 26 04:40:42.028: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 26 04:40:42.028: INFO: update-demo-nautilus-4ffqk is verified up and running
Sep 26 04:40:42.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-4nsn8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1694'
Sep 26 04:40:42.101: INFO: stderr: ""
Sep 26 04:40:42.101: INFO: stdout: "true"
Sep 26 04:40:42.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-4nsn8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1694'
Sep 26 04:40:42.174: INFO: stderr: ""
Sep 26 04:40:42.174: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 26 04:40:42.174: INFO: validating pod update-demo-nautilus-4nsn8
Sep 26 04:40:42.178: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 26 04:40:42.178: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 26 04:40:42.178: INFO: update-demo-nautilus-4nsn8 is verified up and running
STEP: rolling-update to new replication controller
Sep 26 04:40:42.179: INFO: scanned /root for discovery docs: <nil>
Sep 26 04:40:42.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1694'
Sep 26 04:41:04.581: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 26 04:41:04.581: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 26 04:41:04.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1694'
Sep 26 04:41:04.657: INFO: stderr: ""
Sep 26 04:41:04.657: INFO: stdout: "update-demo-kitten-n5kp7 update-demo-kitten-tnj6h update-demo-nautilus-4ffqk "
STEP: Replicas for name=update-demo: expected=2 actual=3
Sep 26 04:41:09.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1694'
Sep 26 04:41:09.735: INFO: stderr: ""
Sep 26 04:41:09.735: INFO: stdout: "update-demo-kitten-n5kp7 update-demo-kitten-tnj6h "
Sep 26 04:41:09.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-kitten-n5kp7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1694'
Sep 26 04:41:09.830: INFO: stderr: ""
Sep 26 04:41:09.830: INFO: stdout: "true"
Sep 26 04:41:09.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-kitten-n5kp7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1694'
Sep 26 04:41:09.900: INFO: stderr: ""
Sep 26 04:41:09.900: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 26 04:41:09.900: INFO: validating pod update-demo-kitten-n5kp7
Sep 26 04:41:09.904: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 26 04:41:09.904: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 26 04:41:09.904: INFO: update-demo-kitten-n5kp7 is verified up and running
Sep 26 04:41:09.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-kitten-tnj6h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1694'
Sep 26 04:41:09.973: INFO: stderr: ""
Sep 26 04:41:09.973: INFO: stdout: "true"
Sep 26 04:41:09.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-kitten-tnj6h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1694'
Sep 26 04:41:10.041: INFO: stderr: ""
Sep 26 04:41:10.041: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 26 04:41:10.041: INFO: validating pod update-demo-kitten-tnj6h
Sep 26 04:41:10.044: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 26 04:41:10.044: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 26 04:41:10.044: INFO: update-demo-kitten-tnj6h is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:41:10.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1694" for this suite.
Sep 26 04:41:32.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:41:32.274: INFO: namespace kubectl-1694 deletion completed in 22.227351391s

• [SLOW TEST:56.226 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:41:32.274: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-e9d575a3-e017-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:41:32.353: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e9d5f653-e017-11e9-8008-76f27b732d80" in namespace "projected-6245" to be "success or failure"
Sep 26 04:41:32.359: INFO: Pod "pod-projected-secrets-e9d5f653-e017-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018434ms
Sep 26 04:41:34.361: INFO: Pod "pod-projected-secrets-e9d5f653-e017-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008556833s
STEP: Saw pod success
Sep 26 04:41:34.361: INFO: Pod "pod-projected-secrets-e9d5f653-e017-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:41:34.363: INFO: Trying to get logs from node aks-1-3 pod pod-projected-secrets-e9d5f653-e017-11e9-8008-76f27b732d80 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 26 04:41:34.376: INFO: Waiting for pod pod-projected-secrets-e9d5f653-e017-11e9-8008-76f27b732d80 to disappear
Sep 26 04:41:34.377: INFO: Pod pod-projected-secrets-e9d5f653-e017-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:41:34.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6245" for this suite.
Sep 26 04:41:40.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:41:40.437: INFO: namespace projected-6245 deletion completed in 6.057844089s

• [SLOW TEST:8.164 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:41:40.438: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8448
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 26 04:41:40.457: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 26 04:42:00.517: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.131:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8448 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:42:00.517: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:42:00.594: INFO: Found all expected endpoints: [netserver-0]
Sep 26 04:42:00.596: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.136:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8448 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:42:00.596: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:42:00.665: INFO: Found all expected endpoints: [netserver-1]
Sep 26 04:42:00.668: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.37:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8448 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 04:42:00.668: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 04:42:00.745: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:42:00.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8448" for this suite.
Sep 26 04:42:22.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:42:22.805: INFO: namespace pod-network-test-8448 deletion completed in 22.055709045s

• [SLOW TEST:42.367 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:42:22.805: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-07ebe059-e018-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:42:22.831: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-07ec2814-e018-11e9-8008-76f27b732d80" in namespace "projected-7596" to be "success or failure"
Sep 26 04:42:22.834: INFO: Pod "pod-projected-secrets-07ec2814-e018-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.090091ms
Sep 26 04:42:24.836: INFO: Pod "pod-projected-secrets-07ec2814-e018-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005685494s
STEP: Saw pod success
Sep 26 04:42:24.836: INFO: Pod "pod-projected-secrets-07ec2814-e018-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:42:24.838: INFO: Trying to get logs from node aks-1-2 pod pod-projected-secrets-07ec2814-e018-11e9-8008-76f27b732d80 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 26 04:42:24.854: INFO: Waiting for pod pod-projected-secrets-07ec2814-e018-11e9-8008-76f27b732d80 to disappear
Sep 26 04:42:24.858: INFO: Pod pod-projected-secrets-07ec2814-e018-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:42:24.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7596" for this suite.
Sep 26 04:42:30.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:42:30.920: INFO: namespace projected-7596 deletion completed in 6.058689137s

• [SLOW TEST:8.115 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:42:30.920: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:42:30.939: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:42:32.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5796" for this suite.
Sep 26 04:43:16.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:43:17.019: INFO: namespace pods-5796 deletion completed in 44.055041572s

• [SLOW TEST:46.099 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:43:17.019: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 26 04:43:17.061: INFO: Waiting up to 5m0s for pod "pod-283e46e1-e018-11e9-8008-76f27b732d80" in namespace "emptydir-5658" to be "success or failure"
Sep 26 04:43:17.069: INFO: Pod "pod-283e46e1-e018-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 7.676628ms
Sep 26 04:43:19.071: INFO: Pod "pod-283e46e1-e018-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010500569s
STEP: Saw pod success
Sep 26 04:43:19.071: INFO: Pod "pod-283e46e1-e018-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:43:19.073: INFO: Trying to get logs from node aks-1-2 pod pod-283e46e1-e018-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:43:19.085: INFO: Waiting for pod pod-283e46e1-e018-11e9-8008-76f27b732d80 to disappear
Sep 26 04:43:19.087: INFO: Pod pod-283e46e1-e018-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:43:19.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5658" for this suite.
Sep 26 04:43:25.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:43:25.163: INFO: namespace emptydir-5658 deletion completed in 6.071305733s

• [SLOW TEST:8.144 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:43:25.164: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-2d16f205-e018-11e9-8008-76f27b732d80
Sep 26 04:43:25.188: INFO: Pod name my-hostname-basic-2d16f205-e018-11e9-8008-76f27b732d80: Found 0 pods out of 1
Sep 26 04:43:30.191: INFO: Pod name my-hostname-basic-2d16f205-e018-11e9-8008-76f27b732d80: Found 1 pods out of 1
Sep 26 04:43:30.191: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-2d16f205-e018-11e9-8008-76f27b732d80" are running
Sep 26 04:43:30.193: INFO: Pod "my-hostname-basic-2d16f205-e018-11e9-8008-76f27b732d80-qghp6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-26 04:43:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-26 04:43:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-26 04:43:26 +0000 UTC Reason: Message:} {Type:ContainerDiskPressure Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-26 04:43:25 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-26 04:43:25 +0000 UTC Reason: Message:}])
Sep 26 04:43:30.193: INFO: Trying to dial the pod
Sep 26 04:43:35.200: INFO: Controller my-hostname-basic-2d16f205-e018-11e9-8008-76f27b732d80: Got expected result from replica 1 [my-hostname-basic-2d16f205-e018-11e9-8008-76f27b732d80-qghp6]: "my-hostname-basic-2d16f205-e018-11e9-8008-76f27b732d80-qghp6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:43:35.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4991" for this suite.
Sep 26 04:43:41.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:43:41.266: INFO: namespace replication-controller-4991 deletion completed in 6.06325444s

• [SLOW TEST:16.102 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:43:41.266: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 26 04:43:41.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-265'
Sep 26 04:43:41.371: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 26 04:43:41.371: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep 26 04:43:41.377: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep 26 04:43:41.380: INFO: scanned /root for discovery docs: <nil>
Sep 26 04:43:41.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-265'
Sep 26 04:43:57.112: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 26 04:43:57.112: INFO: stdout: "Created e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287\nScaling up e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep 26 04:43:57.112: INFO: stdout: "Created e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287\nScaling up e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep 26 04:43:57.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-265'
Sep 26 04:43:57.182: INFO: stderr: ""
Sep 26 04:43:57.182: INFO: stdout: "e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287-dkgg9 "
Sep 26 04:43:57.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287-dkgg9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-265'
Sep 26 04:43:57.258: INFO: stderr: ""
Sep 26 04:43:57.258: INFO: stdout: "true"
Sep 26 04:43:57.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287-dkgg9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-265'
Sep 26 04:43:57.334: INFO: stderr: ""
Sep 26 04:43:57.334: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep 26 04:43:57.334: INFO: e2e-test-nginx-rc-1fcf37d904538fcd0285f329f1b56287-dkgg9 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Sep 26 04:43:57.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete rc e2e-test-nginx-rc --namespace=kubectl-265'
Sep 26 04:43:57.407: INFO: stderr: ""
Sep 26 04:43:57.407: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:43:57.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-265" for this suite.
Sep 26 04:44:03.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:44:03.472: INFO: namespace kubectl-265 deletion completed in 6.060218548s

• [SLOW TEST:22.206 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:44:03.473: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 26 04:44:07.536: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:07.540: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:09.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:09.543: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:11.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:11.543: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:13.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:13.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:15.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:15.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:17.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:17.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:19.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:19.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:21.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:21.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:23.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:23.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:25.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:25.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:27.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:27.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:29.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:29.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:31.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:31.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:33.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:33.542: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 26 04:44:35.540: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 26 04:44:35.542: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:44:35.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8566" for this suite.
Sep 26 04:44:57.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:44:57.613: INFO: namespace container-lifecycle-hook-8566 deletion completed in 22.062906237s

• [SLOW TEST:54.140 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:44:57.613: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Sep 26 04:44:57.641: INFO: Waiting up to 5m0s for pod "client-containers-64324daf-e018-11e9-8008-76f27b732d80" in namespace "containers-8355" to be "success or failure"
Sep 26 04:44:57.642: INFO: Pod "client-containers-64324daf-e018-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.4394ms
Sep 26 04:44:59.645: INFO: Pod "client-containers-64324daf-e018-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003814393s
STEP: Saw pod success
Sep 26 04:44:59.645: INFO: Pod "client-containers-64324daf-e018-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:44:59.647: INFO: Trying to get logs from node aks-1-2 pod client-containers-64324daf-e018-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:44:59.660: INFO: Waiting for pod client-containers-64324daf-e018-11e9-8008-76f27b732d80 to disappear
Sep 26 04:44:59.664: INFO: Pod client-containers-64324daf-e018-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:44:59.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8355" for this suite.
Sep 26 04:45:05.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:45:05.723: INFO: namespace containers-8355 deletion completed in 6.056584091s

• [SLOW TEST:8.110 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:45:05.723: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Sep 26 04:45:05.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-6021'
Sep 26 04:45:05.952: INFO: stderr: ""
Sep 26 04:45:05.953: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Sep 26 04:45:06.956: INFO: Selector matched 1 pods for map[app:redis]
Sep 26 04:45:06.956: INFO: Found 1 / 1
Sep 26 04:45:06.956: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 26 04:45:06.958: INFO: Selector matched 1 pods for map[app:redis]
Sep 26 04:45:06.958: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep 26 04:45:06.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 logs redis-master-ghsmk redis-master --namespace=kubectl-6021'
Sep 26 04:45:07.037: INFO: stderr: ""
Sep 26 04:45:07.037: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 Sep 04:45:06.732 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 Sep 04:45:06.732 # Server started, Redis version 3.2.12\n1:M 26 Sep 04:45:06.732 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 Sep 04:45:06.732 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep 26 04:45:07.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 log redis-master-ghsmk redis-master --namespace=kubectl-6021 --tail=1'
Sep 26 04:45:07.116: INFO: stderr: ""
Sep 26 04:45:07.116: INFO: stdout: "1:M 26 Sep 04:45:06.732 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep 26 04:45:07.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 log redis-master-ghsmk redis-master --namespace=kubectl-6021 --limit-bytes=1'
Sep 26 04:45:07.192: INFO: stderr: ""
Sep 26 04:45:07.192: INFO: stdout: " "
STEP: exposing timestamps
Sep 26 04:45:07.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 log redis-master-ghsmk redis-master --namespace=kubectl-6021 --tail=1 --timestamps'
Sep 26 04:45:07.268: INFO: stderr: ""
Sep 26 04:45:07.268: INFO: stdout: "2019-09-26T04:45:06.732909139Z 1:M 26 Sep 04:45:06.732 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep 26 04:45:09.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 log redis-master-ghsmk redis-master --namespace=kubectl-6021 --since=1s'
Sep 26 04:45:09.850: INFO: stderr: ""
Sep 26 04:45:09.850: INFO: stdout: ""
Sep 26 04:45:09.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 log redis-master-ghsmk redis-master --namespace=kubectl-6021 --since=24h'
Sep 26 04:45:09.931: INFO: stderr: ""
Sep 26 04:45:09.932: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 Sep 04:45:06.732 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 Sep 04:45:06.732 # Server started, Redis version 3.2.12\n1:M 26 Sep 04:45:06.732 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 Sep 04:45:06.732 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Sep 26 04:45:09.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete --grace-period=0 --force -f - --namespace=kubectl-6021'
Sep 26 04:45:10.003: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 26 04:45:10.003: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep 26 04:45:10.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get rc,svc -l name=nginx --no-headers --namespace=kubectl-6021'
Sep 26 04:45:10.077: INFO: stderr: "No resources found.\n"
Sep 26 04:45:10.077: INFO: stdout: ""
Sep 26 04:45:10.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -l name=nginx --namespace=kubectl-6021 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 26 04:45:10.147: INFO: stderr: ""
Sep 26 04:45:10.147: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:45:10.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6021" for this suite.
Sep 26 04:45:16.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:45:16.216: INFO: namespace kubectl-6021 deletion completed in 6.0663266s

• [SLOW TEST:10.493 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:45:16.217: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 26 04:45:16.239: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 26 04:45:21.242: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:45:22.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2045" for this suite.
Sep 26 04:45:28.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:45:28.320: INFO: namespace replication-controller-2045 deletion completed in 6.065011714s

• [SLOW TEST:12.103 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:45:28.320: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-9989
STEP: Creating a pod to test atomic-volume-subpath
Sep 26 04:45:28.352: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9989" in namespace "subpath-3322" to be "success or failure"
Sep 26 04:45:28.355: INFO: Pod "pod-subpath-test-secret-9989": Phase="Pending", Reason="", readiness=false. Elapsed: 3.298732ms
Sep 26 04:45:30.357: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 2.005618239s
Sep 26 04:45:32.360: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 4.008195013s
Sep 26 04:45:34.362: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 6.010867373s
Sep 26 04:45:36.365: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 8.013402552s
Sep 26 04:45:38.368: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 10.016045472s
Sep 26 04:45:40.370: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 12.018884051s
Sep 26 04:45:42.373: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 14.021363196s
Sep 26 04:45:44.376: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 16.024036807s
Sep 26 04:45:46.378: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 18.026457982s
Sep 26 04:45:48.381: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 20.028997883s
Sep 26 04:45:50.383: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 22.03153255s
Sep 26 04:45:52.386: INFO: Pod "pod-subpath-test-secret-9989": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.034256395s
STEP: Saw pod success
Sep 26 04:45:52.386: INFO: Pod "pod-subpath-test-secret-9989" satisfied condition "success or failure"
Sep 26 04:45:52.388: INFO: Trying to get logs from node aks-1-3 pod pod-subpath-test-secret-9989 container test-container-subpath-secret-9989: <nil>
STEP: delete the pod
Sep 26 04:45:52.401: INFO: Waiting for pod pod-subpath-test-secret-9989 to disappear
Sep 26 04:45:52.403: INFO: Pod pod-subpath-test-secret-9989 no longer exists
STEP: Deleting pod pod-subpath-test-secret-9989
Sep 26 04:45:52.403: INFO: Deleting pod "pod-subpath-test-secret-9989" in namespace "subpath-3322"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:45:52.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3322" for this suite.
Sep 26 04:45:58.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:45:58.472: INFO: namespace subpath-3322 deletion completed in 6.065566319s

• [SLOW TEST:30.152 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:45:58.472: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Sep 26 04:45:58.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-8877'
Sep 26 04:45:58.723: INFO: stderr: ""
Sep 26 04:45:58.723: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 26 04:45:58.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8877'
Sep 26 04:45:58.798: INFO: stderr: ""
Sep 26 04:45:58.798: INFO: stdout: "update-demo-nautilus-lqxvz update-demo-nautilus-pvsh2 "
Sep 26 04:45:58.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-lqxvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8877'
Sep 26 04:45:58.864: INFO: stderr: ""
Sep 26 04:45:58.864: INFO: stdout: ""
Sep 26 04:45:58.864: INFO: update-demo-nautilus-lqxvz is created but not running
Sep 26 04:46:03.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8877'
Sep 26 04:46:03.940: INFO: stderr: ""
Sep 26 04:46:03.940: INFO: stdout: "update-demo-nautilus-lqxvz update-demo-nautilus-pvsh2 "
Sep 26 04:46:03.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-lqxvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8877'
Sep 26 04:46:04.009: INFO: stderr: ""
Sep 26 04:46:04.009: INFO: stdout: "true"
Sep 26 04:46:04.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-lqxvz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8877'
Sep 26 04:46:04.078: INFO: stderr: ""
Sep 26 04:46:04.078: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 26 04:46:04.078: INFO: validating pod update-demo-nautilus-lqxvz
Sep 26 04:46:04.081: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 26 04:46:04.081: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 26 04:46:04.081: INFO: update-demo-nautilus-lqxvz is verified up and running
Sep 26 04:46:04.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-pvsh2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8877'
Sep 26 04:46:04.149: INFO: stderr: ""
Sep 26 04:46:04.149: INFO: stdout: "true"
Sep 26 04:46:04.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods update-demo-nautilus-pvsh2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8877'
Sep 26 04:46:04.217: INFO: stderr: ""
Sep 26 04:46:04.217: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 26 04:46:04.217: INFO: validating pod update-demo-nautilus-pvsh2
Sep 26 04:46:04.220: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 26 04:46:04.220: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 26 04:46:04.220: INFO: update-demo-nautilus-pvsh2 is verified up and running
STEP: using delete to clean up resources
Sep 26 04:46:04.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete --grace-period=0 --force -f - --namespace=kubectl-8877'
Sep 26 04:46:04.294: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 26 04:46:04.294: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 26 04:46:04.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8877'
Sep 26 04:46:04.371: INFO: stderr: "No resources found.\n"
Sep 26 04:46:04.371: INFO: stdout: ""
Sep 26 04:46:04.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -l name=update-demo --namespace=kubectl-8877 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 26 04:46:04.453: INFO: stderr: ""
Sep 26 04:46:04.453: INFO: stdout: "update-demo-nautilus-lqxvz\nupdate-demo-nautilus-pvsh2\n"
Sep 26 04:46:04.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8877'
Sep 26 04:46:05.029: INFO: stderr: "No resources found.\n"
Sep 26 04:46:05.029: INFO: stdout: ""
Sep 26 04:46:05.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -l name=update-demo --namespace=kubectl-8877 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 26 04:46:05.103: INFO: stderr: ""
Sep 26 04:46:05.103: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:46:05.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8877" for this suite.
Sep 26 04:46:27.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:46:27.160: INFO: namespace kubectl-8877 deletion completed in 22.05406159s

• [SLOW TEST:28.687 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:46:27.160: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-2281
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2281 to expose endpoints map[]
Sep 26 04:46:27.189: INFO: Get endpoints failed (4.623717ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep 26 04:46:28.191: INFO: successfully validated that service endpoint-test2 in namespace services-2281 exposes endpoints map[] (1.006869415s elapsed)
STEP: Creating pod pod1 in namespace services-2281
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2281 to expose endpoints map[pod1:[80]]
Sep 26 04:46:30.208: INFO: successfully validated that service endpoint-test2 in namespace services-2281 exposes endpoints map[pod1:[80]] (2.012125981s elapsed)
STEP: Creating pod pod2 in namespace services-2281
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2281 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 26 04:46:31.224: INFO: successfully validated that service endpoint-test2 in namespace services-2281 exposes endpoints map[pod1:[80] pod2:[80]] (1.0135128s elapsed)
STEP: Deleting pod pod1 in namespace services-2281
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2281 to expose endpoints map[pod2:[80]]
Sep 26 04:46:32.242: INFO: successfully validated that service endpoint-test2 in namespace services-2281 exposes endpoints map[pod2:[80]] (1.013531909s elapsed)
STEP: Deleting pod pod2 in namespace services-2281
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2281 to expose endpoints map[]
Sep 26 04:46:33.251: INFO: successfully validated that service endpoint-test2 in namespace services-2281 exposes endpoints map[] (1.003608504s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:46:33.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2281" for this suite.
Sep 26 04:46:55.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:46:55.333: INFO: namespace services-2281 deletion completed in 22.06309894s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:28.173 seconds]
[sig-network] Services
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:46:55.333: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:47:19.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8010" for this suite.
Sep 26 04:47:25.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:47:25.479: INFO: namespace namespaces-8010 deletion completed in 6.058200181s
STEP: Destroying namespace "nsdeletetest-3973" for this suite.
Sep 26 04:47:25.480: INFO: Namespace nsdeletetest-3973 was already deleted
STEP: Destroying namespace "nsdeletetest-1128" for this suite.
Sep 26 04:47:31.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:47:31.537: INFO: namespace nsdeletetest-1128 deletion completed in 6.056835488s

• [SLOW TEST:36.204 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:47:31.537: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-bff0b801-e018-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:47:31.564: INFO: Waiting up to 5m0s for pod "pod-configmaps-bff105f6-e018-11e9-8008-76f27b732d80" in namespace "configmap-6197" to be "success or failure"
Sep 26 04:47:31.566: INFO: Pod "pod-configmaps-bff105f6-e018-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.895058ms
Sep 26 04:47:33.569: INFO: Pod "pod-configmaps-bff105f6-e018-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004697197s
STEP: Saw pod success
Sep 26 04:47:33.569: INFO: Pod "pod-configmaps-bff105f6-e018-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:47:33.571: INFO: Trying to get logs from node aks-1-3 pod pod-configmaps-bff105f6-e018-11e9-8008-76f27b732d80 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:47:33.583: INFO: Waiting for pod pod-configmaps-bff105f6-e018-11e9-8008-76f27b732d80 to disappear
Sep 26 04:47:33.585: INFO: Pod pod-configmaps-bff105f6-e018-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:47:33.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6197" for this suite.
Sep 26 04:47:39.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:47:39.649: INFO: namespace configmap-6197 deletion completed in 6.061726983s

• [SLOW TEST:8.112 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:47:39.649: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 26 04:47:39.687: INFO: Number of nodes with available pods: 0
Sep 26 04:47:39.687: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 04:47:40.693: INFO: Number of nodes with available pods: 0
Sep 26 04:47:40.693: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 04:47:41.692: INFO: Number of nodes with available pods: 3
Sep 26 04:47:41.692: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 26 04:47:41.704: INFO: Number of nodes with available pods: 2
Sep 26 04:47:41.704: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:42.709: INFO: Number of nodes with available pods: 2
Sep 26 04:47:42.709: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:43.710: INFO: Number of nodes with available pods: 2
Sep 26 04:47:43.710: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:44.710: INFO: Number of nodes with available pods: 2
Sep 26 04:47:44.710: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:45.709: INFO: Number of nodes with available pods: 2
Sep 26 04:47:45.709: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:46.711: INFO: Number of nodes with available pods: 2
Sep 26 04:47:46.711: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:47.710: INFO: Number of nodes with available pods: 2
Sep 26 04:47:47.710: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:48.710: INFO: Number of nodes with available pods: 2
Sep 26 04:47:48.710: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:49.710: INFO: Number of nodes with available pods: 2
Sep 26 04:47:49.710: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:50.709: INFO: Number of nodes with available pods: 2
Sep 26 04:47:50.709: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:51.709: INFO: Number of nodes with available pods: 2
Sep 26 04:47:51.709: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:52.710: INFO: Number of nodes with available pods: 2
Sep 26 04:47:52.710: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:53.709: INFO: Number of nodes with available pods: 2
Sep 26 04:47:53.709: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:54.710: INFO: Number of nodes with available pods: 2
Sep 26 04:47:54.710: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:55.710: INFO: Number of nodes with available pods: 2
Sep 26 04:47:55.710: INFO: Node aks-1-3 is running more than one daemon pod
Sep 26 04:47:56.710: INFO: Number of nodes with available pods: 3
Sep 26 04:47:56.710: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1143, will wait for the garbage collector to delete the pods
Sep 26 04:47:56.769: INFO: Deleting DaemonSet.extensions daemon-set took: 6.298026ms
Sep 26 04:47:57.070: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.219249ms
Sep 26 04:48:07.772: INFO: Number of nodes with available pods: 0
Sep 26 04:48:07.772: INFO: Number of running nodes: 0, number of available pods: 0
Sep 26 04:48:07.774: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1143/daemonsets","resourceVersion":"31749060"},"items":null}

Sep 26 04:48:07.775: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1143/pods","resourceVersion":"31749060"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:48:07.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1143" for this suite.
Sep 26 04:48:13.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:48:13.848: INFO: namespace daemonsets-1143 deletion completed in 6.062242375s

• [SLOW TEST:34.199 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:48:13.848: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Sep 26 04:48:13.922: INFO: Waiting up to 5m0s for pod "var-expansion-d93057ba-e018-11e9-8008-76f27b732d80" in namespace "var-expansion-9327" to be "success or failure"
Sep 26 04:48:13.924: INFO: Pod "var-expansion-d93057ba-e018-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.501005ms
Sep 26 04:48:15.927: INFO: Pod "var-expansion-d93057ba-e018-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004118453s
STEP: Saw pod success
Sep 26 04:48:15.927: INFO: Pod "var-expansion-d93057ba-e018-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:48:15.928: INFO: Trying to get logs from node aks-1-3 pod var-expansion-d93057ba-e018-11e9-8008-76f27b732d80 container dapi-container: <nil>
STEP: delete the pod
Sep 26 04:48:15.939: INFO: Waiting for pod var-expansion-d93057ba-e018-11e9-8008-76f27b732d80 to disappear
Sep 26 04:48:15.941: INFO: Pod var-expansion-d93057ba-e018-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:48:15.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9327" for this suite.
Sep 26 04:48:21.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:48:22.008: INFO: namespace var-expansion-9327 deletion completed in 6.06455617s

• [SLOW TEST:8.160 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:48:22.009: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0926 04:48:32.078453      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 26 04:48:32.078: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:48:32.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9287" for this suite.
Sep 26 04:48:38.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:48:38.139: INFO: namespace gc-9287 deletion completed in 6.058881706s

• [SLOW TEST:16.130 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:48:38.139: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:49:04.173: INFO: Container started at 2019-09-26 04:48:39 +0000 UTC, pod became ready at 2019-09-26 04:49:02 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:49:04.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4990" for this suite.
Sep 26 04:49:26.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:49:26.231: INFO: namespace container-probe-4990 deletion completed in 22.055456204s

• [SLOW TEST:48.092 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:49:26.232: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:49:26.260: INFO: Waiting up to 5m0s for pod "downwardapi-volume-044dbede-e019-11e9-8008-76f27b732d80" in namespace "projected-7426" to be "success or failure"
Sep 26 04:49:26.263: INFO: Pod "downwardapi-volume-044dbede-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.74656ms
Sep 26 04:49:28.266: INFO: Pod "downwardapi-volume-044dbede-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006352077s
STEP: Saw pod success
Sep 26 04:49:28.266: INFO: Pod "downwardapi-volume-044dbede-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:49:28.268: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-044dbede-e019-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:49:28.280: INFO: Waiting for pod downwardapi-volume-044dbede-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:49:28.282: INFO: Pod downwardapi-volume-044dbede-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:49:28.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7426" for this suite.
Sep 26 04:49:34.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:49:34.339: INFO: namespace projected-7426 deletion completed in 6.054727593s

• [SLOW TEST:8.107 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:49:34.339: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 26 04:49:36.876: INFO: Successfully updated pod "pod-update-activedeadlineseconds-0922cd8d-e019-11e9-8008-76f27b732d80"
Sep 26 04:49:36.876: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-0922cd8d-e019-11e9-8008-76f27b732d80" in namespace "pods-8046" to be "terminated due to deadline exceeded"
Sep 26 04:49:36.881: INFO: Pod "pod-update-activedeadlineseconds-0922cd8d-e019-11e9-8008-76f27b732d80": Phase="Running", Reason="", readiness=true. Elapsed: 4.426416ms
Sep 26 04:49:38.883: INFO: Pod "pod-update-activedeadlineseconds-0922cd8d-e019-11e9-8008-76f27b732d80": Phase="Running", Reason="", readiness=true. Elapsed: 2.006440219s
Sep 26 04:49:40.885: INFO: Pod "pod-update-activedeadlineseconds-0922cd8d-e019-11e9-8008-76f27b732d80": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.008371083s
Sep 26 04:49:40.885: INFO: Pod "pod-update-activedeadlineseconds-0922cd8d-e019-11e9-8008-76f27b732d80" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:49:40.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8046" for this suite.
Sep 26 04:49:46.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:49:46.943: INFO: namespace pods-8046 deletion completed in 6.05613005s

• [SLOW TEST:12.604 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:49:46.943: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-10a66d6f-e019-11e9-8008-76f27b732d80
STEP: Creating configMap with name cm-test-opt-upd-10a66db8-e019-11e9-8008-76f27b732d80
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-10a66d6f-e019-11e9-8008-76f27b732d80
STEP: Updating configmap cm-test-opt-upd-10a66db8-e019-11e9-8008-76f27b732d80
STEP: Creating configMap with name cm-test-opt-create-10a66de1-e019-11e9-8008-76f27b732d80
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:49:53.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6635" for this suite.
Sep 26 04:50:15.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:50:15.089: INFO: namespace configmap-6635 deletion completed in 22.054551596s

• [SLOW TEST:28.146 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:50:15.089: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-216cc719-e019-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:50:15.121: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-216d9fa9-e019-11e9-8008-76f27b732d80" in namespace "projected-6818" to be "success or failure"
Sep 26 04:50:15.128: INFO: Pod "pod-projected-configmaps-216d9fa9-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.456489ms
Sep 26 04:50:17.130: INFO: Pod "pod-projected-configmaps-216d9fa9-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009124693s
STEP: Saw pod success
Sep 26 04:50:17.130: INFO: Pod "pod-projected-configmaps-216d9fa9-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:50:17.132: INFO: Trying to get logs from node aks-1-2 pod pod-projected-configmaps-216d9fa9-e019-11e9-8008-76f27b732d80 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:50:17.147: INFO: Waiting for pod pod-projected-configmaps-216d9fa9-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:50:17.152: INFO: Pod pod-projected-configmaps-216d9fa9-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:50:17.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6818" for this suite.
Sep 26 04:50:23.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:50:23.222: INFO: namespace projected-6818 deletion completed in 6.061704608s

• [SLOW TEST:8.133 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:50:23.222: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-6073/configmap-test-264d81d7-e019-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:50:23.298: INFO: Waiting up to 5m0s for pod "pod-configmaps-264dcb83-e019-11e9-8008-76f27b732d80" in namespace "configmap-6073" to be "success or failure"
Sep 26 04:50:23.302: INFO: Pod "pod-configmaps-264dcb83-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.234021ms
Sep 26 04:50:25.305: INFO: Pod "pod-configmaps-264dcb83-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006885471s
STEP: Saw pod success
Sep 26 04:50:25.305: INFO: Pod "pod-configmaps-264dcb83-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:50:25.307: INFO: Trying to get logs from node aks-1-3 pod pod-configmaps-264dcb83-e019-11e9-8008-76f27b732d80 container env-test: <nil>
STEP: delete the pod
Sep 26 04:50:25.319: INFO: Waiting for pod pod-configmaps-264dcb83-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:50:25.320: INFO: Pod pod-configmaps-264dcb83-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:50:25.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6073" for this suite.
Sep 26 04:50:31.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:50:31.379: INFO: namespace configmap-6073 deletion completed in 6.056910128s

• [SLOW TEST:8.157 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:50:31.380: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-2b22c4e5-e019-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:50:31.477: INFO: Waiting up to 5m0s for pod "pod-secrets-2b2d5b75-e019-11e9-8008-76f27b732d80" in namespace "secrets-4194" to be "success or failure"
Sep 26 04:50:31.483: INFO: Pod "pod-secrets-2b2d5b75-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.651573ms
Sep 26 04:50:33.486: INFO: Pod "pod-secrets-2b2d5b75-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009190444s
STEP: Saw pod success
Sep 26 04:50:33.486: INFO: Pod "pod-secrets-2b2d5b75-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:50:33.487: INFO: Trying to get logs from node aks-1-2 pod pod-secrets-2b2d5b75-e019-11e9-8008-76f27b732d80 container secret-volume-test: <nil>
STEP: delete the pod
Sep 26 04:50:33.503: INFO: Waiting for pod pod-secrets-2b2d5b75-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:50:33.505: INFO: Pod pod-secrets-2b2d5b75-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:50:33.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4194" for this suite.
Sep 26 04:50:39.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:50:39.571: INFO: namespace secrets-4194 deletion completed in 6.062822656s
STEP: Destroying namespace "secret-namespace-2088" for this suite.
Sep 26 04:50:45.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:50:45.632: INFO: namespace secret-namespace-2088 deletion completed in 6.060527097s

• [SLOW TEST:14.252 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:50:45.632: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-33a118fb-e019-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:50:45.656: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-33a16140-e019-11e9-8008-76f27b732d80" in namespace "projected-6369" to be "success or failure"
Sep 26 04:50:45.659: INFO: Pod "pod-projected-configmaps-33a16140-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.635493ms
Sep 26 04:50:47.662: INFO: Pod "pod-projected-configmaps-33a16140-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005357603s
STEP: Saw pod success
Sep 26 04:50:47.662: INFO: Pod "pod-projected-configmaps-33a16140-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:50:47.663: INFO: Trying to get logs from node aks-1-3 pod pod-projected-configmaps-33a16140-e019-11e9-8008-76f27b732d80 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:50:47.676: INFO: Waiting for pod pod-projected-configmaps-33a16140-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:50:47.678: INFO: Pod pod-projected-configmaps-33a16140-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:50:47.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6369" for this suite.
Sep 26 04:50:53.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:50:53.741: INFO: namespace projected-6369 deletion completed in 6.061025268s

• [SLOW TEST:8.110 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:50:53.742: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 04:50:53.776: INFO: Waiting up to 5m0s for pod "downwardapi-volume-387866d2-e019-11e9-8008-76f27b732d80" in namespace "projected-6509" to be "success or failure"
Sep 26 04:50:53.780: INFO: Pod "downwardapi-volume-387866d2-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.539939ms
Sep 26 04:50:55.782: INFO: Pod "downwardapi-volume-387866d2-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006158391s
STEP: Saw pod success
Sep 26 04:50:55.782: INFO: Pod "downwardapi-volume-387866d2-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:50:55.784: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-387866d2-e019-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 04:50:55.795: INFO: Waiting for pod downwardapi-volume-387866d2-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:50:55.797: INFO: Pod downwardapi-volume-387866d2-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:50:55.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6509" for this suite.
Sep 26 04:51:01.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:51:01.896: INFO: namespace projected-6509 deletion completed in 6.096334146s

• [SLOW TEST:8.154 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:51:01.896: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-3d5c1182-e019-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:51:01.985: INFO: Waiting up to 5m0s for pod "pod-secrets-3d5c6493-e019-11e9-8008-76f27b732d80" in namespace "secrets-9763" to be "success or failure"
Sep 26 04:51:01.987: INFO: Pod "pod-secrets-3d5c6493-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.488209ms
Sep 26 04:51:03.990: INFO: Pod "pod-secrets-3d5c6493-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005137454s
STEP: Saw pod success
Sep 26 04:51:03.990: INFO: Pod "pod-secrets-3d5c6493-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:51:03.991: INFO: Trying to get logs from node aks-1-3 pod pod-secrets-3d5c6493-e019-11e9-8008-76f27b732d80 container secret-volume-test: <nil>
STEP: delete the pod
Sep 26 04:51:04.004: INFO: Waiting for pod pod-secrets-3d5c6493-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:51:04.005: INFO: Pod pod-secrets-3d5c6493-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:51:04.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9763" for this suite.
Sep 26 04:51:10.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:51:10.062: INFO: namespace secrets-9763 deletion completed in 6.054687599s

• [SLOW TEST:8.166 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:51:10.062: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 26 04:51:10.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2647'
Sep 26 04:51:10.301: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 26 04:51:10.301: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Sep 26 04:51:12.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2647'
Sep 26 04:51:12.384: INFO: stderr: ""
Sep 26 04:51:12.384: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:51:12.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2647" for this suite.
Sep 26 04:51:34.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:51:34.441: INFO: namespace kubectl-2647 deletion completed in 22.053708563s

• [SLOW TEST:24.379 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:51:34.442: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 26 04:51:34.470: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2290,SelfLink:/api/v1/namespaces/watch-2290/configmaps/e2e-watch-test-label-changed,UID:50b9146a-e019-11e9-af5c-00163e006ee4,ResourceVersion:31750001,Generation:0,CreationTimestamp:2019-09-26 04:51:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 26 04:51:34.470: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2290,SelfLink:/api/v1/namespaces/watch-2290/configmaps/e2e-watch-test-label-changed,UID:50b9146a-e019-11e9-af5c-00163e006ee4,ResourceVersion:31750002,Generation:0,CreationTimestamp:2019-09-26 04:51:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 26 04:51:34.470: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2290,SelfLink:/api/v1/namespaces/watch-2290/configmaps/e2e-watch-test-label-changed,UID:50b9146a-e019-11e9-af5c-00163e006ee4,ResourceVersion:31750003,Generation:0,CreationTimestamp:2019-09-26 04:51:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 26 04:51:44.484: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2290,SelfLink:/api/v1/namespaces/watch-2290/configmaps/e2e-watch-test-label-changed,UID:50b9146a-e019-11e9-af5c-00163e006ee4,ResourceVersion:31750019,Generation:0,CreationTimestamp:2019-09-26 04:51:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 26 04:51:44.485: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2290,SelfLink:/api/v1/namespaces/watch-2290/configmaps/e2e-watch-test-label-changed,UID:50b9146a-e019-11e9-af5c-00163e006ee4,ResourceVersion:31750020,Generation:0,CreationTimestamp:2019-09-26 04:51:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep 26 04:51:44.485: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2290,SelfLink:/api/v1/namespaces/watch-2290/configmaps/e2e-watch-test-label-changed,UID:50b9146a-e019-11e9-af5c-00163e006ee4,ResourceVersion:31750021,Generation:0,CreationTimestamp:2019-09-26 04:51:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:51:44.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2290" for this suite.
Sep 26 04:51:50.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:51:50.546: INFO: namespace watch-2290 deletion completed in 6.058817558s

• [SLOW TEST:16.104 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:51:50.546: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0926 04:51:51.650580      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 26 04:51:51.650: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:51:51.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-452" for this suite.
Sep 26 04:51:57.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:51:57.731: INFO: namespace gc-452 deletion completed in 6.078979403s

• [SLOW TEST:7.185 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:51:57.732: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep 26 04:51:57.759: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:52:00.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4496" for this suite.
Sep 26 04:52:22.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:52:22.959: INFO: namespace init-container-4496 deletion completed in 22.057444639s

• [SLOW TEST:25.227 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:52:22.959: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 26 04:52:22.994: INFO: Waiting up to 5m0s for pod "pod-6da5bc0e-e019-11e9-8008-76f27b732d80" in namespace "emptydir-9100" to be "success or failure"
Sep 26 04:52:23.008: INFO: Pod "pod-6da5bc0e-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 13.808769ms
Sep 26 04:52:25.011: INFO: Pod "pod-6da5bc0e-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016505673s
STEP: Saw pod success
Sep 26 04:52:25.011: INFO: Pod "pod-6da5bc0e-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:52:25.013: INFO: Trying to get logs from node aks-1-2 pod pod-6da5bc0e-e019-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:52:25.026: INFO: Waiting for pod pod-6da5bc0e-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:52:25.034: INFO: Pod pod-6da5bc0e-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:52:25.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9100" for this suite.
Sep 26 04:52:31.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:52:31.097: INFO: namespace emptydir-9100 deletion completed in 6.058969751s

• [SLOW TEST:8.139 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:52:31.098: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 26 04:52:31.169: INFO: Waiting up to 5m0s for pod "pod-72856aa3-e019-11e9-8008-76f27b732d80" in namespace "emptydir-2356" to be "success or failure"
Sep 26 04:52:31.173: INFO: Pod "pod-72856aa3-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110341ms
Sep 26 04:52:33.176: INFO: Pod "pod-72856aa3-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006959352s
STEP: Saw pod success
Sep 26 04:52:33.176: INFO: Pod "pod-72856aa3-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:52:33.178: INFO: Trying to get logs from node aks-1-3 pod pod-72856aa3-e019-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:52:33.190: INFO: Waiting for pod pod-72856aa3-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:52:33.191: INFO: Pod pod-72856aa3-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:52:33.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2356" for this suite.
Sep 26 04:52:39.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:52:39.253: INFO: namespace emptydir-2356 deletion completed in 6.059519793s

• [SLOW TEST:8.156 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:52:39.254: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-77620dfe-e019-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:52:39.330: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-77625e3c-e019-11e9-8008-76f27b732d80" in namespace "projected-5944" to be "success or failure"
Sep 26 04:52:39.333: INFO: Pod "pod-projected-secrets-77625e3c-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.394682ms
Sep 26 04:52:41.335: INFO: Pod "pod-projected-secrets-77625e3c-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005098094s
STEP: Saw pod success
Sep 26 04:52:41.335: INFO: Pod "pod-projected-secrets-77625e3c-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:52:41.337: INFO: Trying to get logs from node aks-1-2 pod pod-projected-secrets-77625e3c-e019-11e9-8008-76f27b732d80 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 26 04:52:41.350: INFO: Waiting for pod pod-projected-secrets-77625e3c-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:52:41.351: INFO: Pod pod-projected-secrets-77625e3c-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:52:41.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5944" for this suite.
Sep 26 04:52:47.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:52:47.414: INFO: namespace projected-5944 deletion completed in 6.059049113s

• [SLOW TEST:8.161 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:52:47.415: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:52:47.443: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 26 04:52:47.449: INFO: Number of nodes with available pods: 0
Sep 26 04:52:47.449: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep 26 04:52:47.465: INFO: Number of nodes with available pods: 0
Sep 26 04:52:47.465: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 04:52:48.467: INFO: Number of nodes with available pods: 0
Sep 26 04:52:48.467: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 04:52:49.468: INFO: Number of nodes with available pods: 1
Sep 26 04:52:49.468: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 26 04:52:49.479: INFO: Number of nodes with available pods: 1
Sep 26 04:52:49.479: INFO: Number of running nodes: 0, number of available pods: 1
Sep 26 04:52:50.482: INFO: Number of nodes with available pods: 0
Sep 26 04:52:50.482: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 26 04:52:50.490: INFO: Number of nodes with available pods: 0
Sep 26 04:52:50.490: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 04:52:51.493: INFO: Number of nodes with available pods: 0
Sep 26 04:52:51.493: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 04:52:52.493: INFO: Number of nodes with available pods: 0
Sep 26 04:52:52.493: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 04:52:53.493: INFO: Number of nodes with available pods: 0
Sep 26 04:52:53.493: INFO: Node aks-1-2 is running more than one daemon pod
Sep 26 04:52:54.492: INFO: Number of nodes with available pods: 1
Sep 26 04:52:54.492: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7951, will wait for the garbage collector to delete the pods
Sep 26 04:52:54.550: INFO: Deleting DaemonSet.extensions daemon-set took: 2.974077ms
Sep 26 04:52:54.850: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.214465ms
Sep 26 04:53:07.853: INFO: Number of nodes with available pods: 0
Sep 26 04:53:07.853: INFO: Number of running nodes: 0, number of available pods: 0
Sep 26 04:53:07.854: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7951/daemonsets","resourceVersion":"31750363"},"items":null}

Sep 26 04:53:07.856: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7951/pods","resourceVersion":"31750363"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:53:07.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7951" for this suite.
Sep 26 04:53:13.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:53:13.926: INFO: namespace daemonsets-7951 deletion completed in 6.054615862s

• [SLOW TEST:26.511 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:53:13.926: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep 26 04:53:16.477: INFO: Successfully updated pod "annotationupdate8c04ec3a-e019-11e9-8008-76f27b732d80"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:53:20.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2364" for this suite.
Sep 26 04:53:48.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:53:48.553: INFO: namespace downward-api-2364 deletion completed in 28.055292766s

• [SLOW TEST:34.627 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:53:48.553: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-a0a8c865-e019-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:53:48.581: INFO: Waiting up to 5m0s for pod "pod-secrets-a0a912a4-e019-11e9-8008-76f27b732d80" in namespace "secrets-4750" to be "success or failure"
Sep 26 04:53:48.586: INFO: Pod "pod-secrets-a0a912a4-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 5.024755ms
Sep 26 04:53:50.589: INFO: Pod "pod-secrets-a0a912a4-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007628343s
STEP: Saw pod success
Sep 26 04:53:50.589: INFO: Pod "pod-secrets-a0a912a4-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:53:50.590: INFO: Trying to get logs from node aks-1-2 pod pod-secrets-a0a912a4-e019-11e9-8008-76f27b732d80 container secret-env-test: <nil>
STEP: delete the pod
Sep 26 04:53:50.604: INFO: Waiting for pod pod-secrets-a0a912a4-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:53:50.608: INFO: Pod pod-secrets-a0a912a4-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:53:50.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4750" for this suite.
Sep 26 04:53:56.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:53:56.667: INFO: namespace secrets-4750 deletion completed in 6.055784403s

• [SLOW TEST:8.113 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:53:56.667: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-a57f2ca5-e019-11e9-8008-76f27b732d80
STEP: Creating secret with name s-test-opt-upd-a57f2ce1-e019-11e9-8008-76f27b732d80
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a57f2ca5-e019-11e9-8008-76f27b732d80
STEP: Updating secret s-test-opt-upd-a57f2ce1-e019-11e9-8008-76f27b732d80
STEP: Creating secret with name s-test-opt-create-a57f2cf9-e019-11e9-8008-76f27b732d80
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:54:00.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5814" for this suite.
Sep 26 04:54:22.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:54:22.818: INFO: namespace secrets-5814 deletion completed in 22.057375391s

• [SLOW TEST:26.151 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:54:22.819: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-b5164d9a-e019-11e9-8008-76f27b732d80
STEP: Creating secret with name s-test-opt-upd-b5164dcf-e019-11e9-8008-76f27b732d80
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b5164d9a-e019-11e9-8008-76f27b732d80
STEP: Updating secret s-test-opt-upd-b5164dcf-e019-11e9-8008-76f27b732d80
STEP: Creating secret with name s-test-opt-create-b5164e2b-e019-11e9-8008-76f27b732d80
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:54:28.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5294" for this suite.
Sep 26 04:54:50.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:54:51.012: INFO: namespace projected-5294 deletion completed in 22.067004623s

• [SLOW TEST:28.193 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:54:51.012: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 26 04:54:51.048: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:55:04.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-836" for this suite.
Sep 26 04:55:10.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:55:10.989: INFO: namespace pods-836 deletion completed in 6.05452344s

• [SLOW TEST:19.977 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:55:10.989: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 04:55:11.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 version'
Sep 26 04:55:11.079: INFO: stderr: ""
Sep 26 04:55:11.079: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.3\", GitCommit:\"5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:44:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14+\", GitVersion:\"v1.14.3-359\", GitCommit:\"a6b855512dd3ee8b4d7a942c93946da2e014fcbc\", GitTreeState:\"clean\", BuildDate:\"2019-09-20T04:07:15Z\", GoVersion:\"go1.12.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:55:11.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6323" for this suite.
Sep 26 04:55:17.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:55:17.138: INFO: namespace kubectl-6323 deletion completed in 6.056068108s

• [SLOW TEST:6.149 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:55:17.138: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Sep 26 04:55:19.169: INFO: Pod pod-hostip-d5758c3a-e019-11e9-8008-76f27b732d80 has hostIP: 192.168.27.79
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:55:19.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3302" for this suite.
Sep 26 04:55:41.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:55:41.226: INFO: namespace pods-3302 deletion completed in 22.054527682s

• [SLOW TEST:24.088 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:55:41.227: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-2166
Sep 26 04:55:43.257: INFO: Started pod liveness-http in namespace container-probe-2166
STEP: checking the pod's current state and verifying that restartCount is present
Sep 26 04:55:43.259: INFO: Initial restart count of pod liveness-http is 0
Sep 26 04:56:01.284: INFO: Restart count of pod container-probe-2166/liveness-http is now 1 (18.024762001s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:56:01.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2166" for this suite.
Sep 26 04:56:07.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:56:07.361: INFO: namespace container-probe-2166 deletion completed in 6.066808214s

• [SLOW TEST:26.134 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:56:07.361: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:56:07.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6841" for this suite.
Sep 26 04:56:13.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:56:13.488: INFO: namespace kubelet-test-6841 deletion completed in 6.067326401s

• [SLOW TEST:6.127 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:56:13.488: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f70bee6d-e019-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:56:13.514: INFO: Waiting up to 5m0s for pod "pod-secrets-f70c5b16-e019-11e9-8008-76f27b732d80" in namespace "secrets-2235" to be "success or failure"
Sep 26 04:56:13.516: INFO: Pod "pod-secrets-f70c5b16-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.182863ms
Sep 26 04:56:15.519: INFO: Pod "pod-secrets-f70c5b16-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00480121s
STEP: Saw pod success
Sep 26 04:56:15.519: INFO: Pod "pod-secrets-f70c5b16-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:56:15.520: INFO: Trying to get logs from node aks-1-3 pod pod-secrets-f70c5b16-e019-11e9-8008-76f27b732d80 container secret-volume-test: <nil>
STEP: delete the pod
Sep 26 04:56:15.533: INFO: Waiting for pod pod-secrets-f70c5b16-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:56:15.535: INFO: Pod pod-secrets-f70c5b16-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:56:15.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2235" for this suite.
Sep 26 04:56:21.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:56:21.609: INFO: namespace secrets-2235 deletion completed in 6.069516964s

• [SLOW TEST:8.121 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:56:21.610: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-fbe36d3b-e019-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 04:56:21.636: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fbe3b872-e019-11e9-8008-76f27b732d80" in namespace "projected-2782" to be "success or failure"
Sep 26 04:56:21.644: INFO: Pod "pod-projected-configmaps-fbe3b872-e019-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 8.159633ms
Sep 26 04:56:23.647: INFO: Pod "pod-projected-configmaps-fbe3b872-e019-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011197496s
STEP: Saw pod success
Sep 26 04:56:23.647: INFO: Pod "pod-projected-configmaps-fbe3b872-e019-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:56:23.649: INFO: Trying to get logs from node aks-1-2 pod pod-projected-configmaps-fbe3b872-e019-11e9-8008-76f27b732d80 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 04:56:23.662: INFO: Waiting for pod pod-projected-configmaps-fbe3b872-e019-11e9-8008-76f27b732d80 to disappear
Sep 26 04:56:23.664: INFO: Pod pod-projected-configmaps-fbe3b872-e019-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:56:23.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2782" for this suite.
Sep 26 04:56:29.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:56:29.722: INFO: namespace projected-2782 deletion completed in 6.054671283s

• [SLOW TEST:8.113 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:56:29.723: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep 26 04:56:32.279: INFO: Successfully updated pod "labelsupdate00bab37d-e01a-11e9-8008-76f27b732d80"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:56:36.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-21" for this suite.
Sep 26 04:56:58.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:56:58.358: INFO: namespace downward-api-21 deletion completed in 22.056042362s

• [SLOW TEST:28.635 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:56:58.358: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep 26 04:56:58.376: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:57:00.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1100" for this suite.
Sep 26 04:57:06.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:57:06.726: INFO: namespace init-container-1100 deletion completed in 6.062313668s

• [SLOW TEST:8.368 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:57:06.726: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:57:09.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9576" for this suite.
Sep 26 04:57:31.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:57:31.838: INFO: namespace replication-controller-9576 deletion completed in 22.066893349s

• [SLOW TEST:25.112 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:57:31.838: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0926 04:58:11.877577      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 26 04:58:11.877: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:58:11.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4906" for this suite.
Sep 26 04:58:17.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:58:17.949: INFO: namespace gc-4906 deletion completed in 6.068451166s

• [SLOW TEST:46.111 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:58:17.950: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7939.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7939.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7939.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7939.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7939.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7939.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 26 04:58:31.999: INFO: DNS probes using dns-7939/dns-test-413bab03-e01a-11e9-8008-76f27b732d80 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:58:32.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7939" for this suite.
Sep 26 04:58:38.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:58:38.081: INFO: namespace dns-7939 deletion completed in 6.056767381s

• [SLOW TEST:20.132 seconds]
[sig-network] DNS
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:58:38.082: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Sep 26 04:58:38.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-9496'
Sep 26 04:58:38.307: INFO: stderr: ""
Sep 26 04:58:38.307: INFO: stdout: "pod/pause created\n"
Sep 26 04:58:38.308: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 26 04:58:38.308: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9496" to be "running and ready"
Sep 26 04:58:38.309: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 1.585339ms
Sep 26 04:58:40.311: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.003805888s
Sep 26 04:58:40.311: INFO: Pod "pause" satisfied condition "running and ready"
Sep 26 04:58:40.311: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 26 04:58:40.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 label pods pause testing-label=testing-label-value --namespace=kubectl-9496'
Sep 26 04:58:40.432: INFO: stderr: ""
Sep 26 04:58:40.432: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 26 04:58:40.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pod pause -L testing-label --namespace=kubectl-9496'
Sep 26 04:58:40.535: INFO: stderr: ""
Sep 26 04:58:40.535: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 26 04:58:40.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 label pods pause testing-label- --namespace=kubectl-9496'
Sep 26 04:58:40.647: INFO: stderr: ""
Sep 26 04:58:40.647: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 26 04:58:40.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pod pause -L testing-label --namespace=kubectl-9496'
Sep 26 04:58:40.721: INFO: stderr: ""
Sep 26 04:58:40.722: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Sep 26 04:58:40.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete --grace-period=0 --force -f - --namespace=kubectl-9496'
Sep 26 04:58:40.793: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 26 04:58:40.793: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 26 04:58:40.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get rc,svc -l name=pause --no-headers --namespace=kubectl-9496'
Sep 26 04:58:40.864: INFO: stderr: "No resources found.\n"
Sep 26 04:58:40.864: INFO: stdout: ""
Sep 26 04:58:40.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 get pods -l name=pause --namespace=kubectl-9496 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 26 04:58:40.935: INFO: stderr: ""
Sep 26 04:58:40.935: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:58:40.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9496" for this suite.
Sep 26 04:58:46.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:58:47.021: INFO: namespace kubectl-9496 deletion completed in 6.079992494s

• [SLOW TEST:8.939 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:58:47.021: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 26 04:58:51.570: INFO: Successfully updated pod "pod-update-528fe2cc-e01a-11e9-8008-76f27b732d80"
STEP: verifying the updated pod is in kubernetes
Sep 26 04:58:51.580: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:58:51.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8305" for this suite.
Sep 26 04:59:13.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:59:13.636: INFO: namespace pods-8305 deletion completed in 22.053884774s

• [SLOW TEST:26.615 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:59:13.636: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Sep 26 04:59:13.659: INFO: Waiting up to 5m0s for pod "client-containers-626c7189-e01a-11e9-8008-76f27b732d80" in namespace "containers-1493" to be "success or failure"
Sep 26 04:59:13.661: INFO: Pod "client-containers-626c7189-e01a-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.907052ms
Sep 26 04:59:15.664: INFO: Pod "client-containers-626c7189-e01a-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004516134s
STEP: Saw pod success
Sep 26 04:59:15.664: INFO: Pod "client-containers-626c7189-e01a-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:59:15.665: INFO: Trying to get logs from node aks-1-2 pod client-containers-626c7189-e01a-11e9-8008-76f27b732d80 container test-container: <nil>
STEP: delete the pod
Sep 26 04:59:15.678: INFO: Waiting for pod client-containers-626c7189-e01a-11e9-8008-76f27b732d80 to disappear
Sep 26 04:59:15.681: INFO: Pod client-containers-626c7189-e01a-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:59:15.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1493" for this suite.
Sep 26 04:59:21.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:59:21.753: INFO: namespace containers-1493 deletion completed in 6.068529955s

• [SLOW TEST:8.116 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:59:21.753: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Sep 26 04:59:21.806: INFO: Waiting up to 5m0s for pod "var-expansion-6746d31b-e01a-11e9-8008-76f27b732d80" in namespace "var-expansion-9452" to be "success or failure"
Sep 26 04:59:21.813: INFO: Pod "var-expansion-6746d31b-e01a-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 7.60433ms
Sep 26 04:59:23.816: INFO: Pod "var-expansion-6746d31b-e01a-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010505118s
STEP: Saw pod success
Sep 26 04:59:23.816: INFO: Pod "var-expansion-6746d31b-e01a-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:59:23.818: INFO: Trying to get logs from node aks-1-2 pod var-expansion-6746d31b-e01a-11e9-8008-76f27b732d80 container dapi-container: <nil>
STEP: delete the pod
Sep 26 04:59:23.837: INFO: Waiting for pod var-expansion-6746d31b-e01a-11e9-8008-76f27b732d80 to disappear
Sep 26 04:59:23.841: INFO: Pod var-expansion-6746d31b-e01a-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:59:23.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9452" for this suite.
Sep 26 04:59:29.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:59:29.922: INFO: namespace var-expansion-9452 deletion completed in 6.076854496s

• [SLOW TEST:8.169 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:59:29.922: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-6c23761f-e01a-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 04:59:29.963: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6c23cc1c-e01a-11e9-8008-76f27b732d80" in namespace "projected-6767" to be "success or failure"
Sep 26 04:59:29.967: INFO: Pod "pod-projected-secrets-6c23cc1c-e01a-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.907327ms
Sep 26 04:59:31.970: INFO: Pod "pod-projected-secrets-6c23cc1c-e01a-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006651469s
STEP: Saw pod success
Sep 26 04:59:31.970: INFO: Pod "pod-projected-secrets-6c23cc1c-e01a-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 04:59:31.971: INFO: Trying to get logs from node aks-1-2 pod pod-projected-secrets-6c23cc1c-e01a-11e9-8008-76f27b732d80 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 26 04:59:31.986: INFO: Waiting for pod pod-projected-secrets-6c23cc1c-e01a-11e9-8008-76f27b732d80 to disappear
Sep 26 04:59:31.990: INFO: Pod pod-projected-secrets-6c23cc1c-e01a-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:59:31.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6767" for this suite.
Sep 26 04:59:38.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 04:59:38.066: INFO: namespace projected-6767 deletion completed in 6.066580252s

• [SLOW TEST:8.144 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 04:59:38.067: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 04:59:40.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9505" for this suite.
Sep 26 05:00:30.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:00:30.214: INFO: namespace kubelet-test-9505 deletion completed in 50.053295434s

• [SLOW TEST:52.147 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:00:30.214: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 26 05:00:30.251: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-a,UID:9012e290-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751829,Generation:0,CreationTimestamp:2019-09-26 05:00:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 26 05:00:30.251: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-a,UID:9012e290-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751829,Generation:0,CreationTimestamp:2019-09-26 05:00:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 26 05:00:40.255: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-a,UID:9012e290-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751844,Generation:0,CreationTimestamp:2019-09-26 05:00:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 26 05:00:40.256: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-a,UID:9012e290-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751844,Generation:0,CreationTimestamp:2019-09-26 05:00:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 26 05:00:50.260: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-a,UID:9012e290-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751860,Generation:0,CreationTimestamp:2019-09-26 05:00:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 26 05:00:50.260: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-a,UID:9012e290-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751860,Generation:0,CreationTimestamp:2019-09-26 05:00:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 26 05:01:00.264: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-a,UID:9012e290-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751876,Generation:0,CreationTimestamp:2019-09-26 05:00:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 26 05:01:00.264: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-a,UID:9012e290-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751876,Generation:0,CreationTimestamp:2019-09-26 05:00:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 26 05:01:10.268: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-b,UID:a7edbb4b-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751891,Generation:0,CreationTimestamp:2019-09-26 05:01:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 26 05:01:10.268: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-b,UID:a7edbb4b-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751891,Generation:0,CreationTimestamp:2019-09-26 05:01:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 26 05:01:20.272: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-b,UID:a7edbb4b-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751906,Generation:0,CreationTimestamp:2019-09-26 05:01:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 26 05:01:20.272: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-494,SelfLink:/api/v1/namespaces/watch-494/configmaps/e2e-watch-test-configmap-b,UID:a7edbb4b-e01a-11e9-af5c-00163e006ee4,ResourceVersion:31751906,Generation:0,CreationTimestamp:2019-09-26 05:01:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:01:30.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-494" for this suite.
Sep 26 05:01:36.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:01:36.340: INFO: namespace watch-494 deletion completed in 6.061504496s

• [SLOW TEST:66.126 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:01:36.341: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-4678
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-4678
STEP: Deleting pre-stop pod
Sep 26 05:01:47.398: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:01:47.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-4678" for this suite.
Sep 26 05:02:25.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:02:25.463: INFO: namespace prestop-4678 deletion completed in 38.057528908s

• [SLOW TEST:49.122 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:02:25.463: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-q7vn
STEP: Creating a pod to test atomic-volume-subpath
Sep 26 05:02:25.494: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-q7vn" in namespace "subpath-2072" to be "success or failure"
Sep 26 05:02:25.496: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Pending", Reason="", readiness=false. Elapsed: 1.516935ms
Sep 26 05:02:27.498: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Running", Reason="", readiness=true. Elapsed: 2.00411436s
Sep 26 05:02:29.501: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Running", Reason="", readiness=true. Elapsed: 4.006990201s
Sep 26 05:02:31.504: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Running", Reason="", readiness=true. Elapsed: 6.00962039s
Sep 26 05:02:33.506: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Running", Reason="", readiness=true. Elapsed: 8.012452859s
Sep 26 05:02:35.509: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Running", Reason="", readiness=true. Elapsed: 10.014992023s
Sep 26 05:02:37.512: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Running", Reason="", readiness=true. Elapsed: 12.017845964s
Sep 26 05:02:39.514: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Running", Reason="", readiness=true. Elapsed: 14.020448692s
Sep 26 05:02:41.517: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Running", Reason="", readiness=true. Elapsed: 16.023109869s
Sep 26 05:02:43.520: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Running", Reason="", readiness=true. Elapsed: 18.025930913s
Sep 26 05:02:45.523: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Running", Reason="", readiness=true. Elapsed: 20.028543394s
Sep 26 05:02:47.525: INFO: Pod "pod-subpath-test-configmap-q7vn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.031335984s
STEP: Saw pod success
Sep 26 05:02:47.525: INFO: Pod "pod-subpath-test-configmap-q7vn" satisfied condition "success or failure"
Sep 26 05:02:47.527: INFO: Trying to get logs from node aks-1-3 pod pod-subpath-test-configmap-q7vn container test-container-subpath-configmap-q7vn: <nil>
STEP: delete the pod
Sep 26 05:02:47.539: INFO: Waiting for pod pod-subpath-test-configmap-q7vn to disappear
Sep 26 05:02:47.541: INFO: Pod pod-subpath-test-configmap-q7vn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-q7vn
Sep 26 05:02:47.541: INFO: Deleting pod "pod-subpath-test-configmap-q7vn" in namespace "subpath-2072"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:02:47.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2072" for this suite.
Sep 26 05:02:53.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:02:53.601: INFO: namespace subpath-2072 deletion completed in 6.055699306s

• [SLOW TEST:28.137 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:02:53.601: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9309.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9309.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9309.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9309.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9309.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9309.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9309.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9309.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9309.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9309.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 44.0.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.0.44_udp@PTR;check="$$(dig +tcp +noall +answer +search 44.0.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.0.44_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9309.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9309.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9309.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9309.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9309.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9309.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9309.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9309.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9309.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9309.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9309.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 44.0.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.0.44_udp@PTR;check="$$(dig +tcp +noall +answer +search 44.0.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.0.44_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 26 05:02:59.699: INFO: Unable to read wheezy_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:02:59.701: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:02:59.706: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:02:59.709: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:02:59.723: INFO: Unable to read jessie_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:02:59.725: INFO: Unable to read jessie_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:02:59.728: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:02:59.730: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:02:59.750: INFO: Lookups using dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80 failed for: [wheezy_udp@dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_udp@dns-test-service.dns-9309.svc.cluster.local jessie_tcp@dns-test-service.dns-9309.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local]

Sep 26 05:03:04.754: INFO: Unable to read wheezy_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:04.756: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:04.757: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:04.759: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:04.771: INFO: Unable to read jessie_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:04.773: INFO: Unable to read jessie_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:04.774: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:04.776: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:04.786: INFO: Lookups using dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80 failed for: [wheezy_udp@dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_udp@dns-test-service.dns-9309.svc.cluster.local jessie_tcp@dns-test-service.dns-9309.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local]

Sep 26 05:03:09.753: INFO: Unable to read wheezy_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:09.755: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:09.757: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:09.759: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:09.771: INFO: Unable to read jessie_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:09.773: INFO: Unable to read jessie_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:09.775: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:09.777: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:09.787: INFO: Lookups using dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80 failed for: [wheezy_udp@dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_udp@dns-test-service.dns-9309.svc.cluster.local jessie_tcp@dns-test-service.dns-9309.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local]

Sep 26 05:03:14.753: INFO: Unable to read wheezy_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:14.755: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:14.757: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:14.759: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:14.771: INFO: Unable to read jessie_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:14.773: INFO: Unable to read jessie_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:14.775: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:14.776: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:14.787: INFO: Lookups using dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80 failed for: [wheezy_udp@dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_udp@dns-test-service.dns-9309.svc.cluster.local jessie_tcp@dns-test-service.dns-9309.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local]

Sep 26 05:03:19.753: INFO: Unable to read wheezy_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:19.755: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:19.757: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:19.759: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:19.781: INFO: Unable to read jessie_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:19.782: INFO: Unable to read jessie_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:19.785: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:19.787: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:19.798: INFO: Lookups using dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80 failed for: [wheezy_udp@dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_udp@dns-test-service.dns-9309.svc.cluster.local jessie_tcp@dns-test-service.dns-9309.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local]

Sep 26 05:03:24.753: INFO: Unable to read wheezy_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:24.755: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:24.757: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:24.759: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:24.771: INFO: Unable to read jessie_udp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:24.773: INFO: Unable to read jessie_tcp@dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:24.774: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:24.777: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local from pod dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80: the server could not find the requested resource (get pods dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80)
Sep 26 05:03:24.787: INFO: Lookups using dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80 failed for: [wheezy_udp@dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@dns-test-service.dns-9309.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_udp@dns-test-service.dns-9309.svc.cluster.local jessie_tcp@dns-test-service.dns-9309.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9309.svc.cluster.local]

Sep 26 05:03:29.794: INFO: DNS probes using dns-9309/dns-test-e58a36f5-e01a-11e9-8008-76f27b732d80 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:03:29.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9309" for this suite.
Sep 26 05:03:35.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:03:35.981: INFO: namespace dns-9309 deletion completed in 6.066438608s

• [SLOW TEST:42.380 seconds]
[sig-network] DNS
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:03:35.981: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-c642
STEP: Creating a pod to test atomic-volume-subpath
Sep 26 05:03:36.011: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-c642" in namespace "subpath-3707" to be "success or failure"
Sep 26 05:03:36.013: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Pending", Reason="", readiness=false. Elapsed: 1.759636ms
Sep 26 05:03:38.015: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Running", Reason="", readiness=true. Elapsed: 2.003965711s
Sep 26 05:03:40.017: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Running", Reason="", readiness=true. Elapsed: 4.006576323s
Sep 26 05:03:42.020: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Running", Reason="", readiness=true. Elapsed: 6.009277746s
Sep 26 05:03:44.023: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Running", Reason="", readiness=true. Elapsed: 8.012037604s
Sep 26 05:03:46.026: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Running", Reason="", readiness=true. Elapsed: 10.014888998s
Sep 26 05:03:48.028: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Running", Reason="", readiness=true. Elapsed: 12.017167014s
Sep 26 05:03:50.031: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Running", Reason="", readiness=true. Elapsed: 14.020625408s
Sep 26 05:03:52.034: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Running", Reason="", readiness=true. Elapsed: 16.023168473s
Sep 26 05:03:54.037: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Running", Reason="", readiness=true. Elapsed: 18.02595287s
Sep 26 05:03:56.040: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Running", Reason="", readiness=true. Elapsed: 20.028755684s
Sep 26 05:03:58.042: INFO: Pod "pod-subpath-test-configmap-c642": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.031039176s
STEP: Saw pod success
Sep 26 05:03:58.042: INFO: Pod "pod-subpath-test-configmap-c642" satisfied condition "success or failure"
Sep 26 05:03:58.044: INFO: Trying to get logs from node aks-1-3 pod pod-subpath-test-configmap-c642 container test-container-subpath-configmap-c642: <nil>
STEP: delete the pod
Sep 26 05:03:58.056: INFO: Waiting for pod pod-subpath-test-configmap-c642 to disappear
Sep 26 05:03:58.058: INFO: Pod pod-subpath-test-configmap-c642 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-c642
Sep 26 05:03:58.058: INFO: Deleting pod "pod-subpath-test-configmap-c642" in namespace "subpath-3707"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:03:58.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3707" for this suite.
Sep 26 05:04:04.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:04:04.119: INFO: namespace subpath-3707 deletion completed in 6.056481109s

• [SLOW TEST:28.138 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:04:04.119: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2422
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 26 05:04:04.139: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 26 05:04:26.211: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.144 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2422 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 05:04:26.211: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 05:04:27.274: INFO: Found all expected endpoints: [netserver-0]
Sep 26 05:04:27.276: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.178 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2422 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 05:04:27.276: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 05:04:28.345: INFO: Found all expected endpoints: [netserver-1]
Sep 26 05:04:28.347: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.80 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2422 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 26 05:04:28.347: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
Sep 26 05:04:29.409: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:04:29.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2422" for this suite.
Sep 26 05:04:51.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:04:51.465: INFO: namespace pod-network-test-2422 deletion completed in 22.053100033s

• [SLOW TEST:47.346 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:04:51.465: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0926 05:05:21.518575      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 26 05:05:21.518: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:05:21.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-669" for this suite.
Sep 26 05:05:27.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:05:27.580: INFO: namespace gc-669 deletion completed in 6.059708092s

• [SLOW TEST:36.115 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:05:27.580: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Sep 26 05:05:27.603: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep 26 05:05:27.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-3302'
Sep 26 05:05:27.958: INFO: stderr: ""
Sep 26 05:05:27.958: INFO: stdout: "service/redis-slave created\n"
Sep 26 05:05:27.958: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep 26 05:05:27.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-3302'
Sep 26 05:05:28.204: INFO: stderr: ""
Sep 26 05:05:28.204: INFO: stdout: "service/redis-master created\n"
Sep 26 05:05:28.207: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 26 05:05:28.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-3302'
Sep 26 05:05:28.438: INFO: stderr: ""
Sep 26 05:05:28.438: INFO: stdout: "service/frontend created\n"
Sep 26 05:05:28.438: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep 26 05:05:28.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-3302'
Sep 26 05:05:28.637: INFO: stderr: ""
Sep 26 05:05:28.637: INFO: stdout: "deployment.apps/frontend created\n"
Sep 26 05:05:28.637: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 26 05:05:28.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-3302'
Sep 26 05:05:28.860: INFO: stderr: ""
Sep 26 05:05:28.861: INFO: stdout: "deployment.apps/redis-master created\n"
Sep 26 05:05:28.861: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep 26 05:05:28.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 create -f - --namespace=kubectl-3302'
Sep 26 05:05:29.130: INFO: stderr: ""
Sep 26 05:05:29.130: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep 26 05:05:29.130: INFO: Waiting for all frontend pods to be Running.
Sep 26 05:07:54.365: INFO: Waiting for frontend to serve content.
Sep 26 05:07:54.673: INFO: Trying to add a new entry to the guestbook.
Sep 26 05:07:54.684: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep 26 05:07:54.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete --grace-period=0 --force -f - --namespace=kubectl-3302'
Sep 26 05:07:55.527: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 26 05:07:55.527: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 26 05:07:55.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete --grace-period=0 --force -f - --namespace=kubectl-3302'
Sep 26 05:07:55.699: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 26 05:07:55.699: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 26 05:07:55.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete --grace-period=0 --force -f - --namespace=kubectl-3302'
Sep 26 05:07:55.892: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 26 05:07:55.892: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 26 05:07:56.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete --grace-period=0 --force -f - --namespace=kubectl-3302'
Sep 26 05:07:56.111: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 26 05:07:56.111: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 26 05:07:56.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete --grace-period=0 --force -f - --namespace=kubectl-3302'
Sep 26 05:07:56.197: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 26 05:07:56.197: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 26 05:07:56.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 delete --grace-period=0 --force -f - --namespace=kubectl-3302'
Sep 26 05:07:56.273: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 26 05:07:56.273: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:07:56.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3302" for this suite.
Sep 26 05:08:38.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:08:38.809: INFO: namespace kubectl-3302 deletion completed in 42.385322803s

• [SLOW TEST:191.229 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:08:38.835: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-b36e7cef-e01b-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume secrets
Sep 26 05:08:39.073: INFO: Waiting up to 5m0s for pod "pod-secrets-b36effed-e01b-11e9-8008-76f27b732d80" in namespace "secrets-512" to be "success or failure"
Sep 26 05:08:39.079: INFO: Pod "pod-secrets-b36effed-e01b-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 5.988542ms
Sep 26 05:08:41.084: INFO: Pod "pod-secrets-b36effed-e01b-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011463992s
STEP: Saw pod success
Sep 26 05:08:41.084: INFO: Pod "pod-secrets-b36effed-e01b-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 05:08:41.086: INFO: Trying to get logs from node aks-1-2 pod pod-secrets-b36effed-e01b-11e9-8008-76f27b732d80 container secret-volume-test: <nil>
STEP: delete the pod
Sep 26 05:08:41.134: INFO: Waiting for pod pod-secrets-b36effed-e01b-11e9-8008-76f27b732d80 to disappear
Sep 26 05:08:41.136: INFO: Pod pod-secrets-b36effed-e01b-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:08:41.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-512" for this suite.
Sep 26 05:08:47.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:08:47.203: INFO: namespace secrets-512 deletion completed in 6.064544576s

• [SLOW TEST:8.368 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:08:47.215: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-b853e35a-e01b-11e9-8008-76f27b732d80
STEP: Creating a pod to test consume configMaps
Sep 26 05:08:47.281: INFO: Waiting up to 5m0s for pod "pod-configmaps-b85432c2-e01b-11e9-8008-76f27b732d80" in namespace "configmap-1775" to be "success or failure"
Sep 26 05:08:47.285: INFO: Pod "pod-configmaps-b85432c2-e01b-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 3.764439ms
Sep 26 05:08:49.287: INFO: Pod "pod-configmaps-b85432c2-e01b-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006183899s
STEP: Saw pod success
Sep 26 05:08:49.287: INFO: Pod "pod-configmaps-b85432c2-e01b-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 05:08:49.289: INFO: Trying to get logs from node aks-1-2 pod pod-configmaps-b85432c2-e01b-11e9-8008-76f27b732d80 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 26 05:08:49.304: INFO: Waiting for pod pod-configmaps-b85432c2-e01b-11e9-8008-76f27b732d80 to disappear
Sep 26 05:08:49.308: INFO: Pod pod-configmaps-b85432c2-e01b-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:08:49.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1775" for this suite.
Sep 26 05:08:55.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:08:55.364: INFO: namespace configmap-1775 deletion completed in 6.05323766s

• [SLOW TEST:8.148 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:08:55.364: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:08:57.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1382" for this suite.
Sep 26 05:09:03.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:09:03.490: INFO: namespace emptydir-wrapper-1382 deletion completed in 6.05347551s

• [SLOW TEST:8.126 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:09:03.491: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep 26 05:09:03.543: INFO: Waiting up to 5m0s for pod "downward-api-c204664a-e01b-11e9-8008-76f27b732d80" in namespace "downward-api-291" to be "success or failure"
Sep 26 05:09:03.549: INFO: Pod "downward-api-c204664a-e01b-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.373941ms
Sep 26 05:09:05.552: INFO: Pod "downward-api-c204664a-e01b-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00917191s
STEP: Saw pod success
Sep 26 05:09:05.552: INFO: Pod "downward-api-c204664a-e01b-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 05:09:05.554: INFO: Trying to get logs from node aks-1-2 pod downward-api-c204664a-e01b-11e9-8008-76f27b732d80 container dapi-container: <nil>
STEP: delete the pod
Sep 26 05:09:05.569: INFO: Waiting for pod downward-api-c204664a-e01b-11e9-8008-76f27b732d80 to disappear
Sep 26 05:09:05.570: INFO: Pod downward-api-c204664a-e01b-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:09:05.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-291" for this suite.
Sep 26 05:09:11.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:09:11.672: INFO: namespace downward-api-291 deletion completed in 6.099630426s

• [SLOW TEST:8.181 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:09:11.672: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Sep 26 05:09:11.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-140668964 --namespace=kubectl-5465 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep 26 05:09:13.936: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep 26 05:09:13.936: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:09:15.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5465" for this suite.
Sep 26 05:09:33.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:09:34.047: INFO: namespace kubectl-5465 deletion completed in 18.104512182s

• [SLOW TEST:22.375 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:09:34.048: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep 26 05:09:34.079: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 26 05:09:34.122: INFO: Waiting for terminating namespaces to be deleted...
Sep 26 05:09:34.124: INFO: 
Logging pods the kubelet thinks is on node aks-1-2 before test
Sep 26 05:09:34.141: INFO: kube-flannel-ds-amd64-tkn7p from kube-system started at 2019-09-24 08:45:03 +0000 UTC (1 container statuses recorded)
Sep 26 05:09:34.141: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 26 05:09:34.141: INFO: coredns-6db98fd5fc-cccmw from kube-system started at 2019-09-24 08:44:09 +0000 UTC (1 container statuses recorded)
Sep 26 05:09:34.141: INFO: 	Container coredns ready: true, restart count 0
Sep 26 05:09:34.141: INFO: sonobuoy from sonobuoy started at 2019-09-26 03:39:58 +0000 UTC (1 container statuses recorded)
Sep 26 05:09:34.141: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 26 05:09:34.141: INFO: sonobuoy-systemd-logs-daemon-set-82964ffec36e47b5-v2964 from sonobuoy started at 2019-09-26 03:39:59 +0000 UTC (2 container statuses recorded)
Sep 26 05:09:34.141: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 26 05:09:34.141: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node aks-1-2
Sep 26 05:09:34.261: INFO: Pod coredns-6db98fd5fc-cccmw requesting resource cpu=100m on Node aks-1-2
Sep 26 05:09:34.261: INFO: Pod kube-flannel-ds-amd64-tkn7p requesting resource cpu=100m on Node aks-1-2
Sep 26 05:09:34.261: INFO: Pod sonobuoy requesting resource cpu=0m on Node aks-1-2
Sep 26 05:09:34.261: INFO: Pod sonobuoy-systemd-logs-daemon-set-82964ffec36e47b5-v2964 requesting resource cpu=0m on Node aks-1-2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4556247-e01b-11e9-8008-76f27b732d80.15c7e4cf53961545], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1968/filler-pod-d4556247-e01b-11e9-8008-76f27b732d80 to aks-1-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4556247-e01b-11e9-8008-76f27b732d80.15c7e4cf78a04e94], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4556247-e01b-11e9-8008-76f27b732d80.15c7e4cf7a0b7560], Reason = [Created], Message = [Created container filler-pod-d4556247-e01b-11e9-8008-76f27b732d80]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4556247-e01b-11e9-8008-76f27b732d80.15c7e4cf7fc3a635], Reason = [Started], Message = [Started container filler-pod-d4556247-e01b-11e9-8008-76f27b732d80]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4556247-e01b-11e9-8008-76f27b732d80.15c7e4cf7fc4a99f], Reason = [WithOutPostStartHook], Message = [Container filler-pod-d4556247-e01b-11e9-8008-76f27b732d80 with out poststart hook]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c7e4cfd239db6d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 Insufficient cpu, 2 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node aks-1-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:09:37.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1968" for this suite.
Sep 26 05:09:43.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:09:43.493: INFO: namespace sched-pred-1968 deletion completed in 6.05868216s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.445 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:09:43.494: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep 26 05:09:43.568: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9e0d6e9-e01b-11e9-8008-76f27b732d80" in namespace "projected-5067" to be "success or failure"
Sep 26 05:09:43.573: INFO: Pod "downwardapi-volume-d9e0d6e9-e01b-11e9-8008-76f27b732d80": Phase="Pending", Reason="", readiness=false. Elapsed: 5.198162ms
Sep 26 05:09:45.575: INFO: Pod "downwardapi-volume-d9e0d6e9-e01b-11e9-8008-76f27b732d80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007858555s
STEP: Saw pod success
Sep 26 05:09:45.576: INFO: Pod "downwardapi-volume-d9e0d6e9-e01b-11e9-8008-76f27b732d80" satisfied condition "success or failure"
Sep 26 05:09:45.577: INFO: Trying to get logs from node aks-1-2 pod downwardapi-volume-d9e0d6e9-e01b-11e9-8008-76f27b732d80 container client-container: <nil>
STEP: delete the pod
Sep 26 05:09:45.590: INFO: Waiting for pod downwardapi-volume-d9e0d6e9-e01b-11e9-8008-76f27b732d80 to disappear
Sep 26 05:09:45.592: INFO: Pod downwardapi-volume-d9e0d6e9-e01b-11e9-8008-76f27b732d80 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:09:45.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5067" for this suite.
Sep 26 05:09:51.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:09:51.652: INFO: namespace projected-5067 deletion completed in 6.05736722s

• [SLOW TEST:8.158 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:09:51.652: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-mp2m
STEP: Creating a pod to test atomic-volume-subpath
Sep 26 05:09:51.704: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mp2m" in namespace "subpath-1916" to be "success or failure"
Sep 26 05:09:51.710: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Pending", Reason="", readiness=false. Elapsed: 5.874823ms
Sep 26 05:09:53.712: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Running", Reason="", readiness=true. Elapsed: 2.008426146s
Sep 26 05:09:55.715: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Running", Reason="", readiness=true. Elapsed: 4.011079225s
Sep 26 05:09:57.718: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Running", Reason="", readiness=true. Elapsed: 6.014035592s
Sep 26 05:09:59.721: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Running", Reason="", readiness=true. Elapsed: 8.016754089s
Sep 26 05:10:01.723: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Running", Reason="", readiness=true. Elapsed: 10.019311804s
Sep 26 05:10:03.725: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Running", Reason="", readiness=true. Elapsed: 12.021539159s
Sep 26 05:10:05.728: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Running", Reason="", readiness=true. Elapsed: 14.024097103s
Sep 26 05:10:07.731: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Running", Reason="", readiness=true. Elapsed: 16.026766843s
Sep 26 05:10:09.733: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Running", Reason="", readiness=true. Elapsed: 18.029608499s
Sep 26 05:10:11.736: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Running", Reason="", readiness=true. Elapsed: 20.032320204s
Sep 26 05:10:13.738: INFO: Pod "pod-subpath-test-downwardapi-mp2m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.034513285s
STEP: Saw pod success
Sep 26 05:10:13.738: INFO: Pod "pod-subpath-test-downwardapi-mp2m" satisfied condition "success or failure"
Sep 26 05:10:13.758: INFO: Trying to get logs from node aks-1-2 pod pod-subpath-test-downwardapi-mp2m container test-container-subpath-downwardapi-mp2m: <nil>
STEP: delete the pod
Sep 26 05:10:13.770: INFO: Waiting for pod pod-subpath-test-downwardapi-mp2m to disappear
Sep 26 05:10:13.772: INFO: Pod pod-subpath-test-downwardapi-mp2m no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mp2m
Sep 26 05:10:13.772: INFO: Deleting pod "pod-subpath-test-downwardapi-mp2m" in namespace "subpath-1916"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:10:13.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1916" for this suite.
Sep 26 05:10:19.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:10:19.835: INFO: namespace subpath-1916 deletion completed in 6.057260306s

• [SLOW TEST:28.182 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:10:19.835: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep 26 05:10:19.857: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:10:22.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-484" for this suite.
Sep 26 05:10:28.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:10:28.939: INFO: namespace init-container-484 deletion completed in 6.059220549s

• [SLOW TEST:9.104 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:10:28.939: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep 26 05:10:28.976: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 26 05:10:28.982: INFO: Waiting for terminating namespaces to be deleted...
Sep 26 05:10:28.983: INFO: 
Logging pods the kubelet thinks is on node aks-1-2 before test
Sep 26 05:10:28.987: INFO: coredns-6db98fd5fc-cccmw from kube-system started at 2019-09-24 08:44:09 +0000 UTC (1 container statuses recorded)
Sep 26 05:10:28.987: INFO: 	Container coredns ready: true, restart count 0
Sep 26 05:10:28.987: INFO: sonobuoy from sonobuoy started at 2019-09-26 03:39:58 +0000 UTC (1 container statuses recorded)
Sep 26 05:10:28.987: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 26 05:10:28.987: INFO: sonobuoy-systemd-logs-daemon-set-82964ffec36e47b5-v2964 from sonobuoy started at 2019-09-26 03:39:59 +0000 UTC (2 container statuses recorded)
Sep 26 05:10:28.987: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 26 05:10:28.987: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 26 05:10:28.987: INFO: kube-flannel-ds-amd64-tkn7p from kube-system started at 2019-09-24 08:45:03 +0000 UTC (1 container statuses recorded)
Sep 26 05:10:28.987: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c7e4dc115f96af], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:10:30.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2106" for this suite.
Sep 26 05:10:36.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:10:36.068: INFO: namespace sched-pred-2106 deletion completed in 6.065388768s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.129 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:10:36.069: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep 26 05:10:38.155: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-f934aad7-e01b-11e9-8008-76f27b732d80,GenerateName:,Namespace:events-7119,SelfLink:/api/v1/namespaces/events-7119/pods/send-events-f934aad7-e01b-11e9-8008-76f27b732d80,UID:f93505e0-e01b-11e9-af5c-00163e006ee4,ResourceVersion:31753564,Generation:0,CreationTimestamp:2019-09-26 05:10:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 122804914,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"p":{"creationTimestamp":"2019-09-26T13:10:36.780714818+08:00","finishTimestamp":"2019-09-26T13:10:37.002668059+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-zwgk6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zwgk6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-zwgk6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d2b460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d2b480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 05:10:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 05:10:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 05:10:37 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 05:10:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 05:10:36 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.79,PodIP:10.244.0.95,StartTime:2019-09-26 05:10:36 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-26 05:10:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ed31eb384f18ca962a8351f78e9cfbea355f9ec02872a9318b84eefbb20d9e9d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep 26 05:10:40.221: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep 26 05:10:42.224: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:10:42.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7119" for this suite.
Sep 26 05:11:20.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:11:20.305: INFO: namespace events-7119 deletion completed in 38.063781185s

• [SLOW TEST:44.237 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:11:20.306: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 26 05:11:24.367: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 26 05:11:24.370: INFO: Pod pod-with-poststart-http-hook still exists
Sep 26 05:11:26.371: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 26 05:11:26.373: INFO: Pod pod-with-poststart-http-hook still exists
Sep 26 05:11:28.371: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 26 05:11:28.373: INFO: Pod pod-with-poststart-http-hook still exists
Sep 26 05:11:30.371: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 26 05:11:30.373: INFO: Pod pod-with-poststart-http-hook still exists
Sep 26 05:11:32.371: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 26 05:11:32.373: INFO: Pod pod-with-poststart-http-hook still exists
Sep 26 05:11:34.371: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 26 05:11:34.373: INFO: Pod pod-with-poststart-http-hook still exists
Sep 26 05:11:36.371: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 26 05:11:36.373: INFO: Pod pod-with-poststart-http-hook still exists
Sep 26 05:11:38.371: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 26 05:11:38.373: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:11:38.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4937" for this suite.
Sep 26 05:12:00.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:12:00.432: INFO: namespace container-lifecycle-hook-4937 deletion completed in 22.05665138s

• [SLOW TEST:40.126 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:12:00.432: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Sep 26 05:12:06.850: INFO: 8 pods remaining
Sep 26 05:12:06.850: INFO: 0 pods has nil DeletionTimestamp
Sep 26 05:12:06.850: INFO: 
Sep 26 05:12:07.832: INFO: 0 pods remaining
Sep 26 05:12:07.832: INFO: 0 pods has nil DeletionTimestamp
Sep 26 05:12:07.832: INFO: 
STEP: Gathering metrics
W0926 05:12:08.558184      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 26 05:12:08.558: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:12:08.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2332" for this suite.
Sep 26 05:12:14.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:12:14.630: INFO: namespace gc-2332 deletion completed in 6.057836429s

• [SLOW TEST:14.198 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep 26 05:12:14.630: INFO: >>> kubeConfig: /tmp/kubeconfig-140668964
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep 26 05:12:15.357: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 26 05:12:20.359: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 26 05:12:20.359: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 26 05:12:22.372: INFO: Creating deployment "test-rollover-deployment"
Sep 26 05:12:22.380: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 26 05:12:22.436: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 26 05:12:22.491: INFO: Ensure that both replica sets have 1 created replica
Sep 26 05:12:22.495: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 26 05:12:22.518: INFO: Updating deployment test-rollover-deployment
Sep 26 05:12:22.518: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 26 05:12:24.524: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 26 05:12:24.527: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 26 05:12:24.531: INFO: all replica sets need to contain the pod-template-hash label
Sep 26 05:12:24.531: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 05:12:26.535: INFO: all replica sets need to contain the pod-template-hash label
Sep 26 05:12:26.535: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071544, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 05:12:28.535: INFO: all replica sets need to contain the pod-template-hash label
Sep 26 05:12:28.535: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071544, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 05:12:30.579: INFO: all replica sets need to contain the pod-template-hash label
Sep 26 05:12:30.579: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071544, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 05:12:32.535: INFO: all replica sets need to contain the pod-template-hash label
Sep 26 05:12:32.535: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071544, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 05:12:34.535: INFO: all replica sets need to contain the pod-template-hash label
Sep 26 05:12:34.535: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071544, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705071542, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 26 05:12:36.535: INFO: 
Sep 26 05:12:36.535: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep 26 05:12:36.548: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-2335,SelfLink:/apis/apps/v1/namespaces/deployment-2335/deployments/test-rollover-deployment,UID:38893fad-e01c-11e9-af5c-00163e006ee4,ResourceVersion:31754059,Generation:2,CreationTimestamp:2019-09-26 05:12:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-26 05:12:22 +0000 UTC 2019-09-26 05:12:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-26 05:12:34 +0000 UTC 2019-09-26 05:12:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 26 05:12:36.550: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-2335,SelfLink:/apis/apps/v1/namespaces/deployment-2335/replicasets/test-rollover-deployment-766b4d6c9d,UID:389f81ba-e01c-11e9-af5c-00163e006ee4,ResourceVersion:31754050,Generation:2,CreationTimestamp:2019-09-26 05:12:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 38893fad-e01c-11e9-af5c-00163e006ee4 0xc002a9bd17 0xc002a9bd18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 26 05:12:36.550: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 26 05:12:36.550: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-2335,SelfLink:/apis/apps/v1/namespaces/deployment-2335/replicasets/test-rollover-controller,UID:34169bd2-e01c-11e9-af5c-00163e006ee4,ResourceVersion:31754058,Generation:2,CreationTimestamp:2019-09-26 05:12:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 38893fad-e01c-11e9-af5c-00163e006ee4 0xc002a9bb67 0xc002a9bb68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 26 05:12:36.550: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-2335,SelfLink:/apis/apps/v1/namespaces/deployment-2335/replicasets/test-rollover-deployment-6455657675,UID:388a7347-e01c-11e9-af5c-00163e006ee4,ResourceVersion:31754012,Generation:2,CreationTimestamp:2019-09-26 05:12:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 38893fad-e01c-11e9-af5c-00163e006ee4 0xc002a9bc37 0xc002a9bc38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 26 05:12:36.552: INFO: Pod "test-rollover-deployment-766b4d6c9d-fk8pm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-fk8pm,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-2335,SelfLink:/api/v1/namespaces/deployment-2335/pods/test-rollover-deployment-766b4d6c9d-fk8pm,UID:38a3149f-e01c-11e9-af5c-00163e006ee4,ResourceVersion:31754030,Generation:0,CreationTimestamp:2019-09-26 05:12:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{pod.beta1.sigma.ali/update-status: {"statuses":{"redis":{"creationTimestamp":"2019-09-26T13:12:23.323986723+08:00","finishTimestamp":"2019-09-26T13:12:23.648965347+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}},},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 389f81ba-e01c-11e9-af5c-00163e006ee4 0xc002b51947 0xc002b51948}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-b6r8m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-b6r8m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-b6r8m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b51ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b51b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 05:12:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 05:12:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 05:12:24 +0000 UTC  } {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2019-09-26 05:12:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-26 05:12:22 +0000 UTC  }],Message:,Reason:,HostIP:192.168.27.79,PodIP:10.244.0.110,StartTime:2019-09-26 05:12:22 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-26 05:12:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e5c861fb501f2ba5ee5cd8a1e40550d873c45019129f1154cea2e31c6b0c9a7d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep 26 05:12:36.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2335" for this suite.
Sep 26 05:12:42.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 26 05:12:42.617: INFO: namespace deployment-2335 deletion completed in 6.062295179s

• [SLOW TEST:27.987 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSep 26 05:12:42.617: INFO: Running AfterSuite actions on all nodes
Sep 26 05:12:42.635: INFO: Running AfterSuite actions on node 1
Sep 26 05:12:42.635: INFO: Skipping dumping logs from cluster

Ran 203 of 3585 Specs in 5529.325 seconds
SUCCESS! -- 203 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h32m10.673492484s
Test Suite Passed
